import os
import json
import re
import uuid
import datetime
import streamlit as st
from dotenv import load_dotenv
from google import genai
from google.genai import types
from youtube_transcript_api import YouTubeTranscriptApi

# Load environment variables
load_dotenv()

# Constants
USAGE_FILE = "usage_stats.json"
SESSIONS_FILE = "chat_sessions.json"
MAX_BUDGET_USD = float(os.getenv("MAX_BUDGET_USD", "5.0"))

# Pricing (USD per 1M tokens) - Approximate
PRICING = {
    "gemini-2.0-flash-exp": {"input": 0.0, "output": 0.0}, 
    "gemini-2.0-flash-thinking-exp": {"input": 0.0, "output": 0.0}, 
    "gemini-3-pro-preview": {"input": 2.0, "output": 12.0}, 
    "gemini-1.5-pro": {"input": 3.50, "output": 10.50},
    "gemini-1.5-flash": {"input": 0.075, "output": 0.30},
}

st.set_page_config(page_title="Gemini 3 Web Studio", layout="wide")

# --- Helper Functions ---

def load_usage():
    if os.path.exists(USAGE_FILE):
        with open(USAGE_FILE, "r") as f:
            return json.load(f)
    return {"total_input_tokens": 0, "total_output_tokens": 0, "total_cost_usd": 0.0}

def save_usage(stats):
    with open(USAGE_FILE, "w") as f:
        json.dump(stats, f, indent=4)

def calculate_cost(model_id, input_tok, output_tok):
    price = PRICING.get(model_id, {"input": 0.0, "output": 0.0})
    cost = (input_tok / 1_000_000 * price["input"]) + (output_tok / 1_000_000 * price["output"])
    return cost

def get_mime_type(filename):
    ext = filename.split('.')[-1].lower()
    if ext in ['jpg', 'jpeg']: return 'image/jpeg'
    if ext == 'png': return 'image/png'
    if ext == 'mp4': return 'video/mp4'
    if ext == 'mov': return 'video/quicktime'
    if ext == 'txt': return 'text/plain'
    if ext == 'pdf': return 'application/pdf'
    if ext == 'csv': return 'text/csv'
    return 'application/octet-stream'

def extract_youtube_id(url):
    regex = r"(?:v=|\/)([0-9A-Za-z_-]{11}).*"
    match = re.search(regex, url)
    if match:
        return match.group(1)
    return None

def get_youtube_transcript(video_id):
    try:
        transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['ja', 'en'])
        text = " ".join([t['text'] for t in transcript_list])
        return text
    except Exception as e:
        return f"å­—å¹•ã®å–å¾—ã‚¨ãƒ©ãƒ¼: {e}"

# --- Session Management ---

def load_sessions():
    if os.path.exists(SESSIONS_FILE):
        with open(SESSIONS_FILE, "r") as f:
            try:
                data = json.load(f)
                return data.get("sessions", [])
            except json.JSONDecodeError:
                return []
    return []

def save_sessions(sessions):
    with open(SESSIONS_FILE, "w") as f:
        json.dump({"sessions": sessions}, f, indent=4, ensure_ascii=False)

def create_new_session():
    new_id = str(uuid.uuid4())
    new_session = {
        "id": new_id,
        "title": "æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ",
        "timestamp": datetime.datetime.now().isoformat(),
        "messages": []
    }
    st.session_state.sessions.insert(0, new_session)
    st.session_state.current_session_id = new_id
    save_sessions(st.session_state.sessions)
    st.rerun()

def switch_session(session_id):
    st.session_state.current_session_id = session_id
    st.rerun()

def update_current_session_messages(messages):
    if st.session_state.current_session_id:
        for session in st.session_state.sessions:
            if session["id"] == st.session_state.current_session_id:
                session["messages"] = messages
                # Auto-title if it's "New Chat" and has messages
                if session["title"] == "æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ" and len(messages) > 0:
                    first_msg = messages[0]["content"]
                    session["title"] = (first_msg[:20] + "...") if len(first_msg) > 20 else first_msg
                session["timestamp"] = datetime.datetime.now().isoformat()
                break
        save_sessions(st.session_state.sessions)

def get_current_messages():
    if st.session_state.current_session_id:
        for session in st.session_state.sessions:
            if session["id"] == st.session_state.current_session_id:
                return session["messages"]
    return []

def delete_session(session_id):
    st.session_state.sessions = [s for s in st.session_state.sessions if s["id"] != session_id]
    save_sessions(st.session_state.sessions)
    if st.session_state.current_session_id == session_id:
        st.session_state.current_session_id = None
        if st.session_state.sessions:
            st.session_state.current_session_id = st.session_state.sessions[0]["id"]
    st.rerun()

# --- Initialization ---

if "sessions" not in st.session_state:
    st.session_state.sessions = load_sessions()

if "current_session_id" not in st.session_state:
    if st.session_state.sessions:
        st.session_state.current_session_id = st.session_state.sessions[0]["id"]
    else:
        create_new_session() # Will rerun

if "session_cost" not in st.session_state:
    st.session_state.session_cost = 0.0

usage_stats = load_usage()

# --- Sidebar ---

with st.sidebar:
    st.title("Gemini 3 Studio")
    
    if st.button("â• æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ", use_container_width=True):
        create_new_session()
    
    st.markdown("---")
    
    # History Search & List
    search_query = st.text_input("ğŸ” å±¥æ­´ã‚’æ¤œç´¢", placeholder="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰...")
    
    filtered_sessions = []
    if search_query:
        for s in st.session_state.sessions:
            # Check title
            if search_query.lower() in s["title"].lower():
                filtered_sessions.append(s)
                continue
            # Check messages
            found_in_msg = False
            for m in s["messages"]:
                if search_query.lower() in m["content"].lower():
                    filtered_sessions.append(s)
                    found_in_msg = True
                    break
            if not found_in_msg:
                pass # Not found
    else:
        filtered_sessions = st.session_state.sessions

    with st.expander("ğŸ“œ éå»ã®ãƒãƒ£ãƒƒãƒˆ", expanded=not bool(search_query)):
        if not filtered_sessions:
            st.caption("ãƒãƒ£ãƒƒãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        for session in filtered_sessions:
            col1, col2 = st.columns([0.8, 0.2])
            with col1:
                if st.button(session["title"], key=f"btn_{session['id']}", use_container_width=True):
                    switch_session(session["id"])
            with col2:
                if st.button("ğŸ—‘ï¸", key=f"del_{session['id']}"):
                    delete_session(session["id"])
    
    st.markdown("---")
    st.title("è¨­å®š")
    
    # Model Selection
    model_options = ["gemini-3-pro-preview", "gemini-2.0-flash-thinking-exp", "gemini-2.0-flash-exp", "gemini-1.5-pro", "gemini-1.5-flash"]
    model_id = st.selectbox("ãƒ¢ãƒ‡ãƒ«ID", options=model_options, index=0)
    
    # Search Grounding
    use_search = st.toggle("Googleæ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã‚’ä½¿ç”¨", value=True)
    
    # Candidate Count
    candidate_count = st.slider("å›ç­”å€™è£œæ•°", min_value=1, max_value=3, value=3)
    if use_search and candidate_count > 1:
        st.caption("âš ï¸ æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ä½¿ç”¨æ™‚ã¯å€™è£œæ•°ãŒ1ã«ãªã‚Šã¾ã™ã€‚")
    
    st.markdown("---")
    
    # File Upload
    st.subheader("æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«")
    uploaded_files = st.file_uploader(
        "ç”»åƒã€å‹•ç”»ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", 
        type=['png', 'jpg', 'jpeg', 'mp4', 'mov', 'txt', 'pdf', 'csv'],
        accept_multiple_files=True
    )
    
    # YouTube Link
    youtube_url = st.text_input("YouTube URL (å­—å¹•ã‚’åˆ†æ)")
    
    st.markdown("---")
    
    # Cost Tracking
    st.subheader("ã‚³ã‚¹ãƒˆè¿½è·¡")
    
    # Budget Check
    if usage_stats["total_cost_usd"] >= MAX_BUDGET_USD:
        st.error(f"ğŸš¨ äºˆç®—ã‚ªãƒ¼ãƒãƒ¼ï¼ ä¸Šé™: ${MAX_BUDGET_USD:.2f}")
        stop_generation = True
    else:
        stop_generation = False
    
    col1, col2 = st.columns(2)
    col1.metric("ã‚»ãƒƒã‚·ãƒ§ãƒ³", f"${st.session_state.session_cost:.4f}")
    col2.metric("åˆè¨ˆ", f"${usage_stats['total_cost_usd']:.4f}")
    
    st.progress(min(usage_stats["total_cost_usd"] / MAX_BUDGET_USD, 1.0) if MAX_BUDGET_USD > 0 else 0)
    st.caption(f"äºˆç®—: ${MAX_BUDGET_USD:.2f}")
    
    st.markdown("---")
    st.code(f"PROJECT: {os.getenv('GOOGLE_CLOUD_PROJECT')}\nLOCATION: {os.getenv('GOOGLE_CLOUD_LOCATION')}")

# --- Main Interface ---

# st.title("Gemini 3 Web Studio") # Moved to sidebar title or keep here? Let's keep a header.
# Actually, let's show the current session title
current_session_title = "æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ"
for s in st.session_state.sessions:
    if s["id"] == st.session_state.current_session_id:
        current_session_title = s["title"]
        break

st.header(current_session_title)
st.markdown("ä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚")

# Initialize Client
@st.cache_resource
def get_client():
    return genai.Client(
        vertexai=True, 
        project=os.getenv("GOOGLE_CLOUD_PROJECT"), 
        location=os.getenv("GOOGLE_CLOUD_LOCATION")
    )

client = get_client()

# Get Messages for Current Session
messages = get_current_messages()

# Display History
for msg in messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Chat Input
if prompt := st.chat_input("ä½•ã‹èã„ã¦ãã ã•ã„...", disabled=stop_generation):
    if stop_generation:
        st.error("äºˆç®—ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚")
    else:
        # 1. Show User Message
        with st.chat_message("user"):
            st.markdown(prompt)
            if uploaded_files:
                for uf in uploaded_files:
                    st.caption(f"ğŸ“ æ·»ä»˜: {uf.name}")
            if youtube_url:
                st.caption(f"ğŸ“º YouTube: {youtube_url}")
        
        # Add to history (User) - Update local var and session state
        messages.append({"role": "user", "content": prompt})
        update_current_session_messages(messages)

        # 2. Generate Response
        with st.chat_message("assistant"):
            status_container = st.status("æ€è€ƒä¸­...", expanded=True)
            
            try:
                # Prepare Contents (History + Current)
                contents = []
                
                # Add History
                for msg in messages[:-1]: 
                    contents.append(types.Content(
                        role=msg["role"],
                        parts=[types.Part.from_text(text=msg["content"])]
                    ))
                
                # Prepare Current Content
                current_parts = [types.Part.from_text(text=prompt)]
                
                # Handle File Uploads
                if uploaded_files:
                    for uf in uploaded_files:
                        mime_type = get_mime_type(uf.name)
                        file_bytes = uf.getvalue()
                        current_parts.append(types.Part.from_bytes(data=file_bytes, mime_type=mime_type))
                
                # Handle YouTube
                if youtube_url:
                    vid_id = extract_youtube_id(youtube_url)
                    if vid_id:
                        status_container.write("YouTubeã®å­—å¹•ã‚’å–å¾—ä¸­...")
                        transcript_text = get_youtube_transcript(vid_id)
                        current_parts.append(types.Part.from_text(text=f"YouTube Transcript:\n{transcript_text}"))
                    else:
                        status_container.write("ç„¡åŠ¹ãªYouTube URLã§ã™ã€‚")
                
                contents.append(types.Content(role="user", parts=current_parts))

                # Config
                tools = []
                final_candidate_count = candidate_count
                
                if use_search:
                    tools.append(types.Tool(google_search=types.GoogleSearch()))
                    final_candidate_count = 1
                
                # System Instruction for "GPT-5.1 Pro Level"
                system_instruction = """
                ã‚ãªãŸã¯ä¸–ç•Œæœ€é«˜å³°ã®é‡‘èãƒ»æŠ€è¡“ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
                ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã€ä»¥ä¸‹ã®ã€Œç†æƒ³çš„ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€ã«å¾“ã£ã¦ã€æ¥µã‚ã¦è©³ç´°ã‹ã¤æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

                **å¿…é ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ:**
                1. **ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼**: çµè«–ã‚’2-3è¡Œã§ã‚ºãƒãƒªã¨è¿°ã¹ã‚‹ï¼ˆå¤ªå­—ã‚’æ´»ç”¨ï¼‰ã€‚
                2. **åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ (Stock Market Info)**: æ ªä¾¡ã€æ™‚ä¾¡ç·é¡ã€å£²ä¸Šé«˜ã€PERãªã©ã®æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’ç®‡æ¡æ›¸ãã§æç¤ºã€‚
                3. **è©³ç´°åˆ†æ (Deep Dive)**:
                   - å„è«–ç‚¹ï¼ˆä¾‹ï¼šNVDAå•é¡Œã€TPUç«¶åˆã€ãƒã‚¤ã‚±ãƒ«ãƒ»ãƒãƒªãƒ¼ã®æŒ‡æ‘˜ï¼‰ã”ã¨ã«è¦‹å‡ºã—ã‚’ç«‹ã¦ã‚‹ã€‚
                   - å˜ãªã‚‹äº‹å®Ÿã ã‘ã§ãªãã€ã€Œãã‚ŒãŒä½•ã‚’æ„å‘³ã™ã‚‹ã‹ï¼ˆImplicationï¼‰ã€ã‚’æ·±æ˜ã‚Šã™ã‚‹ã€‚
                   - ãƒ–ãƒ«ï¼ˆå¼·æ°—ï¼‰ã€ãƒ™ãƒ¼ã‚¹ã€ãƒ™ã‚¢ï¼ˆå¼±æ°—ï¼‰ã®ã‚·ãƒŠãƒªã‚ªåˆ†æã‚’å«ã‚ã‚‹ã€‚
                4. **çµè«–ã¨æŠ•è³‡åˆ¤æ–­**: æ˜ç¢ºãªã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç¤ºã™ã€‚
                5. **å‚è€ƒæ–‡çŒ® (References)**: è¨˜äº‹ã‚„ãƒ‡ãƒ¼ã‚¿ã®å‡ºå±•å…ƒã‚’æ˜è¨˜ã™ã‚‹ã€‚

                **å“è³ªåŸºæº–:**
                - **äº‹å®Ÿé‡è¦–**: Googleæ¤œç´¢ã‚’æ´»ç”¨ã—ã€æœ€æ–°ã®æ•°å­—ï¼ˆæ—¥ä»˜ã¤ãï¼‰ã‚’å¼•ç”¨ã™ã‚‹ã“ã¨ã€‚
                - **è«–ç†æ€§**: æ„Ÿæƒ…è«–ã§ã¯ãªãã€ãƒ­ã‚¸ãƒƒã‚¯ã¨ãƒ‡ãƒ¼ã‚¿ã§èªã‚‹ã“ã¨ã€‚
                - **ç¶²ç¾…æ€§**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæç¤ºã—ãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆå‹•ç”»ã‚„ãƒ•ã‚¡ã‚¤ãƒ«å«ã‚€ï¼‰ã¯å…¨ã¦åˆ†æã«çµ„ã¿è¾¼ã‚€ã“ã¨ã€‚
                """

                config = types.GenerateContentConfig(
                    temperature=0.7, 
                    candidate_count=final_candidate_count,
                    tools=tools,
                    system_instruction=system_instruction
                )

                # Generate
                status_container.write("ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆä¸­...")
                response = client.models.generate_content(
                    model=model_id,
                    contents=contents,
                    config=config,
                )
                
                # Extract Text
                candidates_text = []
                grounding_metadata = None
                
                if response.candidates:
                    for i, cand in enumerate(response.candidates):
                        parts = cand.content.parts if cand.content and cand.content.parts else []
                        text = "".join(p.text or "" for p in parts)
                        candidates_text.append(text)
                        status_container.write(f"å€™è£œç”Ÿæˆå®Œäº† {i+1}")
                        if cand.grounding_metadata:
                            grounding_metadata = cand.grounding_metadata
                
                final_answer = ""
                if len(candidates_text) >= 1:
                    final_answer = candidates_text[0]
                else:
                    final_answer = "å›ç­”ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚"

                # Update Cost
                if response.usage_metadata:
                    cost = calculate_cost(
                        model_id, 
                        response.usage_metadata.prompt_token_count, 
                        response.usage_metadata.candidates_token_count
                    )
                    st.session_state.session_cost += cost
                    usage_stats["total_cost_usd"] += cost
                    usage_stats["total_input_tokens"] += response.usage_metadata.prompt_token_count
                    usage_stats["total_output_tokens"] += response.usage_metadata.candidates_token_count
                
                # Save Stats
                save_usage(usage_stats)

                status_container.update(label="å®Œäº†ï¼", state="complete", expanded=False)
                
                st.markdown(final_answer)
                
                # Append Citations from Grounding Metadata if available
                if grounding_metadata:
                    st.markdown("---")
                    st.subheader("æƒ…å ±æºã¨å¼•ç”¨")
                    if grounding_metadata.search_entry_point:
                        st.markdown(grounding_metadata.search_entry_point.rendered_content, unsafe_allow_html=True)
                    if grounding_metadata.grounding_chunks:
                        with st.expander("è©³ç´°ãªå¼•ç”¨ç®‡æ‰€"):
                            for i, chunk in enumerate(grounding_metadata.grounding_chunks):
                                if chunk.web:
                                    st.markdown(f"**[{i+1}] {chunk.web.title}**")
                                    st.markdown(f"URL: {chunk.web.uri}")
                                    st.caption(f"Source: {chunk.web.uri}")

                # Add to History
                messages.append({"role": "model", "content": final_answer})
                update_current_session_messages(messages)

            except Exception as e:
                status_container.update(label="Error", state="error")
                st.error(f"An error occurred: {e}")
