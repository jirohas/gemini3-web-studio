{
    "sessions": [
        {
            "id": "809b5d01-2ef2-489c-bead-55359ceccead",
            "title": "æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ",
            "timestamp": "2025-12-02T01:17:55.378932",
            "messages": []
        },
        {
            "id": "ba13f461-264e-47d9-9247-895338a77b10",
            "title": "Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter) ...",
            "timestamp": "2025-12-02T01:02:36.982089",
            "messages": [
                {
                    "role": "user",
                    "content": "Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter) ã® ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ) ç†Ÿè€ƒ (æœ¬æ°—MAX ã§ã‚‚claudeãŒæœ€é©ã«ä½¿ãˆã‚‹ã‚ˆã†ã«ãƒã‚¤ãƒ³ãƒˆã‚’æ•´ç†ã—ã¦(ãã‚Œã‚’IDEã«æŠ•ã’ã‚‹)\n\nimport os\nimport uuid\nimport datetime\nimport streamlit as st\nfrom dotenv import load_dotenv\nfrom google import genai\nfrom google.genai import types\nfrom PIL import Image\nimport io\nfrom logic import (\n    USAGE_FILE, SESSIONS_FILE, MAX_BUDGET_USD, PRICING,\n    VERTEX_PROJECT, VERTEX_LOCATION,\n    load_usage, save_usage, calculate_cost, get_mime_type,\n    extract_youtube_id, get_youtube_transcript, get_relevant_context,\n    extract_text_from_response, load_sessions, save_sessions, get_client\n)\n\ntry:\n    from st_img_pastebutton import paste\n    import_error_msg = None\nexcept ImportError as e:\n    paste = None\n    import_error_msg = str(e)\n\n# =========================\n# ç’°å¢ƒå¤‰æ•° & å®šæ•°\n# =========================\n\nload_dotenv()\n\n\n\nst.set_page_config(page_title=\"Gemini 3 Web Studio\", layout=\"wide\")\n\n# ğŸ” ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ­ãƒƒã‚¯ (198501) + URLãƒˆãƒ¼ã‚¯ãƒ³æ°¸ç¶šåŒ–\nSECRET_TOKEN = \"access_granted_198501\"\n\n# 1. URLãƒˆãƒ¼ã‚¯ãƒ³ãƒã‚§ãƒƒã‚¯\nquery_params = st.query_params\nurl_token = query_params.get(\"auth\", None)\n\nif url_token == SECRET_TOKEN:\n    st.session_state.authenticated = True\nelif \"authenticated\" not in st.session_state:\n    st.session_state.authenticated = False\n\n# 2. æœªèªè¨¼ãªã‚‰ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ç”»é¢\nif not st.session_state.authenticated:\n    st.title(\"Gemini 3 Studio\")\n    st.write(\"ã“ã®ã‚¢ãƒ—ãƒªã‚’åˆ©ç”¨ã™ã‚‹ã«ã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒå¿…è¦ã§ã™ã€‚\")\n\n    password = st.text_input(\"ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰\", type=\"password\")\n\n    if st.button(\"ãƒ­ã‚°ã‚¤ãƒ³\"):\n        if password == \"198501\":\n            st.session_state.authenticated = True\n            # URLã«ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä»˜ä¸ã—ã¦ãƒªãƒ­ãƒ¼ãƒ‰ï¼ˆã“ã‚Œã§ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯å¯èƒ½ã«ãªã‚‹ï¼‰\n            st.query_params[\"auth\"] = SECRET_TOKEN\n            st.rerun()\n        else:\n            st.error(\"ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™ã€‚\")\n\n    st.stop()\n\n# =========================\n# Helper Functions\n# =========================\n\n# =========================\n# Helper Functions\n# =========================\n# Moved to logic.py\n\n# =========================\n# Grok Review Function (OpenRouter API)\n# =========================\n\nimport requests\nfrom curl_cffi import requests as crequests  # Puterç”¨\n\n# OpenRouter API Keyã®å–å¾— (st.secretså„ªå…ˆã€ãªã‘ã‚Œã°ç’°å¢ƒå¤‰æ•°)\ntry:\n    if \"OPENROUTER_API_KEY\" in st.secrets:\n        OPENROUTER_API_KEY = st.secrets[\"OPENROUTER_API_KEY\"]\n    else:\n        OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\", \"\")\nexcept:\n    OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\", \"\")\n\n# Puter èªè¨¼æƒ…å ±\nPUTER_USERNAME = None\nPUTER_PASSWORD = None\ntry:\n    if \"PUTER_USERNAME\" in st.secrets:\n        PUTER_USERNAME = st.secrets[\"PUTER_USERNAME\"]\n        PUTER_PASSWORD = st.secrets[\"PUTER_PASSWORD\"]\n    else:\n        PUTER_USERNAME = os.getenv(\"PUTER_USERNAME\")\n        PUTER_PASSWORD = os.getenv(\"PUTER_PASSWORD\")\nexcept Exception:\n    PUTER_USERNAME = os.getenv(\"PUTER_USERNAME\")\n    PUTER_PASSWORD = os.getenv(\"PUTER_PASSWORD\")\n\ndef review_with_grok(user_question: str, gemini_answer: str, research_text: str = None) -> str:\n    \"\"\"\n    Grok 4.1 Fast Free ã‚’ä½¿ã£ã¦ã€Geminiã®å›ç­”ã‚’æœ€çµ‚ãƒ¬ãƒ“ãƒ¥ãƒ¼ã™ã‚‹\n    research_text: GeminiãŒåé›†ã—ãŸèª¿æŸ»ãƒ¡ãƒ¢ï¼ˆæœ€æ–°æƒ…å ±ã‚’å«ã‚€ï¼‰\n    \"\"\"\n    url = \"https://openrouter.ai/api/v1/chat/completions\"\n    headers = {\n        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n        \"Content-Type\": \"application/json\",\n    }\n    \n    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰\n    user_content = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\\n{user_question}\\n\\n\"\n    \n    if research_text:\n        user_content += f\"Gemini ã®èª¿æŸ»ãƒ¡ãƒ¢ï¼ˆæœ€æ–°æƒ…å ±ï¼‰:\\n{research_text}\\n\\n\"\n    \n    user_content += (\n        f\"Gemini ã®æœ€çµ‚å›ç­”:\\n{gemini_answer}\\n\\n\"\n        \"**é‡è¦**: èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹äº‹å®Ÿã®æ–¹ã‚’ã€ã‚ãªãŸè‡ªèº«ã®çŸ¥è­˜ã‚ˆã‚Šã‚‚å„ªå…ˆã—ã¦ãã ã•ã„ã€‚\\n\"\n        \"æœ€æ–°ã®æƒ…å ±ãŒèª¿æŸ»ãƒ¡ãƒ¢ã«ã‚ã‚‹å ´åˆã€ãã‚Œã‚’ä¿¡é ¼ã—ã¦ãã ã•ã„ã€‚\\n\\n\"\n        \"1. **é‡å¤§ãªäº‹å®Ÿèª¤èªãƒ»è«–ç†é£›èºã®æŒ‡æ‘˜**ï¼ˆãªã‘ã‚Œã°ã€ç‰¹ã«ãªã—ã€ï¼‰\\n\"\n        \"2. **å…·ä½“çš„ãªä¿®æ­£ææ¡ˆã®ãƒªã‚¹ãƒˆ**ï¼ˆã€ä¿®æ­£å‰ã€â†’ã€ä¿®æ­£å¾Œã€ã®å½¢å¼ã§ï¼‰\\n\"\n        \"3. **ç‰¹ã«ä¸ç¢ºå®Ÿæ€§ãŒé«˜ã„ãƒã‚¤ãƒ³ãƒˆï¼ˆå‰æä¸è¶³ã€ãƒ‡ãƒ¼ã‚¿ä¸è¶³ãªã©ï¼‰ã® bullet list**\\n\"\n    )\n    \n    data = {\n        \"model\": \"x-ai/grok-4.1-fast:free\",\n        \"reasoning\": {\"enabled\": True},  # Enable multi-step reasoning for deeper review\n        \"messages\": [\n            {\n                \"role\": \"system\",\n                \"content\": (\n                    \"ã‚ãªãŸã¯å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ã§ã™ã€‚\"\n                    \"äº‹å®Ÿèª¤èªãƒ»è«–ç†ã®é£›èºãƒ»æŠœã‘æ¼ã‚Œã‚’å®¹èµ¦ãªãæŒ‡æ‘˜ã—ã€\"\n                    \"å¿…è¦ãªã‚‰å›ç­”ã‚’å…¨æ–‡æ›¸ãç›´ã—ã¦ãã ã•ã„ã€‚\"\n                ),\n            },\n            {\n                \"role\": \"user\",\n                \"content\": user_content.strip() + (\n                    \"ã ã‘ã‚’æ—¥æœ¬èªã§å‡ºã—ã¦ãã ã•ã„ã€‚\"\n                ),\n            },\n        ],\n    }\n    try:\n        resp = requests.post(url, headers=headers, json=data, timeout=60)\n        resp.raise_for_status()\n        j = resp.json()\n        return j[\"choices\"][0][\"message\"][\"content\"]\n    except Exception as e:\n        return f\"[Grokãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}]\\n\\n{gemini_answer}\"\n\n# =========================\n# Session Management\n# =========================\n\n\n\ndef think_with_grok(user_question: str, research_text: str, enable_x_search: bool = False) -> str:\n    \"\"\"\n    Grok 4.1 Fast Free ã‚’ä½¿ã£ã¦ã€ãƒªã‚µãƒ¼ãƒãƒ¡ãƒ¢ã‚’å…ƒã«ç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆã‚’ä½œæˆã™ã‚‹\n    enable_x_search=True ã®å ´åˆã€X/Twitteræƒ…å ±ã®æ´»ç”¨ã‚’ä¿ƒã™\n    \"\"\"\n    url = \"https://openrouter.ai/api/v1/chat/completions\"\n    headers = {\n        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n        \"Content-Type\": \"application/json\",\n    }\n    \n    # Xæ¤œç´¢å¼·åŒ–ç‰ˆã®å ´åˆã€ç‰¹åˆ¥ãªæŒ‡ç¤ºã‚’è¿½åŠ \n    x_search_instruction = \"\"\n    if enable_x_search:\n        x_search_instruction = (\n            \"\\n\\n**é‡è¦**: ã‚ãªãŸã¯Grokã¨ã—ã¦Xï¼ˆTwitterï¼‰ã®æƒ…å ±ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚\\n\"\n            \"ä¸Šè¨˜ã®èª¿æŸ»ãƒ¡ãƒ¢ã«åŠ ãˆã¦ã€Xä¸Šã®æœ€æ–°ã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»è­°è«–ãƒ»åå¿œã‚’è€ƒæ…®ã—ã€\\n\"\n            \"ãã‚Œã‚‰ã‚’å«ã‚ãŸç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\\n\\n\"\n            \"æ³¨æ„: Xä¸Šã®æƒ…å ±ãŒç¢ºèªã§ããªã„å ´åˆã¯ã€ãã®æ—¨ã‚’æ­£ç›´ã«è¿°ã¹ã¦ãã ã•ã„ã€‚\\n\"\n            \"æ¶ç©ºã®æŠ•ç¨¿ã‚„å­˜åœ¨ã—ãªã„åå¿œã‚’ä½œæˆã—ãªã„ã“ã¨ã€‚\"\n        )\n    \n    user_content = (\n        f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\\n{user_question}\\n\\n\"\n        f\"èª¿æŸ»ãƒ¡ãƒ¢:\\n{research_text}\\n\\n\"\n        \"æŒ‡ç¤º:\\n\"\n        \"ã‚ãªãŸã¯Geminiã¨ã¯åˆ¥ã®ç‹¬ç«‹ã—ãŸAIã§ã™ã€‚\\n\"\n        \"ä¸Šè¨˜ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’å‚è€ƒã«ã—ã¤ã¤ã‚‚ã€ã‚ãªãŸè‡ªèº«ã®è¦–ç‚¹ã§ç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\\n\"\n        \"Geminiã®æ„è¦‹ã«åˆã‚ã›ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\"\n        f\"{x_search_instruction}\"\n    )\n    \n    data = {\n        \"model\": \"x-ai/grok-2-1212\",\n        \"messages\": [\n            {\"role\": \"user\", \"content\": user_content}\n        ],\n    }\n    \n    try:\n        resp = requests.post(url, headers=headers, json=data, timeout=60)\n        resp.raise_for_status()\n        j = resp.json()\n        return j[\"choices\"][0][\"message\"][\"content\"]\n    except Exception as e:\n        return f\"[Grokæ€è€ƒã‚¨ãƒ©ãƒ¼: {e}]\"\n\ndef _extract_puter_text(message_content):\n    \"\"\"\n    puter.ai.chat ã®è¿”ã‚Šå€¤ã‹ã‚‰ ãƒ†ã‚­ã‚¹ãƒˆã ã‘ã‚’å–ã‚Šå‡ºã™\n    \"\"\"\n    if isinstance(message_content, str):\n        return message_content\n\n    if isinstance(message_content, list):\n        chunks = []\n        for part in message_content:\n            if isinstance(part, dict) and part.get(\"type\") == \"text\":\n                chunks.append(part.get(\"text\", \"\"))\n        return \"\".join(chunks)\n\n    return str(message_content)\n\n\ndef call_claude_opus_via_puter(\n    user_question: str,\n    research_text: str | None = None,\n    system_prompt: str | None = None,\n) -> str:\n    \"\"\"\n    Claude Opus 4.5ï¼ˆputer.comï¼‰ã§æ¨è«–ã•ã›ã‚‹åŒæœŸé–¢æ•°\n    curl_cffiã§Chrome 124ã‚’å½è£…ã—ã¦ç›´æ¥APIã‚’å©ã\n    \"\"\"\n    if not PUTER_USERNAME or not PUTER_PASSWORD:\n        return \"[Claude (puter) èªè¨¼æƒ…å ±æœªè¨­å®š]\"\n\n    # 1. Prepare Headers (Chrome 124 Masquerading)\n    headers = {\n        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36\",\n        \"Accept\": \"*/*\",\n        \"Accept-Language\": \"en-US,en;q=0.9,ja;q=0.8\",\n        \"Origin\": \"https://puter.com\",\n        \"Referer\": \"https://puter.com/\",\n        \"Sec-Ch-Ua\": '\"Chromium\";v=\"124\", \"Google Chrome\";v=\"124\", \"Not-A.Brand\";v=\"99\"',\n        \"Sec-Ch-Ua-Mobile\": \"?0\",\n        \"Sec-Ch-Ua-Platform\": '\"macOS\"',\n        \"Sec-Fetch-Dest\": \"empty\",\n        \"Sec-Fetch-Mode\": \"cors\",\n        \"Sec-Fetch-Site\": \"same-site\",\n        \"Content-Type\": \"application/json\"\n    }\n\n    token = st.session_state.get(\"puter_token\")\n\n    # ãƒˆãƒ¼ã‚¯ãƒ³ãŒãªã„ã€ã¾ãŸã¯å†è©¦è¡ŒãŒå¿…è¦ãªå ´åˆã®ãƒ­ã‚°ã‚¤ãƒ³é–¢æ•°\n    def perform_login():\n        try:\n            resp = crequests.post(\n                \"https://api.puter.com/login\",\n                json={\"username\": PUTER_USERNAME, \"password\": PUTER_PASSWORD},\n                headers=headers,\n                timeout=30,\n                impersonate=\"chrome124\"\n            )\n            if resp.status_code != 200:\n                return None, f\"[Claude Login Error] Status: {resp.status_code}\"\n            \n            new_token = resp.json().get(\"token\")\n            if not new_token:\n                return None, \"[Claude Login Error] Token not found\"\n            \n            return new_token, None\n        except Exception as e:\n            return None, f\"[Claude Login Error] {str(e)}\"\n\n    # ãƒˆãƒ¼ã‚¯ãƒ³ãŒãªã„å ´åˆã¯ãƒ­ã‚°ã‚¤ãƒ³\n    if not token:\n        token, error = perform_login()\n        if error:\n            return error\n        st.session_state.puter_token = token\n\n    # 2. Chat\n    chat_url = \"https://api.puter.com/drivers/call\"\n    \n    messages = []\n    if system_prompt:\n        messages.append({\"role\": \"system\", \"content\": system_prompt})\n\n    user_content = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\\n{user_question}\\n\\n\"\n    if research_text:\n        user_content += f\"èª¿æŸ»ãƒ¡ãƒ¢:\\n{research_text}\\n\\n\"\n        user_content += \"ã“ã®èª¿æŸ»ãƒ¡ãƒ¢ã®äº‹å®Ÿã‚’å„ªå…ˆã—ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚\\n\"\n\n    messages.append({\"role\": \"user\", \"content\": user_content})\n    \n    payload = {\n        \"interface\": \"puter-chat-completion\",\n        \"driver\": \"claude\",\n        \"method\": \"complete\",\n        \"args\": {\n            \"messages\": messages,\n            \"model\": \"claude-opus-4-5\",\n            \"stream\": False\n        }\n    }\n\n    try:\n        # åˆå›ãƒˆãƒ©ã‚¤\n        auth_headers = headers.copy()\n        auth_headers[\"Authorization\"] = f\"Bearer {token}\"\n        chat_resp = crequests.post(chat_url, json=payload, headers=auth_headers, timeout=120, impersonate=\"chrome124\")\n\n        # 401/403ã®å ´åˆã¯å†ãƒ­ã‚°ã‚¤ãƒ³\n        if chat_resp.status_code in [401, 403]:\n            token, error = perform_login()\n            if error:\n                return error\n            st.session_state.puter_token = token\n            \n            # ãƒªãƒˆãƒ©ã‚¤\n            auth_headers[\"Authorization\"] = f\"Bearer {token}\"\n            chat_resp = crequests.post(chat_url, json=payload, headers=auth_headers, timeout=120, impersonate=\"chrome124\")\n\n        if chat_resp.status_code != 200:\n            return f\"[Claude API Error] Status: {chat_resp.status_code}\"\n            \n        result = chat_resp.json()\n        if not result.get(\"success\", False):\n             return f\"[Claude API Error] {result.get('error', 'Unknown error')}\"\n\n        message = result[\"result\"][\"message\"]\n        return _extract_puter_text(message.get(\"content\"))\n\n    except Exception as e:\n        return f\"[Claude Error] {str(e)}\"\n\ndef create_new_session():\n    current_sessions = load_sessions()\n    \n    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒç©ºãªã‚‰ã€æ–°ã—ãä½œã‚‰ãšã«ãã‚Œã‚’å†åˆ©ç”¨ã™ã‚‹ï¼ˆé‡è¤‡é˜²æ­¢ï¼‰\n    if st.session_state.get(\"current_session_id\"):\n        for s in current_sessions:\n            if s[\"id\"] == st.session_state.current_session_id:\n                if len(s[\"messages\"]) == 0:\n                    st.toast(\"ã™ã§ã«æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã§ã™\")\n                    return\n\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": [],\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.rerun()\n\ndef switch_session(session_id):\n    st.session_state.current_session_id = session_id\n    st.rerun()\n\ndef update_current_session_messages(messages):\n    if st.session_state.current_session_id:\n        current_sessions = load_sessions()\n        target_index = -1\n        for i, session in enumerate(current_sessions):\n            if session[\"id\"] == st.session_state.current_session_id:\n                session[\"messages\"] = messages\n                if session[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(messages) > 0:\n                    first_msg = messages[0][\"content\"]\n                    session[\"title\"] = (first_msg[:20] + \"...\") if len(first_msg) > 20 else first_msg\n                session[\"timestamp\"] = datetime.datetime.now().isoformat()\n                target_index = i\n                break\n        \n        if target_index != -1:\n            # æœ€æ–°ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒªã‚¹ãƒˆã®å…ˆé ­ã«ç§»å‹•\n            updated_session = current_sessions.pop(target_index)\n            current_sessions.insert(0, updated_session)\n            \n        save_sessions(current_sessions)\n        st.session_state.sessions = current_sessions\n\ndef get_current_messages():\n    if st.session_state.current_session_id:\n        for session in st.session_state.sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                return session[\"messages\"]\n    return []\n\ndef delete_session(session_id):\n    current_sessions = load_sessions()\n    current_sessions = [s for s in current_sessions if s[\"id\"] != session_id]\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    if st.session_state.current_session_id == session_id:\n        st.session_state.current_session_id = None\n        if st.session_state.sessions:\n            st.session_state.current_session_id = st.session_state.sessions[0][\"id\"]\n    st.rerun()\n\ndef branch_session():\n    \"\"\"ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚’åˆ†å²\"\"\"\n    current_messages = get_current_messages()\n    current_sessions = load_sessions()\n    \n    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—\n    current_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n    for session in current_sessions:\n        if session[\"id\"] == st.session_state.current_session_id:\n            current_title = session[\"title\"]\n            break\n    \n    # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": f\"{current_title} (åˆ†å²)\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": current_messages.copy(),  # ç¾åœ¨ã®å±¥æ­´ã‚’ã‚³ãƒ”ãƒ¼\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    \n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.session_state.session_cost = 0.0  # ã‚³ã‚¹ãƒˆãƒªã‚»ãƒƒãƒˆ\n    st.rerun()\n\n# =========================\n# Initialization\n# =========================\n\nif \"sessions\" not in st.session_state:\n    st.session_state.sessions = load_sessions()\n\nif \"current_session_id\" not in st.session_state:\n    # Always create a new session when the app starts\n    create_new_session()\n\nif \"session_cost\" not in st.session_state:\n    st.session_state.session_cost = 0.0\n\nusage_stats = load_usage()\n\n# ==========================\n# ã‚³ã‚¹ãƒˆãƒã‚§ãƒƒã‚¯ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã®å‰ã«å®Ÿè¡Œï¼‰\n# ==========================\nusage_stats = load_usage()\nstop_generation = usage_stats[\"total_cost_usd\"] >= MAX_BUDGET_USD\n\n# =========================\n# Sidebar\n# =========================\n\nwith st.sidebar:\n    # ğŸ” ãƒ­ã‚°ã‚¢ã‚¦ãƒˆãƒœã‚¿ãƒ³\n    if st.button(\"ğŸ”’ ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ\", use_container_width=True):\n        st.session_state.authenticated = False\n        st.query_params.clear()  # URLãƒˆãƒ¼ã‚¯ãƒ³ã‚‚å‰Šé™¤\n        st.rerun()\n\n    st.markdown(\"\"\"\n    <div style=\"text-align: center; padding: 0; margin: 0; margin-top: -1rem;\">\n        <h1 style=\"font-size: 18px; font-weight: 700; margin: 0; padding: 0; letter-spacing: 1px;\">\n            Gemini 3<br/>Studio\n        </h1>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n    col1, col2 = st.columns(2)\n    with col1:\n        if st.button(\"â• æ–°è¦\", use_container_width=True):\n            create_new_session()\n    with col2:\n        if st.button(\"ğŸŒ± åˆ†å²\", use_container_width=True):\n            branch_session()\n\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    current_messages = get_current_messages()\n    if current_messages:\n        with st.expander(\"ğŸ”— å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ\", expanded=False):\n            export_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n            for s in st.session_state.sessions:\n                if s[\"id\"] == st.session_state.current_session_id:\n                    export_title = s[\"title\"]\n                    break\n\n            export_md = f\"# {export_title}\\n\\n\"\n            export_md += f\"**ä½œæˆæ—¥æ™‚**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n---\\n\\n\"\n            for msg in current_messages:\n                role_label = \"ğŸ§‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼\" if msg[\"role\"] == \"user\" else \"ğŸ¤– AI\"\n                export_md += f\"## {role_label}\\n\\n{msg['content']}\\n\\n---\\n\\n\"\n\n            if st.button(\"ãƒªãƒ³ã‚¯ç”Ÿæˆ\", use_container_width=True):\n                with st.spinner(\"ç”Ÿæˆä¸­...\"):\n                    try:\n                        import urllib.request\n                        import urllib.parse\n\n                        data = urllib.parse.urlencode(\n                            {\"content\": export_md, \"expiry_days\": 7, \"syntax\": \"md\"}\n                        ).encode()\n\n                        req = urllib.request.Request(\"https://dpaste.org/api/\", data=data)\n                        req.add_header(\"User-Agent\", \"Mozilla/5.0 (Gemini3Studio)\")\n\n                        with urllib.request.urlopen(req) as response:\n                            share_url = response.read().decode(\"utf-8\").strip()\n                            st.success(\"ä½œæˆå®Œäº†ï¼\")\n                            st.code(share_url)\n                            st.caption(\"â€»7æ—¥é–“æœ‰åŠ¹\")\n                    except Exception as e:\n                        st.error(f\"ã‚¨ãƒ©ãƒ¼: {e}\")\n\n    st.markdown(\"---\")\n\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    with st.expander(\"ğŸ“ æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«\", expanded=False):\n        uploaded_files = st.file_uploader(\n            \"ãƒ•ã‚¡ã‚¤ãƒ«\",\n            accept_multiple_files=True,\n            type=[\"png\", \"jpg\", \"jpeg\", \"mp4\", \"mov\", \"txt\", \"pdf\", \"csv\"],\n            label_visibility=\"collapsed\"\n        )\n\n    # ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ï¼ˆExpanderã®å¤–ã«å‡ºã™ï¼‰\n    pasted_image_bytes = None  # åˆæœŸåŒ–ã—ã¦NameErrorã‚’é˜²ã\n    if paste:\n        if \"paste_key\" not in st.session_state:\n            st.session_state.paste_key = 0\n        try:\n            pasted_image_bytes = paste(\n                label=\"ğŸ“‹ ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰è²¼ä»˜\",\n                key=f\"paste_btn_{st.session_state.paste_key}\",\n            )\n        except Exception as e:\n            st.error(f\"Error: {e}\")\n        \n        if pasted_image_bytes:\n            st.success(\"è²¼ä»˜å®Œäº†\")\n            st.image(pasted_image_bytes, caption=\"ç”»åƒ\", use_container_width=True)\n            if st.button(\"ğŸ—‘ï¸ ã‚¯ãƒªã‚¢\", key=\"clear_paste\"):\n                st.session_state.paste_key += 1\n                st.rerun()\n    else:\n        st.warning(\"Clipboard lib missing\")\n\n    # ---- YouTube URL ----\n    with st.expander(\"ğŸ“º YouTubeåˆ†æ\", expanded=False):\n        youtube_url = st.text_input(\"URL\", placeholder=\"https://youtu.be/...\", label_visibility=\"collapsed\")\n\n    st.markdown(\"---\")\n    \n    st.markdown(\"---\")\n    \n    # ---- ãƒ¢ãƒ¼ãƒ‰ã‚«ãƒ†ã‚´ãƒªé¸æŠ ----\n    mode_category = st.radio(\n        \"ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ¼ãƒ‰\",\n        [\"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\", \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(é€šå¸¸)\", \"Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter)\"],\n        index=2,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’Puterãƒ¢ãƒ¼ãƒ‰ã«å¤‰æ›´\n        horizontal=True,\n    )\n    \n    # ---- å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ ----\n    if mode_category == \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\":\n        with st.expander(\"ãƒ¢ãƒ¼ãƒ‰è¨­å®š(å¤šå±¤)\", expanded=True):\n            mode_type = st.radio(\n                \"ã‚¿ã‚¤ãƒ—\",\n                [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n                index=0,\n                horizontal=True,\n                label_visibility=\"collapsed\"\n            )\n            \n            if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. (è©¦é¨“ä¸­)ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                        \"2. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                        \"3. (è©¦é¨“ä¸­)ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                        \"4. ç†Ÿè€ƒ(ãƒ¡ã‚¿æ€è€ƒ)+grokæ¤œç´¢å¼·åŒ–ç‰ˆ\",\n                    ],\n                    index=1  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ãƒ¡ã‚¿æ€è€ƒã«å¤‰æ›´\n                )\n            elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                    ],\n                    index=0\n                )\n            else:\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                    ],\n                    index=0\n                )\n    \n    # ---- å¤šå±¤+puterãƒ¢ãƒ¼ãƒ‰ ----\n    elif mode_category == \"Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter)\":\n        with st.expander(\"ãƒ¢ãƒ¼ãƒ‰è¨­å®š(å¤šå±¤+puter)\", expanded=True):\n            mode_type = st.radio(\n                \"ã‚¿ã‚¤ãƒ—\",\n                [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n                index=0,\n                horizontal=True,\n                label_visibility=\"collapsed\"\n            )\n            \n            if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ + é¬¼è»æ›¹(localã®ã¿)\",\n                        \"2. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                        \"3. ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                    ],\n                    index=0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’é¬¼è»æ›¹ã«å¤‰æ›´\n                )\n            elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                    ],\n                    index=0\n                )\n            else:\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                    ],\n                    index=0\n                )\n    \n    # ---- é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ ----\n    else:\n        with st.expander(\"ãƒ¢ãƒ¼ãƒ‰è¨­å®š(é€šå¸¸)\", expanded=True):\n            mode_type = st.radio(\n                \"ã‚¿ã‚¤ãƒ—\",\n                [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n                index=0,\n                horizontal=True,\n                label_visibility=\"collapsed\"\n            )\n            \n            if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                        \"2. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                        \"3. ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                    ],\n                    index=0\n                )\n            elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                    ],\n                    index=0\n                )\n            else:\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                    ],\n                    index=0\n                )\n    \n    strict_mode = False\n    \n    # ---- è¨­å®š (ãƒ¢ãƒ‡ãƒ«ãªã©) ----\n    with st.expander(\"âš™ï¸ è¨­å®š\", expanded=False):\n        model_options = [\n            \"gemini-3-pro-preview\",\n            \"gemini-2.5-pro\",\n            \"gemini-2.5-flash\",\n            \"gemini-2.5-flash-lite\",\n            \"gemini-2.0-flash\",\n        ]\n        model_id = st.selectbox(\"ãƒ¢ãƒ‡ãƒ«ID\", options=model_options, index=0)\n\n        use_search = st.toggle(\"Googleæ¤œç´¢\", value=True)\n        candidate_count = st.slider(\"å€™è£œæ•°\", min_value=1, max_value=3, value=3)\n\n    st.markdown(\"---\")\n\n    # ---- å±¥æ­´æ¤œç´¢ ----\n    search_query = st.text_input(\"ğŸ” å±¥æ­´æ¤œç´¢\", placeholder=\"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰...\")\n    if search_query:\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if search_query.lower() in s[\"title\"].lower():\n                filtered_sessions.append(s)\n                continue\n            found = False\n            for m in s[\"messages\"]:\n                if search_query.lower() in m[\"content\"].lower():\n                    filtered_sessions.append(s)\n                    found = True\n                    break\n            if not found:\n                pass\n    else:\n        # æ¤œç´¢ã—ã¦ã„ãªã„å ´åˆ: ç©ºã®ã€Œæ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã€ã‚’é™¤å¤–ï¼ˆç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯é™¤ãï¼‰\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if s[\"id\"] == st.session_state.current_session_id:\n                filtered_sessions.append(s)\n                continue\n            if s[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(s[\"messages\"]) == 0:\n                continue\n            filtered_sessions.append(s)\n\n    # CSSã§è¦‹ã‚„ã™ãä½¿ã„ã‚„ã™ãæœ€é©åŒ–\n    st.markdown(\"\"\"\n    <style>\n    /* å…¨ä½“ã®ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºç¸®å° */\n    .stApp, .stMarkdown, .stButton, .stSelectbox, .stTextInput, .stTextArea {\n        font-size: 12px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ä½™ç™½ã‚’æ¥µé™ã¾ã§è©°ã‚ã‚‹ */\n    section[data-testid=\"stSidebar\"] .block-container {\n        padding-top: 0.3rem !important;\n        padding-bottom: 0.3rem !important;\n        padding-left: 0.5rem !important;\n        padding-right: 0.5rem !important;\n    }\n    /* å„è¦ç´ é–“ã®éš™é–“ã‚’è©°ã‚ã‚‹ */\n    div[data-testid=\"stVerticalBlock\"] > div {\n        gap: 0.1rem !important;\n    }\n    /* Expanderã®ä½™ç™½å‰Šæ¸› */\n    .streamlit-expanderHeader {\n        font-size: 11px !important;\n        padding-top: 0px !important;\n        padding-bottom: 0px !important;\n        min-height: 1.3rem !important;\n    }\n    .streamlit-expanderContent {\n        padding-top: 0px !important;\n        padding-bottom: 0px !important;\n    }\n    /* éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã®ã‚¿ã‚¤ãƒˆãƒ« */\n    div[data-testid=\"stExpander\"] summary p {\n        font-size: 10px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ */\n    section[data-testid=\"stSidebar\"] button p {\n        font-size: 10px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã« */\n    section[data-testid=\"stSidebar\"] button {\n        padding: 0rem 0.2rem !important;\n        min-height: 1.4rem !important;\n        font-size: 10px !important;\n        margin-bottom: 0px !important;\n    }\n    /* ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®ãƒ©ãƒ™ãƒ«ã‚’å°ã•ã */\n    section[data-testid=\"stSidebar\"] .stRadio label {\n        font-size: 10px !important;\n    }\n    section[data-testid=\"stSidebar\"] .stRadio > label > div {\n        font-size: 10px !important;\n    }\n    /* ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ‡ã‚Šè©°ã‚ã‚‹ï¼ˆæ”¹è¡Œã•ã›ãªã„ï¼‰ */\n    section[data-testid=\"stSidebar\"] label, \n    section[data-testid=\"stSidebar\"] p,\n    section[data-testid=\"stSidebar\"] span {\n        white-space: nowrap !important;\n        overflow: hidden !important;\n        text-overflow: ellipsis !important;\n    }\n    /* åŒºåˆ‡ã‚Šç·š */\n    hr {\n        margin-top: 0.1rem !important;\n        margin-bottom: 0.1rem !important;\n    }\n    /* ãƒ˜ãƒƒãƒ€ãƒ¼ç¸®å° */\n    h1, h2, h3 {\n        padding-top: 0rem !important;\n        padding-bottom: 0rem !important;\n        margin-top: 0rem !important;\n        margin-bottom: 0rem !important;\n    }\n    </style>\n    \"\"\", unsafe_allow_html=True)\n    \n    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§é™é †ã‚½ãƒ¼ãƒˆï¼ˆæœ€æ–°ãŒå…ˆé ­ï¼‰\n    filtered_sessions.sort(key=lambda s: s.get(\"timestamp\", \"\"), reverse=True)\n    \n    # ç›´è¿‘5ä»¶ã¨éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«åˆ†å‰²\n    recent_sessions = filtered_sessions[:5] if len(filtered_sessions) > 5 else filtered_sessions\n    archive_sessions = filtered_sessions[5:] if len(filtered_sessions) > 5 else []\n    \n    # ç›´è¿‘5ä»¶ï¼ˆå¸¸ã«å±•é–‹ï¼‰\n    if recent_sessions:\n        st.markdown(\"**ğŸ“Œ ç›´è¿‘ã®ãƒãƒ£ãƒƒãƒˆ**\")\n        for session in recent_sessions:\n            col1, col2 = st.columns([0.8, 0.2])\n            with col1:\n                if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                    switch_session(session[\"id\"])\n            with col2:\n                if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                    delete_session(session[\"id\"])\n    \n    # éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆæŠ˜ã‚ŠãŸãŸã¿ï¼‰\n    if archive_sessions:\n        with st.expander(f\"ğŸ“œ éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ– ({len(archive_sessions)}ä»¶)\", expanded=False):\n            for session in archive_sessions:\n                col1, col2 = st.columns([0.8, 0.2])\n                with col1:\n                    if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                        switch_session(session[\"id\"])\n                with col2:\n                    if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                        delete_session(session[\"id\"])\n\n    st.markdown(\"---\")\n\n    # ---- ç”»åƒç”Ÿæˆ ----\n    with st.expander(\"ğŸ¨ ç”»åƒç”Ÿæˆ\", expanded=False):\n        img_prompt = st.text_area(\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\", placeholder=\"æœªæ¥çš„ãªéƒ½å¸‚...\")\n        aspect_ratio = st.selectbox(\"æ¯”ç‡\", [\"16:9\", \"1:1\", \"4:3\", \"3:4\", \"9:16\"])\n\n        generate_img_btn = st.button(\"ç”Ÿæˆ\", type=\"primary\", disabled=not img_prompt)\n        if generate_img_btn and img_prompt:\n            st.session_state.generate_image_trigger = {\n                \"prompt\": img_prompt,\n                \"aspect_ratio\": aspect_ratio,\n            }\n\n    st.markdown(\"---\")\n\n    # ---- è©•ä¾¡åˆ†æ ----\n    with st.expander(\"ğŸ“Š å“è³ªåˆ†æ\", expanded=False):\n        total_ratings = 0\n        positive_ratings = 0\n        model_ratings = {}\n\n        for s in st.session_state.sessions:\n            for m in s[\"messages\"]:\n                if \"rating\" in m and m[\"rating\"] is not None:\n                    total_ratings += 1\n                    if m[\"rating\"] == 1:\n                        positive_ratings += 1\n                    if \"metadata\" in m and \"model\" in m[\"metadata\"]:\n                        mod = m[\"metadata\"][\"model\"]\n                        if mod not in model_ratings:\n                            model_ratings[mod] = {\"total\": 0, \"positive\": 0}\n                        model_ratings[mod][\"total\"] += 1\n                        if m[\"rating\"] == 1:\n                            model_ratings[mod][\"positive\"] += 1\n\n        if total_ratings > 0:\n            approval_rate = (positive_ratings / total_ratings) * 100\n            st.metric(\"Positive Ratings\", f\"{positive_ratings}/{total_ratings}\", f\"{approval_rate:.1f}%\")\n            best_model = \"N/A\"\n            best_rate = -1\n            for mod, stats in model_ratings.items():\n                rate = stats[\"positive\"] / stats[\"total\"]\n                if rate > best_rate:\n                    best_rate = rate\n                    best_model = mod\n            if best_model != \"N/A\":\n                st.caption(f\"ğŸ† Best: **{best_model}** ({best_rate*100:.0f}%)\")\n        else:\n            st.caption(\"ãƒ‡ãƒ¼ã‚¿ãªã—\")\n\n    st.markdown(\"---\")\n\n    # ---- ã‚³ã‚¹ãƒˆè¡¨ç¤º ----\n    from logic import load_manual_cost, save_manual_cost, MAX_BUDGET_JPY, TRIAL_LIMIT_JPY, TRIAL_EXPIRY\n    \n    st.subheader(\"ğŸ’° Cost\")\n    st.caption(f\"äºˆç®—: Â¥{MAX_BUDGET_JPY:,.0f}\")\n    st.caption(f\"ä¸Šé™: Â¥{TRIAL_LIMIT_JPY:,.0f}\")\n    st.caption(f\"æœ‰åŠ¹æœŸé™: {TRIAL_EXPIRY}\")\n    \n    # æ‰‹å‹•ã‚³ã‚¹ãƒˆå…¥åŠ›ï¼ˆæ°¸ç¶šåŒ–ï¼‰\n    current_manual_cost = load_manual_cost()\n    manual_cost = st.number_input(\n        \"æ‰‹å‹•å…¥åŠ› (Â¥)\",\n        min_value=0.0,\n        value=current_manual_cost,\n        step=10.0,\n        format=\"%.0f\",\n        key=\"manual_cost_persistent\",\n        help=\"Google Cloud Consoleã§ç¢ºèªã—ãŸå®Ÿéš›ã®ã‚³ã‚¹ãƒˆï¼ˆå††ï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ã“ã®å€¤ã¯ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‰ã˜ã¦ã‚‚ä¿æŒã•ã‚Œã¾ã™ã€‚\"\n    )\n    \n    # å€¤ãŒå¤‰æ›´ã•ã‚ŒãŸã‚‰ä¿å­˜\n    if manual_cost != current_manual_cost:\n        save_manual_cost(manual_cost)\n    \n    st.link_button(\"ğŸ’° Google Cloud Console\", \"https://console.cloud.google.com/welcome/new?_gl=1*kmr691*_up*MQ..&gclid=CjwKCAiAraXJBhBJEiwAjz7MZT0vQsfDK5zunRBCQmuN5iczgI4bP1lHo1Tcrcbqu1KCBE1D22GpFhoCOdgQAvD_BwE&gclsrc=aw.ds&hl=ja&authuser=5&project=sigma-task-479704-r6\")\n\n    st.markdown(\"---\")\n    st.code(f\"PROJECT: {VERTEX_PROJECT}\\nLOCATION: {VERTEX_LOCATION} (Vertex AI)\")\n\n# =========================\n# Main UI\n# =========================\n\ncurrent_session_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\nfor s in st.session_state.sessions:\n    if s[\"id\"] == st.session_state.current_session_id:\n        current_session_title = s[\"title\"]\n        break\n\nst.header(current_session_title)\nst.markdown(\n    \"ä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\"\n)\n\n\n# ---- ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒœã‚¿ãƒ³ (Floating) ----\nst.markdown(\"\"\"\n    <style>\n        .scroll-btn-container {\n            position: fixed;\n            bottom: 100px;\n            right: 20px;\n            z-index: 9999;\n            display: flex;\n            flex-direction: column;\n            gap: 10px;\n        }\n        .scroll-btn {\n            background-color: #f0f2f6;\n            color: #31333F;\n            border: 1px solid #d6d6d8;\n            border-radius: 50%;\n            width: 40px;\n            height: 40px;\n            display: flex;\n            align-items: center;\n            justify-content: center;\n            cursor: pointer;\n            box-shadow: 0 2px 5px rgba(0,0,0,0.1);\n            transition: all 0.3s ease;\n            font-size: 20px;\n            padding: 0;\n            line-height: 1;\n        }\n        .scroll-btn:hover {\n            background-color: #e0e2e6;\n            transform: scale(1.1);\n            box-shadow: 0 4px 8px rgba(0,0,0,0.15);\n        }\n    </style>\n    \n    <script>\n        window.scrollStreamlit = function(direction) {\n            console.log(\"Scroll triggered: \" + direction);\n            \n            // ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ãªã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹è¦ç´ ã‚’é †ç•ªã«è©¦ã™\n            var targets = [];\n            \n            try {\n                if (window.parent && window.parent.document) {\n                    targets.push(window.parent.document.querySelector('section[data-testid=\"stAppViewContainer\"]'));\n                    targets.push(window.parent.document.querySelector('.main'));\n                    targets.push(window.parent.document.documentElement);\n                }\n            } catch (e) {\n                console.log(\"Access to parent window denied\");\n            }\n            \n            // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆiframeå†…ï¼‰\n            targets.push(document.querySelector('section[data-testid=\"stAppViewContainer\"]'));\n            targets.push(document.documentElement);\n\n            var scrolled = false;\n            for (var i = 0; i < targets.length; i++) {\n                var el = targets[i];\n                if (el) {\n                    try {\n                        // ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯èƒ½ãªè¦ç´ ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“çš„ï¼‰\n                        if (el.scrollHeight > el.clientHeight || el === window.parent.document.documentElement) {\n                            console.log(\"Scrolling element:\", el);\n                            if (direction === 'top') {\n                                el.scrollTo({top: 0, behavior: 'smooth'});\n                            } else {\n                                el.scrollTo({top: el.scrollHeight, behavior: 'smooth'});\n                            }\n                            scrolled = true;\n                        }\n                    } catch (e) {\n                        console.error(\"Error scrolling element:\", e);\n                    }\n                }\n            }\n            \n            if (!scrolled) {\n                console.log(\"No scrollable container found, trying window scroll\");\n                try {\n                    if (direction === 'top') {\n                        window.parent.scrollTo({top: 0, behavior: 'smooth'});\n                    } else {\n                        window.parent.scrollTo({top: window.parent.document.body.scrollHeight, behavior: 'smooth'});\n                    }\n                } catch(e) {\n                    window.scrollTo({top: 0, behavior: 'smooth'});\n                }\n            }\n        }\n    </script>\n\n    <div class=\"scroll-btn-container\">\n        <button class=\"scroll-btn\" onclick=\"window.scrollStreamlit('top')\" title=\"Top\">â¬†ï¸</button>\n        <button class=\"scroll-btn\" onclick=\"window.scrollStreamlit('bottom')\" title=\"Bottom\">â¬‡ï¸</button>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n# ---- Vertex AI Client ----\n\n\n\nclient = get_client()\n\n# ---- å±¥æ­´è¡¨ç¤º ----\n\nmessages = get_current_messages()\nfor idx, msg in enumerate(messages):\n    with st.chat_message(msg[\"role\"]):\n        st.markdown(msg[\"content\"])\n        if msg[\"role\"] == \"model\":\n            col1, col2, col3 = st.columns([0.1, 0.1, 0.8])\n            current_rating = msg.get(\"rating\")\n            with col1:\n                if st.button(\"ğŸ‘\", key=f\"up_{idx}\"):\n                    messages[idx][\"rating\"] = 1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col2:\n                if st.button(\"ğŸ‘\", key=f\"down_{idx}\"):\n                    messages[idx][\"rating\"] = -1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col3:\n                if current_rating == 1:\n                    st.caption(\"âœ… é«˜è©•ä¾¡\")\n                elif current_rating == -1:\n                    st.caption(\"âŒ ä½è©•ä¾¡\")\n\n# ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒœã‚¿ãƒ³ï¼ˆé•·ã„ãƒãƒ£ãƒƒãƒˆç”¨ï¼‰\nif len(messages) > 5:\n    st.markdown(\"\"\"\n    <div style=\"position: fixed; right: 20px; bottom: 100px; z-index: 999;\">\n        <button onclick=\"window.scrollTo({top: 0, behavior: 'smooth'})\" \n                style=\"display: block; margin: 5px; padding: 10px 15px; font-size: 24px; cursor: pointer; \n                       border: 2px solid #ccc; border-radius: 50%; background: white; box-shadow: 0 2px 8px rgba(0,0,0,0.2);\">\n            â¬†ï¸\n        </button>\n        <button onclick=\"window.scrollTo({top: document.body.scrollHeight, behavior: 'smooth'})\" \n                style=\"display: block; margin: 5px; padding: 10px 15px; font-size: 24px; cursor: pointer; \n                       border: 2px solid #ccc; border-radius: 50%; background: white; box-shadow: 0 2px 8px rgba(0,0,0,0.2);\">\n            â¬‡ï¸\n        </button>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n\n# =========================\n# ç”»åƒç”Ÿæˆãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°\n# =========================\n\nif hasattr(st.session_state, \"generate_image_trigger\") and st.session_state.generate_image_trigger:\n    img_data = st.session_state.generate_image_trigger\n    del st.session_state.generate_image_trigger\n\n    with st.chat_message(\"user\"):\n        st.markdown(f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\")\n        st.caption(f\"ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”: {img_data['aspect_ratio']}\")\n\n    messages.append({\"role\": \"user\", \"content\": f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\"})\n    update_current_session_messages(messages)\n\n    with st.chat_message(\"assistant\"):\n        with st.status(\"ç”»åƒã‚’ç”Ÿæˆä¸­...\", expanded=True) as status:\n            try:\n                config = types.GenerateContentConfig(\n                    response_modalities=[\"IMAGE\"],\n                    image_config=types.ImageConfig(\n                        aspect_ratio=img_data[\"aspect_ratio\"]\n                    ),\n                )\n                status.write(\"Gemini 3 Pro Imageã§ç”Ÿæˆä¸­...\")\n                response = client.models.generate_content(\n                    model=\"gemini-3-pro-image-preview\",\n                    contents=img_data[\"prompt\"],\n                    config=config,\n                )\n\n                generated_image = None\n\n                # ç”»åƒã‚’å–ã‚Šå‡ºã™\n                if getattr(response, \"candidates\", None):\n                    for candidate in response.candidates:\n                        if getattr(candidate, \"content\", None) and candidate.content.parts:\n                            for part in candidate.content.parts:\n                                if getattr(part, \"inline_data\", None):\n                                    try:\n                                        generated_image = part.as_image()\n                                    except AttributeError:\n                                        image_bytes_raw = part.inline_data.data\n                                        generated_image = Image.open(io.BytesIO(image_bytes_raw))\n                                    break\n                        if generated_image is not None:\n                            break\n\n                if generated_image is not None:\n                    st.image(generated_image, caption=img_data[\"prompt\"])\n                    buf = io.BytesIO()\n                    generated_image.save(buf, format=\"PNG\")\n                    image_bytes = buf.getvalue()\n                    st.download_button(\n                        label=\"ğŸ’¾ ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\",\n                        data=image_bytes,\n                        file_name=f\"generated_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png\",\n                        mime=\"image/png\",\n                    )\n                    messages.append(\n                        {\"role\": \"model\", \"content\": f\"âœ… ç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {img_data['prompt']}\"}\n                    )\n                    update_current_session_messages(messages)\n                    status.update(label=\"âœ… ç”»åƒç”Ÿæˆå®Œäº†\", state=\"complete\")\n                else:\n                    st.error(\"ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")\n                    status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n\n            except Exception as e:\n                status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n                st.error(f\"ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}\")\n\n# =========================\n# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›\n# =========================\n\nprompt = st.chat_input(\"ä½•ã‹èã„ã¦ãã ã•ã„...\", disabled=stop_generation)\n\nif prompt:\n    if stop_generation:\n        st.error(\"äºˆç®—ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚\")\n    else:\n        # ---- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€è¡¨ç¤º ----\n        with st.chat_message(\"user\"):\n            st.markdown(prompt)\n            if uploaded_files:\n                for uf in uploaded_files:\n                    st.caption(f\"ğŸ“ æ·»ä»˜: {uf.name}\")\n            if youtube_url:\n                st.caption(f\"ğŸ“º YouTube: {youtube_url}\")\n            if pasted_image_bytes:\n                st.caption(\"ğŸ“‹ ç”»åƒãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚Œã¾ã—ãŸ\")\n\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        update_current_session_messages(messages)\n\n        # ---- ãƒ¢ãƒ‡ãƒ«å¿œç­” ----\n        with st.chat_message(\"assistant\"):\n            status_container = st.status(\"æ€è€ƒä¸­...\", expanded=True)\n            try:\n                # ä¼šè©±å±¥æ­´\n                model_history = []\n                for msg in messages[:-1]:\n                    model_history.append(\n                        types.Content(\n                            role=msg[\"role\"],\n                            parts=[types.Part.from_text(text=msg[\"content\"])],\n                        )\n                    )\n\n                # ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³\n                current_parts = [types.Part.from_text(text=prompt)]\n\n                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«\n                for uploaded_file in uploaded_files or []:\n                    try:\n                        mime_type = get_mime_type(uploaded_file.name)\n                        bytes_data = uploaded_file.getvalue()\n                        part = types.Part.from_bytes(data=bytes_data, mime_type=mime_type)\n                        current_parts.append(part)\n                        status_container.write(f\"ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™å®Œäº†: {uploaded_file.name}\")\n                    except Exception as e:\n                        status_container.error(\n                            f\"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {uploaded_file.name} - {e}\"\n                        )\n\n                # è²¼ã‚Šä»˜ã‘ç”»åƒ\n                if pasted_image_bytes:\n                    import base64\n\n                    status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã‚’å‡¦ç†ä¸­...\")\n                    try:\n                        if isinstance(pasted_image_bytes, str):\n                            if pasted_image_bytes.startswith(\"data:\"):\n                                base64_str = pasted_image_bytes.split(\",\", 1)[1]\n                                image_bytes_decoded = base64.b64decode(base64_str)\n                            else:\n                                image_bytes_decoded = base64.b64decode(pasted_image_bytes)\n                        else:\n                            image_bytes_decoded = pasted_image_bytes\n                        part = types.Part.from_bytes(\n                            data=image_bytes_decoded, mime_type=\"image/png\"\n                        )\n                        current_parts.append(part)\n                        status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®æº–å‚™å®Œäº†\")\n                    except Exception as e:\n                        status_container.error(f\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n\n                # YouTube å­—å¹•\n                if youtube_url:\n                    vid_id = extract_youtube_id(youtube_url)\n                    if vid_id:\n                        status_container.write(\"YouTubeã®å­—å¹•ã‚’å–å¾—ä¸­...\")\n                        transcript_text = get_youtube_transcript(vid_id)\n                        current_parts.append(\n                            types.Part.from_text(text=f\"YouTube Transcript:\\n{transcript_text}\")\n                        )\n                    else:\n                        status_container.write(\"ç„¡åŠ¹ãªYouTube URLã§ã™ã€‚\")\n\n                contents_for_model = model_history + [\n                    types.Content(role=\"user\", parts=current_parts)\n                ]\n\n                # ---- Tool / Config ----\n                tools = []\n                final_candidate_count = candidate_count\n                if use_search:\n                    tools.append(types.Tool(google_search=types.GoogleSearch()))\n                    final_candidate_count = 1\n\n                # â˜… System Instruction ã®æ”¹å–„: ãƒ¡ã‚¿ç™ºè¨€ç¦æ­¢ã¨ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªæŒ¯ã‚‹èˆã„ã‚’æŒ‡ç¤º\n                base_system_instruction = (\n                    \"ã‚ãªãŸã¯é«˜åº¦ãªçŸ¥æ€§ã‚’æŒã¤å°‚é–€çš„ãªãƒªã‚µãƒ¼ãƒãƒ»ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\\n\"\n                    \"ä»¥ä¸‹ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’å³å®ˆã—ã¦ãã ã•ã„ï¼š\\n\"\n                    \"1. **ãƒ¡ã‚¿ç™ºè¨€ã®ç¦æ­¢**: ã€Œç§ã¯AIã§ã™ã€ã€Œä¸–ç•Œæœ€é«˜å³°ã®ï½ã¨ã—ã¦ã€ãªã©ã®è‡ªå·±è¨€åŠã‚„å‰ç½®ãã¯ä¸€åˆ‡è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚\\n\"\n                    \"2. **æ„å›³ã®æ±²ã¿å–ã‚Š**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã®èƒŒå¾Œã«ã‚ã‚‹æ„å›³ï¼ˆæ–‡è„ˆã€æš—é»™ã®å‰æï¼‰ã‚’æ¨æ¸¬ã—ã€è¨€è‘‰é€šã‚Šã§ã¯ãªãã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ¬å½“ã«çŸ¥ã‚ŠãŸã„ã“ã¨ã€ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n\"\n                    \"3. **æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”**: çµè«–ã‚’å…ˆã«è¿°ã¹ã€ãã®å¾Œã«è©³ç´°ãªæ ¹æ‹ ã€ã‚·ãƒŠãƒªã‚ªåˆ†æã€ãƒªã‚¹ã‚¯è¦å› ã‚’è«–ç†çš„ã«å±•é–‹ã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"4. **å®¢è¦³æ€§**: äºˆæ¸¬ã‚’è¡Œã†å ´åˆã¯ã€æ–­å®šã‚’é¿ã‘ã€è¤‡æ•°ã®ã‚·ãƒŠãƒªã‚ªï¼ˆæ¥½è¦³ã€æ‚²è¦³ã€ä¸­ç«‹ï¼‰ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"5. **å¼•ç”¨**: æ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸå ´åˆã¯ã€å¿…ãšæƒ…å ±æºã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚\"\n                )\n\n                final_answer = \"\"\n                grounding_metadata = None\n                \n                # =========================\n                # ãƒ¢ãƒ¼ãƒ‰è¨­å®šã®è§£æ\n                # =========================\n                # Î²1é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ä»¥å¤–ã¯ãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œ\n                enable_research = \"Î²1\" not in response_mode\n                enable_meta = \"ãƒ¡ã‚¿\" in response_mode or \"MAX\" in response_mode\n                enable_strict = \"é¬¼è»æ›¹\" in response_mode or \"MAX\" in response_mode\n                enable_grok_x_search = \"grokæ¤œç´¢å¼·åŒ–ç‰ˆ\" in response_mode\n\n                # =========================\n                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (é«˜é€Ÿ / é¬¼è»æ›¹)\n                # =========================\n                if not enable_research:\n                    config = types.GenerateContentConfig(\n                        temperature=0.7,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=base_system_instruction,\n                    )\n                    \n                    status_container.write(\"å›ç­”ç”Ÿæˆä¸­...\")\n                    response = client.models.generate_content(\n                        model=model_id,\n                        contents=contents_for_model,\n                        config=config,\n                    )\n                    \n                    final_answer = extract_text_from_response(response)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®—\n                    if response.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            response.usage_metadata.prompt_token_count,\n                            response.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += response.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += response.usage_metadata.candidates_token_count\n\n                    # é¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ (é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ç‰ˆ)\n                    if enable_strict:\n                        status_container.write(\"ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        reviewer_instruction = base_system_instruction + \"\"\"\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n                        review_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\nåˆç‰ˆå›ç­”:\\n{final_answer}\\n\\nãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\")])]\n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=types.GenerateContentConfig(temperature=0.1, candidate_count=1, system_instruction=reviewer_instruction)\n                        )\n                        final_answer = extract_text_from_response(review_resp)\n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        \n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(model_id, review_resp.usage_metadata.prompt_token_count, review_resp.usage_metadata.candidates_token_count)\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n\n                # =========================\n                # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰\n                # =========================\n                else:\n                    # =========================\n                    # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰: å¤šæ®µéšã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ \n                    # =========================\n                    \n                    # --- Phase 1: ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 1: ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    import datetime as dt\n                    current_year = dt.datetime.now().year\n                    \n                    research_instruction = base_system_instruction + f\"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒªã‚µãƒ¼ãƒå°‚ä»»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚æœ€çµ‚å›ç­”ã¯æ›¸ã‹ãšã€äº‹å®Ÿåé›†ã«é›†ä¸­ã™ã‚‹ã“ã¨ã€‚\n\n**èª¿æŸ»è¦³ç‚¹**:\n- è³ªå•ã«é–¢é€£ã™ã‚‹**æœ€æ–°ã®äº‹å®Ÿãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ»çµ±è¨ˆ**ï¼ˆ**{current_year}å¹´ã®æƒ…å ±ã‚’æœ€å„ªå…ˆ**ï¼‰\n- **ç¾æ™‚ç‚¹ã§å­˜åœ¨ã™ã‚‹å…¨ã¦ã®é¸æŠè‚¢ãƒ»ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¶²ç¾…çš„ã«èª¿æŸ»**ï¼ˆä¾‹: è£½å“æ¯”è¼ƒãªã‚‰ã€æœ€æ–°ç‰ˆã ã‘ã§ãªãç›´è¿‘ã®å…¨ä¸–ä»£ã‚’èª¿æŸ»ï¼‰\n- å…¬å¼æƒ…å ±ã‚„ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã‹ã‚‰ã®å¼•ç”¨\n- é–¢é€£ã™ã‚‹èƒŒæ™¯æƒ…å ±ã‚„æ–‡è„ˆ\n- ç«¶åˆãƒ»ä»£æ›¿æ¡ˆãƒ»æ¯”è¼ƒå¯¾è±¡ã®**å®Œå…¨ãªãƒªã‚¹ãƒˆ**\n- ãƒªã‚¹ã‚¯ãƒ»åˆ¶ç´„ãƒ»æ³¨æ„ç‚¹ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n- å‚è€ƒã«ã—ãŸä¸»è¦ãªæƒ…å ±æºã®URL\n\n**é‡è¦**: \n- çµè«–ã‚„æ¨å¥¨ã¯æ›¸ã‹ãšã€å¾Œå·¥ç¨‹ãŒåˆ¤æ–­ã§ãã‚‹èª¿æŸ»ãƒ¡ãƒ¢ã«é›†ä¸­ã™ã‚‹ã“ã¨\n- **å¿…ãšæ¤œç´¢æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã€æœ€æ–°ã®æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã“ã¨**\n- **æ¤œç´¢çµæœã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æ—¥ä»˜ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒ»ãƒ¢ãƒ‡ãƒ«åã‚’å„ªå…ˆçš„ã«è¨˜è¼‰ã™ã‚‹ã“ã¨**\n- **æ¯”è¼ƒå¯¾è±¡ã¨ãªã‚‹é¸æŠè‚¢ã‚’è¦‹è½ã¨ã•ãªã„ã‚ˆã†ã€è¤‡æ•°ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è©¦ã™ã“ã¨**ï¼ˆä¾‹: ã€ŒiPhone æœ€æ–°ãƒ¢ãƒ‡ãƒ« {current_year}ã€ã€ŒiPhone {current_year}å¹´ç™ºå£²ã€ãªã©ï¼‰\n- **ã€Œã“ã‚Œã‚ˆã‚Šæ–°ã—ã„ãƒ¢ãƒ‡ãƒ«/ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯å­˜åœ¨ã—ãªã„ã‹ï¼Ÿã€ã‚’å¸¸ã«ç¢ºèªã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ï¼ˆ{current_year-1}å¹´ä»¥å‰ãªã©ï¼‰ã—ã‹è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãã®æ—¨ã‚’æ˜è¨˜ã™ã‚‹ã“ã¨\n\"\"\"\n\n                    # éå»ã®é–¢é€£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—\n                    past_context = get_relevant_context(prompt, st.session_state.sessions, st.session_state.current_session_id)\n                    \n                    # ãƒªã‚µãƒ¼ãƒç”¨ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ§‹ç¯‰\n                    import datetime as dt\n                    current_date = dt.datetime.now().strftime(\"%Yå¹´%mæœˆ%dæ—¥\")\n                    research_parts = [types.Part(text=(\n                        f\"é‡è¦: ä»Šæ—¥ã¯{current_date}ã§ã™ã€‚ã“ã®æ—¥ä»˜ã‚ˆã‚Šæ–°ã—ã„æƒ…å ±ã‚’å„ªå…ˆã—ã¦ãã ã•ã„ã€‚\\n\\n\"\n                        f\"è³ªå•: {prompt}\"\n                    ))]\n                    \n                    if past_context:\n                        research_parts.insert(0, types.Part(text=\"ä»¥ä¸‹ã¯éå»ã®é–¢é€£ãƒãƒ£ãƒƒãƒˆã‹ã‚‰æŠ½å‡ºã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã™ï¼š\\n\\n\" + past_context))\n                    \n                    research_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=research_parts)\n                    ]\n                    \n                    research_config = types.GenerateContentConfig(\n                        temperature=0.4,  # æœ€æ–°æƒ…å ±ã‚’æŸ”è»Ÿã«æ¡ç”¨ã™ã‚‹ãŸã‚0.2â†’0.4ã«ä¸Šæ˜‡\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=research_instruction,\n                    )\n                    \n                    research_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=research_contents,\n                        config=research_config,\n                    )\n                    \n                    research_text = extract_text_from_response(research_resp)\n                    \n                    # ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºã®ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ±ã‚’ä¿å­˜\n                    if research_resp.candidates and research_resp.candidates[0].grounding_metadata:\n                        grounding_metadata = research_resp.candidates[0].grounding_metadata\n                    \n                    status_container.write(\"âœ“ ãƒªã‚µãƒ¼ãƒå®Œäº†\")\n                    with status_container.expander(\"åé›†ã—ãŸèª¿æŸ»ãƒ¡ãƒ¢\", expanded=False):\n                        st.markdown(research_text)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1)\n                    if research_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            research_resp.usage_metadata.prompt_token_count,\n                            research_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += research_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += research_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 1.5: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    questions_text = \"\"\n                    if enable_meta:\n                        status_container.write(\"Phase 1.5: ãƒ¡ã‚¿è³ªå•ç”Ÿæˆä¸­...\")\n                        \n                        question_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ç›®çš„**: \nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•ã¨èª¿æŸ»ãƒ¡ãƒ¢ã‚’è¸ã¾ãˆã¦ã€ã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±ãç†è§£ã™ã‚‹ãŸã‚ã®ã€Œé‹­ã„ã‚µãƒ–è³ªå•ã€ã‚’ä½œæˆã™ã‚‹ã“ã¨ã€‚\n\n**ãƒ«ãƒ¼ãƒ«**:\n- æœ€å¤§5å€‹ã¾ã§\n- å„è³ªå•ã¯1-2è¡Œã§å…·ä½“çš„ã‹ã¤é‹­ã\n- ä»¥ä¸‹ã®è¦³ç‚¹ã‚’æ„è­˜:\n  1. å‰æãŒå´©ã‚Œã‚‹å¯èƒ½æ€§ã¯ã©ã“ã‹ï¼Ÿ\n  2. å¼·æ°—/å¼±æ°—ã‚·ãƒŠãƒªã‚ªã®åˆ†å²ç‚¹ã¯ä½•ã‹ï¼Ÿ\n  3. ç«¶åˆãƒ»æŠ€è¡“ãƒ»è¦åˆ¶ã®ä¸ç¢ºå®Ÿæ€§ã¯ï¼Ÿ\n  4. ã€Œäºˆæ¸¬ãŒå¤–ã‚Œã‚‹ã¨ã—ãŸã‚‰ã©ã‚“ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ï¼Ÿã€\n\n**å‡ºåŠ›**: ç®‡æ¡æ›¸ãï¼ˆQ1, Q2...ï¼‰ã®ã¿\n\"\"\"\n\n                        question_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•:\\n{prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\nã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±æ˜ã‚Šã™ã‚‹ãŸã‚ã®é‡è¦ãªã‚µãƒ–è³ªå•ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\")])]\n                        \n                        question_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=question_contents,\n                            config=types.GenerateContentConfig(\n                                temperature=0.4,\n                                candidate_count=1,\n                                system_instruction=question_instruction,\n                            )\n                        )\n                        \n                        questions_text = extract_text_from_response(question_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¡ã‚¿è³ªå•ç”Ÿæˆå®Œäº†\")\n                        with status_container.expander(\"ç”Ÿæˆã•ã‚ŒãŸãƒ¡ã‚¿è³ªå•\", expanded=False):\n                            st.markdown(questions_text)\n                        \n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += question_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += question_resp.usage_metadata.candidates_token_count\n\n                    # å¤šå±¤+puterãƒ¢ãƒ¼ãƒ‰ã®é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã‹ãƒã‚§ãƒƒã‚¯\n                    is_puter_onigunsou = (\n                        mode_category == \"Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter)\" and\n                        response_mode == \"1. ç†Ÿè€ƒ + é¬¼è»æ›¹(localã®ã¿)\"\n                    )\n\n                    # --- Phase 1.5b: Grok ç‹¬ç«‹æ€è€ƒ (å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    # --- Phase 1.5b: Grok ç‹¬ç«‹æ€è€ƒ (å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    grok_thought = \"\"\n                    grok_status = \"skipped\"\n                    if enable_meta and OPENROUTER_API_KEY:\n                        status_container.write(\"Phase 1.5b: Grok ç‹¬ç«‹æ€è€ƒä¸­...\")\n                        try:\n                            grok_thought = think_with_grok(prompt, research_text, enable_x_search=enable_grok_x_search)\n                            if grok_thought:\n                                grok_status = \"success\"\n                                status_container.write(\"âœ“ Grok 4.1 Fast Free ç‹¬ç«‹æ€è€ƒå®Œäº†\")\n                                with status_container.expander(\"Grokã®ç‹¬ç«‹å›ç­”æ¡ˆ\", expanded=False):\n                                    st.markdown(grok_thought)\n                            else:\n                                grok_status = \"empty\"\n                        except Exception as e:\n                            grok_status = \"error\"\n                            status_container.write(f\"âš  Grokæ€è€ƒã‚¨ãƒ©ãƒ¼: {e}\")\n\n                    # --- Phase 1.5c: Claude Opus 4.5 ç‹¬ç«‹æ€è€ƒ (å¤šå±¤+puterã®é¬¼è»æ›¹ã®ã¿) ---\n                    # --- Phase 1.5c: Claude Opus 4.5 ç‹¬ç«‹æ€è€ƒ (å¤šå±¤+puterã®é¬¼è»æ›¹ã®ã¿) ---\n                    claude_thought = \"\"\n                    claude_status = \"skipped\"\n                    if is_puter_onigunsou and PUTER_USERNAME and PUTER_PASSWORD:\n                        status_container.write(\"Phase 1.5c: Claude Opus 4.5 ç‹¬ç«‹æ€è€ƒä¸­...\")\n                        try:\n                            claude_thought = call_claude_opus_via_puter(\n                                user_question=prompt,\n                                research_text=research_text,\n                                system_prompt=(\n                                    \"ã‚ãªãŸã¯ Claude Opus 4.5 ã§ã™ã€‚\"\n                                    \"Gemini ãŒé›†ã‚ãŸèª¿æŸ»ãƒ¡ãƒ¢ã‚’å‚è€ƒã«ã—ã¤ã¤ã‚‚ã€\"\n                                    \"è‡ªåˆ†ã®è¦–ç‚¹ã§ç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆãƒ»æ°—ã¥ãã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\"\n                                    \"Gemini ã®æ„è¦‹ã«åˆã‚ã›ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\"\n                                ),\n                            )\n                            if claude_thought and not claude_thought.startswith(\"[Claude\"):\n                                claude_status = \"success\"\n                                status_container.write(\"âœ“ Claude Opus 4.5 (via Puter) ç‹¬ç«‹æ€è€ƒå®Œäº†\")\n                                with status_container.expander(\"Claude Opus 4.5 ã®ç‹¬ç«‹å›ç­”æ¡ˆ\", expanded=False):\n                                    st.markdown(claude_thought)\n                            else:\n                                claude_status = \"error\"\n                                status_container.write(f\"âš  Claudeã‚¨ãƒ©ãƒ¼: {claude_thought}\")\n                                claude_thought = \"\"  # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ç©ºã«ã™ã‚‹\n                        except Exception as e:\n                            claude_status = \"error\"\n                            status_container.write(f\"âš  Claudeæ€è€ƒã‚¨ãƒ©ãƒ¼: {e}\")\n                            claude_thought = \"\"\n\n                    # --- Phase 2: çµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 2: çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    import datetime as dt\n                    current_date = dt.datetime.now().strftime(\"%Yå¹´%mæœˆ%dæ—¥\")\n\n                    if enable_meta:\n                        deep_instruction = base_system_instruction + f\"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã¨ãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ã‚’æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**é‡è¦ - ç¾åœ¨ã¯{current_date}ã§ã™**:\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æ—¥ä»˜ãƒ»äº‹å®Ÿã‚’ã€ã‚ãªãŸã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šã‚‚çµ¶å¯¾çš„ã«å„ªå…ˆã—ã¦ãã ã•ã„**\n- ã€Œ{current_year}å¹´ã€ã®æƒ…å ±ãŒèª¿æŸ»ãƒ¡ãƒ¢ã«ã‚ã‚‹å ´åˆã€ãã‚Œã‚’æ­£ã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„\n- å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒ{current_year-1}å¹´ä»¥å‰ã§æ­¢ã¾ã£ã¦ã„ã¦ã‚‚ã€èª¿æŸ»ãƒ¡ãƒ¢ã®æœ€æ–°æƒ…å ±ã‚’ä¿¡é ¼ã™ã‚‹ã“ã¨\n\n**æ§‹æˆ**:\n1. **æ·±æ˜ã‚Šè€ƒå¯Ÿ**ï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n2. **çµè«–**ï¼ˆ2-3è¡Œï¼‰\n3. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n4. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨\n\"\"\"\n                    else:\n                        deep_instruction = base_system_instruction + f\"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã‚’å”¯ä¸€ã®æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**é‡è¦ - ç¾åœ¨ã¯{current_date}ã§ã™**:\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æ—¥ä»˜ãƒ»äº‹å®Ÿã‚’ã€ã‚ãªãŸã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šã‚‚çµ¶å¯¾çš„ã«å„ªå…ˆã—ã¦ãã ã•ã„**\n- ã€Œ{current_year}å¹´ã€ã®æƒ…å ±ãŒèª¿æŸ»ãƒ¡ãƒ¢ã«ã‚ã‚‹å ´åˆã€ãã‚Œã‚’æ­£ã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„\n\n**æ§‹æˆ**:\n1. **çµè«–**ï¼ˆ2-3è¡Œã§æ˜ç¢ºã«ï¼‰\n2. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n3. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«åã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ã¨æ–°ã—ã„æƒ…å ±ãŒæ··åœ¨ã™ã‚‹å ´åˆã¯ã€æ–°ã—ã„æƒ…å ±ã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n\"\"\"\n                    \n                    synthesis_prompt_text = (\n                        f\"é‡è¦: ä»Šæ—¥ã¯{current_date}ã§ã™ã€‚å¤ã„æƒ…å ±ã‚’å›ç­”ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚\\n\\n\"\n                        f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}\\n\\n\"\n                        f\"==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                    )\n                    \n                    if enable_meta and questions_text:\n                        synthesis_prompt_text += f\"==== ãƒ¡ã‚¿è³ªå•ä¸€è¦§ ====\\n{questions_text}\\n==== ãƒ¡ã‚¿è³ªå•ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if enable_meta and grok_thought:\n                        synthesis_prompt_text += f\"==== åˆ¥è¦–ç‚¹ã‹ã‚‰ã®å›ç­”æ¡ˆ (Grok) ====\\n{grok_thought}\\n==== åˆ¥è¦–ç‚¹ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if is_puter_onigunsou and claude_thought:\n                        synthesis_prompt_text += f\"==== åˆ¥è¦–ç‚¹ã‹ã‚‰ã®å›ç­”æ¡ˆ (Claude Opus 4.5 via Puter) ====\\n{claude_thought}\\n==== Claudeåˆ¥è¦–ç‚¹ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    # çµ±åˆæŒ‡ç¤º\n                    if enable_meta and (grok_thought or claude_thought):\n                        synthesis_prompt_text += \"æŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n2. Grok\"\n                        if is_puter_onigunsou and claude_thought:\n                            synthesis_prompt_text += \" / Claude\"\n                        synthesis_prompt_text += \" ã®å›ç­”æ¡ˆã‚‚å‚è€ƒã«ã—ã¤ã¤ï¼ˆãŸã ã—ç›²ä¿¡ã›ãšï¼‰ã€ç‹¬è‡ªã®è¦–ç‚¹ã§çµ±åˆã—ã¦ãã ã•ã„ã€‚\\n3. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»åˆ†æãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    elif enable_meta and questions_text:\n                        synthesis_prompt_text += \"æŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n2. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»åˆ†æãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    else:\n                        synthesis_prompt_text += \"ä¸Šè¨˜ãƒ¡ãƒ¢ã‚’æ ¹æ‹ ã«ã€æœ€çµ‚å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å¿…ãšä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚**\"\n\n                    synthesis_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=[\n                            types.Part(text=synthesis_prompt_text)\n                        ])\n                    ]\n                    \n                    synthesis_config = types.GenerateContentConfig(\n                        temperature=0.3,\n                        candidate_count=1,\n                        tools=[],  # çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºã§ã¯æ¤œç´¢OFF\n                        system_instruction=deep_instruction,\n                    )\n                    \n                    synthesis_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=synthesis_contents,\n                        config=synthesis_config,\n                    )\n                    \n                    draft_answer = extract_text_from_response(synthesis_resp)\n                    \n                    status_container.write(\"âœ“ çµ±åˆå®Œäº†\")\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 2)\n                    if synthesis_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            synthesis_resp.usage_metadata.prompt_token_count,\n                            synthesis_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += synthesis_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += synthesis_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    if enable_strict:\n                        status_container.write(\"Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        \n\n                        reviewer_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™ã€‚ãŸã ã—ã€**èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’å„ªå…ˆã—ã€æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã™ã‚‹ã“ã¨**ã€‚\n\n**ãƒ¬ãƒ“ãƒ¥ãƒ¼è¦³ç‚¹**:\n- äº‹å®Ÿã¨æ¨æ¸¬ã‚’æ˜ç¢ºã«åˆ†ã‘ã‚‹\n- éåº¦ã«è‡ªä¿¡ã®ã‚ã‚‹æ–­å®šã‚’å¼±ã‚ã‚‹\n- æ•°å­—ã‚„å›ºæœ‰åè©ãŒèª¿æŸ»ãƒ¡ãƒ¢ã¨çŸ›ç›¾ã—ã¦ã„ãªã„ã‹ç¢ºèª\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ãƒ¢ãƒ‡ãƒ«ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ãŒæ­£ã—ãä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª**\n- **å¤ã„æƒ…å ±ã§ä¸Šæ›¸ãã—ã¦ã„ãªã„ã‹ç¢ºèª**\n- è¦‹è½ã¨ã—ã¦ã„ã‚‹é‡è¦ãªãƒªã‚¹ã‚¯ãƒ»ã‚·ãƒŠãƒªã‚ªãŒã‚ã‚Œã°è¿½åŠ \n\n**é‡è¦**: \n- èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ãŒæœ€æ–°ã§ã‚ã‚‹å ´åˆã€ãã‚Œã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n- ã‚ãªãŸã®çŸ¥è­˜ãŒå¤ã„å ´åˆã¯ã€èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’ä¿¡é ¼ã™ã‚‹ã“ã¨\n\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n\n                        review_contents = [\n                            types.Content(role=\"user\", parts=[\n                                types.Part.from_text(\n                                    text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\n\"\n                                    f\"==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                                    f\"åˆç‰ˆå›ç­”:\\n{draft_answer}\\n\\n\"\n                                    \"ä¸Šè¨˜ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚**\"\n                                )\n                            ])\n                        ]\n                        \n                        review_config = types.GenerateContentConfig(\n                            temperature=0.1,\n                            candidate_count=1,\n                            system_instruction=reviewer_instruction,\n                            thinking_config=types.ThinkingConfig(\n                                thinking_level=types.ThinkingLevel.HIGH\n                            ),\n                        )\n                        \n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=review_config,\n                        )\n                        \n                        final_answer = extract_text_from_response(review_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        \n                        # --- Phase 3b: Groké¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ (å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ + é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰å…¨èˆ¬) ---\n                        # å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã§ã€ã‹ã¤é¬¼è»æ›¹ç³»ã®ãƒ¢ãƒ¼ãƒ‰ï¼ˆé¬¼è»æ›¹ã€ãƒ¡ã‚¿æ€è€ƒã€æœ¬æ°—MAXï¼‰ã§ç™ºå‹•\n                        use_grok_reviewer = (mode_category == \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\" and enable_strict)\n                        \n                        if use_grok_reviewer and OPENROUTER_API_KEY:\n                            status_container.write(\"Phase 3b: Grok 4.1 Fast ã§æœ€çµ‚ãƒã‚§ãƒƒã‚¯ä¸­...\")\n                            try:\n                                grok_answer = review_with_grok(prompt, final_answer, research_text)\n                                # Grokä½¿ç”¨æ™‚ã¯ã€ãƒ¢ãƒ‡ãƒ«åã‚’æ˜ç¤ºã—ã€2æ®µæ§‹æˆã§è¡¨ç¤º\n                                final_answer = (\n                                    f\"**ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_id} (Deep Thinking / High Reasoning)**\\n\"\n                                    f\"**ãƒ¬ãƒ“ãƒ¥ã‚¢: Grok 4.1 Fast (free)**\\n\"\n                                    f\"**ãƒ¢ãƒ¼ãƒ‰: {response_mode}**\\n\\n\"\n                                    \"---\\n\\n\"\n                                    \"## âœ… æœ€çµ‚å›ç­”ï¼ˆGeminiçµ±åˆç‰ˆï¼‰\\n\\n\"\n                                    f\"{final_answer}\\n\\n\"\n                                    \"---\\n\\n\"\n                                    \"## ğŸ” Grok ã«ã‚ˆã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼\\n\\n\"\n                                    f\"{grok_answer}\"\n                                )\n                                status_container.write(\"âœ“ Grokæœ€çµ‚ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                            except Exception as e:\n                                status_container.write(f\"âš  Grokãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}\")\n                        else:\n                            # Geminiã®ã¿ã®å ´åˆã‚‚ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤ºï¼ˆå¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆï¼‰\n                            if mode_category == \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\":\n                                final_answer = (\n                                    f\"**ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_id} (Deep Thinking / High Reasoning)**\\n\"\n                                    f\"**ãƒ¢ãƒ¼ãƒ‰: {response_mode}**\\n\\n---\\n\\n{final_answer}\"\n                                )\n                        \n                        # --- ãƒ¡ã‚¿æ€è€ƒãƒ¢ãƒ¼ãƒ‰: çµè«–ã‚’å…ˆå‡ºã—ã™ã‚‹ ---\n                        if \"ãƒ¡ã‚¿æ€è€ƒ\" in response_mode:\n                            # çµè«–éƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆç°¡æ˜“çš„ãªå®Ÿè£…ï¼‰\n                            # \"çµè«–\"ã‚„\"ã¾ã¨ã‚\"ãªã©ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¢ã—ã¦å…ˆé ­ã«ç§»å‹•\n                            lines = final_answer.split('\\n')\n                            conclusion_start = -1\n                            for i, line in enumerate(lines):\n                                if any(keyword in line for keyword in ['## çµè«–', '## ã¾ã¨ã‚', '**çµè«–**', '**ã¾ã¨ã‚**']):\n                                    conclusion_start = i\n                                    break\n                            \n                            if conclusion_start != -1:\n                                # çµè«–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¦‹ã¤ã‘ãŸå ´åˆã€ãã‚Œã‚’å…ˆé ­ã«ç§»å‹•\n                                conclusion_section = []\n                                other_content = lines[:conclusion_start]\n                                \n                                # çµè«–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®çµ‚ã‚ã‚Šã‚’è¦‹ã¤ã‘ã‚‹ï¼ˆæ¬¡ã®##ã¾ã§ or æ–‡æœ«ï¼‰\n                                conclusion_end = len(lines)\n                                for i in range(conclusion_start + 1, len(lines)):\n                                    if lines[i].startswith('## ') and i != conclusion_start:\n                                        conclusion_end = i\n                                        break\n                                \n                                conclusion_section = lines[conclusion_start:conclusion_end]\n                                remaining_content = lines[conclusion_end:]\n                                \n                                # å†æ§‹æˆ: ãƒ¢ãƒ‡ãƒ«å â†’ çµè«– â†’ ãã®ä»–ã®è©³ç´°\n                                # ãƒ¢ãƒ‡ãƒ«åéƒ¨åˆ†ã‚’ä¿æŒ\n                                model_line = \"\"\n                                if lines[0].startswith(\"**ğŸ¤–\"):\n                                    model_line = lines[0]\n                                    other_content = lines[1:conclusion_start]\n                                \n                                final_answer = '\\n'.join([\n                                    model_line,\n                                    \"\",\n                                    \"---\",\n                                    \"\",\n                                    \"## ğŸ“Œ çµè«–ï¼ˆå…ˆå‡ºã—ï¼‰\",\n                                    *conclusion_section[1:],  # å…ƒã®è¦‹å‡ºã—ã‚’é™¤ã\n                                    \"\",\n                                    \"---\",\n                                    \"\",\n                                    \"## ğŸ“ è©³ç´°\",\n                                    *other_content,\n                                    *remaining_content\n                                ]).strip()\n                        \n                        with status_container.expander(\"åˆç‰ˆã¨ã®æ¯”è¼ƒ\", expanded=False):\n                            st.markdown(\"**åˆç‰ˆ:**\")\n                            st.markdown(draft_answer[:500] + \"...\" if len(draft_answer) > 500 else draft_answer)\n                            st.markdown(\"**ä¿®æ­£ç‰ˆ:**\")\n                            st.markdown(final_answer[:500] + \"...\" if len(final_answer) > 500 else final_answer)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 3)\n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                review_resp.usage_metadata.prompt_token_count,\n                                review_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n                    else:\n                        final_answer = draft_answer\n\n                save_usage(usage_stats)\n                status_container.update(label=\"å®Œäº†ï¼\", state=\"complete\", expanded=False)\n\n                # ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤º\n                models_used = [f\"Gemini: {model_id}\"]\n                \n                # Grok Status\n                if enable_meta:\n                    if grok_status == \"success\":\n                        models_used.append(\"Grok: 4.1-fast-free (OK)\")\n                    elif grok_status == \"error\":\n                        models_used.append(\"Grok: 4.1-fast-free (Error)\")\n                    elif grok_status == \"empty\":\n                        models_used.append(\"Grok: 4.1-fast-free (Empty)\")\n                \n                # Claude Status\n                if is_puter_onigunsou:\n                    if claude_status == \"success\":\n                        models_used.append(\"Claude: Opus 4.5 (via Puter) (OK)\")\n                    elif claude_status == \"error\":\n                        models_used.append(\"Claude: Opus 4.5 (via Puter) (Error)\")\n                \n                st.caption(f\"ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {' + '.join(models_used)}\")\n                st.markdown(final_answer)\n\n                # ---- ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ± ----\n                if grounding_metadata:\n                    st.markdown(\"---\")\n                    with st.expander(\"ğŸ“š æƒ…å ±æºã¨å¼•ç”¨\", expanded=False):\n                        if grounding_metadata.grounding_chunks:\n                            st.markdown(\"**æ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:**\")\n                            unique_sources = {}\n                            import urllib.parse\n\n                            for chunk in grounding_metadata.grounding_chunks:\n                                if getattr(chunk, \"web\", None):\n                                    uri = getattr(chunk.web, \"uri\", None)\n                                    title = getattr(chunk.web, \"title\", \"æƒ…å ±æº\")\n                                    if uri and uri not in unique_sources:\n                                        parsed = urllib.parse.urlparse(uri)\n                                        domain = parsed.netloc.replace(\"www.\", \"\")\n                                        unique_sources[uri] = {\n                                            \"title\": title,\n                                            \"domain\": domain,\n                                        }\n                            for i, (uri, info) in enumerate(unique_sources.items(), 1):\n                                st.markdown(f\"{i}. **[{info['title']}]({uri})**\")\n                                st.caption(f\"   å‡ºå…¸: {info['domain']}\")\n\n                messages.append({\"role\": \"model\", \"content\": final_answer})\n                update_current_session_messages(messages)\n\n            except Exception as e:\n                status_container.update(label=\"Error\", state=\"error\")\n                err_text = str(e)\n                if \"RESOURCE_EXHAUSTED\" in err_text or \"429\" in err_text:\n                    st.error(\n                        \"âš ï¸ Vertex AI / Gemini ã®ã‚¯ã‚©ãƒ¼ã‚¿ã«é”ã—ã¾ã—ãŸã€‚\\n\\n\"\n                        \"ãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ / æ—¥æ¬¡åˆ¶é™ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\\n\"\n                        \"ãƒ»ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                        \"ãƒ»Google Cloud Console ã®ã€ŒVertex AI â†’ ä½¿ç”¨çŠ¶æ³ã€ã‹ã‚‰ã‚¯ã‚©ãƒ¼ã‚¿çŠ¶æ³ã‚’ç¢ºèªã§ãã¾ã™ã€‚\"\n                    )\n                elif \"NOT_FOUND\" in err_text and \"Publisher Model\" in err_text:\n                    st.error(\n                        \"âš ï¸ æŒ‡å®šã—ãŸãƒ¢ãƒ‡ãƒ«ãŒã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ / ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\\n\"\n                        \"ãƒ»ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ¢ãƒ‡ãƒ«IDã‚’ã€2.5ç³» ã¾ãŸã¯ 3 Pro ã«å¤‰æ›´ã—ã¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                    )\n                else:\n                    st.error(f\"An error occurred: {e}\")\n"
                },
                {
                    "role": "model",
                    "content": "## çµè«–\n\nã”è¦æœ›ã®é€šã‚Šã€ã€ŒÎ²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter)ã€ãŒé¸æŠã•ã‚Œã¦ã„ã‚‹å ´åˆã€ã‚µãƒ–ãƒ¢ãƒ¼ãƒ‰ï¼ˆé¬¼è»æ›¹ã€ãƒ¡ã‚¿æ€è€ƒã€æœ¬æ°—MAXï¼‰ã«é–¢ã‚ã‚‰ãš Claude (Puter) ãŒå‹•ä½œã™ã‚‹ã‚ˆã†ã«ãƒ­ã‚¸ãƒƒã‚¯ã‚’æ‹¡å¼µãƒ»æ•´ç†ã—ã¾ã—ãŸã€‚\n\nä»¥ä¸‹ã®2ã¤ã®ä¿®æ­£ãƒ–ãƒ­ãƒƒã‚¯ã‚’ã€æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ï¼ˆ`logic.py` ã§ã¯ãªããƒ¡ã‚¤ãƒ³ã® `app.py` å´ã¨æ¨æ¸¬ã•ã‚Œã¾ã™ï¼‰ã«é©ç”¨ã—ã¦ãã ã•ã„ã€‚\n\n---\n\n### 1. ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã®ä¿®æ­£ (Phase 1.5 ã€œ Phase 2)\n\nã“ã®ãƒ–ãƒ­ãƒƒã‚¯ã¯ã€æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã® **Phase 1.5 (ãƒ¡ã‚¿è³ªå•) ã®ç›´å¾Œ** ã‹ã‚‰ **Phase 2 (çµ±åˆ) ã®å›ç­”ç”Ÿæˆç›´å‰** ã¾ã§ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Œå…¨ã«ç½®ãæ›ãˆã‚‹ã‚‚ã®ã§ã™ã€‚\n`is_puter_onigunsou` ã¨ã„ã†é™å®šçš„ãªãƒ•ãƒ©ã‚°ã‚’å»ƒæ­¢ã—ã€`enable_puter_claude` ã¨ã„ã†æ±ç”¨ãƒ•ãƒ©ã‚°ã«åˆ‡ã‚Šæ›¿ãˆã¦ã„ã¾ã™ã€‚\n\n```python\n                    # ============================================================\n                    # ğŸ”„ ä¿®æ­£: Puter (Claude) ã®æœ‰åŠ¹åŒ–ãƒ­ã‚¸ãƒƒã‚¯ã‚’æ‹¡å¼µ\n                    # ============================================================\n                    \n                    # ã€Œå¤šå±¤+puterã€ã‚«ãƒ†ã‚´ãƒªãŒé¸æŠã•ã‚Œã¦ã„ã‚Œã°ã€ã‚µãƒ–ãƒ¢ãƒ¼ãƒ‰ã«é–¢ã‚ã‚‰ãšClaudeã‚’æœ‰åŠ¹åŒ–\n                    enable_puter_claude = (mode_category == \"Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter)\")\n\n                    # --- Phase 1.5b: Grok ç‹¬ç«‹æ€è€ƒ (å¤šå±¤ãƒ¢ãƒ¼ãƒ‰å…¨èˆ¬) ---\n                    grok_thought = \"\"\n                    grok_status = \"skipped\"\n                    # ãƒ¡ã‚¿æ€è€ƒã€æœ¬æ°—MAXã€ã¾ãŸã¯Grokæ¤œç´¢å¼·åŒ–ç‰ˆã§æœ‰åŠ¹\n                    if (enable_meta or enable_grok_x_search) and OPENROUTER_API_KEY:\n                        status_container.write(\"Phase 1.5b: Grok ç‹¬ç«‹æ€è€ƒä¸­...\")\n                        try:\n                            grok_thought = think_with_grok(prompt, research_text, enable_x_search=enable_grok_x_search)\n                            if grok_thought:\n                                grok_status = \"success\"\n                                status_container.write(\"âœ“ Grok 4.1 Fast Free ç‹¬ç«‹æ€è€ƒå®Œäº†\")\n                                with status_container.expander(\"Grokã®ç‹¬ç«‹å›ç­”æ¡ˆ\", expanded=False):\n                                    st.markdown(grok_thought)\n                            else:\n                                grok_status = \"empty\"\n                        except Exception as e:\n                            grok_status = \"error\"\n                            status_container.write(f\"âš  Grokæ€è€ƒã‚¨ãƒ©ãƒ¼: {e}\")\n\n                    # --- Phase 1.5c: Claude Opus 4.5 ç‹¬ç«‹æ€è€ƒ (Puterãƒ¢ãƒ¼ãƒ‰å…¨èˆ¬) ---\n                    claude_thought = \"\"\n                    claude_status = \"skipped\"\n                    \n                    # ä¿®æ­£: enable_puter_claude ãƒ•ãƒ©ã‚°ã‚’ä½¿ç”¨ (é¬¼è»æ›¹ä»¥å¤–ã§ã‚‚å‹•ä½œ)\n                    if enable_puter_claude and PUTER_USERNAME and PUTER_PASSWORD:\n                        status_container.write(\"Phase 1.5c: Claude Opus 4.5 (via Puter) ç‹¬ç«‹æ€è€ƒä¸­...\")\n                        try:\n                            claude_thought = call_claude_opus_via_puter(\n                                user_question=prompt,\n                                research_text=research_text,\n                                system_prompt=(\n                                    \"ã‚ãªãŸã¯ Claude Opus 4.5 ã§ã™ã€‚\"\n                                    \"Gemini ãŒé›†ã‚ãŸèª¿æŸ»ãƒ¡ãƒ¢ã‚’å‚è€ƒã«ã—ã¤ã¤ã‚‚ã€\"\n                                    \"è‡ªåˆ†ã®è¦–ç‚¹ã§ç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆãƒ»æ°—ã¥ãã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\"\n                                    \"Gemini ã®æ„è¦‹ã«åˆã‚ã›ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\"\n                                    \"ç‰¹ã«ã€è­°è«–ã®æ­»è§’ã‚„ã€ç•°ãªã‚‹è§£é‡ˆã®å¯èƒ½æ€§ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚\"\n                                ),\n                            )\n                            if claude_thought and not claude_thought.startswith(\"[Claude\"):\n                                claude_status = \"success\"\n                                status_container.write(\"âœ“ Claude Opus 4.5 (via Puter) ç‹¬ç«‹æ€è€ƒå®Œäº†\")\n                                with status_container.expander(\"Claude Opus 4.5 ã®ç‹¬ç«‹å›ç­”æ¡ˆ\", expanded=False):\n                                    st.markdown(claude_thought)\n                            else:\n                                claude_status = \"error\"\n                                status_container.write(f\"âš  Claudeã‚¨ãƒ©ãƒ¼: {claude_thought}\")\n                                claude_thought = \"\"  # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ç©ºã«ã™ã‚‹\n                        except Exception as e:\n                            claude_status = \"error\"\n                            status_container.write(f\"âš  Claudeæ€è€ƒã‚¨ãƒ©ãƒ¼: {e}\")\n                            claude_thought = \"\"\n\n                    # --- Phase 2: çµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 2: çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    import datetime as dt\n                    current_date = dt.datetime.now().strftime(\"%Yå¹´%mæœˆ%dæ—¥\")\n\n                    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ãƒ­ã‚¸ãƒƒã‚¯\n                    if enable_meta:\n                        deep_instruction = base_system_instruction + f\"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã€ãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ã€ãŠã‚ˆã³**ä»–ã®AIãƒ¢ãƒ‡ãƒ«ï¼ˆGrok, Claudeï¼‰ã®è¦–ç‚¹**ã‚’çµ±åˆã—ã€æœ€é«˜å“è³ªã®å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**é‡è¦ - ç¾åœ¨ã¯{current_date}ã§ã™**:\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æ—¥ä»˜ãƒ»äº‹å®Ÿã‚’ã€ã‚ãªãŸã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šã‚‚çµ¶å¯¾çš„ã«å„ªå…ˆã—ã¦ãã ã•ã„**\n- ä»–ã®ãƒ¢ãƒ‡ãƒ«ï¼ˆClaude/Grokï¼‰ãŒæç¤ºã—ãŸã€Œç•°ãªã‚‹è¦–ç‚¹ã€ã‚„ã€Œãƒªã‚¹ã‚¯ã€ã‚’ç©æ¥µçš„ã«å–ã‚Šå…¥ã‚Œã¦ãã ã•ã„ã€‚\n\n**æ§‹æˆ**:\n1. **æ·±æ˜ã‚Šè€ƒå¯Ÿ**ï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n2. **å¤šè§’çš„è¦–ç‚¹ã®çµ±åˆ**ï¼ˆGemini, Claude, Grokã®æ„è¦‹ã®ã™ã‚Šåˆã‚ã›ï¼‰\n3. **çµè«–**ï¼ˆ2-3è¡Œï¼‰\n4. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n5. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n\"\"\"\n                    else:\n                        # é€šå¸¸/é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ç­‰ã®å ´åˆ\n                        deep_instruction = base_system_instruction + f\"\"\"\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ãŠã‚ˆã³ä»–ã®AIãƒ¢ãƒ‡ãƒ«ï¼ˆClaudeç­‰ï¼‰ã®æ„è¦‹ã‚’å‚è€ƒã«ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n**é‡è¦ - ç¾åœ¨ã¯{current_date}ã§ã™**:\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æ—¥ä»˜ãƒ»äº‹å®Ÿã‚’çµ¶å¯¾çš„ã«å„ªå…ˆã—ã¦ãã ã•ã„**\n\"\"\"\n                    \n                    synthesis_prompt_text = (\n                        f\"é‡è¦: ä»Šæ—¥ã¯{current_date}ã§ã™ã€‚å¤ã„æƒ…å ±ã‚’å›ç­”ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚\\n\\n\"\n                        f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}\\n\\n\"\n                        f\"==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                    )\n                    \n                    if enable_meta and questions_text:\n                        synthesis_prompt_text += f\"==== ãƒ¡ã‚¿è³ªå•ä¸€è¦§ ====\\n{questions_text}\\n==== ãƒ¡ã‚¿è³ªå•ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if grok_thought:\n                        synthesis_prompt_text += f\"==== åˆ¥è¦–ç‚¹ã‹ã‚‰ã®å›ç­”æ¡ˆ (Grok) ====\\n{grok_thought}\\n==== åˆ¥è¦–ç‚¹ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    # ä¿®æ­£: enable_puter_claude ãƒ•ãƒ©ã‚°ã§åˆ¤å®š\n                    if enable_puter_claude and claude_thought:\n                        synthesis_prompt_text += f\"==== åˆ¥è¦–ç‚¹ã‹ã‚‰ã®å›ç­”æ¡ˆ (Claude Opus 4.5 via Puter) ====\\n{claude_thought}\\n==== Claudeåˆ¥è¦–ç‚¹ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    # çµ±åˆæŒ‡ç¤ºã®æœ€é©åŒ–\n                    if enable_meta:\n                        synthesis_prompt_text += \"æŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n\"\n                        if grok_thought or claude_thought:\n                            synthesis_prompt_text += \"2. Grok ã‚„ Claude ã®å›ç­”æ¡ˆã«å«ã¾ã‚Œã‚‹ã€Œç‹¬è‡ªã®è¦–ç‚¹ã€ã‚„ã€ŒæŒ‡æ‘˜ã€ã‚’æ¤œè¨ã—ã€æœ‰ç”¨ãªã‚‚ã®ã¯å–ã‚Šå…¥ã‚Œã¦ãã ã•ã„ï¼ˆç›²ä¿¡ã¯ã—ãªã„ã“ã¨ï¼‰ã€‚\\n\"\n                        synthesis_prompt_text += \"3. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»åˆ†æãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    else:\n                        synthesis_prompt_text += \"ä¸Šè¨˜ãƒ¡ãƒ¢ãŠã‚ˆã³åˆ¥è¦–ç‚¹ã®å›ç­”æ¡ˆã‚’æ ¹æ‹ ã«ã€æœ€çµ‚å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å¿…ãšä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚**\"\n```\n\n### 2. ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤ºã®ä¿®æ­£ (å‡¦ç†å®Œäº†å¾Œ)\n\nã‚³ãƒ¼ãƒ‰ã®æœ«å°¾ä»˜è¿‘ã€`status_container.update(label=\"å®Œäº†ï¼\"...)` ã®ç›´å¾Œã«ã‚ã‚‹ãƒ¢ãƒ‡ãƒ«åè¡¨ç¤ºéƒ¨åˆ†ã‚’ä»¥ä¸‹ã«ç½®ãæ›ãˆã¦ãã ã•ã„ã€‚\n\n```python\n                # ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤º\n                models_used = [f\"Gemini: {model_id}\"]\n                \n                # Grok Status\n                if (enable_meta or enable_grok_x_search):\n                    if grok_status == \"success\":\n                        models_used.append(\"Grok: 4.1-fast (OK)\")\n                    elif grok_status == \"error\":\n                        models_used.append(\"Grok: 4.1-fast (Error)\")\n                \n                # Claude Status (ä¿®æ­£: enable_puter_claude ãƒ•ãƒ©ã‚°ã‚’ä½¿ç”¨)\n                if enable_puter_claude:\n                    if claude_status == \"success\":\n                        models_used.append(\"Claude: Opus 4.5 (via Puter) (OK)\")\n                    elif claude_status == \"error\":\n                        models_used.append(\"Claude: Opus 4.5 (via Puter) (Error)\")\n                \n                st.caption(f\"ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {' + '.join(models_used)}\")\n```"
                }
            ]
        },
        {
            "id": "33247553-b2f1-48a2-8fc7-9fe6dbf5add2",
            "title": "ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯ã€Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤...",
            "timestamp": "2025-12-02T00:58:24.175442",
            "messages": [
                {
                    "role": "user",
                    "content": "ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯ã€Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter) â†’ 1. ç†Ÿè€ƒ + é¬¼è»æ›¹(localã®ã¿) ä»¥å¤–ã«ã‚‚ã€Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter) ã® \n\nç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\n\nç†Ÿè€ƒ (æœ¬æ°—MAX\n\nã§ã‚‚claudeãŒä½¿ãˆã‚‹ã‚ˆã†ã«ã§ãã‚‹ã‚ˆã­ã€‚\n\nimport os\nimport uuid\nimport datetime\nimport streamlit as st\nfrom dotenv import load_dotenv\nfrom google import genai\nfrom google.genai import types\nfrom PIL import Image\nimport io\nfrom logic import (\n    USAGE_FILE, SESSIONS_FILE, MAX_BUDGET_USD, PRICING,\n    VERTEX_PROJECT, VERTEX_LOCATION,\n    load_usage, save_usage, calculate_cost, get_mime_type,\n    extract_youtube_id, get_youtube_transcript, get_relevant_context,\n    extract_text_from_response, load_sessions, save_sessions, get_client\n)\n\ntry:\n    from st_img_pastebutton import paste\n    import_error_msg = None\nexcept ImportError as e:\n    paste = None\n    import_error_msg = str(e)\n\n# =========================\n# ç’°å¢ƒå¤‰æ•° & å®šæ•°\n# =========================\n\nload_dotenv()\n\n\n\nst.set_page_config(page_title=\"Gemini 3 Web Studio\", layout=\"wide\")\n\n# ğŸ” ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ­ãƒƒã‚¯ (198501) + URLãƒˆãƒ¼ã‚¯ãƒ³æ°¸ç¶šåŒ–\nSECRET_TOKEN = \"access_granted_198501\"\n\n# 1. URLãƒˆãƒ¼ã‚¯ãƒ³ãƒã‚§ãƒƒã‚¯\nquery_params = st.query_params\nurl_token = query_params.get(\"auth\", None)\n\nif url_token == SECRET_TOKEN:\n    st.session_state.authenticated = True\nelif \"authenticated\" not in st.session_state:\n    st.session_state.authenticated = False\n\n# 2. æœªèªè¨¼ãªã‚‰ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ç”»é¢\nif not st.session_state.authenticated:\n    st.title(\"Gemini 3 Studio\")\n    st.write(\"ã“ã®ã‚¢ãƒ—ãƒªã‚’åˆ©ç”¨ã™ã‚‹ã«ã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒå¿…è¦ã§ã™ã€‚\")\n\n    password = st.text_input(\"ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰\", type=\"password\")\n\n    if st.button(\"ãƒ­ã‚°ã‚¤ãƒ³\"):\n        if password == \"198501\":\n            st.session_state.authenticated = True\n            # URLã«ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä»˜ä¸ã—ã¦ãƒªãƒ­ãƒ¼ãƒ‰ï¼ˆã“ã‚Œã§ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯å¯èƒ½ã«ãªã‚‹ï¼‰\n            st.query_params[\"auth\"] = SECRET_TOKEN\n            st.rerun()\n        else:\n            st.error(\"ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™ã€‚\")\n\n    st.stop()\n\n# =========================\n# Helper Functions\n# =========================\n\n# =========================\n# Helper Functions\n# =========================\n# Moved to logic.py\n\n# =========================\n# Grok Review Function (OpenRouter API)\n# =========================\n\nimport requests\nfrom curl_cffi import requests as crequests  # Puterç”¨\n\n# OpenRouter API Keyã®å–å¾— (st.secretså„ªå…ˆã€ãªã‘ã‚Œã°ç’°å¢ƒå¤‰æ•°)\ntry:\n    if \"OPENROUTER_API_KEY\" in st.secrets:\n        OPENROUTER_API_KEY = st.secrets[\"OPENROUTER_API_KEY\"]\n    else:\n        OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\", \"\")\nexcept:\n    OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\", \"\")\n\n# Puter èªè¨¼æƒ…å ±\nPUTER_USERNAME = None\nPUTER_PASSWORD = None\ntry:\n    if \"PUTER_USERNAME\" in st.secrets:\n        PUTER_USERNAME = st.secrets[\"PUTER_USERNAME\"]\n        PUTER_PASSWORD = st.secrets[\"PUTER_PASSWORD\"]\n    else:\n        PUTER_USERNAME = os.getenv(\"PUTER_USERNAME\")\n        PUTER_PASSWORD = os.getenv(\"PUTER_PASSWORD\")\nexcept Exception:\n    PUTER_USERNAME = os.getenv(\"PUTER_USERNAME\")\n    PUTER_PASSWORD = os.getenv(\"PUTER_PASSWORD\")\n\ndef review_with_grok(user_question: str, gemini_answer: str, research_text: str = None) -> str:\n    \"\"\"\n    Grok 4.1 Fast Free ã‚’ä½¿ã£ã¦ã€Geminiã®å›ç­”ã‚’æœ€çµ‚ãƒ¬ãƒ“ãƒ¥ãƒ¼ã™ã‚‹\n    research_text: GeminiãŒåé›†ã—ãŸèª¿æŸ»ãƒ¡ãƒ¢ï¼ˆæœ€æ–°æƒ…å ±ã‚’å«ã‚€ï¼‰\n    \"\"\"\n    url = \"https://openrouter.ai/api/v1/chat/completions\"\n    headers = {\n        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n        \"Content-Type\": \"application/json\",\n    }\n    \n    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰\n    user_content = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\\n{user_question}\\n\\n\"\n    \n    if research_text:\n        user_content += f\"Gemini ã®èª¿æŸ»ãƒ¡ãƒ¢ï¼ˆæœ€æ–°æƒ…å ±ï¼‰:\\n{research_text}\\n\\n\"\n    \n    user_content += (\n        f\"Gemini ã®æœ€çµ‚å›ç­”:\\n{gemini_answer}\\n\\n\"\n        \"**é‡è¦**: èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹äº‹å®Ÿã®æ–¹ã‚’ã€ã‚ãªãŸè‡ªèº«ã®çŸ¥è­˜ã‚ˆã‚Šã‚‚å„ªå…ˆã—ã¦ãã ã•ã„ã€‚\\n\"\n        \"æœ€æ–°ã®æƒ…å ±ãŒèª¿æŸ»ãƒ¡ãƒ¢ã«ã‚ã‚‹å ´åˆã€ãã‚Œã‚’ä¿¡é ¼ã—ã¦ãã ã•ã„ã€‚\\n\\n\"\n        \"1. **é‡å¤§ãªäº‹å®Ÿèª¤èªãƒ»è«–ç†é£›èºã®æŒ‡æ‘˜**ï¼ˆãªã‘ã‚Œã°ã€ç‰¹ã«ãªã—ã€ï¼‰\\n\"\n        \"2. **å…·ä½“çš„ãªä¿®æ­£ææ¡ˆã®ãƒªã‚¹ãƒˆ**ï¼ˆã€ä¿®æ­£å‰ã€â†’ã€ä¿®æ­£å¾Œã€ã®å½¢å¼ã§ï¼‰\\n\"\n        \"3. **ç‰¹ã«ä¸ç¢ºå®Ÿæ€§ãŒé«˜ã„ãƒã‚¤ãƒ³ãƒˆï¼ˆå‰æä¸è¶³ã€ãƒ‡ãƒ¼ã‚¿ä¸è¶³ãªã©ï¼‰ã® bullet list**\\n\"\n    )\n    \n    data = {\n        \"model\": \"x-ai/grok-4.1-fast:free\",\n        \"reasoning\": {\"enabled\": True},  # Enable multi-step reasoning for deeper review\n        \"messages\": [\n            {\n                \"role\": \"system\",\n                \"content\": (\n                    \"ã‚ãªãŸã¯å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ã§ã™ã€‚\"\n                    \"äº‹å®Ÿèª¤èªãƒ»è«–ç†ã®é£›èºãƒ»æŠœã‘æ¼ã‚Œã‚’å®¹èµ¦ãªãæŒ‡æ‘˜ã—ã€\"\n                    \"å¿…è¦ãªã‚‰å›ç­”ã‚’å…¨æ–‡æ›¸ãç›´ã—ã¦ãã ã•ã„ã€‚\"\n                ),\n            },\n            {\n                \"role\": \"user\",\n                \"content\": user_content.strip() + (\n                    \"ã ã‘ã‚’æ—¥æœ¬èªã§å‡ºã—ã¦ãã ã•ã„ã€‚\"\n                ),\n            },\n        ],\n    }\n    try:\n        resp = requests.post(url, headers=headers, json=data, timeout=60)\n        resp.raise_for_status()\n        j = resp.json()\n        return j[\"choices\"][0][\"message\"][\"content\"]\n    except Exception as e:\n        return f\"[Grokãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}]\\n\\n{gemini_answer}\"\n\n# =========================\n# Session Management\n# =========================\n\n\n\ndef think_with_grok(user_question: str, research_text: str, enable_x_search: bool = False) -> str:\n    \"\"\"\n    Grok 4.1 Fast Free ã‚’ä½¿ã£ã¦ã€ãƒªã‚µãƒ¼ãƒãƒ¡ãƒ¢ã‚’å…ƒã«ç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆã‚’ä½œæˆã™ã‚‹\n    enable_x_search=True ã®å ´åˆã€X/Twitteræƒ…å ±ã®æ´»ç”¨ã‚’ä¿ƒã™\n    \"\"\"\n    url = \"https://openrouter.ai/api/v1/chat/completions\"\n    headers = {\n        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n        \"Content-Type\": \"application/json\",\n    }\n    \n    # Xæ¤œç´¢å¼·åŒ–ç‰ˆã®å ´åˆã€ç‰¹åˆ¥ãªæŒ‡ç¤ºã‚’è¿½åŠ \n    x_search_instruction = \"\"\n    if enable_x_search:\n        x_search_instruction = (\n            \"\\n\\n**é‡è¦**: ã‚ãªãŸã¯Grokã¨ã—ã¦Xï¼ˆTwitterï¼‰ã®æƒ…å ±ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚\\n\"\n            \"ä¸Šè¨˜ã®èª¿æŸ»ãƒ¡ãƒ¢ã«åŠ ãˆã¦ã€Xä¸Šã®æœ€æ–°ã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»è­°è«–ãƒ»åå¿œã‚’è€ƒæ…®ã—ã€\\n\"\n            \"ãã‚Œã‚‰ã‚’å«ã‚ãŸç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\\n\\n\"\n            \"æ³¨æ„: Xä¸Šã®æƒ…å ±ãŒç¢ºèªã§ããªã„å ´åˆã¯ã€ãã®æ—¨ã‚’æ­£ç›´ã«è¿°ã¹ã¦ãã ã•ã„ã€‚\\n\"\n            \"æ¶ç©ºã®æŠ•ç¨¿ã‚„å­˜åœ¨ã—ãªã„åå¿œã‚’ä½œæˆã—ãªã„ã“ã¨ã€‚\"\n        )\n    \n    user_content = (\n        f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\\n{user_question}\\n\\n\"\n        f\"èª¿æŸ»ãƒ¡ãƒ¢:\\n{research_text}\\n\\n\"\n        \"æŒ‡ç¤º:\\n\"\n        \"ã‚ãªãŸã¯Geminiã¨ã¯åˆ¥ã®ç‹¬ç«‹ã—ãŸAIã§ã™ã€‚\\n\"\n        \"ä¸Šè¨˜ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’å‚è€ƒã«ã—ã¤ã¤ã‚‚ã€ã‚ãªãŸè‡ªèº«ã®è¦–ç‚¹ã§ç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\\n\"\n        \"Geminiã®æ„è¦‹ã«åˆã‚ã›ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\"\n        f\"{x_search_instruction}\"\n    )\n    \n    data = {\n        \"model\": \"x-ai/grok-2-1212\",\n        \"messages\": [\n            {\"role\": \"user\", \"content\": user_content}\n        ],\n    }\n    \n    try:\n        resp = requests.post(url, headers=headers, json=data, timeout=60)\n        resp.raise_for_status()\n        j = resp.json()\n        return j[\"choices\"][0][\"message\"][\"content\"]\n    except Exception as e:\n        return f\"[Grokæ€è€ƒã‚¨ãƒ©ãƒ¼: {e}]\"\n\ndef _extract_puter_text(message_content):\n    \"\"\"\n    puter.ai.chat ã®è¿”ã‚Šå€¤ã‹ã‚‰ ãƒ†ã‚­ã‚¹ãƒˆã ã‘ã‚’å–ã‚Šå‡ºã™\n    \"\"\"\n    if isinstance(message_content, str):\n        return message_content\n\n    if isinstance(message_content, list):\n        chunks = []\n        for part in message_content:\n            if isinstance(part, dict) and part.get(\"type\") == \"text\":\n                chunks.append(part.get(\"text\", \"\"))\n        return \"\".join(chunks)\n\n    return str(message_content)\n\n\ndef call_claude_opus_via_puter(\n    user_question: str,\n    research_text: str | None = None,\n    system_prompt: str | None = None,\n) -> str:\n    \"\"\"\n    Claude Opus 4.5ï¼ˆputer.comï¼‰ã§æ¨è«–ã•ã›ã‚‹åŒæœŸé–¢æ•°\n    curl_cffiã§Chrome 124ã‚’å½è£…ã—ã¦ç›´æ¥APIã‚’å©ã\n    \"\"\"\n    if not PUTER_USERNAME or not PUTER_PASSWORD:\n        return \"[Claude (puter) èªè¨¼æƒ…å ±æœªè¨­å®š]\"\n\n    # 1. Prepare Headers (Chrome 124 Masquerading)\n    headers = {\n        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36\",\n        \"Accept\": \"*/*\",\n        \"Accept-Language\": \"en-US,en;q=0.9,ja;q=0.8\",\n        \"Origin\": \"https://puter.com\",\n        \"Referer\": \"https://puter.com/\",\n        \"Sec-Ch-Ua\": '\"Chromium\";v=\"124\", \"Google Chrome\";v=\"124\", \"Not-A.Brand\";v=\"99\"',\n        \"Sec-Ch-Ua-Mobile\": \"?0\",\n        \"Sec-Ch-Ua-Platform\": '\"macOS\"',\n        \"Sec-Fetch-Dest\": \"empty\",\n        \"Sec-Fetch-Mode\": \"cors\",\n        \"Sec-Fetch-Site\": \"same-site\",\n        \"Content-Type\": \"application/json\"\n    }\n\n    token = st.session_state.get(\"puter_token\")\n\n    # ãƒˆãƒ¼ã‚¯ãƒ³ãŒãªã„ã€ã¾ãŸã¯å†è©¦è¡ŒãŒå¿…è¦ãªå ´åˆã®ãƒ­ã‚°ã‚¤ãƒ³é–¢æ•°\n    def perform_login():\n        try:\n            resp = crequests.post(\n                \"https://api.puter.com/login\",\n                json={\"username\": PUTER_USERNAME, \"password\": PUTER_PASSWORD},\n                headers=headers,\n                timeout=30,\n                impersonate=\"chrome124\"\n            )\n            if resp.status_code != 200:\n                return None, f\"[Claude Login Error] Status: {resp.status_code}\"\n            \n            new_token = resp.json().get(\"token\")\n            if not new_token:\n                return None, \"[Claude Login Error] Token not found\"\n            \n            return new_token, None\n        except Exception as e:\n            return None, f\"[Claude Login Error] {str(e)}\"\n\n    # ãƒˆãƒ¼ã‚¯ãƒ³ãŒãªã„å ´åˆã¯ãƒ­ã‚°ã‚¤ãƒ³\n    if not token:\n        token, error = perform_login()\n        if error:\n            return error\n        st.session_state.puter_token = token\n\n    # 2. Chat\n    chat_url = \"https://api.puter.com/drivers/call\"\n    \n    messages = []\n    if system_prompt:\n        messages.append({\"role\": \"system\", \"content\": system_prompt})\n\n    user_content = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\\n{user_question}\\n\\n\"\n    if research_text:\n        user_content += f\"èª¿æŸ»ãƒ¡ãƒ¢:\\n{research_text}\\n\\n\"\n        user_content += \"ã“ã®èª¿æŸ»ãƒ¡ãƒ¢ã®äº‹å®Ÿã‚’å„ªå…ˆã—ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚\\n\"\n\n    messages.append({\"role\": \"user\", \"content\": user_content})\n    \n    payload = {\n        \"interface\": \"puter-chat-completion\",\n        \"driver\": \"claude\",\n        \"method\": \"complete\",\n        \"args\": {\n            \"messages\": messages,\n            \"model\": \"claude-opus-4-5\",\n            \"stream\": False\n        }\n    }\n\n    try:\n        # åˆå›ãƒˆãƒ©ã‚¤\n        auth_headers = headers.copy()\n        auth_headers[\"Authorization\"] = f\"Bearer {token}\"\n        chat_resp = crequests.post(chat_url, json=payload, headers=auth_headers, timeout=120, impersonate=\"chrome124\")\n\n        # 401/403ã®å ´åˆã¯å†ãƒ­ã‚°ã‚¤ãƒ³\n        if chat_resp.status_code in [401, 403]:\n            token, error = perform_login()\n            if error:\n                return error\n            st.session_state.puter_token = token\n            \n            # ãƒªãƒˆãƒ©ã‚¤\n            auth_headers[\"Authorization\"] = f\"Bearer {token}\"\n            chat_resp = crequests.post(chat_url, json=payload, headers=auth_headers, timeout=120, impersonate=\"chrome124\")\n\n        if chat_resp.status_code != 200:\n            return f\"[Claude API Error] Status: {chat_resp.status_code}\"\n            \n        result = chat_resp.json()\n        if not result.get(\"success\", False):\n             return f\"[Claude API Error] {result.get('error', 'Unknown error')}\"\n\n        message = result[\"result\"][\"message\"]\n        return _extract_puter_text(message.get(\"content\"))\n\n    except Exception as e:\n        return f\"[Claude Error] {str(e)}\"\n\ndef create_new_session():\n    current_sessions = load_sessions()\n    \n    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒç©ºãªã‚‰ã€æ–°ã—ãä½œã‚‰ãšã«ãã‚Œã‚’å†åˆ©ç”¨ã™ã‚‹ï¼ˆé‡è¤‡é˜²æ­¢ï¼‰\n    if st.session_state.get(\"current_session_id\"):\n        for s in current_sessions:\n            if s[\"id\"] == st.session_state.current_session_id:\n                if len(s[\"messages\"]) == 0:\n                    st.toast(\"ã™ã§ã«æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã§ã™\")\n                    return\n\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": [],\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.rerun()\n\ndef switch_session(session_id):\n    st.session_state.current_session_id = session_id\n    st.rerun()\n\ndef update_current_session_messages(messages):\n    if st.session_state.current_session_id:\n        current_sessions = load_sessions()\n        target_index = -1\n        for i, session in enumerate(current_sessions):\n            if session[\"id\"] == st.session_state.current_session_id:\n                session[\"messages\"] = messages\n                if session[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(messages) > 0:\n                    first_msg = messages[0][\"content\"]\n                    session[\"title\"] = (first_msg[:20] + \"...\") if len(first_msg) > 20 else first_msg\n                session[\"timestamp\"] = datetime.datetime.now().isoformat()\n                target_index = i\n                break\n        \n        if target_index != -1:\n            # æœ€æ–°ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒªã‚¹ãƒˆã®å…ˆé ­ã«ç§»å‹•\n            updated_session = current_sessions.pop(target_index)\n            current_sessions.insert(0, updated_session)\n            \n        save_sessions(current_sessions)\n        st.session_state.sessions = current_sessions\n\ndef get_current_messages():\n    if st.session_state.current_session_id:\n        for session in st.session_state.sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                return session[\"messages\"]\n    return []\n\ndef delete_session(session_id):\n    current_sessions = load_sessions()\n    current_sessions = [s for s in current_sessions if s[\"id\"] != session_id]\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    if st.session_state.current_session_id == session_id:\n        st.session_state.current_session_id = None\n        if st.session_state.sessions:\n            st.session_state.current_session_id = st.session_state.sessions[0][\"id\"]\n    st.rerun()\n\ndef branch_session():\n    \"\"\"ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚’åˆ†å²\"\"\"\n    current_messages = get_current_messages()\n    current_sessions = load_sessions()\n    \n    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—\n    current_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n    for session in current_sessions:\n        if session[\"id\"] == st.session_state.current_session_id:\n            current_title = session[\"title\"]\n            break\n    \n    # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": f\"{current_title} (åˆ†å²)\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": current_messages.copy(),  # ç¾åœ¨ã®å±¥æ­´ã‚’ã‚³ãƒ”ãƒ¼\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    \n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.session_state.session_cost = 0.0  # ã‚³ã‚¹ãƒˆãƒªã‚»ãƒƒãƒˆ\n    st.rerun()\n\n# =========================\n# Initialization\n# =========================\n\nif \"sessions\" not in st.session_state:\n    st.session_state.sessions = load_sessions()\n\nif \"current_session_id\" not in st.session_state:\n    # Always create a new session when the app starts\n    create_new_session()\n\nif \"session_cost\" not in st.session_state:\n    st.session_state.session_cost = 0.0\n\nusage_stats = load_usage()\n\n# ==========================\n# ã‚³ã‚¹ãƒˆãƒã‚§ãƒƒã‚¯ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã®å‰ã«å®Ÿè¡Œï¼‰\n# ==========================\nusage_stats = load_usage()\nstop_generation = usage_stats[\"total_cost_usd\"] >= MAX_BUDGET_USD\n\n# =========================\n# Sidebar\n# =========================\n\nwith st.sidebar:\n    # ğŸ” ãƒ­ã‚°ã‚¢ã‚¦ãƒˆãƒœã‚¿ãƒ³\n    if st.button(\"ğŸ”’ ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ\", use_container_width=True):\n        st.session_state.authenticated = False\n        st.query_params.clear()  # URLãƒˆãƒ¼ã‚¯ãƒ³ã‚‚å‰Šé™¤\n        st.rerun()\n\n    st.markdown(\"\"\"\n    <div style=\"text-align: center; padding: 0; margin: 0; margin-top: -1rem;\">\n        <h1 style=\"font-size: 18px; font-weight: 700; margin: 0; padding: 0; letter-spacing: 1px;\">\n            Gemini 3<br/>Studio\n        </h1>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n    col1, col2 = st.columns(2)\n    with col1:\n        if st.button(\"â• æ–°è¦\", use_container_width=True):\n            create_new_session()\n    with col2:\n        if st.button(\"ğŸŒ± åˆ†å²\", use_container_width=True):\n            branch_session()\n\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    current_messages = get_current_messages()\n    if current_messages:\n        with st.expander(\"ğŸ”— å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ\", expanded=False):\n            export_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n            for s in st.session_state.sessions:\n                if s[\"id\"] == st.session_state.current_session_id:\n                    export_title = s[\"title\"]\n                    break\n\n            export_md = f\"# {export_title}\\n\\n\"\n            export_md += f\"**ä½œæˆæ—¥æ™‚**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n---\\n\\n\"\n            for msg in current_messages:\n                role_label = \"ğŸ§‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼\" if msg[\"role\"] == \"user\" else \"ğŸ¤– AI\"\n                export_md += f\"## {role_label}\\n\\n{msg['content']}\\n\\n---\\n\\n\"\n\n            if st.button(\"ãƒªãƒ³ã‚¯ç”Ÿæˆ\", use_container_width=True):\n                with st.spinner(\"ç”Ÿæˆä¸­...\"):\n                    try:\n                        import urllib.request\n                        import urllib.parse\n\n                        data = urllib.parse.urlencode(\n                            {\"content\": export_md, \"expiry_days\": 7, \"syntax\": \"md\"}\n                        ).encode()\n\n                        req = urllib.request.Request(\"https://dpaste.org/api/\", data=data)\n                        req.add_header(\"User-Agent\", \"Mozilla/5.0 (Gemini3Studio)\")\n\n                        with urllib.request.urlopen(req) as response:\n                            share_url = response.read().decode(\"utf-8\").strip()\n                            st.success(\"ä½œæˆå®Œäº†ï¼\")\n                            st.code(share_url)\n                            st.caption(\"â€»7æ—¥é–“æœ‰åŠ¹\")\n                    except Exception as e:\n                        st.error(f\"ã‚¨ãƒ©ãƒ¼: {e}\")\n\n    st.markdown(\"---\")\n\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    with st.expander(\"ğŸ“ æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«\", expanded=False):\n        uploaded_files = st.file_uploader(\n            \"ãƒ•ã‚¡ã‚¤ãƒ«\",\n            accept_multiple_files=True,\n            type=[\"png\", \"jpg\", \"jpeg\", \"mp4\", \"mov\", \"txt\", \"pdf\", \"csv\"],\n            label_visibility=\"collapsed\"\n        )\n\n    # ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ï¼ˆExpanderã®å¤–ã«å‡ºã™ï¼‰\n    pasted_image_bytes = None  # åˆæœŸåŒ–ã—ã¦NameErrorã‚’é˜²ã\n    if paste:\n        if \"paste_key\" not in st.session_state:\n            st.session_state.paste_key = 0\n        try:\n            pasted_image_bytes = paste(\n                label=\"ğŸ“‹ ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰è²¼ä»˜\",\n                key=f\"paste_btn_{st.session_state.paste_key}\",\n            )\n        except Exception as e:\n            st.error(f\"Error: {e}\")\n        \n        if pasted_image_bytes:\n            st.success(\"è²¼ä»˜å®Œäº†\")\n            st.image(pasted_image_bytes, caption=\"ç”»åƒ\", use_container_width=True)\n            if st.button(\"ğŸ—‘ï¸ ã‚¯ãƒªã‚¢\", key=\"clear_paste\"):\n                st.session_state.paste_key += 1\n                st.rerun()\n    else:\n        st.warning(\"Clipboard lib missing\")\n\n    # ---- YouTube URL ----\n    with st.expander(\"ğŸ“º YouTubeåˆ†æ\", expanded=False):\n        youtube_url = st.text_input(\"URL\", placeholder=\"https://youtu.be/...\", label_visibility=\"collapsed\")\n\n    st.markdown(\"---\")\n    \n    st.markdown(\"---\")\n    \n    # ---- ãƒ¢ãƒ¼ãƒ‰ã‚«ãƒ†ã‚´ãƒªé¸æŠ ----\n    mode_category = st.radio(\n        \"ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ¼ãƒ‰\",\n        [\"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\", \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(é€šå¸¸)\", \"Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter)\"],\n        index=2,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’Puterãƒ¢ãƒ¼ãƒ‰ã«å¤‰æ›´\n        horizontal=True,\n    )\n    \n    # ---- å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ ----\n    if mode_category == \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\":\n        with st.expander(\"ãƒ¢ãƒ¼ãƒ‰è¨­å®š(å¤šå±¤)\", expanded=True):\n            mode_type = st.radio(\n                \"ã‚¿ã‚¤ãƒ—\",\n                [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n                index=0,\n                horizontal=True,\n                label_visibility=\"collapsed\"\n            )\n            \n            if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. (è©¦é¨“ä¸­)ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                        \"2. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                        \"3. (è©¦é¨“ä¸­)ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                        \"4. ç†Ÿè€ƒ(ãƒ¡ã‚¿æ€è€ƒ)+grokæ¤œç´¢å¼·åŒ–ç‰ˆ\",\n                    ],\n                    index=1  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ãƒ¡ã‚¿æ€è€ƒã«å¤‰æ›´\n                )\n            elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                    ],\n                    index=0\n                )\n            else:\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                    ],\n                    index=0\n                )\n    \n    # ---- å¤šå±¤+puterãƒ¢ãƒ¼ãƒ‰ ----\n    elif mode_category == \"Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter)\":\n        with st.expander(\"ãƒ¢ãƒ¼ãƒ‰è¨­å®š(å¤šå±¤+puter)\", expanded=True):\n            mode_type = st.radio(\n                \"ã‚¿ã‚¤ãƒ—\",\n                [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n                index=0,\n                horizontal=True,\n                label_visibility=\"collapsed\"\n            )\n            \n            if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ + é¬¼è»æ›¹(localã®ã¿)\",\n                        \"2. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                        \"3. ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                    ],\n                    index=0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’é¬¼è»æ›¹ã«å¤‰æ›´\n                )\n            elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                    ],\n                    index=0\n                )\n            else:\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                    ],\n                    index=0\n                )\n    \n    # ---- é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ ----\n    else:\n        with st.expander(\"ãƒ¢ãƒ¼ãƒ‰è¨­å®š(é€šå¸¸)\", expanded=True):\n            mode_type = st.radio(\n                \"ã‚¿ã‚¤ãƒ—\",\n                [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n                index=0,\n                horizontal=True,\n                label_visibility=\"collapsed\"\n            )\n            \n            if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                        \"2. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                        \"3. ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                    ],\n                    index=0\n                )\n            elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                    ],\n                    index=0\n                )\n            else:\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                    ],\n                    index=0\n                )\n    \n    strict_mode = False\n    \n    # ---- è¨­å®š (ãƒ¢ãƒ‡ãƒ«ãªã©) ----\n    with st.expander(\"âš™ï¸ è¨­å®š\", expanded=False):\n        model_options = [\n            \"gemini-3-pro-preview\",\n            \"gemini-2.5-pro\",\n            \"gemini-2.5-flash\",\n            \"gemini-2.5-flash-lite\",\n            \"gemini-2.0-flash\",\n        ]\n        model_id = st.selectbox(\"ãƒ¢ãƒ‡ãƒ«ID\", options=model_options, index=0)\n\n        use_search = st.toggle(\"Googleæ¤œç´¢\", value=True)\n        candidate_count = st.slider(\"å€™è£œæ•°\", min_value=1, max_value=3, value=3)\n\n    st.markdown(\"---\")\n\n    # ---- å±¥æ­´æ¤œç´¢ ----\n    search_query = st.text_input(\"ğŸ” å±¥æ­´æ¤œç´¢\", placeholder=\"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰...\")\n    if search_query:\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if search_query.lower() in s[\"title\"].lower():\n                filtered_sessions.append(s)\n                continue\n            found = False\n            for m in s[\"messages\"]:\n                if search_query.lower() in m[\"content\"].lower():\n                    filtered_sessions.append(s)\n                    found = True\n                    break\n            if not found:\n                pass\n    else:\n        # æ¤œç´¢ã—ã¦ã„ãªã„å ´åˆ: ç©ºã®ã€Œæ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã€ã‚’é™¤å¤–ï¼ˆç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯é™¤ãï¼‰\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if s[\"id\"] == st.session_state.current_session_id:\n                filtered_sessions.append(s)\n                continue\n            if s[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(s[\"messages\"]) == 0:\n                continue\n            filtered_sessions.append(s)\n\n    # CSSã§è¦‹ã‚„ã™ãä½¿ã„ã‚„ã™ãæœ€é©åŒ–\n    st.markdown(\"\"\"\n    <style>\n    /* å…¨ä½“ã®ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºç¸®å° */\n    .stApp, .stMarkdown, .stButton, .stSelectbox, .stTextInput, .stTextArea {\n        font-size: 12px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ä½™ç™½ã‚’æ¥µé™ã¾ã§è©°ã‚ã‚‹ */\n    section[data-testid=\"stSidebar\"] .block-container {\n        padding-top: 0.3rem !important;\n        padding-bottom: 0.3rem !important;\n        padding-left: 0.5rem !important;\n        padding-right: 0.5rem !important;\n    }\n    /* å„è¦ç´ é–“ã®éš™é–“ã‚’è©°ã‚ã‚‹ */\n    div[data-testid=\"stVerticalBlock\"] > div {\n        gap: 0.1rem !important;\n    }\n    /* Expanderã®ä½™ç™½å‰Šæ¸› */\n    .streamlit-expanderHeader {\n        font-size: 11px !important;\n        padding-top: 0px !important;\n        padding-bottom: 0px !important;\n        min-height: 1.3rem !important;\n    }\n    .streamlit-expanderContent {\n        padding-top: 0px !important;\n        padding-bottom: 0px !important;\n    }\n    /* éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã®ã‚¿ã‚¤ãƒˆãƒ« */\n    div[data-testid=\"stExpander\"] summary p {\n        font-size: 10px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ */\n    section[data-testid=\"stSidebar\"] button p {\n        font-size: 10px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã« */\n    section[data-testid=\"stSidebar\"] button {\n        padding: 0rem 0.2rem !important;\n        min-height: 1.4rem !important;\n        font-size: 10px !important;\n        margin-bottom: 0px !important;\n    }\n    /* ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®ãƒ©ãƒ™ãƒ«ã‚’å°ã•ã */\n    section[data-testid=\"stSidebar\"] .stRadio label {\n        font-size: 10px !important;\n    }\n    section[data-testid=\"stSidebar\"] .stRadio > label > div {\n        font-size: 10px !important;\n    }\n    /* ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ‡ã‚Šè©°ã‚ã‚‹ï¼ˆæ”¹è¡Œã•ã›ãªã„ï¼‰ */\n    section[data-testid=\"stSidebar\"] label, \n    section[data-testid=\"stSidebar\"] p,\n    section[data-testid=\"stSidebar\"] span {\n        white-space: nowrap !important;\n        overflow: hidden !important;\n        text-overflow: ellipsis !important;\n    }\n    /* åŒºåˆ‡ã‚Šç·š */\n    hr {\n        margin-top: 0.1rem !important;\n        margin-bottom: 0.1rem !important;\n    }\n    /* ãƒ˜ãƒƒãƒ€ãƒ¼ç¸®å° */\n    h1, h2, h3 {\n        padding-top: 0rem !important;\n        padding-bottom: 0rem !important;\n        margin-top: 0rem !important;\n        margin-bottom: 0rem !important;\n    }\n    </style>\n    \"\"\", unsafe_allow_html=True)\n    \n    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§é™é †ã‚½ãƒ¼ãƒˆï¼ˆæœ€æ–°ãŒå…ˆé ­ï¼‰\n    filtered_sessions.sort(key=lambda s: s.get(\"timestamp\", \"\"), reverse=True)\n    \n    # ç›´è¿‘5ä»¶ã¨éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«åˆ†å‰²\n    recent_sessions = filtered_sessions[:5] if len(filtered_sessions) > 5 else filtered_sessions\n    archive_sessions = filtered_sessions[5:] if len(filtered_sessions) > 5 else []\n    \n    # ç›´è¿‘5ä»¶ï¼ˆå¸¸ã«å±•é–‹ï¼‰\n    if recent_sessions:\n        st.markdown(\"**ğŸ“Œ ç›´è¿‘ã®ãƒãƒ£ãƒƒãƒˆ**\")\n        for session in recent_sessions:\n            col1, col2 = st.columns([0.8, 0.2])\n            with col1:\n                if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                    switch_session(session[\"id\"])\n            with col2:\n                if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                    delete_session(session[\"id\"])\n    \n    # éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆæŠ˜ã‚ŠãŸãŸã¿ï¼‰\n    if archive_sessions:\n        with st.expander(f\"ğŸ“œ éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ– ({len(archive_sessions)}ä»¶)\", expanded=False):\n            for session in archive_sessions:\n                col1, col2 = st.columns([0.8, 0.2])\n                with col1:\n                    if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                        switch_session(session[\"id\"])\n                with col2:\n                    if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                        delete_session(session[\"id\"])\n\n    st.markdown(\"---\")\n\n    # ---- ç”»åƒç”Ÿæˆ ----\n    with st.expander(\"ğŸ¨ ç”»åƒç”Ÿæˆ\", expanded=False):\n        img_prompt = st.text_area(\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\", placeholder=\"æœªæ¥çš„ãªéƒ½å¸‚...\")\n        aspect_ratio = st.selectbox(\"æ¯”ç‡\", [\"16:9\", \"1:1\", \"4:3\", \"3:4\", \"9:16\"])\n\n        generate_img_btn = st.button(\"ç”Ÿæˆ\", type=\"primary\", disabled=not img_prompt)\n        if generate_img_btn and img_prompt:\n            st.session_state.generate_image_trigger = {\n                \"prompt\": img_prompt,\n                \"aspect_ratio\": aspect_ratio,\n            }\n\n    st.markdown(\"---\")\n\n    # ---- è©•ä¾¡åˆ†æ ----\n    with st.expander(\"ğŸ“Š å“è³ªåˆ†æ\", expanded=False):\n        total_ratings = 0\n        positive_ratings = 0\n        model_ratings = {}\n\n        for s in st.session_state.sessions:\n            for m in s[\"messages\"]:\n                if \"rating\" in m and m[\"rating\"] is not None:\n                    total_ratings += 1\n                    if m[\"rating\"] == 1:\n                        positive_ratings += 1\n                    if \"metadata\" in m and \"model\" in m[\"metadata\"]:\n                        mod = m[\"metadata\"][\"model\"]\n                        if mod not in model_ratings:\n                            model_ratings[mod] = {\"total\": 0, \"positive\": 0}\n                        model_ratings[mod][\"total\"] += 1\n                        if m[\"rating\"] == 1:\n                            model_ratings[mod][\"positive\"] += 1\n\n        if total_ratings > 0:\n            approval_rate = (positive_ratings / total_ratings) * 100\n            st.metric(\"Positive Ratings\", f\"{positive_ratings}/{total_ratings}\", f\"{approval_rate:.1f}%\")\n            best_model = \"N/A\"\n            best_rate = -1\n            for mod, stats in model_ratings.items():\n                rate = stats[\"positive\"] / stats[\"total\"]\n                if rate > best_rate:\n                    best_rate = rate\n                    best_model = mod\n            if best_model != \"N/A\":\n                st.caption(f\"ğŸ† Best: **{best_model}** ({best_rate*100:.0f}%)\")\n        else:\n            st.caption(\"ãƒ‡ãƒ¼ã‚¿ãªã—\")\n\n    st.markdown(\"---\")\n\n    # ---- ã‚³ã‚¹ãƒˆè¡¨ç¤º ----\n    from logic import load_manual_cost, save_manual_cost, MAX_BUDGET_JPY, TRIAL_LIMIT_JPY, TRIAL_EXPIRY\n    \n    st.subheader(\"ğŸ’° Cost\")\n    st.caption(f\"äºˆç®—: Â¥{MAX_BUDGET_JPY:,.0f}\")\n    st.caption(f\"ä¸Šé™: Â¥{TRIAL_LIMIT_JPY:,.0f}\")\n    st.caption(f\"æœ‰åŠ¹æœŸé™: {TRIAL_EXPIRY}\")\n    \n    # æ‰‹å‹•ã‚³ã‚¹ãƒˆå…¥åŠ›ï¼ˆæ°¸ç¶šåŒ–ï¼‰\n    current_manual_cost = load_manual_cost()\n    manual_cost = st.number_input(\n        \"æ‰‹å‹•å…¥åŠ› (Â¥)\",\n        min_value=0.0,\n        value=current_manual_cost,\n        step=10.0,\n        format=\"%.0f\",\n        key=\"manual_cost_persistent\",\n        help=\"Google Cloud Consoleã§ç¢ºèªã—ãŸå®Ÿéš›ã®ã‚³ã‚¹ãƒˆï¼ˆå††ï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ã“ã®å€¤ã¯ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‰ã˜ã¦ã‚‚ä¿æŒã•ã‚Œã¾ã™ã€‚\"\n    )\n    \n    # å€¤ãŒå¤‰æ›´ã•ã‚ŒãŸã‚‰ä¿å­˜\n    if manual_cost != current_manual_cost:\n        save_manual_cost(manual_cost)\n    \n    st.link_button(\"ğŸ’° Google Cloud Console\", \"https://console.cloud.google.com/welcome/new?_gl=1*kmr691*_up*MQ..&gclid=CjwKCAiAraXJBhBJEiwAjz7MZT0vQsfDK5zunRBCQmuN5iczgI4bP1lHo1Tcrcbqu1KCBE1D22GpFhoCOdgQAvD_BwE&gclsrc=aw.ds&hl=ja&authuser=5&project=sigma-task-479704-r6\")\n\n    st.markdown(\"---\")\n    st.code(f\"PROJECT: {VERTEX_PROJECT}\\nLOCATION: {VERTEX_LOCATION} (Vertex AI)\")\n\n# =========================\n# Main UI\n# =========================\n\ncurrent_session_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\nfor s in st.session_state.sessions:\n    if s[\"id\"] == st.session_state.current_session_id:\n        current_session_title = s[\"title\"]\n        break\n\nst.header(current_session_title)\nst.markdown(\n    \"ä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\"\n)\n\n\n# ---- ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒœã‚¿ãƒ³ (Floating) ----\nst.markdown(\"\"\"\n    <style>\n        .scroll-btn-container {\n            position: fixed;\n            bottom: 100px;\n            right: 20px;\n            z-index: 9999;\n            display: flex;\n            flex-direction: column;\n            gap: 10px;\n        }\n        .scroll-btn {\n            background-color: #f0f2f6;\n            color: #31333F;\n            border: 1px solid #d6d6d8;\n            border-radius: 50%;\n            width: 40px;\n            height: 40px;\n            display: flex;\n            align-items: center;\n            justify-content: center;\n            cursor: pointer;\n            box-shadow: 0 2px 5px rgba(0,0,0,0.1);\n            transition: all 0.3s ease;\n            font-size: 20px;\n            padding: 0;\n            line-height: 1;\n        }\n        .scroll-btn:hover {\n            background-color: #e0e2e6;\n            transform: scale(1.1);\n            box-shadow: 0 4px 8px rgba(0,0,0,0.15);\n        }\n    </style>\n    \n    <script>\n        window.scrollStreamlit = function(direction) {\n            console.log(\"Scroll triggered: \" + direction);\n            \n            // ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ãªã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹è¦ç´ ã‚’é †ç•ªã«è©¦ã™\n            var targets = [];\n            \n            try {\n                if (window.parent && window.parent.document) {\n                    targets.push(window.parent.document.querySelector('section[data-testid=\"stAppViewContainer\"]'));\n                    targets.push(window.parent.document.querySelector('.main'));\n                    targets.push(window.parent.document.documentElement);\n                }\n            } catch (e) {\n                console.log(\"Access to parent window denied\");\n            }\n            \n            // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆiframeå†…ï¼‰\n            targets.push(document.querySelector('section[data-testid=\"stAppViewContainer\"]'));\n            targets.push(document.documentElement);\n\n            var scrolled = false;\n            for (var i = 0; i < targets.length; i++) {\n                var el = targets[i];\n                if (el) {\n                    try {\n                        // ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯èƒ½ãªè¦ç´ ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“çš„ï¼‰\n                        if (el.scrollHeight > el.clientHeight || el === window.parent.document.documentElement) {\n                            console.log(\"Scrolling element:\", el);\n                            if (direction === 'top') {\n                                el.scrollTo({top: 0, behavior: 'smooth'});\n                            } else {\n                                el.scrollTo({top: el.scrollHeight, behavior: 'smooth'});\n                            }\n                            scrolled = true;\n                        }\n                    } catch (e) {\n                        console.error(\"Error scrolling element:\", e);\n                    }\n                }\n            }\n            \n            if (!scrolled) {\n                console.log(\"No scrollable container found, trying window scroll\");\n                try {\n                    if (direction === 'top') {\n                        window.parent.scrollTo({top: 0, behavior: 'smooth'});\n                    } else {\n                        window.parent.scrollTo({top: window.parent.document.body.scrollHeight, behavior: 'smooth'});\n                    }\n                } catch(e) {\n                    window.scrollTo({top: 0, behavior: 'smooth'});\n                }\n            }\n        }\n    </script>\n\n    <div class=\"scroll-btn-container\">\n        <button class=\"scroll-btn\" onclick=\"window.scrollStreamlit('top')\" title=\"Top\">â¬†ï¸</button>\n        <button class=\"scroll-btn\" onclick=\"window.scrollStreamlit('bottom')\" title=\"Bottom\">â¬‡ï¸</button>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n# ---- Vertex AI Client ----\n\n\n\nclient = get_client()\n\n# ---- å±¥æ­´è¡¨ç¤º ----\n\nmessages = get_current_messages()\nfor idx, msg in enumerate(messages):\n    with st.chat_message(msg[\"role\"]):\n        st.markdown(msg[\"content\"])\n        if msg[\"role\"] == \"model\":\n            col1, col2, col3 = st.columns([0.1, 0.1, 0.8])\n            current_rating = msg.get(\"rating\")\n            with col1:\n                if st.button(\"ğŸ‘\", key=f\"up_{idx}\"):\n                    messages[idx][\"rating\"] = 1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col2:\n                if st.button(\"ğŸ‘\", key=f\"down_{idx}\"):\n                    messages[idx][\"rating\"] = -1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col3:\n                if current_rating == 1:\n                    st.caption(\"âœ… é«˜è©•ä¾¡\")\n                elif current_rating == -1:\n                    st.caption(\"âŒ ä½è©•ä¾¡\")\n\n# ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒœã‚¿ãƒ³ï¼ˆé•·ã„ãƒãƒ£ãƒƒãƒˆç”¨ï¼‰\nif len(messages) > 5:\n    st.markdown(\"\"\"\n    <div style=\"position: fixed; right: 20px; bottom: 100px; z-index: 999;\">\n        <button onclick=\"window.scrollTo({top: 0, behavior: 'smooth'})\" \n                style=\"display: block; margin: 5px; padding: 10px 15px; font-size: 24px; cursor: pointer; \n                       border: 2px solid #ccc; border-radius: 50%; background: white; box-shadow: 0 2px 8px rgba(0,0,0,0.2);\">\n            â¬†ï¸\n        </button>\n        <button onclick=\"window.scrollTo({top: document.body.scrollHeight, behavior: 'smooth'})\" \n                style=\"display: block; margin: 5px; padding: 10px 15px; font-size: 24px; cursor: pointer; \n                       border: 2px solid #ccc; border-radius: 50%; background: white; box-shadow: 0 2px 8px rgba(0,0,0,0.2);\">\n            â¬‡ï¸\n        </button>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n\n# =========================\n# ç”»åƒç”Ÿæˆãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°\n# =========================\n\nif hasattr(st.session_state, \"generate_image_trigger\") and st.session_state.generate_image_trigger:\n    img_data = st.session_state.generate_image_trigger\n    del st.session_state.generate_image_trigger\n\n    with st.chat_message(\"user\"):\n        st.markdown(f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\")\n        st.caption(f\"ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”: {img_data['aspect_ratio']}\")\n\n    messages.append({\"role\": \"user\", \"content\": f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\"})\n    update_current_session_messages(messages)\n\n    with st.chat_message(\"assistant\"):\n        with st.status(\"ç”»åƒã‚’ç”Ÿæˆä¸­...\", expanded=True) as status:\n            try:\n                config = types.GenerateContentConfig(\n                    response_modalities=[\"IMAGE\"],\n                    image_config=types.ImageConfig(\n                        aspect_ratio=img_data[\"aspect_ratio\"]\n                    ),\n                )\n                status.write(\"Gemini 3 Pro Imageã§ç”Ÿæˆä¸­...\")\n                response = client.models.generate_content(\n                    model=\"gemini-3-pro-image-preview\",\n                    contents=img_data[\"prompt\"],\n                    config=config,\n                )\n\n                generated_image = None\n\n                # ç”»åƒã‚’å–ã‚Šå‡ºã™\n                if getattr(response, \"candidates\", None):\n                    for candidate in response.candidates:\n                        if getattr(candidate, \"content\", None) and candidate.content.parts:\n                            for part in candidate.content.parts:\n                                if getattr(part, \"inline_data\", None):\n                                    try:\n                                        generated_image = part.as_image()\n                                    except AttributeError:\n                                        image_bytes_raw = part.inline_data.data\n                                        generated_image = Image.open(io.BytesIO(image_bytes_raw))\n                                    break\n                        if generated_image is not None:\n                            break\n\n                if generated_image is not None:\n                    st.image(generated_image, caption=img_data[\"prompt\"])\n                    buf = io.BytesIO()\n                    generated_image.save(buf, format=\"PNG\")\n                    image_bytes = buf.getvalue()\n                    st.download_button(\n                        label=\"ğŸ’¾ ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\",\n                        data=image_bytes,\n                        file_name=f\"generated_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png\",\n                        mime=\"image/png\",\n                    )\n                    messages.append(\n                        {\"role\": \"model\", \"content\": f\"âœ… ç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {img_data['prompt']}\"}\n                    )\n                    update_current_session_messages(messages)\n                    status.update(label=\"âœ… ç”»åƒç”Ÿæˆå®Œäº†\", state=\"complete\")\n                else:\n                    st.error(\"ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")\n                    status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n\n            except Exception as e:\n                status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n                st.error(f\"ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}\")\n\n# =========================\n# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›\n# =========================\n\nprompt = st.chat_input(\"ä½•ã‹èã„ã¦ãã ã•ã„...\", disabled=stop_generation)\n\nif prompt:\n    if stop_generation:\n        st.error(\"äºˆç®—ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚\")\n    else:\n        # ---- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€è¡¨ç¤º ----\n        with st.chat_message(\"user\"):\n            st.markdown(prompt)\n            if uploaded_files:\n                for uf in uploaded_files:\n                    st.caption(f\"ğŸ“ æ·»ä»˜: {uf.name}\")\n            if youtube_url:\n                st.caption(f\"ğŸ“º YouTube: {youtube_url}\")\n            if pasted_image_bytes:\n                st.caption(\"ğŸ“‹ ç”»åƒãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚Œã¾ã—ãŸ\")\n\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        update_current_session_messages(messages)\n\n        # ---- ãƒ¢ãƒ‡ãƒ«å¿œç­” ----\n        with st.chat_message(\"assistant\"):\n            status_container = st.status(\"æ€è€ƒä¸­...\", expanded=True)\n            try:\n                # ä¼šè©±å±¥æ­´\n                model_history = []\n                for msg in messages[:-1]:\n                    model_history.append(\n                        types.Content(\n                            role=msg[\"role\"],\n                            parts=[types.Part.from_text(text=msg[\"content\"])],\n                        )\n                    )\n\n                # ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³\n                current_parts = [types.Part.from_text(text=prompt)]\n\n                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«\n                for uploaded_file in uploaded_files or []:\n                    try:\n                        mime_type = get_mime_type(uploaded_file.name)\n                        bytes_data = uploaded_file.getvalue()\n                        part = types.Part.from_bytes(data=bytes_data, mime_type=mime_type)\n                        current_parts.append(part)\n                        status_container.write(f\"ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™å®Œäº†: {uploaded_file.name}\")\n                    except Exception as e:\n                        status_container.error(\n                            f\"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {uploaded_file.name} - {e}\"\n                        )\n\n                # è²¼ã‚Šä»˜ã‘ç”»åƒ\n                if pasted_image_bytes:\n                    import base64\n\n                    status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã‚’å‡¦ç†ä¸­...\")\n                    try:\n                        if isinstance(pasted_image_bytes, str):\n                            if pasted_image_bytes.startswith(\"data:\"):\n                                base64_str = pasted_image_bytes.split(\",\", 1)[1]\n                                image_bytes_decoded = base64.b64decode(base64_str)\n                            else:\n                                image_bytes_decoded = base64.b64decode(pasted_image_bytes)\n                        else:\n                            image_bytes_decoded = pasted_image_bytes\n                        part = types.Part.from_bytes(\n                            data=image_bytes_decoded, mime_type=\"image/png\"\n                        )\n                        current_parts.append(part)\n                        status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®æº–å‚™å®Œäº†\")\n                    except Exception as e:\n                        status_container.error(f\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n\n                # YouTube å­—å¹•\n                if youtube_url:\n                    vid_id = extract_youtube_id(youtube_url)\n                    if vid_id:\n                        status_container.write(\"YouTubeã®å­—å¹•ã‚’å–å¾—ä¸­...\")\n                        transcript_text = get_youtube_transcript(vid_id)\n                        current_parts.append(\n                            types.Part.from_text(text=f\"YouTube Transcript:\\n{transcript_text}\")\n                        )\n                    else:\n                        status_container.write(\"ç„¡åŠ¹ãªYouTube URLã§ã™ã€‚\")\n\n                contents_for_model = model_history + [\n                    types.Content(role=\"user\", parts=current_parts)\n                ]\n\n                # ---- Tool / Config ----\n                tools = []\n                final_candidate_count = candidate_count\n                if use_search:\n                    tools.append(types.Tool(google_search=types.GoogleSearch()))\n                    final_candidate_count = 1\n\n                # â˜… System Instruction ã®æ”¹å–„: ãƒ¡ã‚¿ç™ºè¨€ç¦æ­¢ã¨ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªæŒ¯ã‚‹èˆã„ã‚’æŒ‡ç¤º\n                base_system_instruction = (\n                    \"ã‚ãªãŸã¯é«˜åº¦ãªçŸ¥æ€§ã‚’æŒã¤å°‚é–€çš„ãªãƒªã‚µãƒ¼ãƒãƒ»ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\\n\"\n                    \"ä»¥ä¸‹ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’å³å®ˆã—ã¦ãã ã•ã„ï¼š\\n\"\n                    \"1. **ãƒ¡ã‚¿ç™ºè¨€ã®ç¦æ­¢**: ã€Œç§ã¯AIã§ã™ã€ã€Œä¸–ç•Œæœ€é«˜å³°ã®ï½ã¨ã—ã¦ã€ãªã©ã®è‡ªå·±è¨€åŠã‚„å‰ç½®ãã¯ä¸€åˆ‡è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚\\n\"\n                    \"2. **æ„å›³ã®æ±²ã¿å–ã‚Š**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã®èƒŒå¾Œã«ã‚ã‚‹æ„å›³ï¼ˆæ–‡è„ˆã€æš—é»™ã®å‰æï¼‰ã‚’æ¨æ¸¬ã—ã€è¨€è‘‰é€šã‚Šã§ã¯ãªãã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ¬å½“ã«çŸ¥ã‚ŠãŸã„ã“ã¨ã€ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n\"\n                    \"3. **æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”**: çµè«–ã‚’å…ˆã«è¿°ã¹ã€ãã®å¾Œã«è©³ç´°ãªæ ¹æ‹ ã€ã‚·ãƒŠãƒªã‚ªåˆ†æã€ãƒªã‚¹ã‚¯è¦å› ã‚’è«–ç†çš„ã«å±•é–‹ã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"4. **å®¢è¦³æ€§**: äºˆæ¸¬ã‚’è¡Œã†å ´åˆã¯ã€æ–­å®šã‚’é¿ã‘ã€è¤‡æ•°ã®ã‚·ãƒŠãƒªã‚ªï¼ˆæ¥½è¦³ã€æ‚²è¦³ã€ä¸­ç«‹ï¼‰ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"5. **å¼•ç”¨**: æ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸå ´åˆã¯ã€å¿…ãšæƒ…å ±æºã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚\"\n                )\n\n                final_answer = \"\"\n                grounding_metadata = None\n                \n                # =========================\n                # ãƒ¢ãƒ¼ãƒ‰è¨­å®šã®è§£æ\n                # =========================\n                # Î²1é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ä»¥å¤–ã¯ãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œ\n                enable_research = \"Î²1\" not in response_mode\n                enable_meta = \"ãƒ¡ã‚¿\" in response_mode or \"MAX\" in response_mode\n                enable_strict = \"é¬¼è»æ›¹\" in response_mode or \"MAX\" in response_mode\n                enable_grok_x_search = \"grokæ¤œç´¢å¼·åŒ–ç‰ˆ\" in response_mode\n\n                # =========================\n                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (é«˜é€Ÿ / é¬¼è»æ›¹)\n                # =========================\n                if not enable_research:\n                    config = types.GenerateContentConfig(\n                        temperature=0.7,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=base_system_instruction,\n                    )\n                    \n                    status_container.write(\"å›ç­”ç”Ÿæˆä¸­...\")\n                    response = client.models.generate_content(\n                        model=model_id,\n                        contents=contents_for_model,\n                        config=config,\n                    )\n                    \n                    final_answer = extract_text_from_response(response)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®—\n                    if response.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            response.usage_metadata.prompt_token_count,\n                            response.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += response.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += response.usage_metadata.candidates_token_count\n\n                    # é¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ (é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ç‰ˆ)\n                    if enable_strict:\n                        status_container.write(\"ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        reviewer_instruction = base_system_instruction + \"\"\"\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n                        review_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\nåˆç‰ˆå›ç­”:\\n{final_answer}\\n\\nãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\")])]\n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=types.GenerateContentConfig(temperature=0.1, candidate_count=1, system_instruction=reviewer_instruction)\n                        )\n                        final_answer = extract_text_from_response(review_resp)\n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        \n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(model_id, review_resp.usage_metadata.prompt_token_count, review_resp.usage_metadata.candidates_token_count)\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n\n                # =========================\n                # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰\n                # =========================\n                else:\n                    # =========================\n                    # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰: å¤šæ®µéšã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ \n                    # =========================\n                    \n                    # --- Phase 1: ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 1: ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    import datetime as dt\n                    current_year = dt.datetime.now().year\n                    \n                    research_instruction = base_system_instruction + f\"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒªã‚µãƒ¼ãƒå°‚ä»»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚æœ€çµ‚å›ç­”ã¯æ›¸ã‹ãšã€äº‹å®Ÿåé›†ã«é›†ä¸­ã™ã‚‹ã“ã¨ã€‚\n\n**èª¿æŸ»è¦³ç‚¹**:\n- è³ªå•ã«é–¢é€£ã™ã‚‹**æœ€æ–°ã®äº‹å®Ÿãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ»çµ±è¨ˆ**ï¼ˆ**{current_year}å¹´ã®æƒ…å ±ã‚’æœ€å„ªå…ˆ**ï¼‰\n- **ç¾æ™‚ç‚¹ã§å­˜åœ¨ã™ã‚‹å…¨ã¦ã®é¸æŠè‚¢ãƒ»ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¶²ç¾…çš„ã«èª¿æŸ»**ï¼ˆä¾‹: è£½å“æ¯”è¼ƒãªã‚‰ã€æœ€æ–°ç‰ˆã ã‘ã§ãªãç›´è¿‘ã®å…¨ä¸–ä»£ã‚’èª¿æŸ»ï¼‰\n- å…¬å¼æƒ…å ±ã‚„ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã‹ã‚‰ã®å¼•ç”¨\n- é–¢é€£ã™ã‚‹èƒŒæ™¯æƒ…å ±ã‚„æ–‡è„ˆ\n- ç«¶åˆãƒ»ä»£æ›¿æ¡ˆãƒ»æ¯”è¼ƒå¯¾è±¡ã®**å®Œå…¨ãªãƒªã‚¹ãƒˆ**\n- ãƒªã‚¹ã‚¯ãƒ»åˆ¶ç´„ãƒ»æ³¨æ„ç‚¹ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n- å‚è€ƒã«ã—ãŸä¸»è¦ãªæƒ…å ±æºã®URL\n\n**é‡è¦**: \n- çµè«–ã‚„æ¨å¥¨ã¯æ›¸ã‹ãšã€å¾Œå·¥ç¨‹ãŒåˆ¤æ–­ã§ãã‚‹èª¿æŸ»ãƒ¡ãƒ¢ã«é›†ä¸­ã™ã‚‹ã“ã¨\n- **å¿…ãšæ¤œç´¢æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã€æœ€æ–°ã®æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã“ã¨**\n- **æ¤œç´¢çµæœã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æ—¥ä»˜ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒ»ãƒ¢ãƒ‡ãƒ«åã‚’å„ªå…ˆçš„ã«è¨˜è¼‰ã™ã‚‹ã“ã¨**\n- **æ¯”è¼ƒå¯¾è±¡ã¨ãªã‚‹é¸æŠè‚¢ã‚’è¦‹è½ã¨ã•ãªã„ã‚ˆã†ã€è¤‡æ•°ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è©¦ã™ã“ã¨**ï¼ˆä¾‹: ã€ŒiPhone æœ€æ–°ãƒ¢ãƒ‡ãƒ« {current_year}ã€ã€ŒiPhone {current_year}å¹´ç™ºå£²ã€ãªã©ï¼‰\n- **ã€Œã“ã‚Œã‚ˆã‚Šæ–°ã—ã„ãƒ¢ãƒ‡ãƒ«/ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯å­˜åœ¨ã—ãªã„ã‹ï¼Ÿã€ã‚’å¸¸ã«ç¢ºèªã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ï¼ˆ{current_year-1}å¹´ä»¥å‰ãªã©ï¼‰ã—ã‹è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãã®æ—¨ã‚’æ˜è¨˜ã™ã‚‹ã“ã¨\n\"\"\"\n\n                    # éå»ã®é–¢é€£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—\n                    past_context = get_relevant_context(prompt, st.session_state.sessions, st.session_state.current_session_id)\n                    \n                    # ãƒªã‚µãƒ¼ãƒç”¨ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ§‹ç¯‰\n                    import datetime as dt\n                    current_date = dt.datetime.now().strftime(\"%Yå¹´%mæœˆ%dæ—¥\")\n                    research_parts = [types.Part(text=(\n                        f\"é‡è¦: ä»Šæ—¥ã¯{current_date}ã§ã™ã€‚ã“ã®æ—¥ä»˜ã‚ˆã‚Šæ–°ã—ã„æƒ…å ±ã‚’å„ªå…ˆã—ã¦ãã ã•ã„ã€‚\\n\\n\"\n                        f\"è³ªå•: {prompt}\"\n                    ))]\n                    \n                    if past_context:\n                        research_parts.insert(0, types.Part(text=\"ä»¥ä¸‹ã¯éå»ã®é–¢é€£ãƒãƒ£ãƒƒãƒˆã‹ã‚‰æŠ½å‡ºã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã™ï¼š\\n\\n\" + past_context))\n                    \n                    research_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=research_parts)\n                    ]\n                    \n                    research_config = types.GenerateContentConfig(\n                        temperature=0.4,  # æœ€æ–°æƒ…å ±ã‚’æŸ”è»Ÿã«æ¡ç”¨ã™ã‚‹ãŸã‚0.2â†’0.4ã«ä¸Šæ˜‡\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=research_instruction,\n                    )\n                    \n                    research_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=research_contents,\n                        config=research_config,\n                    )\n                    \n                    research_text = extract_text_from_response(research_resp)\n                    \n                    # ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºã®ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ±ã‚’ä¿å­˜\n                    if research_resp.candidates and research_resp.candidates[0].grounding_metadata:\n                        grounding_metadata = research_resp.candidates[0].grounding_metadata\n                    \n                    status_container.write(\"âœ“ ãƒªã‚µãƒ¼ãƒå®Œäº†\")\n                    with status_container.expander(\"åé›†ã—ãŸèª¿æŸ»ãƒ¡ãƒ¢\", expanded=False):\n                        st.markdown(research_text)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1)\n                    if research_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            research_resp.usage_metadata.prompt_token_count,\n                            research_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += research_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += research_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 1.5: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    questions_text = \"\"\n                    if enable_meta:\n                        status_container.write(\"Phase 1.5: ãƒ¡ã‚¿è³ªå•ç”Ÿæˆä¸­...\")\n                        \n                        question_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ç›®çš„**: \nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•ã¨èª¿æŸ»ãƒ¡ãƒ¢ã‚’è¸ã¾ãˆã¦ã€ã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±ãç†è§£ã™ã‚‹ãŸã‚ã®ã€Œé‹­ã„ã‚µãƒ–è³ªå•ã€ã‚’ä½œæˆã™ã‚‹ã“ã¨ã€‚\n\n**ãƒ«ãƒ¼ãƒ«**:\n- æœ€å¤§5å€‹ã¾ã§\n- å„è³ªå•ã¯1-2è¡Œã§å…·ä½“çš„ã‹ã¤é‹­ã\n- ä»¥ä¸‹ã®è¦³ç‚¹ã‚’æ„è­˜:\n  1. å‰æãŒå´©ã‚Œã‚‹å¯èƒ½æ€§ã¯ã©ã“ã‹ï¼Ÿ\n  2. å¼·æ°—/å¼±æ°—ã‚·ãƒŠãƒªã‚ªã®åˆ†å²ç‚¹ã¯ä½•ã‹ï¼Ÿ\n  3. ç«¶åˆãƒ»æŠ€è¡“ãƒ»è¦åˆ¶ã®ä¸ç¢ºå®Ÿæ€§ã¯ï¼Ÿ\n  4. ã€Œäºˆæ¸¬ãŒå¤–ã‚Œã‚‹ã¨ã—ãŸã‚‰ã©ã‚“ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ï¼Ÿã€\n\n**å‡ºåŠ›**: ç®‡æ¡æ›¸ãï¼ˆQ1, Q2...ï¼‰ã®ã¿\n\"\"\"\n\n                        question_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•:\\n{prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\nã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±æ˜ã‚Šã™ã‚‹ãŸã‚ã®é‡è¦ãªã‚µãƒ–è³ªå•ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\")])]\n                        \n                        question_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=question_contents,\n                            config=types.GenerateContentConfig(\n                                temperature=0.4,\n                                candidate_count=1,\n                                system_instruction=question_instruction,\n                            )\n                        )\n                        \n                        questions_text = extract_text_from_response(question_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¡ã‚¿è³ªå•ç”Ÿæˆå®Œäº†\")\n                        with status_container.expander(\"ç”Ÿæˆã•ã‚ŒãŸãƒ¡ã‚¿è³ªå•\", expanded=False):\n                            st.markdown(questions_text)\n                        \n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += question_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += question_resp.usage_metadata.candidates_token_count\n\n                    # å¤šå±¤+puterãƒ¢ãƒ¼ãƒ‰ã®é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã‹ãƒã‚§ãƒƒã‚¯\n                    is_puter_onigunsou = (\n                        mode_category == \"Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter)\" and\n                        response_mode == \"1. ç†Ÿè€ƒ + é¬¼è»æ›¹(localã®ã¿)\"\n                    )\n\n                    # --- Phase 1.5b: Grok ç‹¬ç«‹æ€è€ƒ (å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    # --- Phase 1.5b: Grok ç‹¬ç«‹æ€è€ƒ (å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    grok_thought = \"\"\n                    grok_status = \"skipped\"\n                    if enable_meta and OPENROUTER_API_KEY:\n                        status_container.write(\"Phase 1.5b: Grok ç‹¬ç«‹æ€è€ƒä¸­...\")\n                        try:\n                            grok_thought = think_with_grok(prompt, research_text, enable_x_search=enable_grok_x_search)\n                            if grok_thought:\n                                grok_status = \"success\"\n                                status_container.write(\"âœ“ Grok 4.1 Fast Free ç‹¬ç«‹æ€è€ƒå®Œäº†\")\n                                with status_container.expander(\"Grokã®ç‹¬ç«‹å›ç­”æ¡ˆ\", expanded=False):\n                                    st.markdown(grok_thought)\n                            else:\n                                grok_status = \"empty\"\n                        except Exception as e:\n                            grok_status = \"error\"\n                            status_container.write(f\"âš  Grokæ€è€ƒã‚¨ãƒ©ãƒ¼: {e}\")\n\n                    # --- Phase 1.5c: Claude Opus 4.5 ç‹¬ç«‹æ€è€ƒ (å¤šå±¤+puterã®é¬¼è»æ›¹ã®ã¿) ---\n                    # --- Phase 1.5c: Claude Opus 4.5 ç‹¬ç«‹æ€è€ƒ (å¤šå±¤+puterã®é¬¼è»æ›¹ã®ã¿) ---\n                    claude_thought = \"\"\n                    claude_status = \"skipped\"\n                    if is_puter_onigunsou and PUTER_USERNAME and PUTER_PASSWORD:\n                        status_container.write(\"Phase 1.5c: Claude Opus 4.5 ç‹¬ç«‹æ€è€ƒä¸­...\")\n                        try:\n                            claude_thought = call_claude_opus_via_puter(\n                                user_question=prompt,\n                                research_text=research_text,\n                                system_prompt=(\n                                    \"ã‚ãªãŸã¯ Claude Opus 4.5 ã§ã™ã€‚\"\n                                    \"Gemini ãŒé›†ã‚ãŸèª¿æŸ»ãƒ¡ãƒ¢ã‚’å‚è€ƒã«ã—ã¤ã¤ã‚‚ã€\"\n                                    \"è‡ªåˆ†ã®è¦–ç‚¹ã§ç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆãƒ»æ°—ã¥ãã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\"\n                                    \"Gemini ã®æ„è¦‹ã«åˆã‚ã›ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\"\n                                ),\n                            )\n                            if claude_thought and not claude_thought.startswith(\"[Claude\"):\n                                claude_status = \"success\"\n                                status_container.write(\"âœ“ Claude Opus 4.5 (via Puter) ç‹¬ç«‹æ€è€ƒå®Œäº†\")\n                                with status_container.expander(\"Claude Opus 4.5 ã®ç‹¬ç«‹å›ç­”æ¡ˆ\", expanded=False):\n                                    st.markdown(claude_thought)\n                            else:\n                                claude_status = \"error\"\n                                status_container.write(f\"âš  Claudeã‚¨ãƒ©ãƒ¼: {claude_thought}\")\n                                claude_thought = \"\"  # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ç©ºã«ã™ã‚‹\n                        except Exception as e:\n                            claude_status = \"error\"\n                            status_container.write(f\"âš  Claudeæ€è€ƒã‚¨ãƒ©ãƒ¼: {e}\")\n                            claude_thought = \"\"\n\n                    # --- Phase 2: çµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 2: çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    import datetime as dt\n                    current_date = dt.datetime.now().strftime(\"%Yå¹´%mæœˆ%dæ—¥\")\n\n                    if enable_meta:\n                        deep_instruction = base_system_instruction + f\"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã¨ãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ã‚’æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**é‡è¦ - ç¾åœ¨ã¯{current_date}ã§ã™**:\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æ—¥ä»˜ãƒ»äº‹å®Ÿã‚’ã€ã‚ãªãŸã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šã‚‚çµ¶å¯¾çš„ã«å„ªå…ˆã—ã¦ãã ã•ã„**\n- ã€Œ{current_year}å¹´ã€ã®æƒ…å ±ãŒèª¿æŸ»ãƒ¡ãƒ¢ã«ã‚ã‚‹å ´åˆã€ãã‚Œã‚’æ­£ã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„\n- å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒ{current_year-1}å¹´ä»¥å‰ã§æ­¢ã¾ã£ã¦ã„ã¦ã‚‚ã€èª¿æŸ»ãƒ¡ãƒ¢ã®æœ€æ–°æƒ…å ±ã‚’ä¿¡é ¼ã™ã‚‹ã“ã¨\n\n**æ§‹æˆ**:\n1. **æ·±æ˜ã‚Šè€ƒå¯Ÿ**ï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n2. **çµè«–**ï¼ˆ2-3è¡Œï¼‰\n3. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n4. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨\n\"\"\"\n                    else:\n                        deep_instruction = base_system_instruction + f\"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã‚’å”¯ä¸€ã®æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**é‡è¦ - ç¾åœ¨ã¯{current_date}ã§ã™**:\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æ—¥ä»˜ãƒ»äº‹å®Ÿã‚’ã€ã‚ãªãŸã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šã‚‚çµ¶å¯¾çš„ã«å„ªå…ˆã—ã¦ãã ã•ã„**\n- ã€Œ{current_year}å¹´ã€ã®æƒ…å ±ãŒèª¿æŸ»ãƒ¡ãƒ¢ã«ã‚ã‚‹å ´åˆã€ãã‚Œã‚’æ­£ã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„\n\n**æ§‹æˆ**:\n1. **çµè«–**ï¼ˆ2-3è¡Œã§æ˜ç¢ºã«ï¼‰\n2. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n3. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«åã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ã¨æ–°ã—ã„æƒ…å ±ãŒæ··åœ¨ã™ã‚‹å ´åˆã¯ã€æ–°ã—ã„æƒ…å ±ã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n\"\"\"\n                    \n                    synthesis_prompt_text = (\n                        f\"é‡è¦: ä»Šæ—¥ã¯{current_date}ã§ã™ã€‚å¤ã„æƒ…å ±ã‚’å›ç­”ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚\\n\\n\"\n                        f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}\\n\\n\"\n                        f\"==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                    )\n                    \n                    if enable_meta and questions_text:\n                        synthesis_prompt_text += f\"==== ãƒ¡ã‚¿è³ªå•ä¸€è¦§ ====\\n{questions_text}\\n==== ãƒ¡ã‚¿è³ªå•ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if enable_meta and grok_thought:\n                        synthesis_prompt_text += f\"==== åˆ¥è¦–ç‚¹ã‹ã‚‰ã®å›ç­”æ¡ˆ (Grok) ====\\n{grok_thought}\\n==== åˆ¥è¦–ç‚¹ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if is_puter_onigunsou and claude_thought:\n                        synthesis_prompt_text += f\"==== åˆ¥è¦–ç‚¹ã‹ã‚‰ã®å›ç­”æ¡ˆ (Claude Opus 4.5 via Puter) ====\\n{claude_thought}\\n==== Claudeåˆ¥è¦–ç‚¹ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    # çµ±åˆæŒ‡ç¤º\n                    if enable_meta and (grok_thought or claude_thought):\n                        synthesis_prompt_text += \"æŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n2. Grok\"\n                        if is_puter_onigunsou and claude_thought:\n                            synthesis_prompt_text += \" / Claude\"\n                        synthesis_prompt_text += \" ã®å›ç­”æ¡ˆã‚‚å‚è€ƒã«ã—ã¤ã¤ï¼ˆãŸã ã—ç›²ä¿¡ã›ãšï¼‰ã€ç‹¬è‡ªã®è¦–ç‚¹ã§çµ±åˆã—ã¦ãã ã•ã„ã€‚\\n3. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»åˆ†æãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    elif enable_meta and questions_text:\n                        synthesis_prompt_text += \"æŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n2. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»åˆ†æãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    else:\n                        synthesis_prompt_text += \"ä¸Šè¨˜ãƒ¡ãƒ¢ã‚’æ ¹æ‹ ã«ã€æœ€çµ‚å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å¿…ãšä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚**\"\n\n                    synthesis_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=[\n                            types.Part(text=synthesis_prompt_text)\n                        ])\n                    ]\n                    \n                    synthesis_config = types.GenerateContentConfig(\n                        temperature=0.3,\n                        candidate_count=1,\n                        tools=[],  # çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºã§ã¯æ¤œç´¢OFF\n                        system_instruction=deep_instruction,\n                    )\n                    \n                    synthesis_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=synthesis_contents,\n                        config=synthesis_config,\n                    )\n                    \n                    draft_answer = extract_text_from_response(synthesis_resp)\n                    \n                    status_container.write(\"âœ“ çµ±åˆå®Œäº†\")\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 2)\n                    if synthesis_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            synthesis_resp.usage_metadata.prompt_token_count,\n                            synthesis_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += synthesis_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += synthesis_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    if enable_strict:\n                        status_container.write(\"Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        \n\n                        reviewer_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™ã€‚ãŸã ã—ã€**èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’å„ªå…ˆã—ã€æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã™ã‚‹ã“ã¨**ã€‚\n\n**ãƒ¬ãƒ“ãƒ¥ãƒ¼è¦³ç‚¹**:\n- äº‹å®Ÿã¨æ¨æ¸¬ã‚’æ˜ç¢ºã«åˆ†ã‘ã‚‹\n- éåº¦ã«è‡ªä¿¡ã®ã‚ã‚‹æ–­å®šã‚’å¼±ã‚ã‚‹\n- æ•°å­—ã‚„å›ºæœ‰åè©ãŒèª¿æŸ»ãƒ¡ãƒ¢ã¨çŸ›ç›¾ã—ã¦ã„ãªã„ã‹ç¢ºèª\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ãƒ¢ãƒ‡ãƒ«ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ãŒæ­£ã—ãä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª**\n- **å¤ã„æƒ…å ±ã§ä¸Šæ›¸ãã—ã¦ã„ãªã„ã‹ç¢ºèª**\n- è¦‹è½ã¨ã—ã¦ã„ã‚‹é‡è¦ãªãƒªã‚¹ã‚¯ãƒ»ã‚·ãƒŠãƒªã‚ªãŒã‚ã‚Œã°è¿½åŠ \n\n**é‡è¦**: \n- èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ãŒæœ€æ–°ã§ã‚ã‚‹å ´åˆã€ãã‚Œã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n- ã‚ãªãŸã®çŸ¥è­˜ãŒå¤ã„å ´åˆã¯ã€èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’ä¿¡é ¼ã™ã‚‹ã“ã¨\n\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n\n                        review_contents = [\n                            types.Content(role=\"user\", parts=[\n                                types.Part.from_text(\n                                    text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\n\"\n                                    f\"==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                                    f\"åˆç‰ˆå›ç­”:\\n{draft_answer}\\n\\n\"\n                                    \"ä¸Šè¨˜ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚**\"\n                                )\n                            ])\n                        ]\n                        \n                        review_config = types.GenerateContentConfig(\n                            temperature=0.1,\n                            candidate_count=1,\n                            system_instruction=reviewer_instruction,\n                            thinking_config=types.ThinkingConfig(\n                                thinking_level=types.ThinkingLevel.HIGH\n                            ),\n                        )\n                        \n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=review_config,\n                        )\n                        \n                        final_answer = extract_text_from_response(review_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        \n                        # --- Phase 3b: Groké¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ (å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ + é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰å…¨èˆ¬) ---\n                        # å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã§ã€ã‹ã¤é¬¼è»æ›¹ç³»ã®ãƒ¢ãƒ¼ãƒ‰ï¼ˆé¬¼è»æ›¹ã€ãƒ¡ã‚¿æ€è€ƒã€æœ¬æ°—MAXï¼‰ã§ç™ºå‹•\n                        use_grok_reviewer = (mode_category == \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\" and enable_strict)\n                        \n                        if use_grok_reviewer and OPENROUTER_API_KEY:\n                            status_container.write(\"Phase 3b: Grok 4.1 Fast ã§æœ€çµ‚ãƒã‚§ãƒƒã‚¯ä¸­...\")\n                            try:\n                                grok_answer = review_with_grok(prompt, final_answer, research_text)\n                                # Grokä½¿ç”¨æ™‚ã¯ã€ãƒ¢ãƒ‡ãƒ«åã‚’æ˜ç¤ºã—ã€2æ®µæ§‹æˆã§è¡¨ç¤º\n                                final_answer = (\n                                    f\"**ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_id} (Deep Thinking / High Reasoning)**\\n\"\n                                    f\"**ãƒ¬ãƒ“ãƒ¥ã‚¢: Grok 4.1 Fast (free)**\\n\"\n                                    f\"**ãƒ¢ãƒ¼ãƒ‰: {response_mode}**\\n\\n\"\n                                    \"---\\n\\n\"\n                                    \"## âœ… æœ€çµ‚å›ç­”ï¼ˆGeminiçµ±åˆç‰ˆï¼‰\\n\\n\"\n                                    f\"{final_answer}\\n\\n\"\n                                    \"---\\n\\n\"\n                                    \"## ğŸ” Grok ã«ã‚ˆã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼\\n\\n\"\n                                    f\"{grok_answer}\"\n                                )\n                                status_container.write(\"âœ“ Grokæœ€çµ‚ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                            except Exception as e:\n                                status_container.write(f\"âš  Grokãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}\")\n                        else:\n                            # Geminiã®ã¿ã®å ´åˆã‚‚ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤ºï¼ˆå¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆï¼‰\n                            if mode_category == \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\":\n                                final_answer = (\n                                    f\"**ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_id} (Deep Thinking / High Reasoning)**\\n\"\n                                    f\"**ãƒ¢ãƒ¼ãƒ‰: {response_mode}**\\n\\n---\\n\\n{final_answer}\"\n                                )\n                        \n                        # --- ãƒ¡ã‚¿æ€è€ƒãƒ¢ãƒ¼ãƒ‰: çµè«–ã‚’å…ˆå‡ºã—ã™ã‚‹ ---\n                        if \"ãƒ¡ã‚¿æ€è€ƒ\" in response_mode:\n                            # çµè«–éƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆç°¡æ˜“çš„ãªå®Ÿè£…ï¼‰\n                            # \"çµè«–\"ã‚„\"ã¾ã¨ã‚\"ãªã©ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¢ã—ã¦å…ˆé ­ã«ç§»å‹•\n                            lines = final_answer.split('\\n')\n                            conclusion_start = -1\n                            for i, line in enumerate(lines):\n                                if any(keyword in line for keyword in ['## çµè«–', '## ã¾ã¨ã‚', '**çµè«–**', '**ã¾ã¨ã‚**']):\n                                    conclusion_start = i\n                                    break\n                            \n                            if conclusion_start != -1:\n                                # çµè«–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¦‹ã¤ã‘ãŸå ´åˆã€ãã‚Œã‚’å…ˆé ­ã«ç§»å‹•\n                                conclusion_section = []\n                                other_content = lines[:conclusion_start]\n                                \n                                # çµè«–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®çµ‚ã‚ã‚Šã‚’è¦‹ã¤ã‘ã‚‹ï¼ˆæ¬¡ã®##ã¾ã§ or æ–‡æœ«ï¼‰\n                                conclusion_end = len(lines)\n                                for i in range(conclusion_start + 1, len(lines)):\n                                    if lines[i].startswith('## ') and i != conclusion_start:\n                                        conclusion_end = i\n                                        break\n                                \n                                conclusion_section = lines[conclusion_start:conclusion_end]\n                                remaining_content = lines[conclusion_end:]\n                                \n                                # å†æ§‹æˆ: ãƒ¢ãƒ‡ãƒ«å â†’ çµè«– â†’ ãã®ä»–ã®è©³ç´°\n                                # ãƒ¢ãƒ‡ãƒ«åéƒ¨åˆ†ã‚’ä¿æŒ\n                                model_line = \"\"\n                                if lines[0].startswith(\"**ğŸ¤–\"):\n                                    model_line = lines[0]\n                                    other_content = lines[1:conclusion_start]\n                                \n                                final_answer = '\\n'.join([\n                                    model_line,\n                                    \"\",\n                                    \"---\",\n                                    \"\",\n                                    \"## ğŸ“Œ çµè«–ï¼ˆå…ˆå‡ºã—ï¼‰\",\n                                    *conclusion_section[1:],  # å…ƒã®è¦‹å‡ºã—ã‚’é™¤ã\n                                    \"\",\n                                    \"---\",\n                                    \"\",\n                                    \"## ğŸ“ è©³ç´°\",\n                                    *other_content,\n                                    *remaining_content\n                                ]).strip()\n                        \n                        with status_container.expander(\"åˆç‰ˆã¨ã®æ¯”è¼ƒ\", expanded=False):\n                            st.markdown(\"**åˆç‰ˆ:**\")\n                            st.markdown(draft_answer[:500] + \"...\" if len(draft_answer) > 500 else draft_answer)\n                            st.markdown(\"**ä¿®æ­£ç‰ˆ:**\")\n                            st.markdown(final_answer[:500] + \"...\" if len(final_answer) > 500 else final_answer)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 3)\n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                review_resp.usage_metadata.prompt_token_count,\n                                review_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n                    else:\n                        final_answer = draft_answer\n\n                save_usage(usage_stats)\n                status_container.update(label=\"å®Œäº†ï¼\", state=\"complete\", expanded=False)\n\n                # ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤º\n                models_used = [f\"Gemini: {model_id}\"]\n                \n                # Grok Status\n                if enable_meta:\n                    if grok_status == \"success\":\n                        models_used.append(\"Grok: 4.1-fast-free (OK)\")\n                    elif grok_status == \"error\":\n                        models_used.append(\"Grok: 4.1-fast-free (Error)\")\n                    elif grok_status == \"empty\":\n                        models_used.append(\"Grok: 4.1-fast-free (Empty)\")\n                \n                # Claude Status\n                if is_puter_onigunsou:\n                    if claude_status == \"success\":\n                        models_used.append(\"Claude: Opus 4.5 (via Puter) (OK)\")\n                    elif claude_status == \"error\":\n                        models_used.append(\"Claude: Opus 4.5 (via Puter) (Error)\")\n                \n                st.caption(f\"ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {' + '.join(models_used)}\")\n                st.markdown(final_answer)\n\n                # ---- ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ± ----\n                if grounding_metadata:\n                    st.markdown(\"---\")\n                    with st.expander(\"ğŸ“š æƒ…å ±æºã¨å¼•ç”¨\", expanded=False):\n                        if grounding_metadata.grounding_chunks:\n                            st.markdown(\"**æ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:**\")\n                            unique_sources = {}\n                            import urllib.parse\n\n                            for chunk in grounding_metadata.grounding_chunks:\n                                if getattr(chunk, \"web\", None):\n                                    uri = getattr(chunk.web, \"uri\", None)\n                                    title = getattr(chunk.web, \"title\", \"æƒ…å ±æº\")\n                                    if uri and uri not in unique_sources:\n                                        parsed = urllib.parse.urlparse(uri)\n                                        domain = parsed.netloc.replace(\"www.\", \"\")\n                                        unique_sources[uri] = {\n                                            \"title\": title,\n                                            \"domain\": domain,\n                                        }\n                            for i, (uri, info) in enumerate(unique_sources.items(), 1):\n                                st.markdown(f\"{i}. **[{info['title']}]({uri})**\")\n                                st.caption(f\"   å‡ºå…¸: {info['domain']}\")\n\n                messages.append({\"role\": \"model\", \"content\": final_answer})\n                update_current_session_messages(messages)\n\n            except Exception as e:\n                status_container.update(label=\"Error\", state=\"error\")\n                err_text = str(e)\n                if \"RESOURCE_EXHAUSTED\" in err_text or \"429\" in err_text:\n                    st.error(\n                        \"âš ï¸ Vertex AI / Gemini ã®ã‚¯ã‚©ãƒ¼ã‚¿ã«é”ã—ã¾ã—ãŸã€‚\\n\\n\"\n                        \"ãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ / æ—¥æ¬¡åˆ¶é™ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\\n\"\n                        \"ãƒ»ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                        \"ãƒ»Google Cloud Console ã®ã€ŒVertex AI â†’ ä½¿ç”¨çŠ¶æ³ã€ã‹ã‚‰ã‚¯ã‚©ãƒ¼ã‚¿çŠ¶æ³ã‚’ç¢ºèªã§ãã¾ã™ã€‚\"\n                    )\n                elif \"NOT_FOUND\" in err_text and \"Publisher Model\" in err_text:\n                    st.error(\n                        \"âš ï¸ æŒ‡å®šã—ãŸãƒ¢ãƒ‡ãƒ«ãŒã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ / ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\\n\"\n                        \"ãƒ»ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ¢ãƒ‡ãƒ«IDã‚’ã€2.5ç³» ã¾ãŸã¯ 3 Pro ã«å¤‰æ›´ã—ã¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                    )\n                else:\n                    st.error(f\"An error occurred: {e}\")\n"
                }
            ]
        },
        {
            "id": "8aef1bec-4f72-4274-9a3f-05fcd9ab011a",
            "title": "æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ",
            "timestamp": "2025-12-02T00:55:13.601582",
            "messages": []
        },
        {
            "id": "56079501-d4c1-48f9-9601-6687773eb760",
            "title": "æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ",
            "timestamp": "2025-12-02T00:54:50.118911",
            "messages": []
        },
        {
            "id": "7f565520-82c2-4c55-bbf9-fd5eee411b4e",
            "title": "M7ã®ä»Šå¾Œã‚’äºˆæ¸¬ã—ã¦",
            "timestamp": "2025-12-02T00:36:26.424959",
            "messages": [
                {
                    "role": "user",
                    "content": "M7ã®ä»Šå¾Œã‚’äºˆæ¸¬ã—ã¦"
                },
                {
                    "role": "model",
                    "content": "2025å¹´12æœˆ01æ—¥æ™‚ç‚¹ã®æœ€æ–°èª¿æŸ»ã«åŸºã¥ãã€Magnificent Sevenï¼ˆM7ï¼‰ã®2026å¹´ã«å‘ã‘ãŸäºˆæ¸¬ã‚’æç¤ºã—ã¾ã™ã€‚\n\n### 1. çµè«–ï¼š2026å¹´ã¯ã€ŒAIåç›ŠåŒ–ã€ã«ã‚ˆã‚‹é¸åˆ¥ã®å¹´ã¸\nM7å…¨ä½“ã®åˆ©ç›Šæˆé•·ç‡ã¯ã€2025å¹´ã®èª¿æ•´å±€é¢ï¼ˆå‰å¹´æ¯”ç´„18%å¢—ï¼‰ã‚’çµŒã¦ã€2026å¹´ã«ã¯**20-25%å¢—ã¸ã¨å†åŠ é€Ÿ**ã™ã‚‹è¦‹é€šã—ã§ã™ã€‚\nãŸã ã—ã€æ ªä¾¡ãŒä¸€å¾‹ã«ä¸Šæ˜‡ã™ã‚‹å±€é¢ã¯çµ‚äº†ã—ã¾ã—ãŸã€‚2026å¹´ã¯**ã€ŒAIã‚¤ãƒ³ãƒ•ãƒ©æŠ•è³‡ã‚’å…·ä½“çš„ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼ï¼ˆåˆ©ç›Šï¼‰ã«å¤‰ãˆã‚‰ã‚Œã‚‹ä¼æ¥­ã€**ã¨ã€è£½å“ã‚µã‚¤ã‚¯ãƒ«ã®è°·é–“ã‚„æœŸå¾…å…ˆè¡Œã®ä¼æ¥­ã¨ã®é–“ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ ¼å·®ãŒæ‹¡å¤§ã™ã‚‹ã€Œé¸åˆ¥ã€ã®å¹´ã¨ãªã‚Šã¾ã™ã€‚\n\n---\n\n### 2. ä¼æ¥­åˆ¥è©³ç´°åˆ†æï¼ˆ2026å¹´ã®ç„¦ç‚¹ï¼‰\n\nå„ç¤¾ã®ç½®ã‹ã‚ŒãŸçŠ¶æ³ã«åŸºã¥ãã€3ã¤ã®ã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†é¡ã—ã¦äºˆæ¸¬ã—ã¾ã™ã€‚\n\n#### **A. åç›ŠåŒ–ãƒªãƒ¼ãƒ€ãƒ¼ï¼ˆAIã§ç¨¼ããƒ•ã‚§ãƒ¼ã‚ºã¸ï¼‰**\nAIæŠ•è³‡ãŒå…·ä½“çš„ãªå£²ä¸Šãƒ»åˆ©ç›Šã¨ã—ã¦çµå®Ÿã—ã€æ•°å­—ã§æˆé•·ã‚’è¨¼æ˜ã™ã‚‹ã‚°ãƒ«ãƒ¼ãƒ—ã§ã™ã€‚\n\n*   **NVIDIA (NVDA)**\n    *   **äºˆæ¸¬**: æ¬¡ä¸–ä»£ãƒãƒƒãƒ—**ã€ŒRubinã€**ã®æŠ•å…¥æº–å‚™ã¨ã€ŒBlackwell Ultraã€ã®ãƒ•ãƒ«ç”Ÿç”£ãŒ2026å¹´ã®æˆé•·ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼å£²ä¸Šã¯ä¾ç„¶å¼·åŠ›ã§ã€å›½å®¶äºˆç®—ã«ã‚ˆã‚‹ã€Œã‚½ãƒ–ãƒªãƒ³AIã€éœ€è¦ãŒæ–°ãŸãªåç›Šã®æŸ±ã¨ãªã‚Šã¾ã™ã€‚\n    *   **ãƒªã‚¹ã‚¯**: æˆé•·ç‡ã¯å‰å¹´æ¯”50%è¶…ã‹ã‚‰30%å°ã¸éˆåŒ–ã™ã‚‹è¦‹è¾¼ã¿ã§ã™ã€‚å¸‚å ´ãŒã“ã®ã€Œæ­£å¸¸åŒ–ã€ã‚’æˆé•·éˆåŒ–ã¨æ‰ãˆã‚‹ã‹ã€å®‰å®šæˆé•·ã¨æ‰ãˆã‚‹ã‹ãŒæ ªä¾¡ã®åˆ†ã‹ã‚Œç›®ã¨ãªã‚Šã¾ã™ã€‚\n*   **Microsoft (MSFT)**\n    *   **äºˆæ¸¬**: **Copiloté–¢é€£åç›ŠãŒ2026å¹´ã¾ã§ã«100å„„ãƒ‰ãƒ«è¦æ¨¡**ã«é”ã—ã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã«ãŠã‘ã‚‹AIåç›ŠåŒ–ã®ãƒªãƒ¼ãƒ€ãƒ¼ã¨ã—ã¦ã®åœ°ä½ã‚’å›ºã‚ã‚‹è¦‹é€šã—ã§ã™ã€‚Azureã‚‚AIéœ€è¦ã§30%å°å¾ŒåŠã®æˆé•·ç¶­æŒãŒäºˆæ¸¬ã•ã‚Œã¾ã™ã€‚\n    *   **ãƒªã‚¹ã‚¯**: è†¨å¤§ãªAIè¨­å‚™æŠ•è³‡ï¼ˆCapexï¼‰ã«ã‚ˆã‚‹åˆ©ç›Šç‡ã®åœ§è¿«ã¨ã€OpenAIã¸ã®ä¾å­˜åº¦ãŒæ‡¸å¿µææ–™ã¨ã—ã¦æ®‹ã‚Šã¾ã™ã€‚\n*   **Amazon (AMZN)**\n    *   **äºˆæ¸¬**: **AWSã®å£²ä¸Šæˆé•·ç‡ãŒ25%ã¸å†åŠ é€Ÿ**ã™ã‚‹ã‚·ãƒŠãƒªã‚ªãŒæœ‰åŠ›ã§ã™ã€‚è‡ªç¤¾ãƒãƒƒãƒ—ã€ŒTrainium 2ã€ã®å°å…¥ã¨ç‰©æµåŠ¹ç‡åŒ–å®Œäº†ã«ã‚ˆã‚Šã€åˆ©ç›Šç‡ãŒå¤§å¹…ã«æ”¹å–„ã€‚ã€Œ2026å¹´ã«ä¸–ç•Œæœ€å¤§ã®å£²ä¸Šä¼æ¥­ã«ãªã‚‹ã€ã¨ã®äºˆæ¸¬ã‚‚å‡ºã¦ã„ã¾ã™ã€‚\n\n#### **B. ãƒãƒªãƒ¥ãƒ¼ãƒ»å†è©•ä¾¡ï¼ˆå‰²å®‰æ„Ÿã¨å®ˆã‚Šã®å¼·ã•ï¼‰**\næ‡¸å¿µææ–™ãŒæ‰•æ‹­ã•ã‚Œã€å†è©•ä¾¡ãŒé€²ã‚€ã‚°ãƒ«ãƒ¼ãƒ—ã§ã™ã€‚\n\n*   **Alphabet (GOOGL)**\n    *   **äºˆæ¸¬**: 2025å¹´9æœˆã®åˆ¤æ±ºã§**Chromeå¼·åˆ¶å£²å´ã‚’å›é¿**ï¼ˆæ’ä»–çš„å¥‘ç´„ã®ç¦æ­¢ã®ã¿ï¼‰ã—ãŸã“ã¨ãŒæœ€å¤§ã®å®‰å¿ƒææ–™ã§ã™ã€‚Gemini 3ã¨è‡ªç¤¾ãƒãƒƒãƒ—ï¼ˆTPUï¼‰ã«ã‚ˆã‚‹ã‚³ã‚¹ãƒˆç«¶äº‰åŠ›ãŒã€æ¤œç´¢AIã®åˆ©ç›Šç‡ç¶­æŒã«å¯„ä¸ã—ã¾ã™ã€‚\n    *   **ãƒªã‚¹ã‚¯**: ChatGPTã‚„Perplexityç­‰ã«ã‚ˆã‚‹æ¤œç´¢ã‚·ã‚§ã‚¢ã®æ¼¸æ¸›ãƒªã‚¹ã‚¯ã¯ç¶™ç¶šã—ã¦ãŠã‚Šã€é•·æœŸçš„ãªå €ã®æ·±ã•ãŒå•ã‚ã‚Œã¾ã™ã€‚\n*   **Meta (META)**\n    *   **äºˆæ¸¬**: AIã«ã‚ˆã‚‹åºƒå‘Šã‚¿ãƒ¼ã‚²ãƒ†ã‚£ãƒ³ã‚°ç²¾åº¦å‘ä¸Šã§ROASï¼ˆåºƒå‘Šè²»ç”¨å¯¾åŠ¹æœï¼‰ãŒæ”¹å–„ã—ã¦ãŠã‚Šã€PER20å€å°å‰åŠã¨ã„ã†å‰²å®‰æ„ŸãŒè©•ä¾¡ã•ã‚Œã¦ã„ã¾ã™ã€‚\n    *   **ãƒªã‚¹ã‚¯**: **2026å¹´ã®è¨­å‚™æŠ•è³‡é¡ãŒ700å„„ãƒ‰ãƒ«è¶…**ã¨äºˆæ¸¬ã•ã‚Œã€ãƒ¡ã‚¿ãƒãƒ¼ã‚¹éƒ¨é–€ï¼ˆReality Labsï¼‰ã®èµ¤å­—ç¶™ç¶šã¨åˆã‚ã›ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼ã¸ã®æ‡¸å¿µãŒä¸Šå€¤ã‚’æŠ‘ãˆã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n\n#### **C. è»¢æ›ç‚¹ãƒ»ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚µã‚¤ã‚¯ãƒ«ï¼ˆä¸ç¢ºå®Ÿæ€§ãŒé«˜ã„ï¼‰**\næ¬¡ä¸–ä»£è£½å“ã®æˆå¦ãŒæ¥­ç¸¾ã‚’å·¦å³ã™ã‚‹ã‚°ãƒ«ãƒ¼ãƒ—ã§ã™ã€‚\n\n*   **Apple (AAPL)**\n    *   **äºˆæ¸¬**: 2025å¹´ã®iPhone 17ã¯å°å¹…ãªé€²åŒ–ã«ç•™ã¾ã‚Šã¾ã—ãŸãŒã€**2026å¹´å¾ŒåŠï¼ˆiPhone 18/Foldãªã©ï¼‰**ã«äºˆå®šã•ã‚Œã‚‹å¤§å¹…åˆ·æ–°ãŒã€Œã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚µã‚¤ã‚¯ãƒ«ï¼ˆçˆ†ç™ºçš„ãªè²·ã„æ›¿ãˆï¼‰ã€ã‚’å¼•ãèµ·ã“ã™æœŸå¾…ãŒã‚ã‚Šã¾ã™ã€‚\n    *   **ãƒªã‚¹ã‚¯**: ä¸­å›½å¸‚å ´ã§ã®ã‚·ã‚§ã‚¢ä½ä¸‹ï¼ˆHuaweiç­‰ã®å¾©æ´»ï¼‰ã‚„ã€AIæ©Ÿèƒ½ã®èª²é‡‘ãƒ¢ãƒ‡ãƒ«åŒ–ã®é…ã‚ŒãŒæ‡¸å¿µã•ã‚Œã¾ã™ã€‚\n*   **Tesla (TSLA)**\n    *   **äºˆæ¸¬**: Musk CEOã¯**2026å¹´ã«ã€ŒCybercabã€ã‚’å¹´ç”£200ä¸‡å°ä½“åˆ¶ã§é‡ç”£**ã™ã‚‹ã¨æ˜è¨€ã—ã¦ã„ã¾ã™ã€‚ã“ã‚ŒãŒå®Ÿç¾ã™ã‚Œã°ã€è‡ªå‹•è»Šãƒ¡ãƒ¼ã‚«ãƒ¼ã‹ã‚‰AIãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ä¼æ¥­ã¸ã®è©•ä¾¡è»¢æ›ãŒæ±ºå®šçš„ã«ãªã‚Šã¾ã™ã€‚\n    *   **ãƒªã‚¹ã‚¯**: ãƒˆãƒ©ãƒ³ãƒ—æ”¿æ¨©ã®å½±éŸ¿ã«ã‚ˆã‚‹EVç¨é¡æ§é™¤å»ƒæ­¢ãŒç±³å›½éœ€è¦ã‚’å†·ãˆè¾¼ã¾ã›ã‚‹æã‚ŒãŒã‚ã‚Šã¾ã™ã€‚ã¾ãŸã€å®Œå…¨è‡ªå‹•é‹è»¢ï¼ˆFSDï¼‰ã®å®Ÿç”¨åŒ–ã«å¯¾ã™ã‚‹å¸‚å ´ã®æ‡ç–‘å¿ƒã‚‚æ ¹å¼·ã„ã§ã™ã€‚\n\n---\n\n### 3. 2026å¹´ã®æ³¨ç›®ã‚¤ãƒ™ãƒ³ãƒˆãƒ»ã‚«ã‚¿ãƒªã‚¹ãƒˆ\nä»¥ä¸‹ã®ã‚¤ãƒ™ãƒ³ãƒˆãŒæ ªä¾¡å¤‰å‹•ã®ãƒˆãƒªã‚¬ãƒ¼ã¨ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n\n1.  **NVIDIAã€ŒRubinã€ãƒãƒƒãƒ—å‡ºè·**: AIè¨ˆç®—éœ€è¦ã®ç¬¬äºŒæ³¢ã‚’å¼•ãèµ·ã“ã›ã‚‹ã‹ã€‚\n2.  **Teslaã€ŒCybercabã€å…¬é“èµ°è¡Œ**: å®Ÿéš›ã«ç„¡äººã§å•†ç”¨é‹è¡Œã§ãã‚‹ã‹ï¼ˆWaymoã¨ã®æ¯”è¼ƒï¼‰ã€‚\n3.  **Appleã€Œãƒ•ã‚©ãƒ«ãƒ€ãƒ–ãƒ«iPhoneã€ç™ºè¡¨**: ã‚¹ãƒãƒ›å¸‚å ´ã®åœæ»ã‚’æ‰“ç ´ã§ãã‚‹ã‹ã€‚\n4.  **Alphabetæ˜¯æ­£æªç½®ã®å®Ÿæ–½**: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®å¤‰æ›´ç”»é¢å°å…¥ãŒã‚·ã‚§ã‚¢ã«ä¸ãˆã‚‹å½±éŸ¿ã€‚\n\n### 4. ãƒã‚¯ãƒ­ç’°å¢ƒã¨ãƒªã‚¹ã‚¯è¦å› \n*   **é‡‘åˆ©ç’°å¢ƒ**: FRBã®æ”¿ç­–é‡‘åˆ©ã¯3.75-4.00%ï¼ˆ2025å¹´10æœˆæ™‚ç‚¹ï¼‰ã¾ã§ä½ä¸‹ã—ã¦ãŠã‚Šã€ã‚½ãƒ•ãƒˆãƒ©ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãŒãƒ¡ã‚¤ãƒ³ã‚·ãƒŠãƒªã‚ªã§ã™ã€‚\n*   **AIã®ROIï¼ˆæŠ•è³‡å¯¾åŠ¹æœï¼‰**: 2026å¹´ã¯ã€ä¼æ¥­ãŒå·¨é¡ã®AIæŠ•è³‡ã«è¦‹åˆã†ãƒªã‚¿ãƒ¼ãƒ³ã‚’å¾—ã‚‰ã‚Œã¦ã„ã‚‹ã‹ãŒå³ã—ãå•ã‚ã‚Œã¾ã™ã€‚ã€Œå°å…¥ã—ãŸãŒåˆ©ç›ŠãŒå‡ºãªã„ã€ã¨ã„ã†åˆ¤æ–­ãŒå¢—ãˆã‚Œã°ã€NVIDIAã‚„Microsoftã¸ã®æ”¯å‡ºãŒæŠ‘åˆ¶ã•ã‚Œã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚\n\n**æƒ…å ±æº**:\n*   NVIDIA/Amazon/Meta/Tesla 2025å¹´Q3æ±ºç®—è³‡æ–™ãŠã‚ˆã³èª¬æ˜ä¼šï¼ˆ2025å¹´10-11æœˆï¼‰\n*   Alphabeté–¢é€£ ç±³é€£é‚¦åœ°è£åˆ¤æ±ºå ±é“ï¼ˆ2025å¹´9æœˆï¼‰\n*   FRB FOMCè­°äº‹è¦æ—¨ï¼ˆ2025å¹´10æœˆï¼‰"
                }
            ]
        },
        {
            "id": "11eb74df-4911-469b-8c4e-054e4f255aa5",
            "title": "M7ã®ä»Šå¾Œã‚’äºˆæ¸¬ã—ã¦",
            "timestamp": "2025-12-02T00:29:16.931127",
            "messages": [
                {
                    "role": "user",
                    "content": "M7ã®ä»Šå¾Œã‚’äºˆæ¸¬ã—ã¦"
                },
                {
                    "role": "model",
                    "content": "ä¿®æ­£ç‰ˆå›ç­”ã§ã™ã€‚\n\n### çµè«–ï¼š2026å¹´ã¯ã€Œå…¨é¢é«˜ã€ã®çµ‚ç„‰ã¨ã€Œå®Ÿåˆ©ã€ã«ã‚ˆã‚‹é¸åˆ¥ã®å¹´\n\n2025å¹´12æœˆ02æ—¥æ™‚ç‚¹ã®å¸‚å ´ç’°å¢ƒã«åŸºã¥ãã¨ã€2026å¹´ã®Magnificent Sevenï¼ˆM7ï¼‰ã¯ã€2023-2024å¹´ã®ã‚ˆã†ãªä¸€å¾‹ã®æ ªä¾¡ä¸Šæ˜‡ãƒ•ã‚§ãƒ¼ã‚ºã‚’çµ‚ãˆã€**ã€ŒAIåç›ŠåŒ–ã®å®Ÿè¨¼ï¼ˆROIï¼‰ã€ã¨ã€Œãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚µã‚¤ã‚¯ãƒ«ã®è»¢æ›ã€**ã«ã‚ˆã£ã¦æ˜æš—ãŒåˆ†ã‹ã‚Œã‚‹å¹´ã¨ãªã‚Šã¾ã™ã€‚\n\nM7å…¨ä½“ã®åˆ©ç›Šæˆé•·ç‡ã¯2025å¹´ã®æ¸›é€Ÿã‹ã‚‰å†åŠ é€Ÿï¼ˆç´„20%å¢—ï¼‰ã«è»¢ã˜ã‚‹è¦‹é€šã—ã§ã™ãŒã€æŠ•è³‡å¯¾è±¡ã¨ã—ã¦ã¯ä»¥ä¸‹ã®3ã¤ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«é¸åˆ¥ã•ã‚Œã¾ã™ã€‚\n\n1.  **å …å®Ÿãªæˆé•·ï¼ˆCore Holdingsï¼‰**: æ–°è£½å“ã‚µã‚¤ã‚¯ãƒ«ã¨åˆ©ç›Šç‡æ”¹å–„ãŒæ˜ç¢ºãª**NVIDIA**ã€**Amazon**ã€‚\n2.  **è»¢æ›ç‚¹ï¼ˆPivot Pointsï¼‰**: ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢é©æ–°ã¨AIåç›ŠåŒ–ã®éæ¸¡æœŸã«ã‚ã‚‹**Apple**ã€**Google**ã€**Microsoft**ã€‚\n3.  **é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆHigh Risk/Rewardï¼‰**: å˜ä¸€ã‚¤ãƒ™ãƒ³ãƒˆã«å‘½é‹ã‚’è¨—ã™**Tesla**ã€‚\n\n---\n\n### è©³ç´°åˆ†æï¼šä¼æ¥­åˆ¥äºˆæ¸¬ã¨é‡è¦ã‚¤ãƒ™ãƒ³ãƒˆ\n\n#### 1. ç¢ºå®Ÿæ€§ã¨æˆé•·ã®ä¸¡ç«‹ï¼ˆNVIDIA, Amazonï¼‰\n2026å¹´ã®æˆé•·ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ãŒæœ€ã‚‚æ˜ç¢ºã§ã‚ã‚Šã€ç›¸å¯¾çš„ã«å®‰å…¨ãªé¸æŠè‚¢ã¨ç›®ã•ã‚Œã‚‹ã‚°ãƒ«ãƒ¼ãƒ—ã§ã™ã€‚\n\n*   **NVIDIA (NVDA): ã€ŒRubinã€ã«ã‚ˆã‚‹ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚µã‚¤ã‚¯ãƒ«**\n    *   **äºˆæ¸¬**: å¸‚å ´ã®ä¸€éƒ¨ã«ã‚ã‚‹ã€ŒAIæŠ•è³‡ãƒ”ãƒ¼ã‚¯ã‚¢ã‚¦ãƒˆã€æ‡¸å¿µã«åã—ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼éœ€è¦ã¯ç¶™ç¶šã—ã¾ã™ã€‚\n    *   **æ ¹æ‹ **: 2026å¹´å¾ŒåŠã«æŠ•å…¥äºˆå®šã®æ¬¡ä¸–ä»£ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**ã€ŒRubinã€**ï¼ˆHBM4ãƒ¡ãƒ¢ãƒªæ­è¼‰ï¼‰ãŒã€2025å¹´ã®ä¸»åŠ›ã€ŒBlackwell Ultraã€ã‹ã‚‰ã®è²·ã„æ›¿ãˆéœ€è¦ã‚’å–šèµ·ã—ã¾ã™ã€‚\n    *   **ãƒªã‚¹ã‚¯**: å¹´å¾ŒåŠã«ã‹ã‘ã¦ã®ç«¶åˆä»–ç¤¾ã®è¿½ã„ä¸Šã’ã«ã‚ˆã‚‹ã‚·ã‚§ã‚¢å¾®æ¸›ã€‚\n\n*   **Amazon (AMZN): è‡ªç¤¾ãƒãƒƒãƒ—ã«ã‚ˆã‚‹ã€Œåˆ©ç›Šç‡é©å‘½ã€**\n    *   **äºˆæ¸¬**: ã‚¯ãƒ©ã‚¦ãƒ‰äº‹æ¥­ï¼ˆAWSï¼‰ã®åˆ©ç›Šç‡ãŒå¤§å¹…ã«æ”¹å–„ã—ã€æ ªä¾¡ã‚’ç‰½å¼•ã—ã¾ã™ã€‚\n    *   **æ ¹æ‹ **: é«˜ä¾¡ãªNVIDIAè£½GPUã¸ã®ä¾å­˜ã‚’æ¸›ã‚‰ã—ã€è‡ªç¤¾è£½AIãƒãƒƒãƒ—ï¼ˆTrainium/Inferentiaï¼‰ã¸ã®ç§»è¡Œã‚’åŠ é€Ÿã•ã›ã‚‹ã“ã¨ã§ã€ã‚³ã‚¹ãƒˆæ§‹é€ ãŒåŠ‡çš„ã«åŠ¹ç‡åŒ–ã•ã‚Œã¾ã™ã€‚\n\n#### 2. é‹å‘½ã®åˆ†å²ç‚¹ï¼ˆTeslaï¼‰\n*   **Tesla (TSLA): ã€Œ4æœˆã®Cybercabã€ä¸€ç‚¹çªç ´**\n    *   **äºˆæ¸¬**: M7ã®ä¸­ã§æœ€ã‚‚å¤‰å‹•å¹…ï¼ˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼‰ãŒå¤§ãã„éŠ˜æŸ„ã¨ãªã‚Šã¾ã™ã€‚\n    *   **ã‚·ãƒŠãƒªã‚ª**:\n        *   **å¼·æ°—**: 2026å¹´4æœˆã€ãƒ†ã‚­ã‚µã‚¹å·¥å ´ã§ã®**ã€ŒCybercabï¼ˆãƒ­ãƒœã‚¿ã‚¯ã‚·ãƒ¼ï¼‰ã€**ç”Ÿç”£é–‹å§‹ãŒé †èª¿ã«é€²ã¿ã€ãƒãƒ³ãƒ‰ãƒ«ãƒ»ãƒšãƒ€ãƒ«ã®ãªã„å®Œå…¨è‡ªå¾‹èµ°è¡Œè»ŠãŒå¸‚å ´ã«å—ã‘å…¥ã‚Œã‚‰ã‚Œã‚Œã°ã€M7ãƒˆãƒƒãƒ—ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚¤ãƒ¼ãƒ­ãƒ³ãƒ»ãƒã‚¹ã‚¯æ°ã®æ”¿åºœåŠ¹ç‡åŒ–çœï¼ˆDOGEï¼‰é–¢ä¸ã«ã‚ˆã‚‹è¦åˆ¶ç·©å’ŒæœŸå¾…ã‚‚è¿½ã„é¢¨ã§ã™ã€‚\n        *   **å¼±æ°—**: éå»ã®äº‹ä¾‹åŒæ§˜ã«ç”Ÿç”£é…å»¶ãŒç™ºç”Ÿã€ã¾ãŸã¯è¦åˆ¶å½“å±€ã¨ã®æ‘©æ“¦ãŒç”Ÿã˜ãŸå ´åˆã€å¤±æœ›å£²ã‚Šã‚’æ‹›ããƒªã‚¹ã‚¯ãŒé«˜ã„çŠ¶æ…‹ã§ã™ã€‚\n\n#### 3. æ–°ãŸãªã‚«ã‚¿ãƒªã‚¹ãƒˆã®æ¨¡ç´¢ï¼ˆApple, Microsoft, Googleï¼‰\n*   **Apple (AAPL): ãƒ•ã‚©ãƒ¼ãƒ ãƒ•ã‚¡ã‚¯ã‚¿ã®åˆ·æ–°**\n    *   **äºˆæ¸¬**: 2025å¹´9æœˆç™ºå£²ã®**ã€ŒiPhone 17 Airã€**ï¼ˆè¶…è–„å‹ï¼‰ã®ãƒ’ãƒƒãƒˆã«ç¶šãã€ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚µã‚¤ã‚¯ãƒ«ã®è»¢æ›ç‚¹ã‚’è¿ãˆã¾ã™ã€‚\n    *   **æ³¨ç›®ç‚¹**: 2026å¹´å¾ŒåŠã«æœŸå¾…ã•ã‚Œã‚‹**ã€ŒæŠ˜ã‚ŠãŸãŸã¿iPhoneã€**ã®æŠ•å…¥ã‚„ã€ç”»é¢ä¸‹Face IDæ­è¼‰ã€ŒiPhone 18 Proã€ãªã©ã®æŠ€è¡“é©æ–°ã€ãŠã‚ˆã³Apple Intelligenceã®æœ‰æ–™åŒ–ã«ã‚ˆã‚‹ã‚µãƒ¼ãƒ“ã‚¹åç›Šã®è²¢çŒ®åº¦ãŒéµã¨ãªã‚Šã¾ã™ã€‚\n\n*   **Google (GOOGL): æ¤œç´¢é˜²è¡›ã¨AIã®å®Ÿè£…**\n    *   **äºˆæ¸¬**: **ã€ŒGemini 3ã€**ãƒ¢ãƒ‡ãƒ«ã‚’åŸºç›¤ã¨ã—ãŸã‚¯ãƒ©ã‚¦ãƒ‰éƒ¨é–€ã®æˆé•·åŠ é€Ÿï¼ˆAWS/Azureã‚’ä¸Šå›ã‚‹å¯èƒ½æ€§ï¼‰ãŒè©•ä¾¡ãƒã‚¤ãƒ³ãƒˆã§ã™ã€‚\n    *   **èª²é¡Œ**: ç”ŸæˆAIã«ã‚ˆã‚‹æ¤œç´¢åºƒå‘Šã¸ã®ã€Œå…±é£Ÿã„ã€ãƒªã‚¹ã‚¯ã‚’åˆ¶å¾¡ã—ã¤ã¤ã€YouTubeã¨æ¤œç´¢ã®AIåç›ŠåŒ–ã‚’ä¸¡ç«‹ã§ãã‚‹ã‹ãŒå•ã‚ã‚Œã¾ã™ã€‚\n\n*   **Microsoft (MSFT): ä¾›çµ¦åˆ¶ç´„ã¨ã®æˆ¦ã„**\n    *   **äºˆæ¸¬**: OpenAIã¨ã®ææºã¯å¼·å›ºã§ã™ãŒã€æˆé•·ã®è¶³ã‹ã›è¦å› ãŒå­˜åœ¨ã—ã¾ã™ã€‚\n    *   **èª²é¡Œ**: AIã‚µãƒ¼ãƒãƒ¼ã®ä¾›çµ¦åˆ¶ç´„ãŒ2026å¹´å‰åŠã¾ã§ç¶šãã¨äºˆæ¸¬ã•ã‚Œã¦ãŠã‚Šã€Copilotã®æ³•äººå°å…¥ãƒšãƒ¼ã‚¹ãŒå¸‚å ´ã®æœŸå¾…ã«å±Šãã‹ãŒè©¦ã•ã‚Œã¾ã™ã€‚\n\n---\n\n### ãƒã‚¯ãƒ­ãƒ»æ”¿æ²»çš„ãƒªã‚¹ã‚¯è¦å› \n\n#### ãƒˆãƒ©ãƒ³ãƒ—æ”¿æ¨©ã®å½±éŸ¿ï¼šè¦åˆ¶ç·©å’Œ vs é–¢ç¨\n2025å¹´ã®æ”¿æ¨©äº¤ä»£ä»¥é™ã€ä»¥ä¸‹ã®ç›¸åã™ã‚‹åŠ›ãŒM7ã«ä½œç”¨ã—ã¦ã„ã¾ã™ã€‚\n*   **ãƒã‚¸ãƒ†ã‚£ãƒ–**: ãƒã‚¤ãƒ‡ãƒ³æ”¿æ¨©æ™‚ä»£ã®AIè¦åˆ¶æ’¤å›ãƒ»ä¿®æ­£ã¯ã€é–‹ç™ºé€Ÿåº¦ã‚’é‡è¦–ã™ã‚‹M7ã«ã¨ã£ã¦è¿½ã„é¢¨ã§ã™ã€‚\n*   **ãƒã‚¬ãƒ†ã‚£ãƒ–**: ã€Œãƒ†ãƒƒã‚¯ãƒ»ãƒŠã‚·ãƒ§ãƒŠãƒªã‚ºãƒ ã€ã«åŸºã¥ãé–¢ç¨å¼·åŒ–ã¯ã€ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚µãƒ—ãƒ©ã‚¤ãƒã‚§ãƒ¼ãƒ³ã‚’æŒã¤**Apple**ã‚„**Tesla**ã«ã¨ã£ã¦ç›´æ¥çš„ãªã‚³ã‚¹ãƒˆå¢—è¦å› ã¨ãªã‚Šã¾ã™ã€‚\n\n#### ã‚¨ãƒãƒ«ã‚®ãƒ¼å•é¡Œï¼šé›»åŠ›ç¢ºä¿ãŒç«¶äº‰åŠ›ã¸\nAIãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã®é›»åŠ›æ¶ˆè²»å¢—å¤§ã«ä¼´ã„ã€2026å¹´ã¯é›»åŠ›ç¢ºä¿ãŒäº‹æ¥­æˆé•·ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã¨ãªã‚Šã¾ã™ã€‚å„ç¤¾ã¯**åŸå­åŠ›ç™ºé›»ï¼ˆSMR: å°å‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç‚‰ï¼‰ã¸ã®ç›´æ¥æŠ•è³‡**ã‚’åŠ é€Ÿã•ã›ã¦ãŠã‚Šã€ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚¤ãƒ³ãƒ•ãƒ©ã®ç¢ºä¿çŠ¶æ³ãŒã‚¯ãƒ©ã‚¦ãƒ‰ã‚·ã‚§ã‚¢ã‚’å·¦å³ã™ã‚‹é‡è¦æŒ‡æ¨™ã¨ãªã‚Šã¾ã™ã€‚\n\n**æƒ…å ±æº**: \n- 2025å¹´12æœˆ02æ—¥æ™‚ç‚¹ã®èª¿æŸ»ãƒ¡ãƒ¢ï¼ˆM7ç¾çŠ¶ã¨2026å¹´äºˆæ¸¬ï¼‰"
                }
            ]
        },
        {
            "id": "938f7ce9-8454-488b-83ac-c979393ba1e0",
            "title": "M7ã®ä»Šå¾Œã®äºˆæ¸¬ã‚’ã€‚",
            "timestamp": "2025-12-02T00:24:04.657319",
            "messages": [
                {
                    "role": "user",
                    "content": "M7ã®ä»Šå¾Œã®äºˆæ¸¬ã‚’ã€‚"
                },
                {
                    "role": "model",
                    "content": "2025å¹´12æœˆ2æ—¥æ™‚ç‚¹ã®èª¿æŸ»ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãã€ã€ŒM7ã€ãŒæŒ‡ã—å¾—ã‚‹ä¸»è¦ãª2ã¤ã®å¯¾è±¡ï¼ˆç±³å›½ä¸»è¦ãƒã‚¤ãƒ†ã‚¯æ ªã€Apple Siliconï¼‰ã«ã¤ã„ã¦äºˆæ¸¬ã‚’æç¤ºã—ã¾ã™ã€‚\n\n### ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼\n*   **ç±³å›½æ ªï¼ˆMagnificent Sevenï¼‰**: 2025å¹´å¾ŒåŠã®èª¿æ•´ã‚’çµŒã¦ã€**2026å¹´ã¯åç›Šæˆé•·ç‡ãŒå†åŠ é€Ÿ**ã™ã‚‹è¦‹é€šã—ã§ã™ã€‚AIè¨­å‚™æŠ•è³‡ã®å›åãƒ•ã‚§ãƒ¼ã‚ºã«å…¥ã‚Šã€ç‰¹ã«2026å¹´å¾ŒåŠã«å‘ã‘ã¦æˆé•·ç‡ãŒ20%å°ã¸ä¸Šæ˜‡ã™ã‚‹ã¨äºˆæ¸¬ã•ã‚Œã¦ã„ã¾ã™ã€‚\n*   **Apple Siliconï¼ˆM7ãƒãƒƒãƒ—ï¼‰**: ç¾è¡Œã®M5ã«ç¶šãæ¬¡ã€…ä¸–ä»£ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã€**2027å¹´ã®ç™»å ´**ãŒæœ‰åŠ›è¦–ã•ã‚Œã¦ã„ã¾ã™ã€‚TSMC 1.4nmãƒ—ãƒ­ã‚»ã‚¹ã®æ¡ç”¨ã«ã‚ˆã‚‹åŠ‡çš„ãªæ€§èƒ½å‘ä¸ŠãŒæœŸå¾…ã•ã‚Œã¾ã™ã€‚\n\n---\n\n### 1. ç±³å›½æ ªã€ŒMagnificent Sevenã€ã®å¸‚å ´äºˆæ¸¬\n2025å¹´12æœˆç¾åœ¨ã€AIãƒãƒ–ãƒ«ã¸ã®è­¦æˆ’æ„Ÿã¯ä¸€éƒ¨ã«ã‚ã‚‹ã‚‚ã®ã®ã€ä¼æ¥­ã®ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºã¯å …èª¿ã§ã™ã€‚2026å¹´ã®ãƒ¡ã‚¤ãƒ³ã‚·ãƒŠãƒªã‚ªã¯ã€Œæˆé•·ã®å†åŠ é€Ÿã€ã§ã™ã€‚\n\n#### **åç›Šãƒˆãƒ¬ãƒ³ãƒ‰ï¼š2026å¹´ã®å†åŠ é€Ÿ**\nã‚¦ã‚©ãƒ¼ãƒ«è¡—ã®ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹ãƒ‡ãƒ¼ã‚¿ï¼ˆFactSetç­‰ï¼‰ã«ã‚ˆã‚‹ã¨ã€åç›Šæˆé•·ç‡ã¯ä»¥ä¸‹ã®é€šã‚Šå³è‚©ä¸ŠãŒã‚ŠãŒäºˆæ¸¬ã•ã‚Œã¦ã„ã¾ã™ã€‚\n*   **2026å¹´ Q1**: å‰å¹´åŒæœŸæ¯” **18.5%**\n*   **2026å¹´ Q2**: å‰å¹´åŒæœŸæ¯” **22.1%**\n*   **2026å¹´ Q3**: å‰å¹´åŒæœŸæ¯” **24.5%**\n\n#### **æ§‹é€ çš„å¤‰åŒ–ï¼šæŠ•è³‡ã‹ã‚‰å›åã¸**\n2025å¹´ã¾ã§ã®å·¨é¡ã®AIè¨­å‚™æŠ•è³‡ï¼ˆCAPEXï¼‰ãŒã€2026å¹´ã«ã¯å…·ä½“çš„ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼ã¨ã—ã¦é‚„å…ƒã•ã‚Œã‚‹ãƒ•ã‚§ãƒ¼ã‚ºã«å…¥ã‚Šã¾ã™ã€‚Metaã‚’é™¤ã6ç¤¾ã§ã¯ãƒ•ãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼ãŒè¨­å‚™æŠ•è³‡é¡ã‚’å¤§å¹…ã«ä¸Šå›ã£ã¦ãŠã‚Šã€è²¡å‹™å¥å…¨æ€§ã¯ç¶­æŒã•ã‚Œã¦ã„ã‚‹ã¨ã®åˆ†æãŒä¸»æµã§ã™ã€‚\n\n#### **å€‹åˆ¥éŠ˜æŸ„ã®å±•æœ›ã¨ãƒªã‚¹ã‚¯**\n*   **å¼·æ°—ï¼ˆBullï¼‰**:\n    *   **NVIDIA**: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼éœ€è¦ãŒç¶™ç¶šã—ã€2026å¹´ã‚‚å¸‚å ´æ”¯é…åŠ›ã‚’ç¶­æŒã™ã‚‹è¦‹è¾¼ã¿ã€‚\n    *   **ã‚¯ãƒ©ã‚¦ãƒ‰3ç¤¾ï¼ˆMSFT, GOOGL, AMZNï¼‰**: ã‚¯ãƒ©ã‚¦ãƒ‰ã¸ã®AIçµ±åˆãŒåç›Šãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã¨ã—ã¦æ©Ÿèƒ½ã€‚\n*   **ä¸­ç«‹ãƒ»æ…é‡ï¼ˆNeutral/Bearï¼‰**:\n    *   **Tesla**: æœ€ã‚‚æ„è¦‹ãŒåˆ†ã‹ã‚Œã‚‹éŠ˜æŸ„ã§ã™ã€‚EVå¸‚å ´ã®ç«¶äº‰æ¿€åŒ–ã«ã‚ˆã‚‹ã‚³ã‚¢ãƒ“ã‚¸ãƒã‚¹ã®éˆåŒ–æ‡¸å¿µã«å¯¾ã—ã€Robotaxiã‚„äººå‹ãƒ­ãƒœãƒƒãƒˆï¼ˆOptimusï¼‰ã®æˆæœãŒã©ã†è©•ä¾¡ã•ã‚Œã‚‹ã‹ãŒéµã¨ãªã‚Šã¾ã™ã€‚ä¸€éƒ¨ã‚¢ãƒŠãƒªã‚¹ãƒˆã¯2026å¹´ã®æ¨å¥¨ã«ã¤ã„ã¦ã€Œæ§˜å­è¦‹ï¼ˆWait and Seeï¼‰ã€ã®å§¿å‹¢ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚\n\n---\n\n### 2. Apple Siliconã€ŒM7ãƒãƒƒãƒ—ã€ã®æŠ€è¡“äºˆæ¸¬\n2025å¹´12æœˆæ™‚ç‚¹ã®æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã¯ã€ŒM5ã€ã‚·ãƒªãƒ¼ã‚ºã§ã‚ã‚Šã€M7ã¯é–‹ç™ºãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ä¸Šã®å°†æ¥è£½å“ã§ã™ã€‚\n\n*   **ãƒªãƒªãƒ¼ã‚¹æ™‚æœŸ**: Appleã®å¹´é–“ãƒªãƒªãƒ¼ã‚¹ã‚µã‚¤ã‚¯ãƒ«ã«åŸºã¥ãã€**2027å¹´**ã®ç™»å ´ãŒæ¿ƒåšã§ã™ï¼ˆ2026å¹´ã¯M6ï¼‰ã€‚\n*   **è£½é€ ãƒ—ãƒ­ã‚»ã‚¹**: TSMCã®æœ€å…ˆç«¯**1.4nmãƒ—ãƒ­ã‚»ã‚¹ï¼ˆA14ãƒãƒ¼ãƒ‰ï¼‰**ã‚’æ¡ç”¨ã™ã‚‹æœ€åˆã®ãƒãƒƒãƒ—ã¨ãªã‚‹å¯èƒ½æ€§ãŒé«˜ãã€é›»åŠ›åŠ¹ç‡ã¨å‡¦ç†èƒ½åŠ›ã®éé€£ç¶šçš„ãªå‘ä¸ŠãŒäºˆæ¸¬ã•ã‚Œã¾ã™ã€‚\n*   **æŠ€è¡“ä»•æ§˜**:\n    *   ã‚³ãƒ¼ãƒ‰ãƒãƒ¼ãƒ ï¼š**ã€ŒBorneoã€**\n    *   **AIæ€§èƒ½**: ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹AIï¼ˆNeural Engineï¼‰ã®å¤§å¹…å¼·åŒ–ã€‚\n    *   **æ‹¡å¼µæ€§**: ã‚¹ãƒãƒ¼ãƒˆã‚°ãƒ©ã‚¹ã‚„AIã‚µãƒ¼ãƒãƒ¼ãªã©ã€Mac/iPadä»¥å¤–ã®æ–°ã‚«ãƒ†ã‚´ãƒªã¸ã®æ­è¼‰ã‚‚è¦–é‡ã«å…¥ã‚ŒãŸè¨­è¨ˆã¨ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n\n---\n\n### 3. ãã®ä»–ã®å¯èƒ½æ€§\n*   **eã‚¹ãƒãƒ¼ãƒ„**: ãƒ¢ãƒã‚¤ãƒ«ã‚²ãƒ¼ãƒ ã€Mobile Legends: Bang Bangã€ã®ä¸–ç•Œå¤§ä¼šã€ŒM7 World Championshipã€ã¯ã€**2026å¹´1æœˆ**ã«é–‹å‚¬äºˆå®šã§ã™ã€‚"
                }
            ]
        },
        {
            "id": "6b32b381-01b7-4e52-b756-7a6ada2d1d42",
            "title": "M7ã®1å¹´å¾Œã‚’æ•™ãˆã¦ã€‚",
            "timestamp": "2025-12-02T00:15:54.518563",
            "messages": [
                {
                    "role": "user",
                    "content": "M7ã®1å¹´å¾Œã‚’æ•™ãˆã¦ã€‚"
                },
                {
                    "role": "model",
                    "content": "### çµè«–\nç¾åœ¨ï¼ˆ2025å¹´12æœˆ2æ—¥ï¼‰ã‹ã‚‰1å¹´å¾Œã®**2026å¹´12æœˆæ™‚ç‚¹**ã«ãŠã„ã¦ã€ã€ŒM7ã€ãŒæŒ‡ã™å¯¾è±¡ã”ã¨ã®çŠ¶æ³ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚\n\n*   **Appleè£½ãƒãƒƒãƒ—ã®å ´åˆ**: **æœªç™ºå£²**ã§ã™ã€‚å½“æ™‚ã®æœ€æ–°ä¸»åŠ›ãƒ¢ãƒ‡ãƒ«ã¯ã€ŒM6ã€ã§ã‚ã‚Šã€M7ã®ç™»å ´ã¯2027å¹´å¾ŒåŠã¨äºˆæ¸¬ã•ã‚Œã¾ã™ã€‚\n*   **eã‚¹ãƒãƒ¼ãƒ„å¤§ä¼šã®å ´åˆ**: **çµ‚äº†æ¸ˆã¿**ã§ã™ã€‚æ¬¡å›å¤§ä¼šã€ŒM8ã€ã®é–‹å‚¬ç›´å‰ã®æ™‚æœŸã«ã‚ãŸã‚Šã¾ã™ã€‚\n*   **ç±³å›½æ ªï¼ˆMagnificent Sevenï¼‰ã®å ´åˆ**: **å†ç·¨ã®å¯èƒ½æ€§**ãŒã‚ã‚Šã¾ã™ã€‚AIãƒ–ãƒ¼ãƒ ã®å¤‰è³ªã«ã‚ˆã‚Šã€æ§‹æˆéŠ˜æŸ„ã‚„å¸‚å ´ã®ç‰½å¼•å½¹ãŒå¤‰åŒ–ã—ã¦ã„ã‚‹å…¬ç®—ãŒé«˜ã„ã§ã™ã€‚\n\n---\n\n### è©³ç´°åˆ†æã¨äºˆæ¸¬ã‚·ãƒŠãƒªã‚ª\n\n#### 1. Apple Siliconã€ŒM7ã€ãƒãƒƒãƒ—ã‚’æŒ‡ã™å ´åˆ\n**çŠ¶æ³äºˆæ¸¬: æœªç™ºå£²ï¼ˆå¸‚å ´ã®ä¸»åŠ›ã¯ã€ŒM6ã€ï¼‰**\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒMacã‚„iPadã«æ­è¼‰ã•ã‚Œã‚‹æ¬¡ä¸–ä»£ãƒãƒƒãƒ—ã‚’æƒ³å®šã—ã¦ã„ã‚‹å ´åˆã€1å¹´å¾Œã«ã¯ã¾ã å…¥æ‰‹ã§ãã¾ã›ã‚“ã€‚\n\n*   **1å¹´å¾Œã®å¸‚å ´ç’°å¢ƒ (2026å¹´12æœˆ)**:\n    *   å¸‚å ´ã«å‡ºå›ã£ã¦ã„ã‚‹æœ€æ–°ãƒãƒƒãƒ—ã¯ã€2026å¹´å¾ŒåŠã«ãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã‚‹**ã€ŒM6ï¼ˆã‚³ãƒ¼ãƒ‰ãƒãƒ¼ãƒ : Komodoï¼‰ã€**ã¨ãªã‚‹è¦‹è¾¼ã¿ã§ã™ã€‚\n    *   M6ã¯TSMCã®2nmãƒ—ãƒ­ã‚»ã‚¹ã‚’æ¡ç”¨ã™ã‚‹æœ€åˆã®ä¸–ä»£ã«ãªã‚‹ã¨äºˆæ¸¬ã•ã‚Œã¦ãŠã‚Šã€ç¾è¡Œï¼ˆ2025å¹´12æœˆæ™‚ç‚¹ï¼‰ã®M5ãƒãƒƒãƒ—ã‹ã‚‰å¤§å¹…ãªæ€§èƒ½å‘ä¸ŠãŒæœŸå¾…ã•ã‚Œã¾ã™ã€‚\n*   **M7ã®ãƒªãƒªãƒ¼ã‚¹äºˆæ¸¬**:\n    *   M7ãƒãƒƒãƒ—ï¼ˆã‚³ãƒ¼ãƒ‰ãƒãƒ¼ãƒ : Borneoï¼‰ã®ç™ºè¡¨ã¯ã€ã•ã‚‰ã«1å¹´å¾Œã®**2027å¹´å¾ŒåŠï¼ˆ10æœˆé ƒï¼‰**ã«ãªã‚‹ã¨è¦‹ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚\n    *   **æŠ€è¡“çš„ãƒªã‚¹ã‚¯ã¨è»¢æ›ç‚¹**: M7ã§ã¯è£½é€ ãƒ—ãƒ­ã‚»ã‚¹ã«Intelã®ã€Œ18A-Pã€ã‚’åˆ©ç”¨ã™ã‚‹å¯èƒ½æ€§ãŒå ±ã˜ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚ŒãŒå®Ÿç¾ã™ã‚Œã°ã‚µãƒ—ãƒ©ã‚¤ãƒã‚§ãƒ¼ãƒ³ã®å¤§ããªè»¢æ›ç‚¹ã¨ãªã‚Šã¾ã™ãŒã€è£½é€ æ­©ç•™ã¾ã‚Šç­‰ã®ãƒªã‚¹ã‚¯è¦å› ã‚‚è€ƒæ…®ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n\n#### 2. eã‚¹ãƒãƒ¼ãƒ„å¤§ä¼šã€ŒMobile Legends (MLBB) M7ã€ã‚’æŒ‡ã™å ´åˆ\n**çŠ¶æ³: å¤§ä¼šçµ‚äº†æ¸ˆã¿ï¼ˆæ¬¡å›ã€ŒM8ã€ã®æº–å‚™æœŸé–“ï¼‰**\n\n*   **1å¹´å¾Œã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**:\n    *   ã€ŒM7 World Championshipã€ã¯2026å¹´1æœˆï¼ˆã‚¸ãƒ£ã‚«ãƒ«ã‚¿é–‹å‚¬ï¼‰ã«æ±ºå‹ãŒè¡Œã‚ã‚Œã‚‹ãŸã‚ã€2026å¹´12æœˆæ™‚ç‚¹ã§ã¯ã™ã§ã«éå»ã®ã‚¤ãƒ™ãƒ³ãƒˆã§ã™ã€‚\n    *   ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®é–¢å¿ƒã¯ã€2027å¹´åˆé ­ã«é–‹å‚¬äºˆå®šã®æ¬¡æœŸä¸–ç•Œå¤§ä¼š**ã€ŒM8ã€**ã«å‘ã‘ãŸäºˆé¸ã‚„ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³æ´»å‹•ã«ç§»ã£ã¦ã„ã¾ã™ã€‚\n\n#### 3. ç±³å›½ä¸»è¦ãƒã‚¤ãƒ†ã‚¯æ ªã€ŒMagnificent Sevenã€ã‚’æŒ‡ã™å ´åˆ\n**çŠ¶æ³äºˆæ¸¬: æ çµ„ã¿ã®å†ç·¨ã¨æˆé•·ãƒ•ã‚§ãƒ¼ã‚ºã®ç§»è¡Œ**\n\n*   **å¸‚å ´ç’°å¢ƒã®å¤‰åŒ–**:\n    *   2025å¹´ã¾ã§ã®çˆ†ç™ºçš„ãªåˆ©ç›Šæˆé•·ã‹ã‚‰ã€å‰å¹´æ¯”20%ç¨‹åº¦ã®å®‰å®šæˆé•·ãƒ•ã‚§ãƒ¼ã‚ºã¸ç§»è¡Œã™ã‚‹ã¨äºˆæ¸¬ã•ã‚Œã¦ã„ã¾ã™ã€‚\n    *   **æ§‹æˆéŠ˜æŸ„ã®å…¥ã‚Œæ›¿ãˆ**: Teslaã®æ¥­ç¸¾å¤‰å‹•ã‚„ã€Broadcomã€Eli Lillyã¨ã„ã£ãŸä»–ä¼æ¥­ã®å°é ­ã«ã‚ˆã‚Šã€ã€ŒM7ã€ã¨ã„ã†æ çµ„ã¿è‡ªä½“ãŒå´©ã‚Œã€æ–°ãŸãªã‚°ãƒ«ãƒ¼ãƒ—åã§å‘¼ã°ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n    *   **æŠ•è³‡ã®è¦–ç‚¹**: å¸‚å ´ã®ç‰½å¼•å½¹ã¯M7å˜ç‹¬ã§ã¯ãªãã€AIã‚¤ãƒ³ãƒ•ãƒ©ä¼æ¥­ã‹ã‚‰ã€ã‚ˆã‚Šåºƒç¯„ãªã€ŒAIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ä¼æ¥­ç¾¤ã¸ã¨è£¾é‡ãŒåºƒãŒã£ã¦ã„ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚\n\n---\n\n### æ„æ€æ±ºå®šã¸ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹\n*   **PCè²·ã„æ›¿ãˆæ¤œè¨ä¸­ã®å ´åˆ**: ã€ŒM7ã€ã‚’å¾…ã¤ã®ã¯å¾—ç­–ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚1å¹´å¾Œï¼ˆ2026å¹´å¾ŒåŠï¼‰ã«ç™»å ´ã™ã‚‹**ã€ŒM6ã€æ­è¼‰ãƒ¢ãƒ‡ãƒ«**ãŒã€ç›´è¿‘ã®å¤§ããªè²·ã„æ™‚ã¨ãªã‚Šã¾ã™ã€‚M7ã‚’å¾…ã¤å ´åˆã€è³¼å…¥ã¯2027å¹´æœ«ã¾ã§å…ˆé€ã‚Šã™ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚\n\n**æƒ…å ±æº**:\n*   Bloomberg (Mark Gurman's Roadmap)\n*   Liquipedia (MLBB M7 Tournament Info)\n*   J.P. Morgan Asset Management (2026 Investment Outlook)"
                }
            ]
        },
        {
            "id": "46eaa9e8-5767-43d6-8ca6-51267033e6bc",
            "title": "Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter) ...",
            "timestamp": "2025-12-02T00:10:15.321528",
            "messages": [
                {
                    "role": "user",
                    "content": "Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter) â†’ 1. ç†Ÿè€ƒ + é¬¼è»æ›¹ã¯claudeãŒãã„ã¦ã„ã‚‹ã‹ï¼Ÿ\n\nimport os\nimport uuid\nimport datetime\nimport streamlit as st\nfrom dotenv import load_dotenv\nfrom google import genai\nfrom google.genai import types\nfrom PIL import Image\nimport io\nfrom logic import (\n    USAGE_FILE, SESSIONS_FILE, MAX_BUDGET_USD, PRICING,\n    VERTEX_PROJECT, VERTEX_LOCATION,\n    load_usage, save_usage, calculate_cost, get_mime_type,\n    extract_youtube_id, get_youtube_transcript, get_relevant_context,\n    extract_text_from_response, load_sessions, save_sessions, get_client\n)\n\ntry:\n    from st_img_pastebutton import paste\n    import_error_msg = None\nexcept ImportError as e:\n    paste = None\n    import_error_msg = str(e)\n\n# =========================\n# ç’°å¢ƒå¤‰æ•° & å®šæ•°\n# =========================\n\nload_dotenv()\n\n\n\nst.set_page_config(page_title=\"Gemini 3 Web Studio\", layout=\"wide\")\n\n# ğŸ” ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ­ãƒƒã‚¯ (198501) + URLãƒˆãƒ¼ã‚¯ãƒ³æ°¸ç¶šåŒ–\nSECRET_TOKEN = \"access_granted_198501\"\n\n# 1. URLãƒˆãƒ¼ã‚¯ãƒ³ãƒã‚§ãƒƒã‚¯\nquery_params = st.query_params\nurl_token = query_params.get(\"auth\", None)\n\nif url_token == SECRET_TOKEN:\n    st.session_state.authenticated = True\nelif \"authenticated\" not in st.session_state:\n    st.session_state.authenticated = False\n\n# 2. æœªèªè¨¼ãªã‚‰ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ç”»é¢\nif not st.session_state.authenticated:\n    st.title(\"Gemini 3 Studio\")\n    st.write(\"ã“ã®ã‚¢ãƒ—ãƒªã‚’åˆ©ç”¨ã™ã‚‹ã«ã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒå¿…è¦ã§ã™ã€‚\")\n\n    password = st.text_input(\"ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰\", type=\"password\")\n\n    if st.button(\"ãƒ­ã‚°ã‚¤ãƒ³\"):\n        if password == \"198501\":\n            st.session_state.authenticated = True\n            # URLã«ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä»˜ä¸ã—ã¦ãƒªãƒ­ãƒ¼ãƒ‰ï¼ˆã“ã‚Œã§ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯å¯èƒ½ã«ãªã‚‹ï¼‰\n            st.query_params[\"auth\"] = SECRET_TOKEN\n            st.rerun()\n        else:\n            st.error(\"ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™ã€‚\")\n\n    st.stop()\n\n# =========================\n# Helper Functions\n# =========================\n\n# =========================\n# Helper Functions\n# =========================\n# Moved to logic.py\n\n# =========================\n# Grok Review Function (OpenRouter API)\n# =========================\n\nimport requests\nfrom curl_cffi import requests as crequests  # Grokç”¨ï¼ˆå¿…è¦ã«å¿œã˜ã¦æ®‹ã™ï¼‰\nimport asyncio\nimport nest_asyncio\nfrom putergenai import PuterClient\n\n# Streamlitã§Asyncã‚’ä½¿ã†ãŸã‚ã®è¨­å®š\nnest_asyncio.apply()\n\n# OpenRouter API Keyã®å–å¾— (st.secretså„ªå…ˆã€ãªã‘ã‚Œã°ç’°å¢ƒå¤‰æ•°)\ntry:\n    if \"OPENROUTER_API_KEY\" in st.secrets:\n        OPENROUTER_API_KEY = st.secrets[\"OPENROUTER_API_KEY\"]\n    else:\n        OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\", \"\")\nexcept:\n    OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\", \"\")\n\n# Puter èªè¨¼æƒ…å ±\nPUTER_USERNAME = None\nPUTER_PASSWORD = None\ntry:\n    if \"PUTER_USERNAME\" in st.secrets:\n        PUTER_USERNAME = st.secrets[\"PUTER_USERNAME\"]\n        PUTER_PASSWORD = st.secrets[\"PUTER_PASSWORD\"]\n    else:\n        PUTER_USERNAME = os.getenv(\"PUTER_USERNAME\")\n        PUTER_PASSWORD = os.getenv(\"PUTER_PASSWORD\")\nexcept Exception:\n    PUTER_USERNAME = os.getenv(\"PUTER_USERNAME\")\n    PUTER_PASSWORD = os.getenv(\"PUTER_PASSWORD\")\n\ndef review_with_grok(user_question: str, gemini_answer: str, research_text: str = None) -> str:\n    \"\"\"\n    Grok 4.1 Fast Free ã‚’ä½¿ã£ã¦ã€Geminiã®å›ç­”ã‚’æœ€çµ‚ãƒ¬ãƒ“ãƒ¥ãƒ¼ã™ã‚‹\n    research_text: GeminiãŒåé›†ã—ãŸèª¿æŸ»ãƒ¡ãƒ¢ï¼ˆæœ€æ–°æƒ…å ±ã‚’å«ã‚€ï¼‰\n    \"\"\"\n    url = \"https://openrouter.ai/api/v1/chat/completions\"\n    headers = {\n        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n        \"Content-Type\": \"application/json\",\n    }\n    \n    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰\n    user_content = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\\n{user_question}\\n\\n\"\n    \n    if research_text:\n        user_content += f\"Gemini ã®èª¿æŸ»ãƒ¡ãƒ¢ï¼ˆæœ€æ–°æƒ…å ±ï¼‰:\\n{research_text}\\n\\n\"\n    \n    user_content += (\n        f\"Gemini ã®æœ€çµ‚å›ç­”:\\n{gemini_answer}\\n\\n\"\n        \"**é‡è¦**: èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹äº‹å®Ÿã®æ–¹ã‚’ã€ã‚ãªãŸè‡ªèº«ã®çŸ¥è­˜ã‚ˆã‚Šã‚‚å„ªå…ˆã—ã¦ãã ã•ã„ã€‚\\n\"\n        \"æœ€æ–°ã®æƒ…å ±ãŒèª¿æŸ»ãƒ¡ãƒ¢ã«ã‚ã‚‹å ´åˆã€ãã‚Œã‚’ä¿¡é ¼ã—ã¦ãã ã•ã„ã€‚\\n\\n\"\n        \"1. **é‡å¤§ãªäº‹å®Ÿèª¤èªãƒ»è«–ç†é£›èºã®æŒ‡æ‘˜**ï¼ˆãªã‘ã‚Œã°ã€ç‰¹ã«ãªã—ã€ï¼‰\\n\"\n        \"2. **å…·ä½“çš„ãªä¿®æ­£ææ¡ˆã®ãƒªã‚¹ãƒˆ**ï¼ˆã€ä¿®æ­£å‰ã€â†’ã€ä¿®æ­£å¾Œã€ã®å½¢å¼ã§ï¼‰\\n\"\n        \"3. **ç‰¹ã«ä¸ç¢ºå®Ÿæ€§ãŒé«˜ã„ãƒã‚¤ãƒ³ãƒˆï¼ˆå‰æä¸è¶³ã€ãƒ‡ãƒ¼ã‚¿ä¸è¶³ãªã©ï¼‰ã® bullet list**\\n\"\n    )\n    \n    data = {\n        \"model\": \"x-ai/grok-4.1-fast:free\",\n        \"reasoning\": {\"enabled\": True},  # Enable multi-step reasoning for deeper review\n        \"messages\": [\n            {\n                \"role\": \"system\",\n                \"content\": (\n                    \"ã‚ãªãŸã¯å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ã§ã™ã€‚\"\n                    \"äº‹å®Ÿèª¤èªãƒ»è«–ç†ã®é£›èºãƒ»æŠœã‘æ¼ã‚Œã‚’å®¹èµ¦ãªãæŒ‡æ‘˜ã—ã€\"\n                    \"å¿…è¦ãªã‚‰å›ç­”ã‚’å…¨æ–‡æ›¸ãç›´ã—ã¦ãã ã•ã„ã€‚\"\n                ),\n            },\n            {\n                \"role\": \"user\",\n                \"content\": user_content.strip() + (\n                    \"ã ã‘ã‚’æ—¥æœ¬èªã§å‡ºã—ã¦ãã ã•ã„ã€‚\"\n                ),\n            },\n        ],\n    }\n    try:\n        resp = requests.post(url, headers=headers, json=data, timeout=60)\n        resp.raise_for_status()\n        j = resp.json()\n        return j[\"choices\"][0][\"message\"][\"content\"]\n    except Exception as e:\n        return f\"[Grokãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}]\\n\\n{gemini_answer}\"\n\n# =========================\n# Session Management\n# =========================\n\n\n\ndef think_with_grok(user_question: str, research_text: str, enable_x_search: bool = False) -> str:\n    \"\"\"\n    Grok 4.1 Fast Free ã‚’ä½¿ã£ã¦ã€ãƒªã‚µãƒ¼ãƒãƒ¡ãƒ¢ã‚’å…ƒã«ç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆã‚’ä½œæˆã™ã‚‹\n    enable_x_search=True ã®å ´åˆã€X/Twitteræƒ…å ±ã®æ´»ç”¨ã‚’ä¿ƒã™\n    \"\"\"\n    url = \"https://openrouter.ai/api/v1/chat/completions\"\n    headers = {\n        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n        \"Content-Type\": \"application/json\",\n    }\n    \n    # Xæ¤œç´¢å¼·åŒ–ç‰ˆã®å ´åˆã€ç‰¹åˆ¥ãªæŒ‡ç¤ºã‚’è¿½åŠ \n    x_search_instruction = \"\"\n    if enable_x_search:\n        x_search_instruction = (\n            \"\\n\\n**é‡è¦**: ã‚ãªãŸã¯Grokã¨ã—ã¦Xï¼ˆTwitterï¼‰ã®æƒ…å ±ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚\\n\"\n            \"ä¸Šè¨˜ã®èª¿æŸ»ãƒ¡ãƒ¢ã«åŠ ãˆã¦ã€Xä¸Šã®æœ€æ–°ã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»è­°è«–ãƒ»åå¿œã‚’è€ƒæ…®ã—ã€\\n\"\n            \"ãã‚Œã‚‰ã‚’å«ã‚ãŸç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\\n\\n\"\n            \"æ³¨æ„: Xä¸Šã®æƒ…å ±ãŒç¢ºèªã§ããªã„å ´åˆã¯ã€ãã®æ—¨ã‚’æ­£ç›´ã«è¿°ã¹ã¦ãã ã•ã„ã€‚\\n\"\n            \"æ¶ç©ºã®æŠ•ç¨¿ã‚„å­˜åœ¨ã—ãªã„åå¿œã‚’ä½œæˆã—ãªã„ã“ã¨ã€‚\"\n        )\n    \n    user_content = (\n        f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\\n{user_question}\\n\\n\"\n        f\"èª¿æŸ»ãƒ¡ãƒ¢:\\n{research_text}\\n\\n\"\n        \"æŒ‡ç¤º:\\n\"\n        \"ã‚ãªãŸã¯Geminiã¨ã¯åˆ¥ã®ç‹¬ç«‹ã—ãŸAIã§ã™ã€‚\\n\"\n        \"ä¸Šè¨˜ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’å‚è€ƒã«ã—ã¤ã¤ã‚‚ã€ã‚ãªãŸè‡ªèº«ã®è¦–ç‚¹ã§ç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\\n\"\n        \"Geminiã®æ„è¦‹ã«åˆã‚ã›ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\"\n        f\"{x_search_instruction}\"\n    )\n    \n    data = {\n        \"model\": \"x-ai/grok-2-1212\",\n        \"messages\": [\n            {\"role\": \"user\", \"content\": user_content}\n        ],\n    }\n    \n    try:\n        resp = requests.post(url, headers=headers, json=data, timeout=60)\n        resp.raise_for_status()\n        j = resp.json()\n        return j[\"choices\"][0][\"message\"][\"content\"]\n    except Exception as e:\n        return f\"[Grokæ€è€ƒã‚¨ãƒ©ãƒ¼: {e}]\"\n\ndef _extract_puter_text(message_content):\n    \"\"\"\n    puter.ai.chat ã®è¿”ã‚Šå€¤ã‹ã‚‰ ãƒ†ã‚­ã‚¹ãƒˆã ã‘ã‚’å–ã‚Šå‡ºã™\n    \"\"\"\n    if isinstance(message_content, str):\n        return message_content\n\n    if isinstance(message_content, list):\n        chunks = []\n        for part in message_content:\n            if isinstance(part, dict) and part.get(\"type\") == \"text\":\n                chunks.append(part.get(\"text\", \"\"))\n        return \"\".join(chunks)\n\n    return str(message_content)\n\n\ndef call_claude_opus_via_puter(\n    user_question: str,\n    research_text: str | None = None,\n    system_prompt: str | None = None,\n) -> str:\n    \"\"\"\n    Claude Opus 4.5ï¼ˆputer.comï¼‰via putergenai SDK\n    å…¬å¼ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¦Claudeã«ã‚¢ã‚¯ã‚»ã‚¹\n    \"\"\"\n    if not PUTER_USERNAME or not PUTER_PASSWORD:\n        return \"[Claude (puter) èªè¨¼æƒ…å ±æœªè¨­å®š]\"\n\n    async def _run() -> str:\n        try:\n            async with PuterClient() as client:\n                # SDKã§ãƒ­ã‚°ã‚¤ãƒ³\n                await client.login(PUTER_USERNAME, PUTER_PASSWORD)\n\n                # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹ç¯‰\n                messages = []\n                if system_prompt:\n                    messages.append({\"role\": \"system\", \"content\": system_prompt})\n\n                user_content = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\\n{user_question}\\n\\n\"\n                if research_text:\n                    user_content += f\"èª¿æŸ»ãƒ¡ãƒ¢:\\n{research_text}\\n\\n\"\n                    user_content += \"ã“ã®èª¿æŸ»ãƒ¡ãƒ¢ã®äº‹å®Ÿã‚’å„ªå…ˆã—ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚\\n\"\n\n                messages.append({\"role\": \"user\", \"content\": user_content})\n\n                # Claude Opus 4.5 ã‚’å‘¼ã³å‡ºã—\n                # ai_chat ã¯ messages ã®ã¿ã‚’å—ã‘å–ã‚‹ï¼ˆãƒ¢ãƒ‡ãƒ«ã¯è‡ªå‹•é¸æŠï¼‰\n                result = await client.ai_chat(messages)\n\n                # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰æœ¬æ–‡ã‚’å–å¾—\n                # ãƒ‡ãƒãƒƒã‚°ç”¨ã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹å…¨ä½“ã‚’è¡¨ç¤º\n                import json\n                print(f\"DEBUG: Puter response: {json.dumps(result, indent=2)}\")\n                \n                message_content = result[\"response\"][\"result\"][\"message\"][\"content\"]\n                return _extract_puter_text(message_content)\n\n        except KeyError as e:\n            import traceback\n            return f\"[Claude SDK KeyError] Missing key: {e}\\nTraceback: {traceback.format_exc()}\"\n        except Exception as e:\n            import traceback\n            return f\"[Claude SDK Error] {type(e).__name__}: {str(e)}\\nTraceback: {traceback.format_exc()}\"\n\n    # Streamlitã®åŒæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§asyncã‚’å®Ÿè¡Œ\n    try:\n        return asyncio.run(_run())\n    except Exception as e:\n        import traceback\n        return f\"[Claude Connection Error] {type(e).__name__}: {str(e)}\\nTraceback: {traceback.format_exc()}\"\n\ndef create_new_session():\n    current_sessions = load_sessions()\n    \n    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒç©ºãªã‚‰ã€æ–°ã—ãä½œã‚‰ãšã«ãã‚Œã‚’å†åˆ©ç”¨ã™ã‚‹ï¼ˆé‡è¤‡é˜²æ­¢ï¼‰\n    if st.session_state.get(\"current_session_id\"):\n        for s in current_sessions:\n            if s[\"id\"] == st.session_state.current_session_id:\n                if len(s[\"messages\"]) == 0:\n                    st.toast(\"ã™ã§ã«æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã§ã™\")\n                    return\n\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": [],\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.rerun()\n\ndef switch_session(session_id):\n    st.session_state.current_session_id = session_id\n    st.rerun()\n\ndef update_current_session_messages(messages):\n    if st.session_state.current_session_id:\n        current_sessions = load_sessions()\n        target_index = -1\n        for i, session in enumerate(current_sessions):\n            if session[\"id\"] == st.session_state.current_session_id:\n                session[\"messages\"] = messages\n                if session[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(messages) > 0:\n                    first_msg = messages[0][\"content\"]\n                    session[\"title\"] = (first_msg[:20] + \"...\") if len(first_msg) > 20 else first_msg\n                session[\"timestamp\"] = datetime.datetime.now().isoformat()\n                target_index = i\n                break\n        \n        if target_index != -1:\n            # æœ€æ–°ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒªã‚¹ãƒˆã®å…ˆé ­ã«ç§»å‹•\n            updated_session = current_sessions.pop(target_index)\n            current_sessions.insert(0, updated_session)\n            \n        save_sessions(current_sessions)\n        st.session_state.sessions = current_sessions\n\ndef get_current_messages():\n    if st.session_state.current_session_id:\n        for session in st.session_state.sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                return session[\"messages\"]\n    return []\n\ndef delete_session(session_id):\n    current_sessions = load_sessions()\n    current_sessions = [s for s in current_sessions if s[\"id\"] != session_id]\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    if st.session_state.current_session_id == session_id:\n        st.session_state.current_session_id = None\n        if st.session_state.sessions:\n            st.session_state.current_session_id = st.session_state.sessions[0][\"id\"]\n    st.rerun()\n\ndef branch_session():\n    \"\"\"ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚’åˆ†å²\"\"\"\n    current_messages = get_current_messages()\n    current_sessions = load_sessions()\n    \n    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—\n    current_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n    for session in current_sessions:\n        if session[\"id\"] == st.session_state.current_session_id:\n            current_title = session[\"title\"]\n            break\n    \n    # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": f\"{current_title} (åˆ†å²)\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": current_messages.copy(),  # ç¾åœ¨ã®å±¥æ­´ã‚’ã‚³ãƒ”ãƒ¼\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    \n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.session_state.session_cost = 0.0  # ã‚³ã‚¹ãƒˆãƒªã‚»ãƒƒãƒˆ\n    st.rerun()\n\n# =========================\n# Initialization\n# =========================\n\nif \"sessions\" not in st.session_state:\n    st.session_state.sessions = load_sessions()\n\nif \"current_session_id\" not in st.session_state:\n    # Always create a new session when the app starts\n    create_new_session()\n\nif \"session_cost\" not in st.session_state:\n    st.session_state.session_cost = 0.0\n\nusage_stats = load_usage()\n\n# ==========================\n# ã‚³ã‚¹ãƒˆãƒã‚§ãƒƒã‚¯ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã®å‰ã«å®Ÿè¡Œï¼‰\n# ==========================\nusage_stats = load_usage()\nstop_generation = usage_stats[\"total_cost_usd\"] >= MAX_BUDGET_USD\n\n# =========================\n# Sidebar\n# =========================\n\nwith st.sidebar:\n    # ğŸ” ãƒ­ã‚°ã‚¢ã‚¦ãƒˆãƒœã‚¿ãƒ³\n    if st.button(\"ğŸ”’ ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ\", use_container_width=True):\n        st.session_state.authenticated = False\n        st.query_params.clear()  # URLãƒˆãƒ¼ã‚¯ãƒ³ã‚‚å‰Šé™¤\n        st.rerun()\n\n    st.markdown(\"\"\"\n    <div style=\"text-align: center; padding: 0; margin: 0; margin-top: -1rem;\">\n        <h1 style=\"font-size: 18px; font-weight: 700; margin: 0; padding: 0; letter-spacing: 1px;\">\n            Gemini 3<br/>Studio\n        </h1>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n    col1, col2 = st.columns(2)\n    with col1:\n        if st.button(\"â• æ–°è¦\", use_container_width=True):\n            create_new_session()\n    with col2:\n        if st.button(\"ğŸŒ± åˆ†å²\", use_container_width=True):\n            branch_session()\n\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    current_messages = get_current_messages()\n    if current_messages:\n        with st.expander(\"ğŸ”— å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ\", expanded=False):\n            export_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n            for s in st.session_state.sessions:\n                if s[\"id\"] == st.session_state.current_session_id:\n                    export_title = s[\"title\"]\n                    break\n\n            export_md = f\"# {export_title}\\n\\n\"\n            export_md += f\"**ä½œæˆæ—¥æ™‚**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n---\\n\\n\"\n            for msg in current_messages:\n                role_label = \"ğŸ§‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼\" if msg[\"role\"] == \"user\" else \"ğŸ¤– AI\"\n                export_md += f\"## {role_label}\\n\\n{msg['content']}\\n\\n---\\n\\n\"\n\n            if st.button(\"ãƒªãƒ³ã‚¯ç”Ÿæˆ\", use_container_width=True):\n                with st.spinner(\"ç”Ÿæˆä¸­...\"):\n                    try:\n                        import urllib.request\n                        import urllib.parse\n\n                        data = urllib.parse.urlencode(\n                            {\"content\": export_md, \"expiry_days\": 7, \"syntax\": \"md\"}\n                        ).encode()\n\n                        req = urllib.request.Request(\"https://dpaste.org/api/\", data=data)\n                        req.add_header(\"User-Agent\", \"Mozilla/5.0 (Gemini3Studio)\")\n\n                        with urllib.request.urlopen(req) as response:\n                            share_url = response.read().decode(\"utf-8\").strip()\n                            st.success(\"ä½œæˆå®Œäº†ï¼\")\n                            st.code(share_url)\n                            st.caption(\"â€»7æ—¥é–“æœ‰åŠ¹\")\n                    except Exception as e:\n                        st.error(f\"ã‚¨ãƒ©ãƒ¼: {e}\")\n\n    st.markdown(\"---\")\n\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    with st.expander(\"ğŸ“ æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«\", expanded=False):\n        uploaded_files = st.file_uploader(\n            \"ãƒ•ã‚¡ã‚¤ãƒ«\",\n            accept_multiple_files=True,\n            type=[\"png\", \"jpg\", \"jpeg\", \"mp4\", \"mov\", \"txt\", \"pdf\", \"csv\"],\n            label_visibility=\"collapsed\"\n        )\n\n    # ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ï¼ˆExpanderã®å¤–ã«å‡ºã™ï¼‰\n    pasted_image_bytes = None  # åˆæœŸåŒ–ã—ã¦NameErrorã‚’é˜²ã\n    if paste:\n        if \"paste_key\" not in st.session_state:\n            st.session_state.paste_key = 0\n        try:\n            pasted_image_bytes = paste(\n                label=\"ğŸ“‹ ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰è²¼ä»˜\",\n                key=f\"paste_btn_{st.session_state.paste_key}\",\n            )\n        except Exception as e:\n            st.error(f\"Error: {e}\")\n        \n        if pasted_image_bytes:\n            st.success(\"è²¼ä»˜å®Œäº†\")\n            st.image(pasted_image_bytes, caption=\"ç”»åƒ\", use_container_width=True)\n            if st.button(\"ğŸ—‘ï¸ ã‚¯ãƒªã‚¢\", key=\"clear_paste\"):\n                st.session_state.paste_key += 1\n                st.rerun()\n    else:\n        st.warning(\"Clipboard lib missing\")\n\n    # ---- YouTube URL ----\n    with st.expander(\"ğŸ“º YouTubeåˆ†æ\", expanded=False):\n        youtube_url = st.text_input(\"URL\", placeholder=\"https://youtu.be/...\", label_visibility=\"collapsed\")\n\n    st.markdown(\"---\")\n    \n    st.markdown(\"---\")\n    \n    # ---- ãƒ¢ãƒ¼ãƒ‰ã‚«ãƒ†ã‚´ãƒªé¸æŠ ----\n    mode_category = st.radio(\n        \"ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ¼ãƒ‰\",\n        [\"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\", \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(é€šå¸¸)\", \"Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter)\"],\n        index=0,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’å¤šå±¤ã«å¤‰æ›´\n        horizontal=True,\n    )\n    \n    # ---- å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ ----\n    if mode_category == \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\":\n        with st.expander(\"ãƒ¢ãƒ¼ãƒ‰è¨­å®š(å¤šå±¤)\", expanded=True):\n            mode_type = st.radio(\n                \"ã‚¿ã‚¤ãƒ—\",\n                [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n                index=0,\n                horizontal=True,\n                label_visibility=\"collapsed\"\n            )\n            \n            if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. (è©¦é¨“ä¸­)ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                        \"2. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                        \"3. (è©¦é¨“ä¸­)ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                        \"4. ç†Ÿè€ƒ(ãƒ¡ã‚¿æ€è€ƒ)+grokæ¤œç´¢å¼·åŒ–ç‰ˆ\",\n                    ],\n                    index=1  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ãƒ¡ã‚¿æ€è€ƒã«å¤‰æ›´\n                )\n            elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                    ],\n                    index=0\n                )\n            else:\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                    ],\n                    index=0\n                )\n    \n    # ---- å¤šå±¤+puterãƒ¢ãƒ¼ãƒ‰ ----\n    elif mode_category == \"Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter)\":\n        with st.expander(\"ãƒ¢ãƒ¼ãƒ‰è¨­å®š(å¤šå±¤+puter)\", expanded=True):\n            mode_type = st.radio(\n                \"ã‚¿ã‚¤ãƒ—\",\n                [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n                index=0,\n                horizontal=True,\n                label_visibility=\"collapsed\"\n            )\n            \n            if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                        \"2. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                        \"3. ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                    ],\n                    index=0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’é¬¼è»æ›¹ã«å¤‰æ›´\n                )\n            elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                    ],\n                    index=0\n                )\n            else:\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                    ],\n                    index=0\n                )\n    \n    # ---- é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ ----\n    else:\n        with st.expander(\"ãƒ¢ãƒ¼ãƒ‰è¨­å®š(é€šå¸¸)\", expanded=True):\n            mode_type = st.radio(\n                \"ã‚¿ã‚¤ãƒ—\",\n                [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n                index=0,\n                horizontal=True,\n                label_visibility=\"collapsed\"\n            )\n            \n            if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                        \"2. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                        \"3. ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                    ],\n                    index=0\n                )\n            elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                    ],\n                    index=0\n                )\n            else:\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                    ],\n                    index=0\n                )\n    \n    strict_mode = False\n    \n    # ---- è¨­å®š (ãƒ¢ãƒ‡ãƒ«ãªã©) ----\n    with st.expander(\"âš™ï¸ è¨­å®š\", expanded=False):\n        model_options = [\n            \"gemini-3-pro-preview\",\n            \"gemini-2.5-pro\",\n            \"gemini-2.5-flash\",\n            \"gemini-2.5-flash-lite\",\n            \"gemini-2.0-flash\",\n        ]\n        model_id = st.selectbox(\"ãƒ¢ãƒ‡ãƒ«ID\", options=model_options, index=0)\n\n        use_search = st.toggle(\"Googleæ¤œç´¢\", value=True)\n        candidate_count = st.slider(\"å€™è£œæ•°\", min_value=1, max_value=3, value=3)\n\n    st.markdown(\"---\")\n\n    # ---- å±¥æ­´æ¤œç´¢ ----\n    search_query = st.text_input(\"ğŸ” å±¥æ­´æ¤œç´¢\", placeholder=\"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰...\")\n    if search_query:\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if search_query.lower() in s[\"title\"].lower():\n                filtered_sessions.append(s)\n                continue\n            found = False\n            for m in s[\"messages\"]:\n                if search_query.lower() in m[\"content\"].lower():\n                    filtered_sessions.append(s)\n                    found = True\n                    break\n            if not found:\n                pass\n    else:\n        # æ¤œç´¢ã—ã¦ã„ãªã„å ´åˆ: ç©ºã®ã€Œæ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã€ã‚’é™¤å¤–ï¼ˆç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯é™¤ãï¼‰\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if s[\"id\"] == st.session_state.current_session_id:\n                filtered_sessions.append(s)\n                continue\n            if s[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(s[\"messages\"]) == 0:\n                continue\n            filtered_sessions.append(s)\n\n    # CSSã§è¦‹ã‚„ã™ãä½¿ã„ã‚„ã™ãæœ€é©åŒ–\n    st.markdown(\"\"\"\n    <style>\n    /* å…¨ä½“ã®ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºç¸®å° */\n    .stApp, .stMarkdown, .stButton, .stSelectbox, .stTextInput, .stTextArea {\n        font-size: 12px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ä½™ç™½ã‚’æ¥µé™ã¾ã§è©°ã‚ã‚‹ */\n    section[data-testid=\"stSidebar\"] .block-container {\n        padding-top: 0.3rem !important;\n        padding-bottom: 0.3rem !important;\n        padding-left: 0.5rem !important;\n        padding-right: 0.5rem !important;\n    }\n    /* å„è¦ç´ é–“ã®éš™é–“ã‚’è©°ã‚ã‚‹ */\n    div[data-testid=\"stVerticalBlock\"] > div {\n        gap: 0.1rem !important;\n    }\n    /* Expanderã®ä½™ç™½å‰Šæ¸› */\n    .streamlit-expanderHeader {\n        font-size: 11px !important;\n        padding-top: 0px !important;\n        padding-bottom: 0px !important;\n        min-height: 1.3rem !important;\n    }\n    .streamlit-expanderContent {\n        padding-top: 0px !important;\n        padding-bottom: 0px !important;\n    }\n    /* éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã®ã‚¿ã‚¤ãƒˆãƒ« */\n    div[data-testid=\"stExpander\"] summary p {\n        font-size: 10px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ */\n    section[data-testid=\"stSidebar\"] button p {\n        font-size: 10px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã« */\n    section[data-testid=\"stSidebar\"] button {\n        padding: 0rem 0.2rem !important;\n        min-height: 1.4rem !important;\n        font-size: 10px !important;\n        margin-bottom: 0px !important;\n    }\n    /* ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®ãƒ©ãƒ™ãƒ«ã‚’å°ã•ã */\n    section[data-testid=\"stSidebar\"] .stRadio label {\n        font-size: 10px !important;\n    }\n    section[data-testid=\"stSidebar\"] .stRadio > label > div {\n        font-size: 10px !important;\n    }\n    /* ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ‡ã‚Šè©°ã‚ã‚‹ï¼ˆæ”¹è¡Œã•ã›ãªã„ï¼‰ */\n    section[data-testid=\"stSidebar\"] label, \n    section[data-testid=\"stSidebar\"] p,\n    section[data-testid=\"stSidebar\"] span {\n        white-space: nowrap !important;\n        overflow: hidden !important;\n        text-overflow: ellipsis !important;\n    }\n    /* åŒºåˆ‡ã‚Šç·š */\n    hr {\n        margin-top: 0.1rem !important;\n        margin-bottom: 0.1rem !important;\n    }\n    /* ãƒ˜ãƒƒãƒ€ãƒ¼ç¸®å° */\n    h1, h2, h3 {\n        padding-top: 0rem !important;\n        padding-bottom: 0rem !important;\n        margin-top: 0rem !important;\n        margin-bottom: 0rem !important;\n    }\n    </style>\n    \"\"\", unsafe_allow_html=True)\n    \n    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§é™é †ã‚½ãƒ¼ãƒˆï¼ˆæœ€æ–°ãŒå…ˆé ­ï¼‰\n    filtered_sessions.sort(key=lambda s: s.get(\"timestamp\", \"\"), reverse=True)\n    \n    # ç›´è¿‘5ä»¶ã¨éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«åˆ†å‰²\n    recent_sessions = filtered_sessions[:5] if len(filtered_sessions) > 5 else filtered_sessions\n    archive_sessions = filtered_sessions[5:] if len(filtered_sessions) > 5 else []\n    \n    # ç›´è¿‘5ä»¶ï¼ˆå¸¸ã«å±•é–‹ï¼‰\n    if recent_sessions:\n        st.markdown(\"**ğŸ“Œ ç›´è¿‘ã®ãƒãƒ£ãƒƒãƒˆ**\")\n        for session in recent_sessions:\n            col1, col2 = st.columns([0.8, 0.2])\n            with col1:\n                if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                    switch_session(session[\"id\"])\n            with col2:\n                if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                    delete_session(session[\"id\"])\n    \n    # éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆæŠ˜ã‚ŠãŸãŸã¿ï¼‰\n    if archive_sessions:\n        with st.expander(f\"ğŸ“œ éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ– ({len(archive_sessions)}ä»¶)\", expanded=False):\n            for session in archive_sessions:\n                col1, col2 = st.columns([0.8, 0.2])\n                with col1:\n                    if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                        switch_session(session[\"id\"])\n                with col2:\n                    if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                        delete_session(session[\"id\"])\n\n    st.markdown(\"---\")\n\n    # ---- ç”»åƒç”Ÿæˆ ----\n    with st.expander(\"ğŸ¨ ç”»åƒç”Ÿæˆ\", expanded=False):\n        img_prompt = st.text_area(\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\", placeholder=\"æœªæ¥çš„ãªéƒ½å¸‚...\")\n        aspect_ratio = st.selectbox(\"æ¯”ç‡\", [\"16:9\", \"1:1\", \"4:3\", \"3:4\", \"9:16\"])\n\n        generate_img_btn = st.button(\"ç”Ÿæˆ\", type=\"primary\", disabled=not img_prompt)\n        if generate_img_btn and img_prompt:\n            st.session_state.generate_image_trigger = {\n                \"prompt\": img_prompt,\n                \"aspect_ratio\": aspect_ratio,\n            }\n\n    st.markdown(\"---\")\n\n    # ---- è©•ä¾¡åˆ†æ ----\n    with st.expander(\"ğŸ“Š å“è³ªåˆ†æ\", expanded=False):\n        total_ratings = 0\n        positive_ratings = 0\n        model_ratings = {}\n\n        for s in st.session_state.sessions:\n            for m in s[\"messages\"]:\n                if \"rating\" in m and m[\"rating\"] is not None:\n                    total_ratings += 1\n                    if m[\"rating\"] == 1:\n                        positive_ratings += 1\n                    if \"metadata\" in m and \"model\" in m[\"metadata\"]:\n                        mod = m[\"metadata\"][\"model\"]\n                        if mod not in model_ratings:\n                            model_ratings[mod] = {\"total\": 0, \"positive\": 0}\n                        model_ratings[mod][\"total\"] += 1\n                        if m[\"rating\"] == 1:\n                            model_ratings[mod][\"positive\"] += 1\n\n        if total_ratings > 0:\n            approval_rate = (positive_ratings / total_ratings) * 100\n            st.metric(\"Positive Ratings\", f\"{positive_ratings}/{total_ratings}\", f\"{approval_rate:.1f}%\")\n            best_model = \"N/A\"\n            best_rate = -1\n            for mod, stats in model_ratings.items():\n                rate = stats[\"positive\"] / stats[\"total\"]\n                if rate > best_rate:\n                    best_rate = rate\n                    best_model = mod\n            if best_model != \"N/A\":\n                st.caption(f\"ğŸ† Best: **{best_model}** ({best_rate*100:.0f}%)\")\n        else:\n            st.caption(\"ãƒ‡ãƒ¼ã‚¿ãªã—\")\n\n    st.markdown(\"---\")\n\n    # ---- ã‚³ã‚¹ãƒˆè¡¨ç¤º ----\n    from logic import load_manual_cost, save_manual_cost, MAX_BUDGET_JPY, TRIAL_LIMIT_JPY, TRIAL_EXPIRY\n    \n    st.subheader(\"ğŸ’° Cost\")\n    st.caption(f\"äºˆç®—: Â¥{MAX_BUDGET_JPY:,.0f}\")\n    st.caption(f\"ä¸Šé™: Â¥{TRIAL_LIMIT_JPY:,.0f}\")\n    st.caption(f\"æœ‰åŠ¹æœŸé™: {TRIAL_EXPIRY}\")\n    \n    # æ‰‹å‹•ã‚³ã‚¹ãƒˆå…¥åŠ›ï¼ˆæ°¸ç¶šåŒ–ï¼‰\n    current_manual_cost = load_manual_cost()\n    manual_cost = st.number_input(\n        \"æ‰‹å‹•å…¥åŠ› (Â¥)\",\n        min_value=0.0,\n        value=current_manual_cost,\n        step=10.0,\n        format=\"%.0f\",\n        key=\"manual_cost_persistent\",\n        help=\"Google Cloud Consoleã§ç¢ºèªã—ãŸå®Ÿéš›ã®ã‚³ã‚¹ãƒˆï¼ˆå††ï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ã“ã®å€¤ã¯ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‰ã˜ã¦ã‚‚ä¿æŒã•ã‚Œã¾ã™ã€‚\"\n    )\n    \n    # å€¤ãŒå¤‰æ›´ã•ã‚ŒãŸã‚‰ä¿å­˜\n    if manual_cost != current_manual_cost:\n        save_manual_cost(manual_cost)\n    \n    st.link_button(\"ğŸ’° Google Cloud Console\", \"https://console.cloud.google.com/welcome/new?_gl=1*kmr691*_up*MQ..&gclid=CjwKCAiAraXJBhBJEiwAjz7MZT0vQsfDK5zunRBCQmuN5iczgI4bP1lHo1Tcrcbqu1KCBE1D22GpFhoCOdgQAvD_BwE&gclsrc=aw.ds&hl=ja&authuser=5&project=sigma-task-479704-r6\")\n\n    st.markdown(\"---\")\n    st.code(f\"PROJECT: {VERTEX_PROJECT}\\nLOCATION: {VERTEX_LOCATION} (Vertex AI)\")\n\n# =========================\n# Main UI\n# =========================\n\ncurrent_session_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\nfor s in st.session_state.sessions:\n    if s[\"id\"] == st.session_state.current_session_id:\n        current_session_title = s[\"title\"]\n        break\n\nst.header(current_session_title)\nst.markdown(\n    \"ä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\"\n)\n\n\n# ---- ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒœã‚¿ãƒ³ (Floating) ----\nst.markdown(\"\"\"\n    <style>\n        .scroll-btn-container {\n            position: fixed;\n            bottom: 100px;\n            right: 20px;\n            z-index: 9999;\n            display: flex;\n            flex-direction: column;\n            gap: 10px;\n        }\n        .scroll-btn {\n            background-color: #f0f2f6;\n            color: #31333F;\n            border: 1px solid #d6d6d8;\n            border-radius: 50%;\n            width: 40px;\n            height: 40px;\n            display: flex;\n            align-items: center;\n            justify-content: center;\n            cursor: pointer;\n            box-shadow: 0 2px 5px rgba(0,0,0,0.1);\n            transition: all 0.3s ease;\n            font-size: 20px;\n            padding: 0;\n            line-height: 1;\n        }\n        .scroll-btn:hover {\n            background-color: #e0e2e6;\n            transform: scale(1.1);\n            box-shadow: 0 4px 8px rgba(0,0,0,0.15);\n        }\n    </style>\n    \n    <script>\n        window.scrollStreamlit = function(direction) {\n            console.log(\"Scroll triggered: \" + direction);\n            \n            // ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ãªã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹è¦ç´ ã‚’é †ç•ªã«è©¦ã™\n            var targets = [];\n            \n            try {\n                if (window.parent && window.parent.document) {\n                    targets.push(window.parent.document.querySelector('section[data-testid=\"stAppViewContainer\"]'));\n                    targets.push(window.parent.document.querySelector('.main'));\n                    targets.push(window.parent.document.documentElement);\n                }\n            } catch (e) {\n                console.log(\"Access to parent window denied\");\n            }\n            \n            // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆiframeå†…ï¼‰\n            targets.push(document.querySelector('section[data-testid=\"stAppViewContainer\"]'));\n            targets.push(document.documentElement);\n\n            var scrolled = false;\n            for (var i = 0; i < targets.length; i++) {\n                var el = targets[i];\n                if (el) {\n                    try {\n                        // ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯èƒ½ãªè¦ç´ ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“çš„ï¼‰\n                        if (el.scrollHeight > el.clientHeight || el === window.parent.document.documentElement) {\n                            console.log(\"Scrolling element:\", el);\n                            if (direction === 'top') {\n                                el.scrollTo({top: 0, behavior: 'smooth'});\n                            } else {\n                                el.scrollTo({top: el.scrollHeight, behavior: 'smooth'});\n                            }\n                            scrolled = true;\n                        }\n                    } catch (e) {\n                        console.error(\"Error scrolling element:\", e);\n                    }\n                }\n            }\n            \n            if (!scrolled) {\n                console.log(\"No scrollable container found, trying window scroll\");\n                try {\n                    if (direction === 'top') {\n                        window.parent.scrollTo({top: 0, behavior: 'smooth'});\n                    } else {\n                        window.parent.scrollTo({top: window.parent.document.body.scrollHeight, behavior: 'smooth'});\n                    }\n                } catch(e) {\n                    window.scrollTo({top: 0, behavior: 'smooth'});\n                }\n            }\n        }\n    </script>\n\n    <div class=\"scroll-btn-container\">\n        <button class=\"scroll-btn\" onclick=\"window.scrollStreamlit('top')\" title=\"Top\">â¬†ï¸</button>\n        <button class=\"scroll-btn\" onclick=\"window.scrollStreamlit('bottom')\" title=\"Bottom\">â¬‡ï¸</button>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n# ---- Vertex AI Client ----\n\n\n\nclient = get_client()\n\n# ---- å±¥æ­´è¡¨ç¤º ----\n\nmessages = get_current_messages()\nfor idx, msg in enumerate(messages):\n    with st.chat_message(msg[\"role\"]):\n        st.markdown(msg[\"content\"])\n        if msg[\"role\"] == \"model\":\n            col1, col2, col3 = st.columns([0.1, 0.1, 0.8])\n            current_rating = msg.get(\"rating\")\n            with col1:\n                if st.button(\"ğŸ‘\", key=f\"up_{idx}\"):\n                    messages[idx][\"rating\"] = 1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col2:\n                if st.button(\"ğŸ‘\", key=f\"down_{idx}\"):\n                    messages[idx][\"rating\"] = -1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col3:\n                if current_rating == 1:\n                    st.caption(\"âœ… é«˜è©•ä¾¡\")\n                elif current_rating == -1:\n                    st.caption(\"âŒ ä½è©•ä¾¡\")\n\n# ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒœã‚¿ãƒ³ï¼ˆé•·ã„ãƒãƒ£ãƒƒãƒˆç”¨ï¼‰\nif len(messages) > 5:\n    st.markdown(\"\"\"\n    <div style=\"position: fixed; right: 20px; bottom: 100px; z-index: 999;\">\n        <button onclick=\"window.scrollTo({top: 0, behavior: 'smooth'})\" \n                style=\"display: block; margin: 5px; padding: 10px 15px; font-size: 24px; cursor: pointer; \n                       border: 2px solid #ccc; border-radius: 50%; background: white; box-shadow: 0 2px 8px rgba(0,0,0,0.2);\">\n            â¬†ï¸\n        </button>\n        <button onclick=\"window.scrollTo({top: document.body.scrollHeight, behavior: 'smooth'})\" \n                style=\"display: block; margin: 5px; padding: 10px 15px; font-size: 24px; cursor: pointer; \n                       border: 2px solid #ccc; border-radius: 50%; background: white; box-shadow: 0 2px 8px rgba(0,0,0,0.2);\">\n            â¬‡ï¸\n        </button>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n\n# =========================\n# ç”»åƒç”Ÿæˆãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°\n# =========================\n\nif hasattr(st.session_state, \"generate_image_trigger\") and st.session_state.generate_image_trigger:\n    img_data = st.session_state.generate_image_trigger\n    del st.session_state.generate_image_trigger\n\n    with st.chat_message(\"user\"):\n        st.markdown(f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\")\n        st.caption(f\"ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”: {img_data['aspect_ratio']}\")\n\n    messages.append({\"role\": \"user\", \"content\": f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\"})\n    update_current_session_messages(messages)\n\n    with st.chat_message(\"assistant\"):\n        with st.status(\"ç”»åƒã‚’ç”Ÿæˆä¸­...\", expanded=True) as status:\n            try:\n                config = types.GenerateContentConfig(\n                    response_modalities=[\"IMAGE\"],\n                    image_config=types.ImageConfig(\n                        aspect_ratio=img_data[\"aspect_ratio\"]\n                    ),\n                )\n                status.write(\"Gemini 3 Pro Imageã§ç”Ÿæˆä¸­...\")\n                response = client.models.generate_content(\n                    model=\"gemini-3-pro-image-preview\",\n                    contents=img_data[\"prompt\"],\n                    config=config,\n                )\n\n                generated_image = None\n\n                # ç”»åƒã‚’å–ã‚Šå‡ºã™\n                if getattr(response, \"candidates\", None):\n                    for candidate in response.candidates:\n                        if getattr(candidate, \"content\", None) and candidate.content.parts:\n                            for part in candidate.content.parts:\n                                if getattr(part, \"inline_data\", None):\n                                    try:\n                                        generated_image = part.as_image()\n                                    except AttributeError:\n                                        image_bytes_raw = part.inline_data.data\n                                        generated_image = Image.open(io.BytesIO(image_bytes_raw))\n                                    break\n                        if generated_image is not None:\n                            break\n\n                if generated_image is not None:\n                    st.image(generated_image, caption=img_data[\"prompt\"])\n                    buf = io.BytesIO()\n                    generated_image.save(buf, format=\"PNG\")\n                    image_bytes = buf.getvalue()\n                    st.download_button(\n                        label=\"ğŸ’¾ ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\",\n                        data=image_bytes,\n                        file_name=f\"generated_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png\",\n                        mime=\"image/png\",\n                    )\n                    messages.append(\n                        {\"role\": \"model\", \"content\": f\"âœ… ç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {img_data['prompt']}\"}\n                    )\n                    update_current_session_messages(messages)\n                    status.update(label=\"âœ… ç”»åƒç”Ÿæˆå®Œäº†\", state=\"complete\")\n                else:\n                    st.error(\"ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")\n                    status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n\n            except Exception as e:\n                status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n                st.error(f\"ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}\")\n\n# =========================\n# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›\n# =========================\n\nprompt = st.chat_input(\"ä½•ã‹èã„ã¦ãã ã•ã„...\", disabled=stop_generation)\n\nif prompt:\n    if stop_generation:\n        st.error(\"äºˆç®—ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚\")\n    else:\n        # ---- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€è¡¨ç¤º ----\n        with st.chat_message(\"user\"):\n            st.markdown(prompt)\n            if uploaded_files:\n                for uf in uploaded_files:\n                    st.caption(f\"ğŸ“ æ·»ä»˜: {uf.name}\")\n            if youtube_url:\n                st.caption(f\"ğŸ“º YouTube: {youtube_url}\")\n            if pasted_image_bytes:\n                st.caption(\"ğŸ“‹ ç”»åƒãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚Œã¾ã—ãŸ\")\n\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        update_current_session_messages(messages)\n\n        # ---- ãƒ¢ãƒ‡ãƒ«å¿œç­” ----\n        with st.chat_message(\"assistant\"):\n            status_container = st.status(\"æ€è€ƒä¸­...\", expanded=True)\n            try:\n                # ä¼šè©±å±¥æ­´\n                model_history = []\n                for msg in messages[:-1]:\n                    model_history.append(\n                        types.Content(\n                            role=msg[\"role\"],\n                            parts=[types.Part.from_text(text=msg[\"content\"])],\n                        )\n                    )\n\n                # ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³\n                current_parts = [types.Part.from_text(text=prompt)]\n\n                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«\n                for uploaded_file in uploaded_files or []:\n                    try:\n                        mime_type = get_mime_type(uploaded_file.name)\n                        bytes_data = uploaded_file.getvalue()\n                        part = types.Part.from_bytes(data=bytes_data, mime_type=mime_type)\n                        current_parts.append(part)\n                        status_container.write(f\"ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™å®Œäº†: {uploaded_file.name}\")\n                    except Exception as e:\n                        status_container.error(\n                            f\"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {uploaded_file.name} - {e}\"\n                        )\n\n                # è²¼ã‚Šä»˜ã‘ç”»åƒ\n                if pasted_image_bytes:\n                    import base64\n\n                    status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã‚’å‡¦ç†ä¸­...\")\n                    try:\n                        if isinstance(pasted_image_bytes, str):\n                            if pasted_image_bytes.startswith(\"data:\"):\n                                base64_str = pasted_image_bytes.split(\",\", 1)[1]\n                                image_bytes_decoded = base64.b64decode(base64_str)\n                            else:\n                                image_bytes_decoded = base64.b64decode(pasted_image_bytes)\n                        else:\n                            image_bytes_decoded = pasted_image_bytes\n                        part = types.Part.from_bytes(\n                            data=image_bytes_decoded, mime_type=\"image/png\"\n                        )\n                        current_parts.append(part)\n                        status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®æº–å‚™å®Œäº†\")\n                    except Exception as e:\n                        status_container.error(f\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n\n                # YouTube å­—å¹•\n                if youtube_url:\n                    vid_id = extract_youtube_id(youtube_url)\n                    if vid_id:\n                        status_container.write(\"YouTubeã®å­—å¹•ã‚’å–å¾—ä¸­...\")\n                        transcript_text = get_youtube_transcript(vid_id)\n                        current_parts.append(\n                            types.Part.from_text(text=f\"YouTube Transcript:\\n{transcript_text}\")\n                        )\n                    else:\n                        status_container.write(\"ç„¡åŠ¹ãªYouTube URLã§ã™ã€‚\")\n\n                contents_for_model = model_history + [\n                    types.Content(role=\"user\", parts=current_parts)\n                ]\n\n                # ---- Tool / Config ----\n                tools = []\n                final_candidate_count = candidate_count\n                if use_search:\n                    tools.append(types.Tool(google_search=types.GoogleSearch()))\n                    final_candidate_count = 1\n\n                # â˜… System Instruction ã®æ”¹å–„: ãƒ¡ã‚¿ç™ºè¨€ç¦æ­¢ã¨ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªæŒ¯ã‚‹èˆã„ã‚’æŒ‡ç¤º\n                base_system_instruction = (\n                    \"ã‚ãªãŸã¯é«˜åº¦ãªçŸ¥æ€§ã‚’æŒã¤å°‚é–€çš„ãªãƒªã‚µãƒ¼ãƒãƒ»ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\\n\"\n                    \"ä»¥ä¸‹ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’å³å®ˆã—ã¦ãã ã•ã„ï¼š\\n\"\n                    \"1. **ãƒ¡ã‚¿ç™ºè¨€ã®ç¦æ­¢**: ã€Œç§ã¯AIã§ã™ã€ã€Œä¸–ç•Œæœ€é«˜å³°ã®ï½ã¨ã—ã¦ã€ãªã©ã®è‡ªå·±è¨€åŠã‚„å‰ç½®ãã¯ä¸€åˆ‡è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚\\n\"\n                    \"2. **æ„å›³ã®æ±²ã¿å–ã‚Š**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã®èƒŒå¾Œã«ã‚ã‚‹æ„å›³ï¼ˆæ–‡è„ˆã€æš—é»™ã®å‰æï¼‰ã‚’æ¨æ¸¬ã—ã€è¨€è‘‰é€šã‚Šã§ã¯ãªãã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ¬å½“ã«çŸ¥ã‚ŠãŸã„ã“ã¨ã€ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n\"\n                    \"3. **æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”**: çµè«–ã‚’å…ˆã«è¿°ã¹ã€ãã®å¾Œã«è©³ç´°ãªæ ¹æ‹ ã€ã‚·ãƒŠãƒªã‚ªåˆ†æã€ãƒªã‚¹ã‚¯è¦å› ã‚’è«–ç†çš„ã«å±•é–‹ã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"4. **å®¢è¦³æ€§**: äºˆæ¸¬ã‚’è¡Œã†å ´åˆã¯ã€æ–­å®šã‚’é¿ã‘ã€è¤‡æ•°ã®ã‚·ãƒŠãƒªã‚ªï¼ˆæ¥½è¦³ã€æ‚²è¦³ã€ä¸­ç«‹ï¼‰ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"5. **å¼•ç”¨**: æ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸå ´åˆã¯ã€å¿…ãšæƒ…å ±æºã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚\"\n                )\n\n                final_answer = \"\"\n                grounding_metadata = None\n                \n                # =========================\n                # ãƒ¢ãƒ¼ãƒ‰è¨­å®šã®è§£æ\n                # =========================\n                # Î²1é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ä»¥å¤–ã¯ãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œ\n                enable_research = \"Î²1\" not in response_mode\n                enable_meta = \"ãƒ¡ã‚¿\" in response_mode or \"MAX\" in response_mode\n                enable_strict = \"é¬¼è»æ›¹\" in response_mode or \"MAX\" in response_mode\n                enable_grok_x_search = \"grokæ¤œç´¢å¼·åŒ–ç‰ˆ\" in response_mode\n\n                # =========================\n                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (é«˜é€Ÿ / é¬¼è»æ›¹)\n                # =========================\n                if not enable_research:\n                    config = types.GenerateContentConfig(\n                        temperature=0.7,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=base_system_instruction,\n                    )\n                    \n                    status_container.write(\"å›ç­”ç”Ÿæˆä¸­...\")\n                    response = client.models.generate_content(\n                        model=model_id,\n                        contents=contents_for_model,\n                        config=config,\n                    )\n                    \n                    final_answer = extract_text_from_response(response)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®—\n                    if response.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            response.usage_metadata.prompt_token_count,\n                            response.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += response.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += response.usage_metadata.candidates_token_count\n\n                    # é¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ (é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ç‰ˆ)\n                    if enable_strict:\n                        status_container.write(\"ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        reviewer_instruction = base_system_instruction + \"\"\"\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n                        review_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\nåˆç‰ˆå›ç­”:\\n{final_answer}\\n\\nãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\")])]\n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=types.GenerateContentConfig(temperature=0.1, candidate_count=1, system_instruction=reviewer_instruction)\n                        )\n                        final_answer = extract_text_from_response(review_resp)\n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        \n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(model_id, review_resp.usage_metadata.prompt_token_count, review_resp.usage_metadata.candidates_token_count)\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n\n                # =========================\n                # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰\n                # =========================\n                else:\n                    # =========================\n                    # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰: å¤šæ®µéšã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ \n                    # =========================\n                    \n                    # --- Phase 1: ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 1: ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    import datetime as dt\n                    current_year = dt.datetime.now().year\n                    \n                    research_instruction = base_system_instruction + f\"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒªã‚µãƒ¼ãƒå°‚ä»»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚æœ€çµ‚å›ç­”ã¯æ›¸ã‹ãšã€äº‹å®Ÿåé›†ã«é›†ä¸­ã™ã‚‹ã“ã¨ã€‚\n\n**èª¿æŸ»è¦³ç‚¹**:\n- è³ªå•ã«é–¢é€£ã™ã‚‹**æœ€æ–°ã®äº‹å®Ÿãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ»çµ±è¨ˆ**ï¼ˆ**{current_year}å¹´ã®æƒ…å ±ã‚’æœ€å„ªå…ˆ**ï¼‰\n- **ç¾æ™‚ç‚¹ã§å­˜åœ¨ã™ã‚‹å…¨ã¦ã®é¸æŠè‚¢ãƒ»ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¶²ç¾…çš„ã«èª¿æŸ»**ï¼ˆä¾‹: è£½å“æ¯”è¼ƒãªã‚‰ã€æœ€æ–°ç‰ˆã ã‘ã§ãªãç›´è¿‘ã®å…¨ä¸–ä»£ã‚’èª¿æŸ»ï¼‰\n- å…¬å¼æƒ…å ±ã‚„ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã‹ã‚‰ã®å¼•ç”¨\n- é–¢é€£ã™ã‚‹èƒŒæ™¯æƒ…å ±ã‚„æ–‡è„ˆ\n- ç«¶åˆãƒ»ä»£æ›¿æ¡ˆãƒ»æ¯”è¼ƒå¯¾è±¡ã®**å®Œå…¨ãªãƒªã‚¹ãƒˆ**\n- ãƒªã‚¹ã‚¯ãƒ»åˆ¶ç´„ãƒ»æ³¨æ„ç‚¹ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n- å‚è€ƒã«ã—ãŸä¸»è¦ãªæƒ…å ±æºã®URL\n\n**é‡è¦**: \n- çµè«–ã‚„æ¨å¥¨ã¯æ›¸ã‹ãšã€å¾Œå·¥ç¨‹ãŒåˆ¤æ–­ã§ãã‚‹èª¿æŸ»ãƒ¡ãƒ¢ã«é›†ä¸­ã™ã‚‹ã“ã¨\n- **å¿…ãšæ¤œç´¢æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã€æœ€æ–°ã®æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã“ã¨**\n- **æ¤œç´¢çµæœã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æ—¥ä»˜ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒ»ãƒ¢ãƒ‡ãƒ«åã‚’å„ªå…ˆçš„ã«è¨˜è¼‰ã™ã‚‹ã“ã¨**\n- **æ¯”è¼ƒå¯¾è±¡ã¨ãªã‚‹é¸æŠè‚¢ã‚’è¦‹è½ã¨ã•ãªã„ã‚ˆã†ã€è¤‡æ•°ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è©¦ã™ã“ã¨**ï¼ˆä¾‹: ã€ŒiPhone æœ€æ–°ãƒ¢ãƒ‡ãƒ« {current_year}ã€ã€ŒiPhone {current_year}å¹´ç™ºå£²ã€ãªã©ï¼‰\n- **ã€Œã“ã‚Œã‚ˆã‚Šæ–°ã—ã„ãƒ¢ãƒ‡ãƒ«/ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯å­˜åœ¨ã—ãªã„ã‹ï¼Ÿã€ã‚’å¸¸ã«ç¢ºèªã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ï¼ˆ{current_year-1}å¹´ä»¥å‰ãªã©ï¼‰ã—ã‹è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãã®æ—¨ã‚’æ˜è¨˜ã™ã‚‹ã“ã¨\n\"\"\"\n\n                    # éå»ã®é–¢é€£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—\n                    past_context = get_relevant_context(prompt, st.session_state.sessions, st.session_state.current_session_id)\n                    \n                    # ãƒªã‚µãƒ¼ãƒç”¨ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ§‹ç¯‰\n                    import datetime as dt\n                    current_date = dt.datetime.now().strftime(\"%Yå¹´%mæœˆ%dæ—¥\")\n                    research_parts = [types.Part(text=(\n                        f\"é‡è¦: ä»Šæ—¥ã¯{current_date}ã§ã™ã€‚ã“ã®æ—¥ä»˜ã‚ˆã‚Šæ–°ã—ã„æƒ…å ±ã‚’å„ªå…ˆã—ã¦ãã ã•ã„ã€‚\\n\\n\"\n                        f\"è³ªå•: {prompt}\"\n                    ))]\n                    \n                    if past_context:\n                        research_parts.insert(0, types.Part(text=\"ä»¥ä¸‹ã¯éå»ã®é–¢é€£ãƒãƒ£ãƒƒãƒˆã‹ã‚‰æŠ½å‡ºã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã™ï¼š\\n\\n\" + past_context))\n                    \n                    research_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=research_parts)\n                    ]\n                    \n                    research_config = types.GenerateContentConfig(\n                        temperature=0.4,  # æœ€æ–°æƒ…å ±ã‚’æŸ”è»Ÿã«æ¡ç”¨ã™ã‚‹ãŸã‚0.2â†’0.4ã«ä¸Šæ˜‡\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=research_instruction,\n                    )\n                    \n                    research_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=research_contents,\n                        config=research_config,\n                    )\n                    \n                    research_text = extract_text_from_response(research_resp)\n                    \n                    # ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºã®ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ±ã‚’ä¿å­˜\n                    if research_resp.candidates and research_resp.candidates[0].grounding_metadata:\n                        grounding_metadata = research_resp.candidates[0].grounding_metadata\n                    \n                    status_container.write(\"âœ“ ãƒªã‚µãƒ¼ãƒå®Œäº†\")\n                    with status_container.expander(\"åé›†ã—ãŸèª¿æŸ»ãƒ¡ãƒ¢\", expanded=False):\n                        st.markdown(research_text)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1)\n                    if research_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            research_resp.usage_metadata.prompt_token_count,\n                            research_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += research_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += research_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 1.5: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    questions_text = \"\"\n                    if enable_meta:\n                        status_container.write(\"Phase 1.5: ãƒ¡ã‚¿è³ªå•ç”Ÿæˆä¸­...\")\n                        \n                        question_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ç›®çš„**: \nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•ã¨èª¿æŸ»ãƒ¡ãƒ¢ã‚’è¸ã¾ãˆã¦ã€ã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±ãç†è§£ã™ã‚‹ãŸã‚ã®ã€Œé‹­ã„ã‚µãƒ–è³ªå•ã€ã‚’ä½œæˆã™ã‚‹ã“ã¨ã€‚\n\n**ãƒ«ãƒ¼ãƒ«**:\n- æœ€å¤§5å€‹ã¾ã§\n- å„è³ªå•ã¯1-2è¡Œã§å…·ä½“çš„ã‹ã¤é‹­ã\n- ä»¥ä¸‹ã®è¦³ç‚¹ã‚’æ„è­˜:\n  1. å‰æãŒå´©ã‚Œã‚‹å¯èƒ½æ€§ã¯ã©ã“ã‹ï¼Ÿ\n  2. å¼·æ°—/å¼±æ°—ã‚·ãƒŠãƒªã‚ªã®åˆ†å²ç‚¹ã¯ä½•ã‹ï¼Ÿ\n  3. ç«¶åˆãƒ»æŠ€è¡“ãƒ»è¦åˆ¶ã®ä¸ç¢ºå®Ÿæ€§ã¯ï¼Ÿ\n  4. ã€Œäºˆæ¸¬ãŒå¤–ã‚Œã‚‹ã¨ã—ãŸã‚‰ã©ã‚“ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ï¼Ÿã€\n\n**å‡ºåŠ›**: ç®‡æ¡æ›¸ãï¼ˆQ1, Q2...ï¼‰ã®ã¿\n\"\"\"\n\n                        question_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•:\\n{prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\nã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±æ˜ã‚Šã™ã‚‹ãŸã‚ã®é‡è¦ãªã‚µãƒ–è³ªå•ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\")])]\n                        \n                        question_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=question_contents,\n                            config=types.GenerateContentConfig(\n                                temperature=0.4,\n                                candidate_count=1,\n                                system_instruction=question_instruction,\n                            )\n                        )\n                        \n                        questions_text = extract_text_from_response(question_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¡ã‚¿è³ªå•ç”Ÿæˆå®Œäº†\")\n                        with status_container.expander(\"ç”Ÿæˆã•ã‚ŒãŸãƒ¡ã‚¿è³ªå•\", expanded=False):\n                            st.markdown(questions_text)\n                        \n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += question_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += question_resp.usage_metadata.candidates_token_count\n\n                    # å¤šå±¤+puterãƒ¢ãƒ¼ãƒ‰ã®é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã‹ãƒã‚§ãƒƒã‚¯\n                    is_puter_onigunsou = (\n                        mode_category == \"Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter)\" and\n                        response_mode == \"1. ç†Ÿè€ƒ + é¬¼è»æ›¹\"\n                    )\n\n                    # --- Phase 1.5b: Grok ç‹¬ç«‹æ€è€ƒ (å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    # --- Phase 1.5b: Grok ç‹¬ç«‹æ€è€ƒ (å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    grok_thought = \"\"\n                    grok_status = \"skipped\"\n                    if enable_meta and OPENROUTER_API_KEY:\n                        status_container.write(\"Phase 1.5b: Grok ç‹¬ç«‹æ€è€ƒä¸­...\")\n                        try:\n                            grok_thought = think_with_grok(prompt, research_text, enable_x_search=enable_grok_x_search)\n                            if grok_thought:\n                                grok_status = \"success\"\n                                status_container.write(\"âœ“ Grok 4.1 Fast Free ç‹¬ç«‹æ€è€ƒå®Œäº†\")\n                                with status_container.expander(\"Grokã®ç‹¬ç«‹å›ç­”æ¡ˆ\", expanded=False):\n                                    st.markdown(grok_thought)\n                            else:\n                                grok_status = \"empty\"\n                        except Exception as e:\n                            grok_status = \"error\"\n                            status_container.write(f\"âš  Grokæ€è€ƒã‚¨ãƒ©ãƒ¼: {e}\")\n\n                    # --- Phase 1.5c: Claude Opus 4.5 ç‹¬ç«‹æ€è€ƒ (å¤šå±¤+puterã®é¬¼è»æ›¹ã®ã¿) ---\n                    # --- Phase 1.5c: Claude Opus 4.5 ç‹¬ç«‹æ€è€ƒ (å¤šå±¤+puterã®é¬¼è»æ›¹ã®ã¿) ---\n                    claude_thought = \"\"\n                    claude_status = \"skipped\"\n                    if is_puter_onigunsou and PUTER_USERNAME and PUTER_PASSWORD:\n                        status_container.write(\"Phase 1.5c: Claude Opus 4.5 ç‹¬ç«‹æ€è€ƒä¸­...\")\n                        try:\n                            claude_thought = call_claude_opus_via_puter(\n                                user_question=prompt,\n                                research_text=research_text,\n                                system_prompt=(\n                                    \"ã‚ãªãŸã¯ Claude Opus 4.5 ã§ã™ã€‚\"\n                                    \"Gemini ãŒé›†ã‚ãŸèª¿æŸ»ãƒ¡ãƒ¢ã‚’å‚è€ƒã«ã—ã¤ã¤ã‚‚ã€\"\n                                    \"è‡ªåˆ†ã®è¦–ç‚¹ã§ç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆãƒ»æ°—ã¥ãã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\"\n                                    \"Gemini ã®æ„è¦‹ã«åˆã‚ã›ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\"\n                                ),\n                            )\n                            if claude_thought and not claude_thought.startswith(\"[Claude\"):\n                                claude_status = \"success\"\n                                status_container.write(\"âœ“ Claude Opus 4.5 (via Puter) ç‹¬ç«‹æ€è€ƒå®Œäº†\")\n                                with status_container.expander(\"Claude Opus 4.5 ã®ç‹¬ç«‹å›ç­”æ¡ˆ\", expanded=False):\n                                    st.markdown(claude_thought)\n                            else:\n                                claude_status = \"error\"\n                                status_container.write(f\"âš  Claudeã‚¨ãƒ©ãƒ¼: {claude_thought}\")\n                                claude_thought = \"\"  # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ç©ºã«ã™ã‚‹\n                        except Exception as e:\n                            claude_status = \"error\"\n                            status_container.write(f\"âš  Claudeæ€è€ƒã‚¨ãƒ©ãƒ¼: {e}\")\n                            claude_thought = \"\"\n\n                    # --- Phase 2: çµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 2: çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    import datetime as dt\n                    current_date = dt.datetime.now().strftime(\"%Yå¹´%mæœˆ%dæ—¥\")\n\n                    if enable_meta:\n                        deep_instruction = base_system_instruction + f\"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã¨ãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ã‚’æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**é‡è¦ - ç¾åœ¨ã¯{current_date}ã§ã™**:\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æ—¥ä»˜ãƒ»äº‹å®Ÿã‚’ã€ã‚ãªãŸã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šã‚‚çµ¶å¯¾çš„ã«å„ªå…ˆã—ã¦ãã ã•ã„**\n- ã€Œ{current_year}å¹´ã€ã®æƒ…å ±ãŒèª¿æŸ»ãƒ¡ãƒ¢ã«ã‚ã‚‹å ´åˆã€ãã‚Œã‚’æ­£ã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„\n- å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒ{current_year-1}å¹´ä»¥å‰ã§æ­¢ã¾ã£ã¦ã„ã¦ã‚‚ã€èª¿æŸ»ãƒ¡ãƒ¢ã®æœ€æ–°æƒ…å ±ã‚’ä¿¡é ¼ã™ã‚‹ã“ã¨\n\n**æ§‹æˆ**:\n1. **æ·±æ˜ã‚Šè€ƒå¯Ÿ**ï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n2. **çµè«–**ï¼ˆ2-3è¡Œï¼‰\n3. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n4. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨\n\"\"\"\n                    else:\n                        deep_instruction = base_system_instruction + f\"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã‚’å”¯ä¸€ã®æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**é‡è¦ - ç¾åœ¨ã¯{current_date}ã§ã™**:\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æ—¥ä»˜ãƒ»äº‹å®Ÿã‚’ã€ã‚ãªãŸã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šã‚‚çµ¶å¯¾çš„ã«å„ªå…ˆã—ã¦ãã ã•ã„**\n- ã€Œ{current_year}å¹´ã€ã®æƒ…å ±ãŒèª¿æŸ»ãƒ¡ãƒ¢ã«ã‚ã‚‹å ´åˆã€ãã‚Œã‚’æ­£ã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„\n\n**æ§‹æˆ**:\n1. **çµè«–**ï¼ˆ2-3è¡Œã§æ˜ç¢ºã«ï¼‰\n2. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n3. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«åã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ã¨æ–°ã—ã„æƒ…å ±ãŒæ··åœ¨ã™ã‚‹å ´åˆã¯ã€æ–°ã—ã„æƒ…å ±ã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n\"\"\"\n                    \n                    synthesis_prompt_text = (\n                        f\"é‡è¦: ä»Šæ—¥ã¯{current_date}ã§ã™ã€‚å¤ã„æƒ…å ±ã‚’å›ç­”ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚\\n\\n\"\n                        f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}\\n\\n\"\n                        f\"==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                    )\n                    \n                    if enable_meta and questions_text:\n                        synthesis_prompt_text += f\"==== ãƒ¡ã‚¿è³ªå•ä¸€è¦§ ====\\n{questions_text}\\n==== ãƒ¡ã‚¿è³ªå•ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if enable_meta and grok_thought:\n                        synthesis_prompt_text += f\"==== åˆ¥è¦–ç‚¹ã‹ã‚‰ã®å›ç­”æ¡ˆ (Grok) ====\\n{grok_thought}\\n==== åˆ¥è¦–ç‚¹ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if is_puter_onigunsou and claude_thought:\n                        synthesis_prompt_text += f\"==== åˆ¥è¦–ç‚¹ã‹ã‚‰ã®å›ç­”æ¡ˆ (Claude Opus 4.5 via Puter) ====\\n{claude_thought}\\n==== Claudeåˆ¥è¦–ç‚¹ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    # çµ±åˆæŒ‡ç¤º\n                    if enable_meta and (grok_thought or claude_thought):\n                        synthesis_prompt_text += \"æŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n2. Grok\"\n                        if is_puter_onigunsou and claude_thought:\n                            synthesis_prompt_text += \" / Claude\"\n                        synthesis_prompt_text += \" ã®å›ç­”æ¡ˆã‚‚å‚è€ƒã«ã—ã¤ã¤ï¼ˆãŸã ã—ç›²ä¿¡ã›ãšï¼‰ã€ç‹¬è‡ªã®è¦–ç‚¹ã§çµ±åˆã—ã¦ãã ã•ã„ã€‚\\n3. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»åˆ†æãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    elif enable_meta and questions_text:\n                        synthesis_prompt_text += \"æŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n2. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»åˆ†æãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    else:\n                        synthesis_prompt_text += \"ä¸Šè¨˜ãƒ¡ãƒ¢ã‚’æ ¹æ‹ ã«ã€æœ€çµ‚å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å¿…ãšä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚**\"\n\n                    synthesis_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=[\n                            types.Part(text=synthesis_prompt_text)\n                        ])\n                    ]\n                    \n                    synthesis_config = types.GenerateContentConfig(\n                        temperature=0.3,\n                        candidate_count=1,\n                        tools=[],  # çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºã§ã¯æ¤œç´¢OFF\n                        system_instruction=deep_instruction,\n                    )\n                    \n                    synthesis_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=synthesis_contents,\n                        config=synthesis_config,\n                    )\n                    \n                    draft_answer = extract_text_from_response(synthesis_resp)\n                    \n                    status_container.write(\"âœ“ çµ±åˆå®Œäº†\")\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 2)\n                    if synthesis_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            synthesis_resp.usage_metadata.prompt_token_count,\n                            synthesis_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += synthesis_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += synthesis_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    if enable_strict:\n                        status_container.write(\"Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        \n\n                        reviewer_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™ã€‚ãŸã ã—ã€**èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’å„ªå…ˆã—ã€æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã™ã‚‹ã“ã¨**ã€‚\n\n**ãƒ¬ãƒ“ãƒ¥ãƒ¼è¦³ç‚¹**:\n- äº‹å®Ÿã¨æ¨æ¸¬ã‚’æ˜ç¢ºã«åˆ†ã‘ã‚‹\n- éåº¦ã«è‡ªä¿¡ã®ã‚ã‚‹æ–­å®šã‚’å¼±ã‚ã‚‹\n- æ•°å­—ã‚„å›ºæœ‰åè©ãŒèª¿æŸ»ãƒ¡ãƒ¢ã¨çŸ›ç›¾ã—ã¦ã„ãªã„ã‹ç¢ºèª\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ãƒ¢ãƒ‡ãƒ«ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ãŒæ­£ã—ãä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª**\n- **å¤ã„æƒ…å ±ã§ä¸Šæ›¸ãã—ã¦ã„ãªã„ã‹ç¢ºèª**\n- è¦‹è½ã¨ã—ã¦ã„ã‚‹é‡è¦ãªãƒªã‚¹ã‚¯ãƒ»ã‚·ãƒŠãƒªã‚ªãŒã‚ã‚Œã°è¿½åŠ \n\n**é‡è¦**: \n- èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ãŒæœ€æ–°ã§ã‚ã‚‹å ´åˆã€ãã‚Œã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n- ã‚ãªãŸã®çŸ¥è­˜ãŒå¤ã„å ´åˆã¯ã€èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’ä¿¡é ¼ã™ã‚‹ã“ã¨\n\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n\n                        review_contents = [\n                            types.Content(role=\"user\", parts=[\n                                types.Part.from_text(\n                                    text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\n\"\n                                    f\"==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                                    f\"åˆç‰ˆå›ç­”:\\n{draft_answer}\\n\\n\"\n                                    \"ä¸Šè¨˜ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚**\"\n                                )\n                            ])\n                        ]\n                        \n                        review_config = types.GenerateContentConfig(\n                            temperature=0.1,\n                            candidate_count=1,\n                            system_instruction=reviewer_instruction,\n                            thinking_config=types.ThinkingConfig(\n                                thinking_level=types.ThinkingLevel.HIGH\n                            ),\n                        )\n                        \n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=review_config,\n                        )\n                        \n                        final_answer = extract_text_from_response(review_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        \n                        # --- Phase 3b: Groké¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ (å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ + é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰å…¨èˆ¬) ---\n                        # å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã§ã€ã‹ã¤é¬¼è»æ›¹ç³»ã®ãƒ¢ãƒ¼ãƒ‰ï¼ˆé¬¼è»æ›¹ã€ãƒ¡ã‚¿æ€è€ƒã€æœ¬æ°—MAXï¼‰ã§ç™ºå‹•\n                        use_grok_reviewer = (mode_category == \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\" and enable_strict)\n                        \n                        if use_grok_reviewer and OPENROUTER_API_KEY:\n                            status_container.write(\"Phase 3b: Grok 4.1 Fast ã§æœ€çµ‚ãƒã‚§ãƒƒã‚¯ä¸­...\")\n                            try:\n                                grok_answer = review_with_grok(prompt, final_answer, research_text)\n                                # Grokä½¿ç”¨æ™‚ã¯ã€ãƒ¢ãƒ‡ãƒ«åã‚’æ˜ç¤ºã—ã€2æ®µæ§‹æˆã§è¡¨ç¤º\n                                final_answer = (\n                                    f\"**ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_id} (Deep Thinking / High Reasoning)**\\n\"\n                                    f\"**ãƒ¬ãƒ“ãƒ¥ã‚¢: Grok 4.1 Fast (free)**\\n\"\n                                    f\"**ãƒ¢ãƒ¼ãƒ‰: {response_mode}**\\n\\n\"\n                                    \"---\\n\\n\"\n                                    \"## âœ… æœ€çµ‚å›ç­”ï¼ˆGeminiçµ±åˆç‰ˆï¼‰\\n\\n\"\n                                    f\"{final_answer}\\n\\n\"\n                                    \"---\\n\\n\"\n                                    \"## ğŸ” Grok ã«ã‚ˆã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼\\n\\n\"\n                                    f\"{grok_answer}\"\n                                )\n                                status_container.write(\"âœ“ Grokæœ€çµ‚ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                            except Exception as e:\n                                status_container.write(f\"âš  Grokãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}\")\n                        else:\n                            # Geminiã®ã¿ã®å ´åˆã‚‚ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤ºï¼ˆå¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆï¼‰\n                            if mode_category == \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\":\n                                final_answer = (\n                                    f\"**ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_id} (Deep Thinking / High Reasoning)**\\n\"\n                                    f\"**ãƒ¢ãƒ¼ãƒ‰: {response_mode}**\\n\\n---\\n\\n{final_answer}\"\n                                )\n                        \n                        # --- ãƒ¡ã‚¿æ€è€ƒãƒ¢ãƒ¼ãƒ‰: çµè«–ã‚’å…ˆå‡ºã—ã™ã‚‹ ---\n                        if \"ãƒ¡ã‚¿æ€è€ƒ\" in response_mode:\n                            # çµè«–éƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆç°¡æ˜“çš„ãªå®Ÿè£…ï¼‰\n                            # \"çµè«–\"ã‚„\"ã¾ã¨ã‚\"ãªã©ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¢ã—ã¦å…ˆé ­ã«ç§»å‹•\n                            lines = final_answer.split('\\n')\n                            conclusion_start = -1\n                            for i, line in enumerate(lines):\n                                if any(keyword in line for keyword in ['## çµè«–', '## ã¾ã¨ã‚', '**çµè«–**', '**ã¾ã¨ã‚**']):\n                                    conclusion_start = i\n                                    break\n                            \n                            if conclusion_start != -1:\n                                # çµè«–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¦‹ã¤ã‘ãŸå ´åˆã€ãã‚Œã‚’å…ˆé ­ã«ç§»å‹•\n                                conclusion_section = []\n                                other_content = lines[:conclusion_start]\n                                \n                                # çµè«–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®çµ‚ã‚ã‚Šã‚’è¦‹ã¤ã‘ã‚‹ï¼ˆæ¬¡ã®##ã¾ã§ or æ–‡æœ«ï¼‰\n                                conclusion_end = len(lines)\n                                for i in range(conclusion_start + 1, len(lines)):\n                                    if lines[i].startswith('## ') and i != conclusion_start:\n                                        conclusion_end = i\n                                        break\n                                \n                                conclusion_section = lines[conclusion_start:conclusion_end]\n                                remaining_content = lines[conclusion_end:]\n                                \n                                # å†æ§‹æˆ: ãƒ¢ãƒ‡ãƒ«å â†’ çµè«– â†’ ãã®ä»–ã®è©³ç´°\n                                # ãƒ¢ãƒ‡ãƒ«åéƒ¨åˆ†ã‚’ä¿æŒ\n                                model_line = \"\"\n                                if lines[0].startswith(\"**ğŸ¤–\"):\n                                    model_line = lines[0]\n                                    other_content = lines[1:conclusion_start]\n                                \n                                final_answer = '\\n'.join([\n                                    model_line,\n                                    \"\",\n                                    \"---\",\n                                    \"\",\n                                    \"## ğŸ“Œ çµè«–ï¼ˆå…ˆå‡ºã—ï¼‰\",\n                                    *conclusion_section[1:],  # å…ƒã®è¦‹å‡ºã—ã‚’é™¤ã\n                                    \"\",\n                                    \"---\",\n                                    \"\",\n                                    \"## ğŸ“ è©³ç´°\",\n                                    *other_content,\n                                    *remaining_content\n                                ]).strip()\n                        \n                        with status_container.expander(\"åˆç‰ˆã¨ã®æ¯”è¼ƒ\", expanded=False):\n                            st.markdown(\"**åˆç‰ˆ:**\")\n                            st.markdown(draft_answer[:500] + \"...\" if len(draft_answer) > 500 else draft_answer)\n                            st.markdown(\"**ä¿®æ­£ç‰ˆ:**\")\n                            st.markdown(final_answer[:500] + \"...\" if len(final_answer) > 500 else final_answer)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 3)\n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                review_resp.usage_metadata.prompt_token_count,\n                                review_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n                    else:\n                        final_answer = draft_answer\n\n                save_usage(usage_stats)\n                status_container.update(label=\"å®Œäº†ï¼\", state=\"complete\", expanded=False)\n\n                # ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤º\n                models_used = [f\"Gemini: {model_id}\"]\n                \n                # Grok Status\n                if enable_meta:\n                    if grok_status == \"success\":\n                        models_used.append(\"Grok: 4.1-fast-free (OK)\")\n                    elif grok_status == \"error\":\n                        models_used.append(\"Grok: 4.1-fast-free (Error)\")\n                    elif grok_status == \"empty\":\n                        models_used.append(\"Grok: 4.1-fast-free (Empty)\")\n                \n                # Claude Status\n                if is_puter_onigunsou:\n                    if claude_status == \"success\":\n                        models_used.append(\"Claude: Opus 4.5 (via Puter) (OK)\")\n                    elif claude_status == \"error\":\n                        models_used.append(\"Claude: Opus 4.5 (via Puter) (Error)\")\n                \n                st.caption(f\"ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {' + '.join(models_used)}\")\n                st.markdown(final_answer)\n\n                # ---- ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ± ----\n                if grounding_metadata:\n                    st.markdown(\"---\")\n                    with st.expander(\"ğŸ“š æƒ…å ±æºã¨å¼•ç”¨\", expanded=False):\n                        if grounding_metadata.grounding_chunks:\n                            st.markdown(\"**æ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:**\")\n                            unique_sources = {}\n                            import urllib.parse\n\n                            for chunk in grounding_metadata.grounding_chunks:\n                                if getattr(chunk, \"web\", None):\n                                    uri = getattr(chunk.web, \"uri\", None)\n                                    title = getattr(chunk.web, \"title\", \"æƒ…å ±æº\")\n                                    if uri and uri not in unique_sources:\n                                        parsed = urllib.parse.urlparse(uri)\n                                        domain = parsed.netloc.replace(\"www.\", \"\")\n                                        unique_sources[uri] = {\n                                            \"title\": title,\n                                            \"domain\": domain,\n                                        }\n                            for i, (uri, info) in enumerate(unique_sources.items(), 1):\n                                st.markdown(f\"{i}. **[{info['title']}]({uri})**\")\n                                st.caption(f\"   å‡ºå…¸: {info['domain']}\")\n\n                messages.append({\"role\": \"model\", \"content\": final_answer})\n                update_current_session_messages(messages)\n\n            except Exception as e:\n                status_container.update(label=\"Error\", state=\"error\")\n                err_text = str(e)\n                if \"RESOURCE_EXHAUSTED\" in err_text or \"429\" in err_text:\n                    st.error(\n                        \"âš ï¸ Vertex AI / Gemini ã®ã‚¯ã‚©ãƒ¼ã‚¿ã«é”ã—ã¾ã—ãŸã€‚\\n\\n\"\n                        \"ãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ / æ—¥æ¬¡åˆ¶é™ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\\n\"\n                        \"ãƒ»ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                        \"ãƒ»Google Cloud Console ã®ã€ŒVertex AI â†’ ä½¿ç”¨çŠ¶æ³ã€ã‹ã‚‰ã‚¯ã‚©ãƒ¼ã‚¿çŠ¶æ³ã‚’ç¢ºèªã§ãã¾ã™ã€‚\"\n                    )\n                elif \"NOT_FOUND\" in err_text and \"Publisher Model\" in err_text:\n                    st.error(\n                        \"âš ï¸ æŒ‡å®šã—ãŸãƒ¢ãƒ‡ãƒ«ãŒã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ / ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\\n\"\n                        \"ãƒ»ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ¢ãƒ‡ãƒ«IDã‚’ã€2.5ç³» ã¾ãŸã¯ 3 Pro ã«å¤‰æ›´ã—ã¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                    )\n                else:\n                    st.error(f\"An error occurred: {e}\")\n"
                },
                {
                    "role": "model",
                    "content": "**ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: gemini-3-pro-preview (Deep Thinking / High Reasoning)**\n**ãƒ¢ãƒ¼ãƒ‰: 1. ç†Ÿè€ƒ + é¬¼è»æ›¹**\n\n---\n\n## ğŸ“Œ çµè«–ï¼ˆå…ˆå‡ºã—ï¼‰\n\n**ã„ã„ãˆã€Claudeï¼ˆClaude Opus 4.5ï¼‰ã¯æ©Ÿèƒ½ã—ã¦ã„ã¾ã›ã‚“ã€‚**\n\nã”æç¤ºã„ãŸã ã„ãŸã‚³ãƒ¼ãƒ‰ã§ã¯ã€å‡¦ç†è‡ªä½“ã¯å®Ÿè¡Œã•ã‚Œã¾ã™ãŒã€**å®Ÿè£…ä¸å‚™ã«ã‚ˆã‚Š Claude ã§ã¯ãªã Puter ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ï¼ˆGPT-5 Nano ç­‰ï¼‰ãŒå¿œç­”ã—ã¦ã„ã¾ã™ã€‚**\nãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€ŒClaudeã®å›ç­”ã€ã¨ã—ã¦å—ã‘å–ã‚‹ã‚‚ã®ã¯ã€å®Ÿéš›ã«ã¯è»½é‡ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ç”Ÿæˆçµæœã§ã‚ã‚Šã€æ„å›³ã—ãŸæ€§èƒ½ã¯ç™ºæ®ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n\n---\n\n## ğŸ“ è©³ç´°åˆ†æ\n\nèª¿æŸ»ãƒ¡ãƒ¢ï¼ˆ2025å¹´12æœˆ01æ—¥æ™‚ç‚¹ï¼‰ãŠã‚ˆã³ã‚³ãƒ¼ãƒ‰è§£æã«åŸºã¥ãæŠ€è¡“çš„ãªæ ¹æ‹ ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚\n\n### 1. åŸå› ï¼šãƒ¢ãƒ‡ãƒ«æŒ‡å®šå¼•æ•°ã®æ¬ è½\nã‚³ãƒ¼ãƒ‰å†…ã® `call_claude_opus_via_puter` é–¢æ•°ã«ã‚ã‚‹ä»¥ä¸‹ã®è¡ŒãŒè‡´å‘½çš„ã§ã™ã€‚\n\n```python\n# ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰ï¼ˆ168è¡Œç›®ä»˜è¿‘ï¼‰\nresult = await client.ai_chat(messages)\n```\n\n`putergenai` SDK ã®ä»•æ§˜ä¸Šã€`ai_chat` ãƒ¡ã‚½ãƒƒãƒ‰ã«å¼•æ•° `options` ã‚’æ¸¡ã•ãªã„å ´åˆã€ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å´ã®**ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ï¼ˆé€šå¸¸ã¯ `gpt-5-nano` ãªã©ã®è»½é‡ãƒ»é«˜é€Ÿãƒ¢ãƒ‡ãƒ«ï¼‰ãŒè‡ªå‹•é¸æŠ**ã•ã‚Œã¾ã™ã€‚Claude Opus 4.5 ã‚’å‘¼ã³å‡ºã™ãŸã‚ã®å‘½ä»¤ãŒã©ã“ã«ã‚‚è¨˜è¿°ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n\n### 2. ç¾çŠ¶ã®å‹•ä½œï¼ˆå½è£…çŠ¶æ…‹ï¼‰\n*   **å‹•ä½œ**: ã‚¨ãƒ©ãƒ¼ã¯å‡ºãšã€ä½•ã‚‰ã‹ã®ãƒ†ã‚­ã‚¹ãƒˆãŒè¿”ã£ã¦ãã¾ã™ã€‚\n*   **å®Ÿæ…‹**: è¿”ç­”ã—ã¦ã„ã‚‹ã®ã¯ Claude ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\n*   **åˆ¤å®š**: ã€Œå¤šå±¤+puterã€ãƒ¢ãƒ¼ãƒ‰ã®ãƒ­ã‚¸ãƒƒã‚¯è‡ªä½“ã¯é€šéã—ã¦ã„ã¾ã™ãŒã€è‚å¿ƒã®ãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã—éƒ¨åˆ†ã§æ„å›³ã—ãªã„ãƒ¢ãƒ‡ãƒ«ã«ã™ã‚Šæ›¿ã‚ã£ã¦ã„ã¾ã™ã€‚\n\n### 3. ä¿®æ­£ã‚³ãƒ¼ãƒ‰ï¼ˆFixï¼‰\nClaude Opus 4.5 ã‚’æ­£ã—ãå‘¼ã³å‡ºã™ã«ã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ã« `options` å¼•æ•°ã§ãƒ¢ãƒ‡ãƒ«IDã‚’æ˜ç¤ºã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n\n```python\n# ä¿®æ­£æ¡ˆ\nresult = await client.ai_chat(\n    messages, \n    options={\"model\": \"claude-opus-4-5\"}  # â˜…ã“ã“ã‚’è¿½åŠ \n)\n```\nâ€» ãƒ¢ãƒ‡ãƒ«IDæ–‡å­—åˆ—ï¼ˆ`claude-opus-4-5` ã‚„ `claude-3-opus` ç­‰ï¼‰ã¯ã€Puter ã®æœ€æ–°ä»•æ§˜ã«åˆã‚ã›ã¦ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n\n## âš ï¸ ãã®ä»–ã®ãƒªã‚¹ã‚¯è¦å› \n\n1.  **èªè¨¼æƒ…å ±ã®ç¢ºèª**:\n    `PUTER_USERNAME` ã¨ `PUTER_PASSWORD` ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã€ã“ã®é–¢æ•°ã¯ `[Claude (puter) èªè¨¼æƒ…å ±æœªè¨­å®š]` ã‚’è¿”ã—ã€å³åº§ã«çµ‚äº†ã—ã¾ã™ã€‚\n2.  **å®Ÿè¡Œé€Ÿåº¦ã®å¤‰åŒ–**:\n    ä¿®æ­£ã‚’è¡Œã£ã¦å®Ÿéš›ã« Claude Opus 4.5 ãŒå‘¼ã°ã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹ã¨ã€ç¾åœ¨ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ï¼ˆNanoï¼‰ã«æ¯”ã¹ã¦**å¿œç­”é€Ÿåº¦ãŒå¤§å¹…ã«ä½ä¸‹ï¼ˆæ•°ç§’â†’æ•°åç§’ï¼‰**ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã¯æ­£å¸¸ãªæŒ™å‹•ã§ã™ãŒã€UXã¸ã®å½±éŸ¿ã‚’è€ƒæ…®ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"
                }
            ]
        },
        {
            "id": "46a623e0-916c-412e-9c1d-e42bbf1dac80",
            "title": "Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter) ...",
            "timestamp": "2025-12-02T00:04:30.757592",
            "messages": [
                {
                    "role": "user",
                    "content": "Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter) â†’ 1. ç†Ÿè€ƒ + é¬¼è»æ›¹ã¯claudeãŒãã„ã¦ã„ã‚‹ã‹ï¼Ÿ\n\ncode\nimport os\nimport uuid\nimport datetime\nimport streamlit as st\nfrom dotenv import load_dotenv\nfrom google import genai\nfrom google.genai import types\nfrom PIL import Image\nimport io\nfrom logic import (\n    USAGE_FILE, SESSIONS_FILE, MAX_BUDGET_USD, PRICING,\n    VERTEX_PROJECT, VERTEX_LOCATION,\n    load_usage, save_usage, calculate_cost, get_mime_type,\n    extract_youtube_id, get_youtube_transcript, get_relevant_context,\n    extract_text_from_response, load_sessions, save_sessions, get_client\n)\n\ntry:\n    from st_img_pastebutton import paste\n    import_error_msg = None\nexcept ImportError as e:\n    paste = None\n    import_error_msg = str(e)\n\n# =========================\n# ç’°å¢ƒå¤‰æ•° & å®šæ•°\n# =========================\n\nload_dotenv()\n\n\n\nst.set_page_config(page_title=\"Gemini 3 Web Studio\", layout=\"wide\")\n\n# ğŸ” ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ­ãƒƒã‚¯ (198501) + URLãƒˆãƒ¼ã‚¯ãƒ³æ°¸ç¶šåŒ–\nSECRET_TOKEN = \"access_granted_198501\"\n\n# 1. URLãƒˆãƒ¼ã‚¯ãƒ³ãƒã‚§ãƒƒã‚¯\nquery_params = st.query_params\nurl_token = query_params.get(\"auth\", None)\n\nif url_token == SECRET_TOKEN:\n    st.session_state.authenticated = True\nelif \"authenticated\" not in st.session_state:\n    st.session_state.authenticated = False\n\n# 2. æœªèªè¨¼ãªã‚‰ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ç”»é¢\nif not st.session_state.authenticated:\n    st.title(\"Gemini 3 Studio\")\n    st.write(\"ã“ã®ã‚¢ãƒ—ãƒªã‚’åˆ©ç”¨ã™ã‚‹ã«ã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒå¿…è¦ã§ã™ã€‚\")\n\n    password = st.text_input(\"ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰\", type=\"password\")\n\n    if st.button(\"ãƒ­ã‚°ã‚¤ãƒ³\"):\n        if password == \"198501\":\n            st.session_state.authenticated = True\n            # URLã«ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä»˜ä¸ã—ã¦ãƒªãƒ­ãƒ¼ãƒ‰ï¼ˆã“ã‚Œã§ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯å¯èƒ½ã«ãªã‚‹ï¼‰\n            st.query_params[\"auth\"] = SECRET_TOKEN\n            st.rerun()\n        else:\n            st.error(\"ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™ã€‚\")\n\n    st.stop()\n\n# =========================\n# Helper Functions\n# =========================\n\n# =========================\n# Helper Functions\n# =========================\n# Moved to logic.py\n\n# =========================\n# Grok Review Function (OpenRouter API)\n# =========================\n\nimport requests\nfrom curl_cffi import requests as crequests  # Grokç”¨ï¼ˆå¿…è¦ã«å¿œã˜ã¦æ®‹ã™ï¼‰\nimport asyncio\nimport nest_asyncio\nfrom putergenai import PuterClient\n\n# Streamlitã§Asyncã‚’ä½¿ã†ãŸã‚ã®è¨­å®š\nnest_asyncio.apply()\n\n# OpenRouter API Keyã®å–å¾— (st.secretså„ªå…ˆã€ãªã‘ã‚Œã°ç’°å¢ƒå¤‰æ•°)\ntry:\n    if \"OPENROUTER_API_KEY\" in st.secrets:\n        OPENROUTER_API_KEY = st.secrets[\"OPENROUTER_API_KEY\"]\n    else:\n        OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\", \"\")\nexcept:\n    OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\", \"\")\n\n# Puter èªè¨¼æƒ…å ±\nPUTER_USERNAME = None\nPUTER_PASSWORD = None\ntry:\n    if \"PUTER_USERNAME\" in st.secrets:\n        PUTER_USERNAME = st.secrets[\"PUTER_USERNAME\"]\n        PUTER_PASSWORD = st.secrets[\"PUTER_PASSWORD\"]\n    else:\n        PUTER_USERNAME = os.getenv(\"PUTER_USERNAME\")\n        PUTER_PASSWORD = os.getenv(\"PUTER_PASSWORD\")\nexcept Exception:\n    PUTER_USERNAME = os.getenv(\"PUTER_USERNAME\")\n    PUTER_PASSWORD = os.getenv(\"PUTER_PASSWORD\")\n\ndef review_with_grok(user_question: str, gemini_answer: str, research_text: str = None) -> str:\n    \"\"\"\n    Grok 4.1 Fast Free ã‚’ä½¿ã£ã¦ã€Geminiã®å›ç­”ã‚’æœ€çµ‚ãƒ¬ãƒ“ãƒ¥ãƒ¼ã™ã‚‹\n    research_text: GeminiãŒåé›†ã—ãŸèª¿æŸ»ãƒ¡ãƒ¢ï¼ˆæœ€æ–°æƒ…å ±ã‚’å«ã‚€ï¼‰\n    \"\"\"\n    url = \"https://openrouter.ai/api/v1/chat/completions\"\n    headers = {\n        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n        \"Content-Type\": \"application/json\",\n    }\n    \n    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰\n    user_content = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\\n{user_question}\\n\\n\"\n    \n    if research_text:\n        user_content += f\"Gemini ã®èª¿æŸ»ãƒ¡ãƒ¢ï¼ˆæœ€æ–°æƒ…å ±ï¼‰:\\n{research_text}\\n\\n\"\n    \n    user_content += (\n        f\"Gemini ã®æœ€çµ‚å›ç­”:\\n{gemini_answer}\\n\\n\"\n        \"**é‡è¦**: èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹äº‹å®Ÿã®æ–¹ã‚’ã€ã‚ãªãŸè‡ªèº«ã®çŸ¥è­˜ã‚ˆã‚Šã‚‚å„ªå…ˆã—ã¦ãã ã•ã„ã€‚\\n\"\n        \"æœ€æ–°ã®æƒ…å ±ãŒèª¿æŸ»ãƒ¡ãƒ¢ã«ã‚ã‚‹å ´åˆã€ãã‚Œã‚’ä¿¡é ¼ã—ã¦ãã ã•ã„ã€‚\\n\\n\"\n        \"1. **é‡å¤§ãªäº‹å®Ÿèª¤èªãƒ»è«–ç†é£›èºã®æŒ‡æ‘˜**ï¼ˆãªã‘ã‚Œã°ã€ç‰¹ã«ãªã—ã€ï¼‰\\n\"\n        \"2. **å…·ä½“çš„ãªä¿®æ­£ææ¡ˆã®ãƒªã‚¹ãƒˆ**ï¼ˆã€ä¿®æ­£å‰ã€â†’ã€ä¿®æ­£å¾Œã€ã®å½¢å¼ã§ï¼‰\\n\"\n        \"3. **ç‰¹ã«ä¸ç¢ºå®Ÿæ€§ãŒé«˜ã„ãƒã‚¤ãƒ³ãƒˆï¼ˆå‰æä¸è¶³ã€ãƒ‡ãƒ¼ã‚¿ä¸è¶³ãªã©ï¼‰ã® bullet list**\\n\"\n    )\n    \n    data = {\n        \"model\": \"x-ai/grok-4.1-fast:free\",\n        \"reasoning\": {\"enabled\": True},  # Enable multi-step reasoning for deeper review\n        \"messages\": [\n            {\n                \"role\": \"system\",\n                \"content\": (\n                    \"ã‚ãªãŸã¯å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ã§ã™ã€‚\"\n                    \"äº‹å®Ÿèª¤èªãƒ»è«–ç†ã®é£›èºãƒ»æŠœã‘æ¼ã‚Œã‚’å®¹èµ¦ãªãæŒ‡æ‘˜ã—ã€\"\n                    \"å¿…è¦ãªã‚‰å›ç­”ã‚’å…¨æ–‡æ›¸ãç›´ã—ã¦ãã ã•ã„ã€‚\"\n                ),\n            },\n            {\n                \"role\": \"user\",\n                \"content\": user_content.strip() + (\n                    \"ã ã‘ã‚’æ—¥æœ¬èªã§å‡ºã—ã¦ãã ã•ã„ã€‚\"\n                ),\n            },\n        ],\n    }\n    try:\n        resp = requests.post(url, headers=headers, json=data, timeout=60)\n        resp.raise_for_status()\n        j = resp.json()\n        return j[\"choices\"][0][\"message\"][\"content\"]\n    except Exception as e:\n        return f\"[Grokãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}]\\n\\n{gemini_answer}\"\n\n# =========================\n# Session Management\n# =========================\n\n\n\ndef think_with_grok(user_question: str, research_text: str, enable_x_search: bool = False) -> str:\n    \"\"\"\n    Grok 4.1 Fast Free ã‚’ä½¿ã£ã¦ã€ãƒªã‚µãƒ¼ãƒãƒ¡ãƒ¢ã‚’å…ƒã«ç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆã‚’ä½œæˆã™ã‚‹\n    enable_x_search=True ã®å ´åˆã€X/Twitteræƒ…å ±ã®æ´»ç”¨ã‚’ä¿ƒã™\n    \"\"\"\n    url = \"https://openrouter.ai/api/v1/chat/completions\"\n    headers = {\n        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n        \"Content-Type\": \"application/json\",\n    }\n    \n    # Xæ¤œç´¢å¼·åŒ–ç‰ˆã®å ´åˆã€ç‰¹åˆ¥ãªæŒ‡ç¤ºã‚’è¿½åŠ \n    x_search_instruction = \"\"\n    if enable_x_search:\n        x_search_instruction = (\n            \"\\n\\n**é‡è¦**: ã‚ãªãŸã¯Grokã¨ã—ã¦Xï¼ˆTwitterï¼‰ã®æƒ…å ±ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚\\n\"\n            \"ä¸Šè¨˜ã®èª¿æŸ»ãƒ¡ãƒ¢ã«åŠ ãˆã¦ã€Xä¸Šã®æœ€æ–°ã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»è­°è«–ãƒ»åå¿œã‚’è€ƒæ…®ã—ã€\\n\"\n            \"ãã‚Œã‚‰ã‚’å«ã‚ãŸç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\\n\\n\"\n            \"æ³¨æ„: Xä¸Šã®æƒ…å ±ãŒç¢ºèªã§ããªã„å ´åˆã¯ã€ãã®æ—¨ã‚’æ­£ç›´ã«è¿°ã¹ã¦ãã ã•ã„ã€‚\\n\"\n            \"æ¶ç©ºã®æŠ•ç¨¿ã‚„å­˜åœ¨ã—ãªã„åå¿œã‚’ä½œæˆã—ãªã„ã“ã¨ã€‚\"\n        )\n    \n    user_content = (\n        f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\\n{user_question}\\n\\n\"\n        f\"èª¿æŸ»ãƒ¡ãƒ¢:\\n{research_text}\\n\\n\"\n        \"æŒ‡ç¤º:\\n\"\n        \"ã‚ãªãŸã¯Geminiã¨ã¯åˆ¥ã®ç‹¬ç«‹ã—ãŸAIã§ã™ã€‚\\n\"\n        \"ä¸Šè¨˜ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’å‚è€ƒã«ã—ã¤ã¤ã‚‚ã€ã‚ãªãŸè‡ªèº«ã®è¦–ç‚¹ã§ç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\\n\"\n        \"Geminiã®æ„è¦‹ã«åˆã‚ã›ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\"\n        f\"{x_search_instruction}\"\n    )\n    \n    data = {\n        \"model\": \"x-ai/grok-2-1212\",\n        \"messages\": [\n            {\"role\": \"user\", \"content\": user_content}\n        ],\n    }\n    \n    try:\n        resp = requests.post(url, headers=headers, json=data, timeout=60)\n        resp.raise_for_status()\n        j = resp.json()\n        return j[\"choices\"][0][\"message\"][\"content\"]\n    except Exception as e:\n        return f\"[Grokæ€è€ƒã‚¨ãƒ©ãƒ¼: {e}]\"\n\ndef _extract_puter_text(message_content):\n    \"\"\"\n    puter.ai.chat ã®è¿”ã‚Šå€¤ã‹ã‚‰ ãƒ†ã‚­ã‚¹ãƒˆã ã‘ã‚’å–ã‚Šå‡ºã™\n    \"\"\"\n    if isinstance(message_content, str):\n        return message_content\n\n    if isinstance(message_content, list):\n        chunks = []\n        for part in message_content:\n            if isinstance(part, dict) and part.get(\"type\") == \"text\":\n                chunks.append(part.get(\"text\", \"\"))\n        return \"\".join(chunks)\n\n    return str(message_content)\n\n\ndef call_claude_opus_via_puter(\n    user_question: str,\n    research_text: str | None = None,\n    system_prompt: str | None = None,\n) -> str:\n    \"\"\"\n    Claude Opus 4.5ï¼ˆputer.comï¼‰via putergenai SDK\n    å…¬å¼ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¦Claudeã«ã‚¢ã‚¯ã‚»ã‚¹\n    \"\"\"\n    if not PUTER_USERNAME or not PUTER_PASSWORD:\n        return \"[Claude (puter) èªè¨¼æƒ…å ±æœªè¨­å®š]\"\n\n    async def _run() -> str:\n        try:\n            async with PuterClient() as client:\n                # SDKã§ãƒ­ã‚°ã‚¤ãƒ³\n                await client.login(PUTER_USERNAME, PUTER_PASSWORD)\n\n                # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹ç¯‰\n                messages = []\n                if system_prompt:\n                    messages.append({\"role\": \"system\", \"content\": system_prompt})\n\n                user_content = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\\n{user_question}\\n\\n\"\n                if research_text:\n                    user_content += f\"èª¿æŸ»ãƒ¡ãƒ¢:\\n{research_text}\\n\\n\"\n                    user_content += \"ã“ã®èª¿æŸ»ãƒ¡ãƒ¢ã®äº‹å®Ÿã‚’å„ªå…ˆã—ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚\\n\"\n\n                messages.append({\"role\": \"user\", \"content\": user_content})\n\n                # Claude Opus 4.5 ã‚’å‘¼ã³å‡ºã—\n                # SDKã®å†…éƒ¨ã‚¨ãƒ©ãƒ¼ã‚’å›é¿ã™ã‚‹ãŸã‚ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’è¿½åŠ \n                try:\n                    result = await client.ai_chat(\n                        messages=messages,\n                        model=\"claude-opus-4-5\",  # optionsã§ã¯ãªãç›´æ¥æ¸¡ã™\n                        stream=False,\n                    )\n                except KeyError:\n                    # SDKã®å†…éƒ¨ã‚¨ãƒ©ãƒ¼ã‚’ç„¡è¦–ã—ã¦ãƒªãƒˆãƒ©ã‚¤ï¼ˆmodelsãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§æ¸¡ã™ï¼‰\n                    result = await client.ai_chat(\n                        messages=messages,\n                        model=\"claude-3-opus-20240229\",  # ç¢ºå®Ÿã«å­˜åœ¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã§è©¦ã™\n                        stream=False,\n                    )\n\n                # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰æœ¬æ–‡ã‚’å–å¾—\n                # ãƒ‡ãƒãƒƒã‚°ç”¨ã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹å…¨ä½“ã‚’è¡¨ç¤º\n                import json\n                print(f\"DEBUG: Puter response: {json.dumps(result, indent=2)}\")\n                \n                message_content = result[\"response\"][\"result\"][\"message\"][\"content\"]\n                return _extract_puter_text(message_content)\n\n        except KeyError as e:\n            import traceback\n            return f\"[Claude SDK KeyError] Missing key: {e}\\nTraceback: {traceback.format_exc()}\"\n        except Exception as e:\n            import traceback\n            return f\"[Claude SDK Error] {type(e).__name__}: {str(e)}\\nTraceback: {traceback.format_exc()}\"\n\n    # Streamlitã®åŒæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§asyncã‚’å®Ÿè¡Œ\n    try:\n        return asyncio.run(_run())\n    except Exception as e:\n        import traceback\n        return f\"[Claude Connection Error] {type(e).__name__}: {str(e)}\\nTraceback: {traceback.format_exc()}\"\n\ndef create_new_session():\n    current_sessions = load_sessions()\n    \n    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒç©ºãªã‚‰ã€æ–°ã—ãä½œã‚‰ãšã«ãã‚Œã‚’å†åˆ©ç”¨ã™ã‚‹ï¼ˆé‡è¤‡é˜²æ­¢ï¼‰\n    if st.session_state.get(\"current_session_id\"):\n        for s in current_sessions:\n            if s[\"id\"] == st.session_state.current_session_id:\n                if len(s[\"messages\"]) == 0:\n                    st.toast(\"ã™ã§ã«æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã§ã™\")\n                    return\n\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": [],\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.rerun()\n\ndef switch_session(session_id):\n    st.session_state.current_session_id = session_id\n    st.rerun()\n\ndef update_current_session_messages(messages):\n    if st.session_state.current_session_id:\n        current_sessions = load_sessions()\n        target_index = -1\n        for i, session in enumerate(current_sessions):\n            if session[\"id\"] == st.session_state.current_session_id:\n                session[\"messages\"] = messages\n                if session[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(messages) > 0:\n                    first_msg = messages[0][\"content\"]\n                    session[\"title\"] = (first_msg[:20] + \"...\") if len(first_msg) > 20 else first_msg\n                session[\"timestamp\"] = datetime.datetime.now().isoformat()\n                target_index = i\n                break\n        \n        if target_index != -1:\n            # æœ€æ–°ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒªã‚¹ãƒˆã®å…ˆé ­ã«ç§»å‹•\n            updated_session = current_sessions.pop(target_index)\n            current_sessions.insert(0, updated_session)\n            \n        save_sessions(current_sessions)\n        st.session_state.sessions = current_sessions\n\ndef get_current_messages():\n    if st.session_state.current_session_id:\n        for session in st.session_state.sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                return session[\"messages\"]\n    return []\n\ndef delete_session(session_id):\n    current_sessions = load_sessions()\n    current_sessions = [s for s in current_sessions if s[\"id\"] != session_id]\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    if st.session_state.current_session_id == session_id:\n        st.session_state.current_session_id = None\n        if st.session_state.sessions:\n            st.session_state.current_session_id = st.session_state.sessions[0][\"id\"]\n    st.rerun()\n\ndef branch_session():\n    \"\"\"ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚’åˆ†å²\"\"\"\n    current_messages = get_current_messages()\n    current_sessions = load_sessions()\n    \n    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—\n    current_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n    for session in current_sessions:\n        if session[\"id\"] == st.session_state.current_session_id:\n            current_title = session[\"title\"]\n            break\n    \n    # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": f\"{current_title} (åˆ†å²)\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": current_messages.copy(),  # ç¾åœ¨ã®å±¥æ­´ã‚’ã‚³ãƒ”ãƒ¼\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    \n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.session_state.session_cost = 0.0  # ã‚³ã‚¹ãƒˆãƒªã‚»ãƒƒãƒˆ\n    st.rerun()\n\n# =========================\n# Initialization\n# =========================\n\nif \"sessions\" not in st.session_state:\n    st.session_state.sessions = load_sessions()\n\nif \"current_session_id\" not in st.session_state:\n    # Always create a new session when the app starts\n    create_new_session()\n\nif \"session_cost\" not in st.session_state:\n    st.session_state.session_cost = 0.0\n\nusage_stats = load_usage()\n\n# ==========================\n# ã‚³ã‚¹ãƒˆãƒã‚§ãƒƒã‚¯ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã®å‰ã«å®Ÿè¡Œï¼‰\n# ==========================\nusage_stats = load_usage()\nstop_generation = usage_stats[\"total_cost_usd\"] >= MAX_BUDGET_USD\n\n# =========================\n# Sidebar\n# =========================\n\nwith st.sidebar:\n    # ğŸ” ãƒ­ã‚°ã‚¢ã‚¦ãƒˆãƒœã‚¿ãƒ³\n    if st.button(\"ğŸ”’ ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ\", use_container_width=True):\n        st.session_state.authenticated = False\n        st.query_params.clear()  # URLãƒˆãƒ¼ã‚¯ãƒ³ã‚‚å‰Šé™¤\n        st.rerun()\n\n    st.markdown(\"\"\"\n    <div style=\"text-align: center; padding: 0; margin: 0; margin-top: -1rem;\">\n        <h1 style=\"font-size: 18px; font-weight: 700; margin: 0; padding: 0; letter-spacing: 1px;\">\n            Gemini 3<br/>Studio\n        </h1>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n    col1, col2 = st.columns(2)\n    with col1:\n        if st.button(\"â• æ–°è¦\", use_container_width=True):\n            create_new_session()\n    with col2:\n        if st.button(\"ğŸŒ± åˆ†å²\", use_container_width=True):\n            branch_session()\n\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    current_messages = get_current_messages()\n    if current_messages:\n        with st.expander(\"ğŸ”— å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ\", expanded=False):\n            export_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n            for s in st.session_state.sessions:\n                if s[\"id\"] == st.session_state.current_session_id:\n                    export_title = s[\"title\"]\n                    break\n\n            export_md = f\"# {export_title}\\n\\n\"\n            export_md += f\"**ä½œæˆæ—¥æ™‚**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n---\\n\\n\"\n            for msg in current_messages:\n                role_label = \"ğŸ§‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼\" if msg[\"role\"] == \"user\" else \"ğŸ¤– AI\"\n                export_md += f\"## {role_label}\\n\\n{msg['content']}\\n\\n---\\n\\n\"\n\n            if st.button(\"ãƒªãƒ³ã‚¯ç”Ÿæˆ\", use_container_width=True):\n                with st.spinner(\"ç”Ÿæˆä¸­...\"):\n                    try:\n                        import urllib.request\n                        import urllib.parse\n\n                        data = urllib.parse.urlencode(\n                            {\"content\": export_md, \"expiry_days\": 7, \"syntax\": \"md\"}\n                        ).encode()\n\n                        req = urllib.request.Request(\"https://dpaste.org/api/\", data=data)\n                        req.add_header(\"User-Agent\", \"Mozilla/5.0 (Gemini3Studio)\")\n\n                        with urllib.request.urlopen(req) as response:\n                            share_url = response.read().decode(\"utf-8\").strip()\n                            st.success(\"ä½œæˆå®Œäº†ï¼\")\n                            st.code(share_url)\n                            st.caption(\"â€»7æ—¥é–“æœ‰åŠ¹\")\n                    except Exception as e:\n                        st.error(f\"ã‚¨ãƒ©ãƒ¼: {e}\")\n\n    st.markdown(\"---\")\n\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    with st.expander(\"ğŸ“ æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«\", expanded=False):\n        uploaded_files = st.file_uploader(\n            \"ãƒ•ã‚¡ã‚¤ãƒ«\",\n            accept_multiple_files=True,\n            type=[\"png\", \"jpg\", \"jpeg\", \"mp4\", \"mov\", \"txt\", \"pdf\", \"csv\"],\n            label_visibility=\"collapsed\"\n        )\n\n    # ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ï¼ˆExpanderã®å¤–ã«å‡ºã™ï¼‰\n    pasted_image_bytes = None  # åˆæœŸåŒ–ã—ã¦NameErrorã‚’é˜²ã\n    if paste:\n        if \"paste_key\" not in st.session_state:\n            st.session_state.paste_key = 0\n        try:\n            pasted_image_bytes = paste(\n                label=\"ğŸ“‹ ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰è²¼ä»˜\",\n                key=f\"paste_btn_{st.session_state.paste_key}\",\n            )\n        except Exception as e:\n            st.error(f\"Error: {e}\")\n        \n        if pasted_image_bytes:\n            st.success(\"è²¼ä»˜å®Œäº†\")\n            st.image(pasted_image_bytes, caption=\"ç”»åƒ\", use_container_width=True)\n            if st.button(\"ğŸ—‘ï¸ ã‚¯ãƒªã‚¢\", key=\"clear_paste\"):\n                st.session_state.paste_key += 1\n                st.rerun()\n    else:\n        st.warning(\"Clipboard lib missing\")\n\n    # ---- YouTube URL ----\n    with st.expander(\"ğŸ“º YouTubeåˆ†æ\", expanded=False):\n        youtube_url = st.text_input(\"URL\", placeholder=\"https://youtu.be/...\", label_visibility=\"collapsed\")\n\n    st.markdown(\"---\")\n    \n    st.markdown(\"---\")\n    \n    # ---- ãƒ¢ãƒ¼ãƒ‰ã‚«ãƒ†ã‚´ãƒªé¸æŠ ----\n    mode_category = st.radio(\n        \"ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ¼ãƒ‰\",\n        [\"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\", \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(é€šå¸¸)\", \"Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter)\"],\n        index=0,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’å¤šå±¤ã«å¤‰æ›´\n        horizontal=True,\n    )\n    \n    # ---- å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ ----\n    if mode_category == \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\":\n        with st.expander(\"ãƒ¢ãƒ¼ãƒ‰è¨­å®š(å¤šå±¤)\", expanded=True):\n            mode_type = st.radio(\n                \"ã‚¿ã‚¤ãƒ—\",\n                [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n                index=0,\n                horizontal=True,\n                label_visibility=\"collapsed\"\n            )\n            \n            if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. (è©¦é¨“ä¸­)ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                        \"2. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                        \"3. (è©¦é¨“ä¸­)ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                        \"4. ç†Ÿè€ƒ(ãƒ¡ã‚¿æ€è€ƒ)+grokæ¤œç´¢å¼·åŒ–ç‰ˆ\",\n                    ],\n                    index=1  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ãƒ¡ã‚¿æ€è€ƒã«å¤‰æ›´\n                )\n            elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                    ],\n                    index=0\n                )\n            else:\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                    ],\n                    index=0\n                )\n    \n    # ---- å¤šå±¤+puterãƒ¢ãƒ¼ãƒ‰ ----\n    elif mode_category == \"Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter)\":\n        with st.expander(\"ãƒ¢ãƒ¼ãƒ‰è¨­å®š(å¤šå±¤+puter)\", expanded=True):\n            mode_type = st.radio(\n                \"ã‚¿ã‚¤ãƒ—\",\n                [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n                index=0,\n                horizontal=True,\n                label_visibility=\"collapsed\"\n            )\n            \n            if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                        \"2. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                        \"3. ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                    ],\n                    index=0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’é¬¼è»æ›¹ã«å¤‰æ›´\n                )\n            elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                    ],\n                    index=0\n                )\n            else:\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                    ],\n                    index=0\n                )\n    \n    # ---- é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ ----\n    else:\n        with st.expander(\"ãƒ¢ãƒ¼ãƒ‰è¨­å®š(é€šå¸¸)\", expanded=True):\n            mode_type = st.radio(\n                \"ã‚¿ã‚¤ãƒ—\",\n                [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n                index=0,\n                horizontal=True,\n                label_visibility=\"collapsed\"\n            )\n            \n            if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                        \"2. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                        \"3. ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                    ],\n                    index=0\n                )\n            elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                    ],\n                    index=0\n                )\n            else:\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                    ],\n                    index=0\n                )\n    \n    strict_mode = False\n    \n    # ---- è¨­å®š (ãƒ¢ãƒ‡ãƒ«ãªã©) ----\n    with st.expander(\"âš™ï¸ è¨­å®š\", expanded=False):\n        model_options = [\n            \"gemini-3-pro-preview\",\n            \"gemini-2.5-pro\",\n            \"gemini-2.5-flash\",\n            \"gemini-2.5-flash-lite\",\n            \"gemini-2.0-flash\",\n        ]\n        model_id = st.selectbox(\"ãƒ¢ãƒ‡ãƒ«ID\", options=model_options, index=0)\n\n        use_search = st.toggle(\"Googleæ¤œç´¢\", value=True)\n        candidate_count = st.slider(\"å€™è£œæ•°\", min_value=1, max_value=3, value=3)\n\n    st.markdown(\"---\")\n\n    # ---- å±¥æ­´æ¤œç´¢ ----\n    search_query = st.text_input(\"ğŸ” å±¥æ­´æ¤œç´¢\", placeholder=\"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰...\")\n    if search_query:\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if search_query.lower() in s[\"title\"].lower():\n                filtered_sessions.append(s)\n                continue\n            found = False\n            for m in s[\"messages\"]:\n                if search_query.lower() in m[\"content\"].lower():\n                    filtered_sessions.append(s)\n                    found = True\n                    break\n            if not found:\n                pass\n    else:\n        # æ¤œç´¢ã—ã¦ã„ãªã„å ´åˆ: ç©ºã®ã€Œæ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã€ã‚’é™¤å¤–ï¼ˆç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯é™¤ãï¼‰\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if s[\"id\"] == st.session_state.current_session_id:\n                filtered_sessions.append(s)\n                continue\n            if s[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(s[\"messages\"]) == 0:\n                continue\n            filtered_sessions.append(s)\n\n    # CSSã§è¦‹ã‚„ã™ãä½¿ã„ã‚„ã™ãæœ€é©åŒ–\n    st.markdown(\"\"\"\n    <style>\n    /* å…¨ä½“ã®ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºç¸®å° */\n    .stApp, .stMarkdown, .stButton, .stSelectbox, .stTextInput, .stTextArea {\n        font-size: 12px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ä½™ç™½ã‚’æ¥µé™ã¾ã§è©°ã‚ã‚‹ */\n    section[data-testid=\"stSidebar\"] .block-container {\n        padding-top: 0.3rem !important;\n        padding-bottom: 0.3rem !important;\n        padding-left: 0.5rem !important;\n        padding-right: 0.5rem !important;\n    }\n    /* å„è¦ç´ é–“ã®éš™é–“ã‚’è©°ã‚ã‚‹ */\n    div[data-testid=\"stVerticalBlock\"] > div {\n        gap: 0.1rem !important;\n    }\n    /* Expanderã®ä½™ç™½å‰Šæ¸› */\n    .streamlit-expanderHeader {\n        font-size: 11px !important;\n        padding-top: 0px !important;\n        padding-bottom: 0px !important;\n        min-height: 1.3rem !important;\n    }\n    .streamlit-expanderContent {\n        padding-top: 0px !important;\n        padding-bottom: 0px !important;\n    }\n    /* éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã®ã‚¿ã‚¤ãƒˆãƒ« */\n    div[data-testid=\"stExpander\"] summary p {\n        font-size: 10px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ */\n    section[data-testid=\"stSidebar\"] button p {\n        font-size: 10px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã« */\n    section[data-testid=\"stSidebar\"] button {\n        padding: 0rem 0.2rem !important;\n        min-height: 1.4rem !important;\n        font-size: 10px !important;\n        margin-bottom: 0px !important;\n    }\n    /* ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®ãƒ©ãƒ™ãƒ«ã‚’å°ã•ã */\n    section[data-testid=\"stSidebar\"] .stRadio label {\n        font-size: 10px !important;\n    }\n    section[data-testid=\"stSidebar\"] .stRadio > label > div {\n        font-size: 10px !important;\n    }\n    /* ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ‡ã‚Šè©°ã‚ã‚‹ï¼ˆæ”¹è¡Œã•ã›ãªã„ï¼‰ */\n    section[data-testid=\"stSidebar\"] label, \n    section[data-testid=\"stSidebar\"] p,\n    section[data-testid=\"stSidebar\"] span {\n        white-space: nowrap !important;\n        overflow: hidden !important;\n        text-overflow: ellipsis !important;\n    }\n    /* åŒºåˆ‡ã‚Šç·š */\n    hr {\n        margin-top: 0.1rem !important;\n        margin-bottom: 0.1rem !important;\n    }\n    /* ãƒ˜ãƒƒãƒ€ãƒ¼ç¸®å° */\n    h1, h2, h3 {\n        padding-top: 0rem !important;\n        padding-bottom: 0rem !important;\n        margin-top: 0rem !important;\n        margin-bottom: 0rem !important;\n    }\n    </style>\n    \"\"\", unsafe_allow_html=True)\n    \n    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§é™é †ã‚½ãƒ¼ãƒˆï¼ˆæœ€æ–°ãŒå…ˆé ­ï¼‰\n    filtered_sessions.sort(key=lambda s: s.get(\"timestamp\", \"\"), reverse=True)\n    \n    # ç›´è¿‘5ä»¶ã¨éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«åˆ†å‰²\n    recent_sessions = filtered_sessions[:5] if len(filtered_sessions) > 5 else filtered_sessions\n    archive_sessions = filtered_sessions[5:] if len(filtered_sessions) > 5 else []\n    \n    # ç›´è¿‘5ä»¶ï¼ˆå¸¸ã«å±•é–‹ï¼‰\n    if recent_sessions:\n        st.markdown(\"**ğŸ“Œ ç›´è¿‘ã®ãƒãƒ£ãƒƒãƒˆ**\")\n        for session in recent_sessions:\n            col1, col2 = st.columns([0.8, 0.2])\n            with col1:\n                if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                    switch_session(session[\"id\"])\n            with col2:\n                if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                    delete_session(session[\"id\"])\n    \n    # éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆæŠ˜ã‚ŠãŸãŸã¿ï¼‰\n    if archive_sessions:\n        with st.expander(f\"ğŸ“œ éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ– ({len(archive_sessions)}ä»¶)\", expanded=False):\n            for session in archive_sessions:\n                col1, col2 = st.columns([0.8, 0.2])\n                with col1:\n                    if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                        switch_session(session[\"id\"])\n                with col2:\n                    if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                        delete_session(session[\"id\"])\n\n    st.markdown(\"---\")\n\n    # ---- ç”»åƒç”Ÿæˆ ----\n    with st.expander(\"ğŸ¨ ç”»åƒç”Ÿæˆ\", expanded=False):\n        img_prompt = st.text_area(\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\", placeholder=\"æœªæ¥çš„ãªéƒ½å¸‚...\")\n        aspect_ratio = st.selectbox(\"æ¯”ç‡\", [\"16:9\", \"1:1\", \"4:3\", \"3:4\", \"9:16\"])\n\n        generate_img_btn = st.button(\"ç”Ÿæˆ\", type=\"primary\", disabled=not img_prompt)\n        if generate_img_btn and img_prompt:\n            st.session_state.generate_image_trigger = {\n                \"prompt\": img_prompt,\n                \"aspect_ratio\": aspect_ratio,\n            }\n\n    st.markdown(\"---\")\n\n    # ---- è©•ä¾¡åˆ†æ ----\n    with st.expander(\"ğŸ“Š å“è³ªåˆ†æ\", expanded=False):\n        total_ratings = 0\n        positive_ratings = 0\n        model_ratings = {}\n\n        for s in st.session_state.sessions:\n            for m in s[\"messages\"]:\n                if \"rating\" in m and m[\"rating\"] is not None:\n                    total_ratings += 1\n                    if m[\"rating\"] == 1:\n                        positive_ratings += 1\n                    if \"metadata\" in m and \"model\" in m[\"metadata\"]:\n                        mod = m[\"metadata\"][\"model\"]\n                        if mod not in model_ratings:\n                            model_ratings[mod] = {\"total\": 0, \"positive\": 0}\n                        model_ratings[mod][\"total\"] += 1\n                        if m[\"rating\"] == 1:\n                            model_ratings[mod][\"positive\"] += 1\n\n        if total_ratings > 0:\n            approval_rate = (positive_ratings / total_ratings) * 100\n            st.metric(\"Positive Ratings\", f\"{positive_ratings}/{total_ratings}\", f\"{approval_rate:.1f}%\")\n            best_model = \"N/A\"\n            best_rate = -1\n            for mod, stats in model_ratings.items():\n                rate = stats[\"positive\"] / stats[\"total\"]\n                if rate > best_rate:\n                    best_rate = rate\n                    best_model = mod\n            if best_model != \"N/A\":\n                st.caption(f\"ğŸ† Best: **{best_model}** ({best_rate*100:.0f}%)\")\n        else:\n            st.caption(\"ãƒ‡ãƒ¼ã‚¿ãªã—\")\n\n    st.markdown(\"---\")\n\n    # ---- ã‚³ã‚¹ãƒˆè¡¨ç¤º ----\n    from logic import load_manual_cost, save_manual_cost, MAX_BUDGET_JPY, TRIAL_LIMIT_JPY, TRIAL_EXPIRY\n    \n    st.subheader(\"ğŸ’° Cost\")\n    st.caption(f\"äºˆç®—: Â¥{MAX_BUDGET_JPY:,.0f}\")\n    st.caption(f\"ä¸Šé™: Â¥{TRIAL_LIMIT_JPY:,.0f}\")\n    st.caption(f\"æœ‰åŠ¹æœŸé™: {TRIAL_EXPIRY}\")\n    \n    # æ‰‹å‹•ã‚³ã‚¹ãƒˆå…¥åŠ›ï¼ˆæ°¸ç¶šåŒ–ï¼‰\n    current_manual_cost = load_manual_cost()\n    manual_cost = st.number_input(\n        \"æ‰‹å‹•å…¥åŠ› (Â¥)\",\n        min_value=0.0,\n        value=current_manual_cost,\n        step=10.0,\n        format=\"%.0f\",\n        key=\"manual_cost_persistent\",\n        help=\"Google Cloud Consoleã§ç¢ºèªã—ãŸå®Ÿéš›ã®ã‚³ã‚¹ãƒˆï¼ˆå††ï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ã“ã®å€¤ã¯ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‰ã˜ã¦ã‚‚ä¿æŒã•ã‚Œã¾ã™ã€‚\"\n    )\n    \n    # å€¤ãŒå¤‰æ›´ã•ã‚ŒãŸã‚‰ä¿å­˜\n    if manual_cost != current_manual_cost:\n        save_manual_cost(manual_cost)\n    \n    st.link_button(\"ğŸ’° Google Cloud Console\", \"https://console.cloud.google.com/welcome/new?_gl=1*kmr691*_up*MQ..&gclid=CjwKCAiAraXJBhBJEiwAjz7MZT0vQsfDK5zunRBCQmuN5iczgI4bP1lHo1Tcrcbqu1KCBE1D22GpFhoCOdgQAvD_BwE&gclsrc=aw.ds&hl=ja&authuser=5&project=sigma-task-479704-r6\")\n\n    st.markdown(\"---\")\n    st.code(f\"PROJECT: {VERTEX_PROJECT}\\nLOCATION: {VERTEX_LOCATION} (Vertex AI)\")\n\n# =========================\n# Main UI\n# =========================\n\ncurrent_session_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\nfor s in st.session_state.sessions:\n    if s[\"id\"] == st.session_state.current_session_id:\n        current_session_title = s[\"title\"]\n        break\n\nst.header(current_session_title)\nst.markdown(\n    \"ä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\"\n)\n\n\n# ---- ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒœã‚¿ãƒ³ (Floating) ----\nst.markdown(\"\"\"\n    <style>\n        .scroll-btn-container {\n            position: fixed;\n            bottom: 100px;\n            right: 20px;\n            z-index: 9999;\n            display: flex;\n            flex-direction: column;\n            gap: 10px;\n        }\n        .scroll-btn {\n            background-color: #f0f2f6;\n            color: #31333F;\n            border: 1px solid #d6d6d8;\n            border-radius: 50%;\n            width: 40px;\n            height: 40px;\n            display: flex;\n            align-items: center;\n            justify-content: center;\n            cursor: pointer;\n            box-shadow: 0 2px 5px rgba(0,0,0,0.1);\n            transition: all 0.3s ease;\n            font-size: 20px;\n            padding: 0;\n            line-height: 1;\n        }\n        .scroll-btn:hover {\n            background-color: #e0e2e6;\n            transform: scale(1.1);\n            box-shadow: 0 4px 8px rgba(0,0,0,0.15);\n        }\n    </style>\n    \n    <script>\n        window.scrollStreamlit = function(direction) {\n            console.log(\"Scroll triggered: \" + direction);\n            \n            // ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ãªã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹è¦ç´ ã‚’é †ç•ªã«è©¦ã™\n            var targets = [];\n            \n            try {\n                if (window.parent && window.parent.document) {\n                    targets.push(window.parent.document.querySelector('section[data-testid=\"stAppViewContainer\"]'));\n                    targets.push(window.parent.document.querySelector('.main'));\n                    targets.push(window.parent.document.documentElement);\n                }\n            } catch (e) {\n                console.log(\"Access to parent window denied\");\n            }\n            \n            // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆiframeå†…ï¼‰\n            targets.push(document.querySelector('section[data-testid=\"stAppViewContainer\"]'));\n            targets.push(document.documentElement);\n\n            var scrolled = false;\n            for (var i = 0; i < targets.length; i++) {\n                var el = targets[i];\n                if (el) {\n                    try {\n                        // ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯èƒ½ãªè¦ç´ ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“çš„ï¼‰\n                        if (el.scrollHeight > el.clientHeight || el === window.parent.document.documentElement) {\n                            console.log(\"Scrolling element:\", el);\n                            if (direction === 'top') {\n                                el.scrollTo({top: 0, behavior: 'smooth'});\n                            } else {\n                                el.scrollTo({top: el.scrollHeight, behavior: 'smooth'});\n                            }\n                            scrolled = true;\n                        }\n                    } catch (e) {\n                        console.error(\"Error scrolling element:\", e);\n                    }\n                }\n            }\n            \n            if (!scrolled) {\n                console.log(\"No scrollable container found, trying window scroll\");\n                try {\n                    if (direction === 'top') {\n                        window.parent.scrollTo({top: 0, behavior: 'smooth'});\n                    } else {\n                        window.parent.scrollTo({top: window.parent.document.body.scrollHeight, behavior: 'smooth'});\n                    }\n                } catch(e) {\n                    window.scrollTo({top: 0, behavior: 'smooth'});\n                }\n            }\n        }\n    </script>\n\n    <div class=\"scroll-btn-container\">\n        <button class=\"scroll-btn\" onclick=\"window.scrollStreamlit('top')\" title=\"Top\">â¬†ï¸</button>\n        <button class=\"scroll-btn\" onclick=\"window.scrollStreamlit('bottom')\" title=\"Bottom\">â¬‡ï¸</button>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n# ---- Vertex AI Client ----\n\n\n\nclient = get_client()\n\n# ---- å±¥æ­´è¡¨ç¤º ----\n\nmessages = get_current_messages()\nfor idx, msg in enumerate(messages):\n    with st.chat_message(msg[\"role\"]):\n        st.markdown(msg[\"content\"])\n        if msg[\"role\"] == \"model\":\n            col1, col2, col3 = st.columns([0.1, 0.1, 0.8])\n            current_rating = msg.get(\"rating\")\n            with col1:\n                if st.button(\"ğŸ‘\", key=f\"up_{idx}\"):\n                    messages[idx][\"rating\"] = 1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col2:\n                if st.button(\"ğŸ‘\", key=f\"down_{idx}\"):\n                    messages[idx][\"rating\"] = -1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col3:\n                if current_rating == 1:\n                    st.caption(\"âœ… é«˜è©•ä¾¡\")\n                elif current_rating == -1:\n                    st.caption(\"âŒ ä½è©•ä¾¡\")\n\n# ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒœã‚¿ãƒ³ï¼ˆé•·ã„ãƒãƒ£ãƒƒãƒˆç”¨ï¼‰\nif len(messages) > 5:\n    st.markdown(\"\"\"\n    <div style=\"position: fixed; right: 20px; bottom: 100px; z-index: 999;\">\n        <button onclick=\"window.scrollTo({top: 0, behavior: 'smooth'})\" \n                style=\"display: block; margin: 5px; padding: 10px 15px; font-size: 24px; cursor: pointer; \n                       border: 2px solid #ccc; border-radius: 50%; background: white; box-shadow: 0 2px 8px rgba(0,0,0,0.2);\">\n            â¬†ï¸\n        </button>\n        <button onclick=\"window.scrollTo({top: document.body.scrollHeight, behavior: 'smooth'})\" \n                style=\"display: block; margin: 5px; padding: 10px 15px; font-size: 24px; cursor: pointer; \n                       border: 2px solid #ccc; border-radius: 50%; background: white; box-shadow: 0 2px 8px rgba(0,0,0,0.2);\">\n            â¬‡ï¸\n        </button>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n\n# =========================\n# ç”»åƒç”Ÿæˆãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°\n# =========================\n\nif hasattr(st.session_state, \"generate_image_trigger\") and st.session_state.generate_image_trigger:\n    img_data = st.session_state.generate_image_trigger\n    del st.session_state.generate_image_trigger\n\n    with st.chat_message(\"user\"):\n        st.markdown(f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\")\n        st.caption(f\"ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”: {img_data['aspect_ratio']}\")\n\n    messages.append({\"role\": \"user\", \"content\": f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\"})\n    update_current_session_messages(messages)\n\n    with st.chat_message(\"assistant\"):\n        with st.status(\"ç”»åƒã‚’ç”Ÿæˆä¸­...\", expanded=True) as status:\n            try:\n                config = types.GenerateContentConfig(\n                    response_modalities=[\"IMAGE\"],\n                    image_config=types.ImageConfig(\n                        aspect_ratio=img_data[\"aspect_ratio\"]\n                    ),\n                )\n                status.write(\"Gemini 3 Pro Imageã§ç”Ÿæˆä¸­...\")\n                response = client.models.generate_content(\n                    model=\"gemini-3-pro-image-preview\",\n                    contents=img_data[\"prompt\"],\n                    config=config,\n                )\n\n                generated_image = None\n\n                # ç”»åƒã‚’å–ã‚Šå‡ºã™\n                if getattr(response, \"candidates\", None):\n                    for candidate in response.candidates:\n                        if getattr(candidate, \"content\", None) and candidate.content.parts:\n                            for part in candidate.content.parts:\n                                if getattr(part, \"inline_data\", None):\n                                    try:\n                                        generated_image = part.as_image()\n                                    except AttributeError:\n                                        image_bytes_raw = part.inline_data.data\n                                        generated_image = Image.open(io.BytesIO(image_bytes_raw))\n                                    break\n                        if generated_image is not None:\n                            break\n\n                if generated_image is not None:\n                    st.image(generated_image, caption=img_data[\"prompt\"])\n                    buf = io.BytesIO()\n                    generated_image.save(buf, format=\"PNG\")\n                    image_bytes = buf.getvalue()\n                    st.download_button(\n                        label=\"ğŸ’¾ ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\",\n                        data=image_bytes,\n                        file_name=f\"generated_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png\",\n                        mime=\"image/png\",\n                    )\n                    messages.append(\n                        {\"role\": \"model\", \"content\": f\"âœ… ç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {img_data['prompt']}\"}\n                    )\n                    update_current_session_messages(messages)\n                    status.update(label=\"âœ… ç”»åƒç”Ÿæˆå®Œäº†\", state=\"complete\")\n                else:\n                    st.error(\"ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")\n                    status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n\n            except Exception as e:\n                status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n                st.error(f\"ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}\")\n\n# =========================\n# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›\n# =========================\n\nprompt = st.chat_input(\"ä½•ã‹èã„ã¦ãã ã•ã„...\", disabled=stop_generation)\n\nif prompt:\n    if stop_generation:\n        st.error(\"äºˆç®—ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚\")\n    else:\n        # ---- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€è¡¨ç¤º ----\n        with st.chat_message(\"user\"):\n            st.markdown(prompt)\n            if uploaded_files:\n                for uf in uploaded_files:\n                    st.caption(f\"ğŸ“ æ·»ä»˜: {uf.name}\")\n            if youtube_url:\n                st.caption(f\"ğŸ“º YouTube: {youtube_url}\")\n            if pasted_image_bytes:\n                st.caption(\"ğŸ“‹ ç”»åƒãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚Œã¾ã—ãŸ\")\n\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        update_current_session_messages(messages)\n\n        # ---- ãƒ¢ãƒ‡ãƒ«å¿œç­” ----\n        with st.chat_message(\"assistant\"):\n            status_container = st.status(\"æ€è€ƒä¸­...\", expanded=True)\n            try:\n                # ä¼šè©±å±¥æ­´\n                model_history = []\n                for msg in messages[:-1]:\n                    model_history.append(\n                        types.Content(\n                            role=msg[\"role\"],\n                            parts=[types.Part.from_text(text=msg[\"content\"])],\n                        )\n                    )\n\n                # ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³\n                current_parts = [types.Part.from_text(text=prompt)]\n\n                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«\n                for uploaded_file in uploaded_files or []:\n                    try:\n                        mime_type = get_mime_type(uploaded_file.name)\n                        bytes_data = uploaded_file.getvalue()\n                        part = types.Part.from_bytes(data=bytes_data, mime_type=mime_type)\n                        current_parts.append(part)\n                        status_container.write(f\"ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™å®Œäº†: {uploaded_file.name}\")\n                    except Exception as e:\n                        status_container.error(\n                            f\"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {uploaded_file.name} - {e}\"\n                        )\n\n                # è²¼ã‚Šä»˜ã‘ç”»åƒ\n                if pasted_image_bytes:\n                    import base64\n\n                    status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã‚’å‡¦ç†ä¸­...\")\n                    try:\n                        if isinstance(pasted_image_bytes, str):\n                            if pasted_image_bytes.startswith(\"data:\"):\n                                base64_str = pasted_image_bytes.split(\",\", 1)[1]\n                                image_bytes_decoded = base64.b64decode(base64_str)\n                            else:\n                                image_bytes_decoded = base64.b64decode(pasted_image_bytes)\n                        else:\n                            image_bytes_decoded = pasted_image_bytes\n                        part = types.Part.from_bytes(\n                            data=image_bytes_decoded, mime_type=\"image/png\"\n                        )\n                        current_parts.append(part)\n                        status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®æº–å‚™å®Œäº†\")\n                    except Exception as e:\n                        status_container.error(f\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n\n                # YouTube å­—å¹•\n                if youtube_url:\n                    vid_id = extract_youtube_id(youtube_url)\n                    if vid_id:\n                        status_container.write(\"YouTubeã®å­—å¹•ã‚’å–å¾—ä¸­...\")\n                        transcript_text = get_youtube_transcript(vid_id)\n                        current_parts.append(\n                            types.Part.from_text(text=f\"YouTube Transcript:\\n{transcript_text}\")\n                        )\n                    else:\n                        status_container.write(\"ç„¡åŠ¹ãªYouTube URLã§ã™ã€‚\")\n\n                contents_for_model = model_history + [\n                    types.Content(role=\"user\", parts=current_parts)\n                ]\n\n                # ---- Tool / Config ----\n                tools = []\n                final_candidate_count = candidate_count\n                if use_search:\n                    tools.append(types.Tool(google_search=types.GoogleSearch()))\n                    final_candidate_count = 1\n\n                # â˜… System Instruction ã®æ”¹å–„: ãƒ¡ã‚¿ç™ºè¨€ç¦æ­¢ã¨ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªæŒ¯ã‚‹èˆã„ã‚’æŒ‡ç¤º\n                base_system_instruction = (\n                    \"ã‚ãªãŸã¯é«˜åº¦ãªçŸ¥æ€§ã‚’æŒã¤å°‚é–€çš„ãªãƒªã‚µãƒ¼ãƒãƒ»ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\\n\"\n                    \"ä»¥ä¸‹ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’å³å®ˆã—ã¦ãã ã•ã„ï¼š\\n\"\n                    \"1. **ãƒ¡ã‚¿ç™ºè¨€ã®ç¦æ­¢**: ã€Œç§ã¯AIã§ã™ã€ã€Œä¸–ç•Œæœ€é«˜å³°ã®ï½ã¨ã—ã¦ã€ãªã©ã®è‡ªå·±è¨€åŠã‚„å‰ç½®ãã¯ä¸€åˆ‡è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚\\n\"\n                    \"2. **æ„å›³ã®æ±²ã¿å–ã‚Š**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã®èƒŒå¾Œã«ã‚ã‚‹æ„å›³ï¼ˆæ–‡è„ˆã€æš—é»™ã®å‰æï¼‰ã‚’æ¨æ¸¬ã—ã€è¨€è‘‰é€šã‚Šã§ã¯ãªãã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ¬å½“ã«çŸ¥ã‚ŠãŸã„ã“ã¨ã€ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n\"\n                    \"3. **æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”**: çµè«–ã‚’å…ˆã«è¿°ã¹ã€ãã®å¾Œã«è©³ç´°ãªæ ¹æ‹ ã€ã‚·ãƒŠãƒªã‚ªåˆ†æã€ãƒªã‚¹ã‚¯è¦å› ã‚’è«–ç†çš„ã«å±•é–‹ã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"4. **å®¢è¦³æ€§**: äºˆæ¸¬ã‚’è¡Œã†å ´åˆã¯ã€æ–­å®šã‚’é¿ã‘ã€è¤‡æ•°ã®ã‚·ãƒŠãƒªã‚ªï¼ˆæ¥½è¦³ã€æ‚²è¦³ã€ä¸­ç«‹ï¼‰ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"5. **å¼•ç”¨**: æ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸå ´åˆã¯ã€å¿…ãšæƒ…å ±æºã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚\"\n                )\n\n                final_answer = \"\"\n                grounding_metadata = None\n                \n                # =========================\n                # ãƒ¢ãƒ¼ãƒ‰è¨­å®šã®è§£æ\n                # =========================\n                # Î²1é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ä»¥å¤–ã¯ãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œ\n                enable_research = \"Î²1\" not in response_mode\n                enable_meta = \"ãƒ¡ã‚¿\" in response_mode or \"MAX\" in response_mode\n                enable_strict = \"é¬¼è»æ›¹\" in response_mode or \"MAX\" in response_mode\n                enable_grok_x_search = \"grokæ¤œç´¢å¼·åŒ–ç‰ˆ\" in response_mode\n\n                # =========================\n                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (é«˜é€Ÿ / é¬¼è»æ›¹)\n                # =========================\n                if not enable_research:\n                    config = types.GenerateContentConfig(\n                        temperature=0.7,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=base_system_instruction,\n                    )\n                    \n                    status_container.write(\"å›ç­”ç”Ÿæˆä¸­...\")\n                    response = client.models.generate_content(\n                        model=model_id,\n                        contents=contents_for_model,\n                        config=config,\n                    )\n                    \n                    final_answer = extract_text_from_response(response)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®—\n                    if response.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            response.usage_metadata.prompt_token_count,\n                            response.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += response.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += response.usage_metadata.candidates_token_count\n\n                    # é¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ (é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ç‰ˆ)\n                    if enable_strict:\n                        status_container.write(\"ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        reviewer_instruction = base_system_instruction + \"\"\"\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n                        review_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\nåˆç‰ˆå›ç­”:\\n{final_answer}\\n\\nãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\")])]\n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=types.GenerateContentConfig(temperature=0.1, candidate_count=1, system_instruction=reviewer_instruction)\n                        )\n                        final_answer = extract_text_from_response(review_resp)\n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        \n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(model_id, review_resp.usage_metadata.prompt_token_count, review_resp.usage_metadata.candidates_token_count)\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n\n                # =========================\n                # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰\n                # =========================\n                else:\n                    # =========================\n                    # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰: å¤šæ®µéšã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ \n                    # =========================\n                    \n                    # --- Phase 1: ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 1: ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    import datetime as dt\n                    current_year = dt.datetime.now().year\n                    \n                    research_instruction = base_system_instruction + f\"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒªã‚µãƒ¼ãƒå°‚ä»»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚æœ€çµ‚å›ç­”ã¯æ›¸ã‹ãšã€äº‹å®Ÿåé›†ã«é›†ä¸­ã™ã‚‹ã“ã¨ã€‚\n\n**èª¿æŸ»è¦³ç‚¹**:\n- è³ªå•ã«é–¢é€£ã™ã‚‹**æœ€æ–°ã®äº‹å®Ÿãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ»çµ±è¨ˆ**ï¼ˆ**{current_year}å¹´ã®æƒ…å ±ã‚’æœ€å„ªå…ˆ**ï¼‰\n- **ç¾æ™‚ç‚¹ã§å­˜åœ¨ã™ã‚‹å…¨ã¦ã®é¸æŠè‚¢ãƒ»ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¶²ç¾…çš„ã«èª¿æŸ»**ï¼ˆä¾‹: è£½å“æ¯”è¼ƒãªã‚‰ã€æœ€æ–°ç‰ˆã ã‘ã§ãªãç›´è¿‘ã®å…¨ä¸–ä»£ã‚’èª¿æŸ»ï¼‰\n- å…¬å¼æƒ…å ±ã‚„ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã‹ã‚‰ã®å¼•ç”¨\n- é–¢é€£ã™ã‚‹èƒŒæ™¯æƒ…å ±ã‚„æ–‡è„ˆ\n- ç«¶åˆãƒ»ä»£æ›¿æ¡ˆãƒ»æ¯”è¼ƒå¯¾è±¡ã®**å®Œå…¨ãªãƒªã‚¹ãƒˆ**\n- ãƒªã‚¹ã‚¯ãƒ»åˆ¶ç´„ãƒ»æ³¨æ„ç‚¹ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n- å‚è€ƒã«ã—ãŸä¸»è¦ãªæƒ…å ±æºã®URL\n\n**é‡è¦**: \n- çµè«–ã‚„æ¨å¥¨ã¯æ›¸ã‹ãšã€å¾Œå·¥ç¨‹ãŒåˆ¤æ–­ã§ãã‚‹èª¿æŸ»ãƒ¡ãƒ¢ã«é›†ä¸­ã™ã‚‹ã“ã¨\n- **å¿…ãšæ¤œç´¢æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã€æœ€æ–°ã®æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã“ã¨**\n- **æ¤œç´¢çµæœã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æ—¥ä»˜ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒ»ãƒ¢ãƒ‡ãƒ«åã‚’å„ªå…ˆçš„ã«è¨˜è¼‰ã™ã‚‹ã“ã¨**\n- **æ¯”è¼ƒå¯¾è±¡ã¨ãªã‚‹é¸æŠè‚¢ã‚’è¦‹è½ã¨ã•ãªã„ã‚ˆã†ã€è¤‡æ•°ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è©¦ã™ã“ã¨**ï¼ˆä¾‹: ã€ŒiPhone æœ€æ–°ãƒ¢ãƒ‡ãƒ« {current_year}ã€ã€ŒiPhone {current_year}å¹´ç™ºå£²ã€ãªã©ï¼‰\n- **ã€Œã“ã‚Œã‚ˆã‚Šæ–°ã—ã„ãƒ¢ãƒ‡ãƒ«/ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯å­˜åœ¨ã—ãªã„ã‹ï¼Ÿã€ã‚’å¸¸ã«ç¢ºèªã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ï¼ˆ{current_year-1}å¹´ä»¥å‰ãªã©ï¼‰ã—ã‹è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãã®æ—¨ã‚’æ˜è¨˜ã™ã‚‹ã“ã¨\n\"\"\"\n\n                    # éå»ã®é–¢é€£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—\n                    past_context = get_relevant_context(prompt, st.session_state.sessions, st.session_state.current_session_id)\n                    \n                    # ãƒªã‚µãƒ¼ãƒç”¨ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ§‹ç¯‰\n                    import datetime as dt\n                    current_date = dt.datetime.now().strftime(\"%Yå¹´%mæœˆ%dæ—¥\")\n                    research_parts = [types.Part(text=(\n                        f\"é‡è¦: ä»Šæ—¥ã¯{current_date}ã§ã™ã€‚ã“ã®æ—¥ä»˜ã‚ˆã‚Šæ–°ã—ã„æƒ…å ±ã‚’å„ªå…ˆã—ã¦ãã ã•ã„ã€‚\\n\\n\"\n                        f\"è³ªå•: {prompt}\"\n                    ))]\n                    \n                    if past_context:\n                        research_parts.insert(0, types.Part(text=\"ä»¥ä¸‹ã¯éå»ã®é–¢é€£ãƒãƒ£ãƒƒãƒˆã‹ã‚‰æŠ½å‡ºã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã™ï¼š\\n\\n\" + past_context))\n                    \n                    research_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=research_parts)\n                    ]\n                    \n                    research_config = types.GenerateContentConfig(\n                        temperature=0.4,  # æœ€æ–°æƒ…å ±ã‚’æŸ”è»Ÿã«æ¡ç”¨ã™ã‚‹ãŸã‚0.2â†’0.4ã«ä¸Šæ˜‡\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=research_instruction,\n                    )\n                    \n                    research_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=research_contents,\n                        config=research_config,\n                    )\n                    \n                    research_text = extract_text_from_response(research_resp)\n                    \n                    # ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºã®ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ±ã‚’ä¿å­˜\n                    if research_resp.candidates and research_resp.candidates[0].grounding_metadata:\n                        grounding_metadata = research_resp.candidates[0].grounding_metadata\n                    \n                    status_container.write(\"âœ“ ãƒªã‚µãƒ¼ãƒå®Œäº†\")\n                    with status_container.expander(\"åé›†ã—ãŸèª¿æŸ»ãƒ¡ãƒ¢\", expanded=False):\n                        st.markdown(research_text)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1)\n                    if research_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            research_resp.usage_metadata.prompt_token_count,\n                            research_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += research_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += research_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 1.5: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    questions_text = \"\"\n                    if enable_meta:\n                        status_container.write(\"Phase 1.5: ãƒ¡ã‚¿è³ªå•ç”Ÿæˆä¸­...\")\n                        \n                        question_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ç›®çš„**: \nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•ã¨èª¿æŸ»ãƒ¡ãƒ¢ã‚’è¸ã¾ãˆã¦ã€ã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±ãç†è§£ã™ã‚‹ãŸã‚ã®ã€Œé‹­ã„ã‚µãƒ–è³ªå•ã€ã‚’ä½œæˆã™ã‚‹ã“ã¨ã€‚\n\n**ãƒ«ãƒ¼ãƒ«**:\n- æœ€å¤§5å€‹ã¾ã§\n- å„è³ªå•ã¯1-2è¡Œã§å…·ä½“çš„ã‹ã¤é‹­ã\n- ä»¥ä¸‹ã®è¦³ç‚¹ã‚’æ„è­˜:\n  1. å‰æãŒå´©ã‚Œã‚‹å¯èƒ½æ€§ã¯ã©ã“ã‹ï¼Ÿ\n  2. å¼·æ°—/å¼±æ°—ã‚·ãƒŠãƒªã‚ªã®åˆ†å²ç‚¹ã¯ä½•ã‹ï¼Ÿ\n  3. ç«¶åˆãƒ»æŠ€è¡“ãƒ»è¦åˆ¶ã®ä¸ç¢ºå®Ÿæ€§ã¯ï¼Ÿ\n  4. ã€Œäºˆæ¸¬ãŒå¤–ã‚Œã‚‹ã¨ã—ãŸã‚‰ã©ã‚“ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ï¼Ÿã€\n\n**å‡ºåŠ›**: ç®‡æ¡æ›¸ãï¼ˆQ1, Q2...ï¼‰ã®ã¿\n\"\"\"\n\n                        question_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•:\\n{prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\nã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±æ˜ã‚Šã™ã‚‹ãŸã‚ã®é‡è¦ãªã‚µãƒ–è³ªå•ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\")])]\n                        \n                        question_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=question_contents,\n                            config=types.GenerateContentConfig(\n                                temperature=0.4,\n                                candidate_count=1,\n                                system_instruction=question_instruction,\n                            )\n                        )\n                        \n                        questions_text = extract_text_from_response(question_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¡ã‚¿è³ªå•ç”Ÿæˆå®Œäº†\")\n                        with status_container.expander(\"ç”Ÿæˆã•ã‚ŒãŸãƒ¡ã‚¿è³ªå•\", expanded=False):\n                            st.markdown(questions_text)\n                        \n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += question_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += question_resp.usage_metadata.candidates_token_count\n\n                    # å¤šå±¤+puterãƒ¢ãƒ¼ãƒ‰ã®é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã‹ãƒã‚§ãƒƒã‚¯\n                    is_puter_onigunsou = (\n                        mode_category == \"Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter)\" and\n                        response_mode == \"1. ç†Ÿè€ƒ + é¬¼è»æ›¹\"\n                    )\n\n                    # --- Phase 1.5b: Grok ç‹¬ç«‹æ€è€ƒ (å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    # --- Phase 1.5b: Grok ç‹¬ç«‹æ€è€ƒ (å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    grok_thought = \"\"\n                    grok_status = \"skipped\"\n                    if enable_meta and OPENROUTER_API_KEY:\n                        status_container.write(\"Phase 1.5b: Grok ç‹¬ç«‹æ€è€ƒä¸­...\")\n                        try:\n                            grok_thought = think_with_grok(prompt, research_text, enable_x_search=enable_grok_x_search)\n                            if grok_thought:\n                                grok_status = \"success\"\n                                status_container.write(\"âœ“ Grok 4.1 Fast Free ç‹¬ç«‹æ€è€ƒå®Œäº†\")\n                                with status_container.expander(\"Grokã®ç‹¬ç«‹å›ç­”æ¡ˆ\", expanded=False):\n                                    st.markdown(grok_thought)\n                            else:\n                                grok_status = \"empty\"\n                        except Exception as e:\n                            grok_status = \"error\"\n                            status_container.write(f\"âš  Grokæ€è€ƒã‚¨ãƒ©ãƒ¼: {e}\")\n\n                    # --- Phase 1.5c: Claude Opus 4.5 ç‹¬ç«‹æ€è€ƒ (å¤šå±¤+puterã®é¬¼è»æ›¹ã®ã¿) ---\n                    # --- Phase 1.5c: Claude Opus 4.5 ç‹¬ç«‹æ€è€ƒ (å¤šå±¤+puterã®é¬¼è»æ›¹ã®ã¿) ---\n                    claude_thought = \"\"\n                    claude_status = \"skipped\"\n                    if is_puter_onigunsou and PUTER_USERNAME and PUTER_PASSWORD:\n                        status_container.write(\"Phase 1.5c: Claude Opus 4.5 ç‹¬ç«‹æ€è€ƒä¸­...\")\n                        try:\n                            claude_thought = call_claude_opus_via_puter(\n                                user_question=prompt,\n                                research_text=research_text,\n                                system_prompt=(\n                                    \"ã‚ãªãŸã¯ Claude Opus 4.5 ã§ã™ã€‚\"\n                                    \"Gemini ãŒé›†ã‚ãŸèª¿æŸ»ãƒ¡ãƒ¢ã‚’å‚è€ƒã«ã—ã¤ã¤ã‚‚ã€\"\n                                    \"è‡ªåˆ†ã®è¦–ç‚¹ã§ç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆãƒ»æ°—ã¥ãã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\"\n                                    \"Gemini ã®æ„è¦‹ã«åˆã‚ã›ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\"\n                                ),\n                            )\n                            if claude_thought and not claude_thought.startswith(\"[Claude\"):\n                                claude_status = \"success\"\n                                status_container.write(\"âœ“ Claude Opus 4.5 (via Puter) ç‹¬ç«‹æ€è€ƒå®Œäº†\")\n                                with status_container.expander(\"Claude Opus 4.5 ã®ç‹¬ç«‹å›ç­”æ¡ˆ\", expanded=False):\n                                    st.markdown(claude_thought)\n                            else:\n                                claude_status = \"error\"\n                                status_container.write(f\"âš  Claudeã‚¨ãƒ©ãƒ¼: {claude_thought}\")\n                                claude_thought = \"\"  # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ç©ºã«ã™ã‚‹\n                        except Exception as e:\n                            claude_status = \"error\"\n                            status_container.write(f\"âš  Claudeæ€è€ƒã‚¨ãƒ©ãƒ¼: {e}\")\n                            claude_thought = \"\"\n\n                    # --- Phase 2: çµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 2: çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    import datetime as dt\n                    current_date = dt.datetime.now().strftime(\"%Yå¹´%mæœˆ%dæ—¥\")\n\n                    if enable_meta:\n                        deep_instruction = base_system_instruction + f\"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã¨ãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ã‚’æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**é‡è¦ - ç¾åœ¨ã¯{current_date}ã§ã™**:\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æ—¥ä»˜ãƒ»äº‹å®Ÿã‚’ã€ã‚ãªãŸã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šã‚‚çµ¶å¯¾çš„ã«å„ªå…ˆã—ã¦ãã ã•ã„**\n- ã€Œ{current_year}å¹´ã€ã®æƒ…å ±ãŒèª¿æŸ»ãƒ¡ãƒ¢ã«ã‚ã‚‹å ´åˆã€ãã‚Œã‚’æ­£ã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„\n- å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒ{current_year-1}å¹´ä»¥å‰ã§æ­¢ã¾ã£ã¦ã„ã¦ã‚‚ã€èª¿æŸ»ãƒ¡ãƒ¢ã®æœ€æ–°æƒ…å ±ã‚’ä¿¡é ¼ã™ã‚‹ã“ã¨\n\n**æ§‹æˆ**:\n1. **æ·±æ˜ã‚Šè€ƒå¯Ÿ**ï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n2. **çµè«–**ï¼ˆ2-3è¡Œï¼‰\n3. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n4. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨\n\"\"\"\n                    else:\n                        deep_instruction = base_system_instruction + f\"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã‚’å”¯ä¸€ã®æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**é‡è¦ - ç¾åœ¨ã¯{current_date}ã§ã™**:\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æ—¥ä»˜ãƒ»äº‹å®Ÿã‚’ã€ã‚ãªãŸã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šã‚‚çµ¶å¯¾çš„ã«å„ªå…ˆã—ã¦ãã ã•ã„**\n- ã€Œ{current_year}å¹´ã€ã®æƒ…å ±ãŒèª¿æŸ»ãƒ¡ãƒ¢ã«ã‚ã‚‹å ´åˆã€ãã‚Œã‚’æ­£ã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„\n\n**æ§‹æˆ**:\n1. **çµè«–**ï¼ˆ2-3è¡Œã§æ˜ç¢ºã«ï¼‰\n2. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n3. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«åã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ã¨æ–°ã—ã„æƒ…å ±ãŒæ··åœ¨ã™ã‚‹å ´åˆã¯ã€æ–°ã—ã„æƒ…å ±ã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n\"\"\"\n                    \n                    synthesis_prompt_text = (\n                        f\"é‡è¦: ä»Šæ—¥ã¯{current_date}ã§ã™ã€‚å¤ã„æƒ…å ±ã‚’å›ç­”ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚\\n\\n\"\n                        f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}\\n\\n\"\n                        f\"==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                    )\n                    \n                    if enable_meta and questions_text:\n                        synthesis_prompt_text += f\"==== ãƒ¡ã‚¿è³ªå•ä¸€è¦§ ====\\n{questions_text}\\n==== ãƒ¡ã‚¿è³ªå•ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if enable_meta and grok_thought:\n                        synthesis_prompt_text += f\"==== åˆ¥è¦–ç‚¹ã‹ã‚‰ã®å›ç­”æ¡ˆ (Grok) ====\\n{grok_thought}\\n==== åˆ¥è¦–ç‚¹ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if is_puter_onigunsou and claude_thought:\n                        synthesis_prompt_text += f\"==== åˆ¥è¦–ç‚¹ã‹ã‚‰ã®å›ç­”æ¡ˆ (Claude Opus 4.5 via Puter) ====\\n{claude_thought}\\n==== Claudeåˆ¥è¦–ç‚¹ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    # çµ±åˆæŒ‡ç¤º\n                    if enable_meta and (grok_thought or claude_thought):\n                        synthesis_prompt_text += \"æŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n2. Grok\"\n                        if is_puter_onigunsou and claude_thought:\n                            synthesis_prompt_text += \" / Claude\"\n                        synthesis_prompt_text += \" ã®å›ç­”æ¡ˆã‚‚å‚è€ƒã«ã—ã¤ã¤ï¼ˆãŸã ã—ç›²ä¿¡ã›ãšï¼‰ã€ç‹¬è‡ªã®è¦–ç‚¹ã§çµ±åˆã—ã¦ãã ã•ã„ã€‚\\n3. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»åˆ†æãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    elif enable_meta and questions_text:\n                        synthesis_prompt_text += \"æŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n2. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»åˆ†æãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    else:\n                        synthesis_prompt_text += \"ä¸Šè¨˜ãƒ¡ãƒ¢ã‚’æ ¹æ‹ ã«ã€æœ€çµ‚å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å¿…ãšä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚**\"\n\n                    synthesis_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=[\n                            types.Part(text=synthesis_prompt_text)\n                        ])\n                    ]\n                    \n                    synthesis_config = types.GenerateContentConfig(\n                        temperature=0.3,\n                        candidate_count=1,\n                        tools=[],  # çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºã§ã¯æ¤œç´¢OFF\n                        system_instruction=deep_instruction,\n                    )\n                    \n                    synthesis_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=synthesis_contents,\n                        config=synthesis_config,\n                    )\n                    \n                    draft_answer = extract_text_from_response(synthesis_resp)\n                    \n                    status_container.write(\"âœ“ çµ±åˆå®Œäº†\")\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 2)\n                    if synthesis_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            synthesis_resp.usage_metadata.prompt_token_count,\n                            synthesis_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += synthesis_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += synthesis_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    if enable_strict:\n                        status_container.write(\"Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        \n\n                        reviewer_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™ã€‚ãŸã ã—ã€**èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’å„ªå…ˆã—ã€æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã™ã‚‹ã“ã¨**ã€‚\n\n**ãƒ¬ãƒ“ãƒ¥ãƒ¼è¦³ç‚¹**:\n- äº‹å®Ÿã¨æ¨æ¸¬ã‚’æ˜ç¢ºã«åˆ†ã‘ã‚‹\n- éåº¦ã«è‡ªä¿¡ã®ã‚ã‚‹æ–­å®šã‚’å¼±ã‚ã‚‹\n- æ•°å­—ã‚„å›ºæœ‰åè©ãŒèª¿æŸ»ãƒ¡ãƒ¢ã¨çŸ›ç›¾ã—ã¦ã„ãªã„ã‹ç¢ºèª\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ãƒ¢ãƒ‡ãƒ«ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ãŒæ­£ã—ãä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª**\n- **å¤ã„æƒ…å ±ã§ä¸Šæ›¸ãã—ã¦ã„ãªã„ã‹ç¢ºèª**\n- è¦‹è½ã¨ã—ã¦ã„ã‚‹é‡è¦ãªãƒªã‚¹ã‚¯ãƒ»ã‚·ãƒŠãƒªã‚ªãŒã‚ã‚Œã°è¿½åŠ \n\n**é‡è¦**: \n- èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ãŒæœ€æ–°ã§ã‚ã‚‹å ´åˆã€ãã‚Œã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n- ã‚ãªãŸã®çŸ¥è­˜ãŒå¤ã„å ´åˆã¯ã€èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’ä¿¡é ¼ã™ã‚‹ã“ã¨\n\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n\n                        review_contents = [\n                            types.Content(role=\"user\", parts=[\n                                types.Part.from_text(\n                                    text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\n\"\n                                    f\"==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                                    f\"åˆç‰ˆå›ç­”:\\n{draft_answer}\\n\\n\"\n                                    \"ä¸Šè¨˜ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚**\"\n                                )\n                            ])\n                        ]\n                        \n                        review_config = types.GenerateContentConfig(\n                            temperature=0.1,\n                            candidate_count=1,\n                            system_instruction=reviewer_instruction,\n                            thinking_config=types.ThinkingConfig(\n                                thinking_level=types.ThinkingLevel.HIGH\n                            ),\n                        )\n                        \n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=review_config,\n                        )\n                        \n                        final_answer = extract_text_from_response(review_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        \n                        # --- Phase 3b: Groké¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ (å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ + é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰å…¨èˆ¬) ---\n                        # å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã§ã€ã‹ã¤é¬¼è»æ›¹ç³»ã®ãƒ¢ãƒ¼ãƒ‰ï¼ˆé¬¼è»æ›¹ã€ãƒ¡ã‚¿æ€è€ƒã€æœ¬æ°—MAXï¼‰ã§ç™ºå‹•\n                        use_grok_reviewer = (mode_category == \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\" and enable_strict)\n                        \n                        if use_grok_reviewer and OPENROUTER_API_KEY:\n                            status_container.write(\"Phase 3b: Grok 4.1 Fast ã§æœ€çµ‚ãƒã‚§ãƒƒã‚¯ä¸­...\")\n                            try:\n                                grok_answer = review_with_grok(prompt, final_answer, research_text)\n                                # Grokä½¿ç”¨æ™‚ã¯ã€ãƒ¢ãƒ‡ãƒ«åã‚’æ˜ç¤ºã—ã€2æ®µæ§‹æˆã§è¡¨ç¤º\n                                final_answer = (\n                                    f\"**ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_id} (Deep Thinking / High Reasoning)**\\n\"\n                                    f\"**ãƒ¬ãƒ“ãƒ¥ã‚¢: Grok 4.1 Fast (free)**\\n\"\n                                    f\"**ãƒ¢ãƒ¼ãƒ‰: {response_mode}**\\n\\n\"\n                                    \"---\\n\\n\"\n                                    \"## âœ… æœ€çµ‚å›ç­”ï¼ˆGeminiçµ±åˆç‰ˆï¼‰\\n\\n\"\n                                    f\"{final_answer}\\n\\n\"\n                                    \"---\\n\\n\"\n                                    \"## ğŸ” Grok ã«ã‚ˆã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼\\n\\n\"\n                                    f\"{grok_answer}\"\n                                )\n                                status_container.write(\"âœ“ Grokæœ€çµ‚ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                            except Exception as e:\n                                status_container.write(f\"âš  Grokãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}\")\n                        else:\n                            # Geminiã®ã¿ã®å ´åˆã‚‚ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤ºï¼ˆå¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆï¼‰\n                            if mode_category == \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\":\n                                final_answer = (\n                                    f\"**ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_id} (Deep Thinking / High Reasoning)**\\n\"\n                                    f\"**ãƒ¢ãƒ¼ãƒ‰: {response_mode}**\\n\\n---\\n\\n{final_answer}\"\n                                )\n                        \n                        # --- ãƒ¡ã‚¿æ€è€ƒãƒ¢ãƒ¼ãƒ‰: çµè«–ã‚’å…ˆå‡ºã—ã™ã‚‹ ---\n                        if \"ãƒ¡ã‚¿æ€è€ƒ\" in response_mode:\n                            # çµè«–éƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆç°¡æ˜“çš„ãªå®Ÿè£…ï¼‰\n                            # \"çµè«–\"ã‚„\"ã¾ã¨ã‚\"ãªã©ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¢ã—ã¦å…ˆé ­ã«ç§»å‹•\n                            lines = final_answer.split('\\n')\n                            conclusion_start = -1\n                            for i, line in enumerate(lines):\n                                if any(keyword in line for keyword in ['## çµè«–', '## ã¾ã¨ã‚', '**çµè«–**', '**ã¾ã¨ã‚**']):\n                                    conclusion_start = i\n                                    break\n                            \n                            if conclusion_start != -1:\n                                # çµè«–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¦‹ã¤ã‘ãŸå ´åˆã€ãã‚Œã‚’å…ˆé ­ã«ç§»å‹•\n                                conclusion_section = []\n                                other_content = lines[:conclusion_start]\n                                \n                                # çµè«–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®çµ‚ã‚ã‚Šã‚’è¦‹ã¤ã‘ã‚‹ï¼ˆæ¬¡ã®##ã¾ã§ or æ–‡æœ«ï¼‰\n                                conclusion_end = len(lines)\n                                for i in range(conclusion_start + 1, len(lines)):\n                                    if lines[i].startswith('## ') and i != conclusion_start:\n                                        conclusion_end = i\n                                        break\n                                \n                                conclusion_section = lines[conclusion_start:conclusion_end]\n                                remaining_content = lines[conclusion_end:]\n                                \n                                # å†æ§‹æˆ: ãƒ¢ãƒ‡ãƒ«å â†’ çµè«– â†’ ãã®ä»–ã®è©³ç´°\n                                # ãƒ¢ãƒ‡ãƒ«åéƒ¨åˆ†ã‚’ä¿æŒ\n                                model_line = \"\"\n                                if lines[0].startswith(\"**ğŸ¤–\"):\n                                    model_line = lines[0]\n                                    other_content = lines[1:conclusion_start]\n                                \n                                final_answer = '\\n'.join([\n                                    model_line,\n                                    \"\",\n                                    \"---\",\n                                    \"\",\n                                    \"## ğŸ“Œ çµè«–ï¼ˆå…ˆå‡ºã—ï¼‰\",\n                                    *conclusion_section[1:],  # å…ƒã®è¦‹å‡ºã—ã‚’é™¤ã\n                                    \"\",\n                                    \"---\",\n                                    \"\",\n                                    \"## ğŸ“ è©³ç´°\",\n                                    *other_content,\n                                    *remaining_content\n                                ]).strip()\n                        \n                        with status_container.expander(\"åˆç‰ˆã¨ã®æ¯”è¼ƒ\", expanded=False):\n                            st.markdown(\"**åˆç‰ˆ:**\")\n                            st.markdown(draft_answer[:500] + \"...\" if len(draft_answer) > 500 else draft_answer)\n                            st.markdown(\"**ä¿®æ­£ç‰ˆ:**\")\n                            st.markdown(final_answer[:500] + \"...\" if len(final_answer) > 500 else final_answer)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 3)\n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                review_resp.usage_metadata.prompt_token_count,\n                                review_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n                    else:\n                        final_answer = draft_answer\n\n                save_usage(usage_stats)\n                status_container.update(label=\"å®Œäº†ï¼\", state=\"complete\", expanded=False)\n\n                # ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤º\n                models_used = [f\"Gemini: {model_id}\"]\n                \n                # Grok Status\n                if enable_meta:\n                    if grok_status == \"success\":\n                        models_used.append(\"Grok: 4.1-fast-free (OK)\")\n                    elif grok_status == \"error\":\n                        models_used.append(\"Grok: 4.1-fast-free (Error)\")\n                    elif grok_status == \"empty\":\n                        models_used.append(\"Grok: 4.1-fast-free (Empty)\")\n                \n                # Claude Status\n                if is_puter_onigunsou:\n                    if claude_status == \"success\":\n                        models_used.append(\"Claude: Opus 4.5 (via Puter) (OK)\")\n                    elif claude_status == \"error\":\n                        models_used.append(\"Claude: Opus 4.5 (via Puter) (Error)\")\n                \n                st.caption(f\"ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {' + '.join(models_used)}\")\n                st.markdown(final_answer)\n\n                # ---- ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ± ----\n                if grounding_metadata:\n                    st.markdown(\"---\")\n                    with st.expander(\"ğŸ“š æƒ…å ±æºã¨å¼•ç”¨\", expanded=False):\n                        if grounding_metadata.grounding_chunks:\n                            st.markdown(\"**æ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:**\")\n                            unique_sources = {}\n                            import urllib.parse\n\n                            for chunk in grounding_metadata.grounding_chunks:\n                                if getattr(chunk, \"web\", None):\n                                    uri = getattr(chunk.web, \"uri\", None)\n                                    title = getattr(chunk.web, \"title\", \"æƒ…å ±æº\")\n                                    if uri and uri not in unique_sources:\n                                        parsed = urllib.parse.urlparse(uri)\n                                        domain = parsed.netloc.replace(\"www.\", \"\")\n                                        unique_sources[uri] = {\n                                            \"title\": title,\n                                            \"domain\": domain,\n                                        }\n                            for i, (uri, info) in enumerate(unique_sources.items(), 1):\n                                st.markdown(f\"{i}. **[{info['title']}]({uri})**\")\n                                st.caption(f\"   å‡ºå…¸: {info['domain']}\")\n\n                messages.append({\"role\": \"model\", \"content\": final_answer})\n                update_current_session_messages(messages)\n\n            except Exception as e:\n                status_container.update(label=\"Error\", state=\"error\")\n                err_text = str(e)\n                if \"RESOURCE_EXHAUSTED\" in err_text or \"429\" in err_text:\n                    st.error(\n                        \"âš ï¸ Vertex AI / Gemini ã®ã‚¯ã‚©ãƒ¼ã‚¿ã«é”ã—ã¾ã—ãŸã€‚\\n\\n\"\n                        \"ãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ / æ—¥æ¬¡åˆ¶é™ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\\n\"\n                        \"ãƒ»ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                        \"ãƒ»Google Cloud Console ã®ã€ŒVertex AI â†’ ä½¿ç”¨çŠ¶æ³ã€ã‹ã‚‰ã‚¯ã‚©ãƒ¼ã‚¿çŠ¶æ³ã‚’ç¢ºèªã§ãã¾ã™ã€‚\"\n                    )\n                elif \"NOT_FOUND\" in err_text and \"Publisher Model\" in err_text:\n                    st.error(\n                        \"âš ï¸ æŒ‡å®šã—ãŸãƒ¢ãƒ‡ãƒ«ãŒã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ / ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\\n\"\n                        \"ãƒ»ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ¢ãƒ‡ãƒ«IDã‚’ã€2.5ç³» ã¾ãŸã¯ 3 Pro ã«å¤‰æ›´ã—ã¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                    )\n                else:\n                    st.error(f\"An error occurred: {e}\")\n"
                }
            ]
        },
        {
            "id": "f7ee4754-4b2c-4259-a992-26acfb712b9c",
            "title": "ä»¥ä¸‹Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter...",
            "timestamp": "2025-12-02T00:01:36.765482",
            "messages": [
                {
                    "role": "user",
                    "content": "ä»¥ä¸‹Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter) â†’ 1. ç†Ÿè€ƒ + é¬¼è»æ›¹ã§claudeã¯ã¤ã‹ãˆã‚‹ã‹ã€‚\n\nimport os\nimport uuid\nimport datetime\nimport streamlit as st\nfrom dotenv import load_dotenv\nfrom google import genai\nfrom google.genai import types\nfrom PIL import Image\nimport io\nfrom logic import (\n    USAGE_FILE, SESSIONS_FILE, MAX_BUDGET_USD, PRICING,\n    VERTEX_PROJECT, VERTEX_LOCATION,\n    load_usage, save_usage, calculate_cost, get_mime_type,\n    extract_youtube_id, get_youtube_transcript, get_relevant_context,\n    extract_text_from_response, load_sessions, save_sessions, get_client\n)\n\ntry:\n    from st_img_pastebutton import paste\n    import_error_msg = None\nexcept ImportError as e:\n    paste = None\n    import_error_msg = str(e)\n\n# =========================\n# ç’°å¢ƒå¤‰æ•° & å®šæ•°\n# =========================\n\nload_dotenv()\n\n\n\nst.set_page_config(page_title=\"Gemini 3 Web Studio\", layout=\"wide\")\n\n# ğŸ” ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ­ãƒƒã‚¯ (198501) + URLãƒˆãƒ¼ã‚¯ãƒ³æ°¸ç¶šåŒ–\nSECRET_TOKEN = \"access_granted_198501\"\n\n# 1. URLãƒˆãƒ¼ã‚¯ãƒ³ãƒã‚§ãƒƒã‚¯\nquery_params = st.query_params\nurl_token = query_params.get(\"auth\", None)\n\nif url_token == SECRET_TOKEN:\n    st.session_state.authenticated = True\nelif \"authenticated\" not in st.session_state:\n    st.session_state.authenticated = False\n\n# 2. æœªèªè¨¼ãªã‚‰ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ç”»é¢\nif not st.session_state.authenticated:\n    st.title(\"Gemini 3 Studio\")\n    st.write(\"ã“ã®ã‚¢ãƒ—ãƒªã‚’åˆ©ç”¨ã™ã‚‹ã«ã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒå¿…è¦ã§ã™ã€‚\")\n\n    password = st.text_input(\"ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰\", type=\"password\")\n\n    if st.button(\"ãƒ­ã‚°ã‚¤ãƒ³\"):\n        if password == \"198501\":\n            st.session_state.authenticated = True\n            # URLã«ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä»˜ä¸ã—ã¦ãƒªãƒ­ãƒ¼ãƒ‰ï¼ˆã“ã‚Œã§ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯å¯èƒ½ã«ãªã‚‹ï¼‰\n            st.query_params[\"auth\"] = SECRET_TOKEN\n            st.rerun()\n        else:\n            st.error(\"ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™ã€‚\")\n\n    st.stop()\n\n# =========================\n# Helper Functions\n# =========================\n\n# =========================\n# Helper Functions\n# =========================\n# Moved to logic.py\n\n# =========================\n# Grok Review Function (OpenRouter API)\n# =========================\n\nimport requests\nfrom curl_cffi import requests as crequests  # Grokç”¨ï¼ˆå¿…è¦ã«å¿œã˜ã¦æ®‹ã™ï¼‰\nimport asyncio\nimport nest_asyncio\nfrom putergenai import PuterClient\n\n# Streamlitã§Asyncã‚’ä½¿ã†ãŸã‚ã®è¨­å®š\nnest_asyncio.apply()\n\n# OpenRouter API Keyã®å–å¾— (st.secretså„ªå…ˆã€ãªã‘ã‚Œã°ç’°å¢ƒå¤‰æ•°)\ntry:\n    if \"OPENROUTER_API_KEY\" in st.secrets:\n        OPENROUTER_API_KEY = st.secrets[\"OPENROUTER_API_KEY\"]\n    else:\n        OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\", \"\")\nexcept:\n    OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\", \"\")\n\n# Puter èªè¨¼æƒ…å ±\nPUTER_USERNAME = None\nPUTER_PASSWORD = None\ntry:\n    if \"PUTER_USERNAME\" in st.secrets:\n        PUTER_USERNAME = st.secrets[\"PUTER_USERNAME\"]\n        PUTER_PASSWORD = st.secrets[\"PUTER_PASSWORD\"]\n    else:\n        PUTER_USERNAME = os.getenv(\"PUTER_USERNAME\")\n        PUTER_PASSWORD = os.getenv(\"PUTER_PASSWORD\")\nexcept Exception:\n    PUTER_USERNAME = os.getenv(\"PUTER_USERNAME\")\n    PUTER_PASSWORD = os.getenv(\"PUTER_PASSWORD\")\n\ndef review_with_grok(user_question: str, gemini_answer: str, research_text: str = None) -> str:\n    \"\"\"\n    Grok 4.1 Fast Free ã‚’ä½¿ã£ã¦ã€Geminiã®å›ç­”ã‚’æœ€çµ‚ãƒ¬ãƒ“ãƒ¥ãƒ¼ã™ã‚‹\n    research_text: GeminiãŒåé›†ã—ãŸèª¿æŸ»ãƒ¡ãƒ¢ï¼ˆæœ€æ–°æƒ…å ±ã‚’å«ã‚€ï¼‰\n    \"\"\"\n    url = \"https://openrouter.ai/api/v1/chat/completions\"\n    headers = {\n        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n        \"Content-Type\": \"application/json\",\n    }\n    \n    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰\n    user_content = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\\n{user_question}\\n\\n\"\n    \n    if research_text:\n        user_content += f\"Gemini ã®èª¿æŸ»ãƒ¡ãƒ¢ï¼ˆæœ€æ–°æƒ…å ±ï¼‰:\\n{research_text}\\n\\n\"\n    \n    user_content += (\n        f\"Gemini ã®æœ€çµ‚å›ç­”:\\n{gemini_answer}\\n\\n\"\n        \"**é‡è¦**: èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹äº‹å®Ÿã®æ–¹ã‚’ã€ã‚ãªãŸè‡ªèº«ã®çŸ¥è­˜ã‚ˆã‚Šã‚‚å„ªå…ˆã—ã¦ãã ã•ã„ã€‚\\n\"\n        \"æœ€æ–°ã®æƒ…å ±ãŒèª¿æŸ»ãƒ¡ãƒ¢ã«ã‚ã‚‹å ´åˆã€ãã‚Œã‚’ä¿¡é ¼ã—ã¦ãã ã•ã„ã€‚\\n\\n\"\n        \"1. **é‡å¤§ãªäº‹å®Ÿèª¤èªãƒ»è«–ç†é£›èºã®æŒ‡æ‘˜**ï¼ˆãªã‘ã‚Œã°ã€ç‰¹ã«ãªã—ã€ï¼‰\\n\"\n        \"2. **å…·ä½“çš„ãªä¿®æ­£ææ¡ˆã®ãƒªã‚¹ãƒˆ**ï¼ˆã€ä¿®æ­£å‰ã€â†’ã€ä¿®æ­£å¾Œã€ã®å½¢å¼ã§ï¼‰\\n\"\n        \"3. **ç‰¹ã«ä¸ç¢ºå®Ÿæ€§ãŒé«˜ã„ãƒã‚¤ãƒ³ãƒˆï¼ˆå‰æä¸è¶³ã€ãƒ‡ãƒ¼ã‚¿ä¸è¶³ãªã©ï¼‰ã® bullet list**\\n\"\n    )\n    \n    data = {\n        \"model\": \"x-ai/grok-4.1-fast:free\",\n        \"reasoning\": {\"enabled\": True},  # Enable multi-step reasoning for deeper review\n        \"messages\": [\n            {\n                \"role\": \"system\",\n                \"content\": (\n                    \"ã‚ãªãŸã¯å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ã§ã™ã€‚\"\n                    \"äº‹å®Ÿèª¤èªãƒ»è«–ç†ã®é£›èºãƒ»æŠœã‘æ¼ã‚Œã‚’å®¹èµ¦ãªãæŒ‡æ‘˜ã—ã€\"\n                    \"å¿…è¦ãªã‚‰å›ç­”ã‚’å…¨æ–‡æ›¸ãç›´ã—ã¦ãã ã•ã„ã€‚\"\n                ),\n            },\n            {\n                \"role\": \"user\",\n                \"content\": user_content.strip() + (\n                    \"ã ã‘ã‚’æ—¥æœ¬èªã§å‡ºã—ã¦ãã ã•ã„ã€‚\"\n                ),\n            },\n        ],\n    }\n    try:\n        resp = requests.post(url, headers=headers, json=data, timeout=60)\n        resp.raise_for_status()\n        j = resp.json()\n        return j[\"choices\"][0][\"message\"][\"content\"]\n    except Exception as e:\n        return f\"[Grokãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}]\\n\\n{gemini_answer}\"\n\n# =========================\n# Session Management\n# =========================\n\n\n\ndef think_with_grok(user_question: str, research_text: str, enable_x_search: bool = False) -> str:\n    \"\"\"\n    Grok 4.1 Fast Free ã‚’ä½¿ã£ã¦ã€ãƒªã‚µãƒ¼ãƒãƒ¡ãƒ¢ã‚’å…ƒã«ç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆã‚’ä½œæˆã™ã‚‹\n    enable_x_search=True ã®å ´åˆã€X/Twitteræƒ…å ±ã®æ´»ç”¨ã‚’ä¿ƒã™\n    \"\"\"\n    url = \"https://openrouter.ai/api/v1/chat/completions\"\n    headers = {\n        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n        \"Content-Type\": \"application/json\",\n    }\n    \n    # Xæ¤œç´¢å¼·åŒ–ç‰ˆã®å ´åˆã€ç‰¹åˆ¥ãªæŒ‡ç¤ºã‚’è¿½åŠ \n    x_search_instruction = \"\"\n    if enable_x_search:\n        x_search_instruction = (\n            \"\\n\\n**é‡è¦**: ã‚ãªãŸã¯Grokã¨ã—ã¦Xï¼ˆTwitterï¼‰ã®æƒ…å ±ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚\\n\"\n            \"ä¸Šè¨˜ã®èª¿æŸ»ãƒ¡ãƒ¢ã«åŠ ãˆã¦ã€Xä¸Šã®æœ€æ–°ã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»è­°è«–ãƒ»åå¿œã‚’è€ƒæ…®ã—ã€\\n\"\n            \"ãã‚Œã‚‰ã‚’å«ã‚ãŸç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\\n\\n\"\n            \"æ³¨æ„: Xä¸Šã®æƒ…å ±ãŒç¢ºèªã§ããªã„å ´åˆã¯ã€ãã®æ—¨ã‚’æ­£ç›´ã«è¿°ã¹ã¦ãã ã•ã„ã€‚\\n\"\n            \"æ¶ç©ºã®æŠ•ç¨¿ã‚„å­˜åœ¨ã—ãªã„åå¿œã‚’ä½œæˆã—ãªã„ã“ã¨ã€‚\"\n        )\n    \n    user_content = (\n        f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\\n{user_question}\\n\\n\"\n        f\"èª¿æŸ»ãƒ¡ãƒ¢:\\n{research_text}\\n\\n\"\n        \"æŒ‡ç¤º:\\n\"\n        \"ã‚ãªãŸã¯Geminiã¨ã¯åˆ¥ã®ç‹¬ç«‹ã—ãŸAIã§ã™ã€‚\\n\"\n        \"ä¸Šè¨˜ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’å‚è€ƒã«ã—ã¤ã¤ã‚‚ã€ã‚ãªãŸè‡ªèº«ã®è¦–ç‚¹ã§ç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\\n\"\n        \"Geminiã®æ„è¦‹ã«åˆã‚ã›ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\"\n        f\"{x_search_instruction}\"\n    )\n    \n    data = {\n        \"model\": \"x-ai/grok-2-1212\",\n        \"messages\": [\n            {\"role\": \"user\", \"content\": user_content}\n        ],\n    }\n    \n    try:\n        resp = requests.post(url, headers=headers, json=data, timeout=60)\n        resp.raise_for_status()\n        j = resp.json()\n        return j[\"choices\"][0][\"message\"][\"content\"]\n    except Exception as e:\n        return f\"[Grokæ€è€ƒã‚¨ãƒ©ãƒ¼: {e}]\"\n\ndef _extract_puter_text(message_content):\n    \"\"\"\n    puter.ai.chat ã®è¿”ã‚Šå€¤ã‹ã‚‰ ãƒ†ã‚­ã‚¹ãƒˆã ã‘ã‚’å–ã‚Šå‡ºã™\n    \"\"\"\n    if isinstance(message_content, str):\n        return message_content\n\n    if isinstance(message_content, list):\n        chunks = []\n        for part in message_content:\n            if isinstance(part, dict) and part.get(\"type\") == \"text\":\n                chunks.append(part.get(\"text\", \"\"))\n        return \"\".join(chunks)\n\n    return str(message_content)\n\n\ndef call_claude_opus_via_puter(\n    user_question: str,\n    research_text: str | None = None,\n    system_prompt: str | None = None,\n) -> str:\n    \"\"\"\n    Claude Opus 4.5ï¼ˆputer.comï¼‰via putergenai SDK\n    å…¬å¼ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¦Claudeã«ã‚¢ã‚¯ã‚»ã‚¹\n    \"\"\"\n    if not PUTER_USERNAME or not PUTER_PASSWORD:\n        return \"[Claude (puter) èªè¨¼æƒ…å ±æœªè¨­å®š]\"\n\n    async def _run() -> str:\n        try:\n            async with PuterClient() as client:\n                # SDKã§ãƒ­ã‚°ã‚¤ãƒ³\n                await client.login(PUTER_USERNAME, PUTER_PASSWORD)\n\n                # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹ç¯‰\n                messages = []\n                if system_prompt:\n                    messages.append({\"role\": \"system\", \"content\": system_prompt})\n\n                user_content = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\\n{user_question}\\n\\n\"\n                if research_text:\n                    user_content += f\"èª¿æŸ»ãƒ¡ãƒ¢:\\n{research_text}\\n\\n\"\n                    suser_content += \"ã“ã®èª¿æŸ»ãƒ¡ãƒ¢ã®äº‹å®Ÿã‚’å„ªå…ˆã—ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚\\n\"\n\n                messages.append({\"role\": \"user\", \"content\": user_content})\n\n                # Claude Opus 4.5 ã‚’å‘¼ã³å‡ºã—\n                result = await client.ai_chat(\n                    messages=messages,\n                    options={\n                        \"model\": \"claude-opus-4-5\",  # ãƒã‚¤ãƒ•ãƒ³åŒºåˆ‡ã‚Š\n                        \"stream\": False,\n                    },\n                    strict_model=False,  # SDKã®ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—\n                )\n\n                # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰æœ¬æ–‡ã‚’å–å¾—\n                # ãƒ‡ãƒãƒƒã‚°ç”¨ã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹å…¨ä½“ã‚’è¡¨ç¤º\n                import json\n                print(f\"DEBUG: Puter response: {json.dumps(result, indent=2)}\")\n                \n                message_content = result[\"response\"][\"result\"][\"message\"][\"content\"]\n                return _extract_puter_text(message_content)\n\n        except KeyError as e:\n            import traceback\n            return f\"[Claude SDK KeyError] Missing key: {e}\\nTraceback: {traceback.format_exc()}\"\n        except Exception as e:\n            import traceback\n            return f\"[Claude SDK Error] {type(e).__name__}: {str(e)}\\nTraceback: {traceback.format_exc()}\"\n\n    # Streamlitã®åŒæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§asyncã‚’å®Ÿè¡Œ\n    try:\n        return asyncio.run(_run())\n    except Exception as e:\n        import traceback\n        return f\"[Claude Connection Error] {type(e).__name__}: {str(e)}\\nTraceback: {traceback.format_exc()}\"\n\ndef create_new_session():\n    current_sessions = load_sessions()\n    \n    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒç©ºãªã‚‰ã€æ–°ã—ãä½œã‚‰ãšã«ãã‚Œã‚’å†åˆ©ç”¨ã™ã‚‹ï¼ˆé‡è¤‡é˜²æ­¢ï¼‰\n    if st.session_state.get(\"current_session_id\"):\n        for s in current_sessions:\n            if s[\"id\"] == st.session_state.current_session_id:\n                if len(s[\"messages\"]) == 0:\n                    st.toast(\"ã™ã§ã«æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã§ã™\")\n                    return\n\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": [],\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.rerun()\n\ndef switch_session(session_id):\n    st.session_state.current_session_id = session_id\n    st.rerun()\n\ndef update_current_session_messages(messages):\n    if st.session_state.current_session_id:\n        current_sessions = load_sessions()\n        target_index = -1\n        for i, session in enumerate(current_sessions):\n            if session[\"id\"] == st.session_state.current_session_id:\n                session[\"messages\"] = messages\n                if session[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(messages) > 0:\n                    first_msg = messages[0][\"content\"]\n                    session[\"title\"] = (first_msg[:20] + \"...\") if len(first_msg) > 20 else first_msg\n                session[\"timestamp\"] = datetime.datetime.now().isoformat()\n                target_index = i\n                break\n        \n        if target_index != -1:\n            # æœ€æ–°ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒªã‚¹ãƒˆã®å…ˆé ­ã«ç§»å‹•\n            updated_session = current_sessions.pop(target_index)\n            current_sessions.insert(0, updated_session)\n            \n        save_sessions(current_sessions)\n        st.session_state.sessions = current_sessions\n\ndef get_current_messages():\n    if st.session_state.current_session_id:\n        for session in st.session_state.sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                return session[\"messages\"]\n    return []\n\ndef delete_session(session_id):\n    current_sessions = load_sessions()\n    current_sessions = [s for s in current_sessions if s[\"id\"] != session_id]\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    if st.session_state.current_session_id == session_id:\n        st.session_state.current_session_id = None\n        if st.session_state.sessions:\n            st.session_state.current_session_id = st.session_state.sessions[0][\"id\"]\n    st.rerun()\n\ndef branch_session():\n    \"\"\"ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚’åˆ†å²\"\"\"\n    current_messages = get_current_messages()\n    current_sessions = load_sessions()\n    \n    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—\n    current_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n    for session in current_sessions:\n        if session[\"id\"] == st.session_state.current_session_id:\n            current_title = session[\"title\"]\n            break\n    \n    # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": f\"{current_title} (åˆ†å²)\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": current_messages.copy(),  # ç¾åœ¨ã®å±¥æ­´ã‚’ã‚³ãƒ”ãƒ¼\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    \n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.session_state.session_cost = 0.0  # ã‚³ã‚¹ãƒˆãƒªã‚»ãƒƒãƒˆ\n    st.rerun()\n\n# =========================\n# Initialization\n# =========================\n\nif \"sessions\" not in st.session_state:\n    st.session_state.sessions = load_sessions()\n\nif \"current_session_id\" not in st.session_state:\n    # Always create a new session when the app starts\n    create_new_session()\n\nif \"session_cost\" not in st.session_state:\n    st.session_state.session_cost = 0.0\n\nusage_stats = load_usage()\n\n# ==========================\n# ã‚³ã‚¹ãƒˆãƒã‚§ãƒƒã‚¯ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã®å‰ã«å®Ÿè¡Œï¼‰\n# ==========================\nusage_stats = load_usage()\nstop_generation = usage_stats[\"total_cost_usd\"] >= MAX_BUDGET_USD\n\n# =========================\n# Sidebar\n# =========================\n\nwith st.sidebar:\n    # ğŸ” ãƒ­ã‚°ã‚¢ã‚¦ãƒˆãƒœã‚¿ãƒ³\n    if st.button(\"ğŸ”’ ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ\", use_container_width=True):\n        st.session_state.authenticated = False\n        st.query_params.clear()  # URLãƒˆãƒ¼ã‚¯ãƒ³ã‚‚å‰Šé™¤\n        st.rerun()\n\n    st.markdown(\"\"\"\n    <div style=\"text-align: center; padding: 0; margin: 0; margin-top: -1rem;\">\n        <h1 style=\"font-size: 18px; font-weight: 700; margin: 0; padding: 0; letter-spacing: 1px;\">\n            Gemini 3<br/>Studio\n        </h1>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n    col1, col2 = st.columns(2)\n    with col1:\n        if st.button(\"â• æ–°è¦\", use_container_width=True):\n            create_new_session()\n    with col2:\n        if st.button(\"ğŸŒ± åˆ†å²\", use_container_width=True):\n            branch_session()\n\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    current_messages = get_current_messages()\n    if current_messages:\n        with st.expander(\"ğŸ”— å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ\", expanded=False):\n            export_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n            for s in st.session_state.sessions:\n                if s[\"id\"] == st.session_state.current_session_id:\n                    export_title = s[\"title\"]\n                    break\n\n            export_md = f\"# {export_title}\\n\\n\"\n            export_md += f\"**ä½œæˆæ—¥æ™‚**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n---\\n\\n\"\n            for msg in current_messages:\n                role_label = \"ğŸ§‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼\" if msg[\"role\"] == \"user\" else \"ğŸ¤– AI\"\n                export_md += f\"## {role_label}\\n\\n{msg['content']}\\n\\n---\\n\\n\"\n\n            if st.button(\"ãƒªãƒ³ã‚¯ç”Ÿæˆ\", use_container_width=True):\n                with st.spinner(\"ç”Ÿæˆä¸­...\"):\n                    try:\n                        import urllib.request\n                        import urllib.parse\n\n                        data = urllib.parse.urlencode(\n                            {\"content\": export_md, \"expiry_days\": 7, \"syntax\": \"md\"}\n                        ).encode()\n\n                        req = urllib.request.Request(\"https://dpaste.org/api/\", data=data)\n                        req.add_header(\"User-Agent\", \"Mozilla/5.0 (Gemini3Studio)\")\n\n                        with urllib.request.urlopen(req) as response:\n                            share_url = response.read().decode(\"utf-8\").strip()\n                            st.success(\"ä½œæˆå®Œäº†ï¼\")\n                            st.code(share_url)\n                            st.caption(\"â€»7æ—¥é–“æœ‰åŠ¹\")\n                    except Exception as e:\n                        st.error(f\"ã‚¨ãƒ©ãƒ¼: {e}\")\n\n    st.markdown(\"---\")\n\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    with st.expander(\"ğŸ“ æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«\", expanded=False):\n        uploaded_files = st.file_uploader(\n            \"ãƒ•ã‚¡ã‚¤ãƒ«\",\n            accept_multiple_files=True,\n            type=[\"png\", \"jpg\", \"jpeg\", \"mp4\", \"mov\", \"txt\", \"pdf\", \"csv\"],\n            label_visibility=\"collapsed\"\n        )\n\n    # ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ï¼ˆExpanderã®å¤–ã«å‡ºã™ï¼‰\n    pasted_image_bytes = None  # åˆæœŸåŒ–ã—ã¦NameErrorã‚’é˜²ã\n    if paste:\n        if \"paste_key\" not in st.session_state:\n            st.session_state.paste_key = 0\n        try:\n            pasted_image_bytes = paste(\n                label=\"ğŸ“‹ ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰è²¼ä»˜\",\n                key=f\"paste_btn_{st.session_state.paste_key}\",\n            )\n        except Exception as e:\n            st.error(f\"Error: {e}\")\n        \n        if pasted_image_bytes:\n            st.success(\"è²¼ä»˜å®Œäº†\")\n            st.image(pasted_image_bytes, caption=\"ç”»åƒ\", use_container_width=True)\n            if st.button(\"ğŸ—‘ï¸ ã‚¯ãƒªã‚¢\", key=\"clear_paste\"):\n                st.session_state.paste_key += 1\n                st.rerun()\n    else:\n        st.warning(\"Clipboard lib missing\")\n\n    # ---- YouTube URL ----\n    with st.expander(\"ğŸ“º YouTubeåˆ†æ\", expanded=False):\n        youtube_url = st.text_input(\"URL\", placeholder=\"https://youtu.be/...\", label_visibility=\"collapsed\")\n\n    st.markdown(\"---\")\n    \n    st.markdown(\"---\")\n    \n    # ---- ãƒ¢ãƒ¼ãƒ‰ã‚«ãƒ†ã‚´ãƒªé¸æŠ ----\n    mode_category = st.radio(\n        \"ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ¼ãƒ‰\",\n        [\"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\", \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(é€šå¸¸)\", \"Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter)\"],\n        index=0,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’å¤šå±¤ã«å¤‰æ›´\n        horizontal=True,\n    )\n    \n    # ---- å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ ----\n    if mode_category == \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\":\n        with st.expander(\"ãƒ¢ãƒ¼ãƒ‰è¨­å®š(å¤šå±¤)\", expanded=True):\n            mode_type = st.radio(\n                \"ã‚¿ã‚¤ãƒ—\",\n                [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n                index=0,\n                horizontal=True,\n                label_visibility=\"collapsed\"\n            )\n            \n            if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. (è©¦é¨“ä¸­)ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                        \"2. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                        \"3. (è©¦é¨“ä¸­)ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                        \"4. ç†Ÿè€ƒ(ãƒ¡ã‚¿æ€è€ƒ)+grokæ¤œç´¢å¼·åŒ–ç‰ˆ\",\n                    ],\n                    index=1  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ãƒ¡ã‚¿æ€è€ƒã«å¤‰æ›´\n                )\n            elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                    ],\n                    index=0\n                )\n            else:\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                    ],\n                    index=0\n                )\n    \n    # ---- å¤šå±¤+puterãƒ¢ãƒ¼ãƒ‰ ----\n    elif mode_category == \"Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter)\":\n        with st.expander(\"ãƒ¢ãƒ¼ãƒ‰è¨­å®š(å¤šå±¤+puter)\", expanded=True):\n            mode_type = st.radio(\n                \"ã‚¿ã‚¤ãƒ—\",\n                [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n                index=0,\n                horizontal=True,\n                label_visibility=\"collapsed\"\n            )\n            \n            if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                        \"2. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                        \"3. ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                    ],\n                    index=0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’é¬¼è»æ›¹ã«å¤‰æ›´\n                )\n            elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                    ],\n                    index=0\n                )\n            else:\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                    ],\n                    index=0\n                )\n    \n    # ---- é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ ----\n    else:\n        with st.expander(\"ãƒ¢ãƒ¼ãƒ‰è¨­å®š(é€šå¸¸)\", expanded=True):\n            mode_type = st.radio(\n                \"ã‚¿ã‚¤ãƒ—\",\n                [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n                index=0,\n                horizontal=True,\n                label_visibility=\"collapsed\"\n            )\n            \n            if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                        \"2. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                        \"3. ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                    ],\n                    index=0\n                )\n            elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                    ],\n                    index=0\n                )\n            else:\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                    ],\n                    index=0\n                )\n    \n    strict_mode = False\n    \n    # ---- è¨­å®š (ãƒ¢ãƒ‡ãƒ«ãªã©) ----\n    with st.expander(\"âš™ï¸ è¨­å®š\", expanded=False):\n        model_options = [\n            \"gemini-3-pro-preview\",\n            \"gemini-2.5-pro\",\n            \"gemini-2.5-flash\",\n            \"gemini-2.5-flash-lite\",\n            \"gemini-2.0-flash\",\n        ]\n        model_id = st.selectbox(\"ãƒ¢ãƒ‡ãƒ«ID\", options=model_options, index=0)\n\n        use_search = st.toggle(\"Googleæ¤œç´¢\", value=True)\n        candidate_count = st.slider(\"å€™è£œæ•°\", min_value=1, max_value=3, value=3)\n\n    st.markdown(\"---\")\n\n    # ---- å±¥æ­´æ¤œç´¢ ----\n    search_query = st.text_input(\"ğŸ” å±¥æ­´æ¤œç´¢\", placeholder=\"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰...\")\n    if search_query:\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if search_query.lower() in s[\"title\"].lower():\n                filtered_sessions.append(s)\n                continue\n            found = False\n            for m in s[\"messages\"]:\n                if search_query.lower() in m[\"content\"].lower():\n                    filtered_sessions.append(s)\n                    found = True\n                    break\n            if not found:\n                pass\n    else:\n        # æ¤œç´¢ã—ã¦ã„ãªã„å ´åˆ: ç©ºã®ã€Œæ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã€ã‚’é™¤å¤–ï¼ˆç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯é™¤ãï¼‰\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if s[\"id\"] == st.session_state.current_session_id:\n                filtered_sessions.append(s)\n                continue\n            if s[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(s[\"messages\"]) == 0:\n                continue\n            filtered_sessions.append(s)\n\n    # CSSã§è¦‹ã‚„ã™ãä½¿ã„ã‚„ã™ãæœ€é©åŒ–\n    st.markdown(\"\"\"\n    <style>\n    /* å…¨ä½“ã®ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºç¸®å° */\n    .stApp, .stMarkdown, .stButton, .stSelectbox, .stTextInput, .stTextArea {\n        font-size: 12px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ä½™ç™½ã‚’æ¥µé™ã¾ã§è©°ã‚ã‚‹ */\n    section[data-testid=\"stSidebar\"] .block-container {\n        padding-top: 0.3rem !important;\n        padding-bottom: 0.3rem !important;\n        padding-left: 0.5rem !important;\n        padding-right: 0.5rem !important;\n    }\n    /* å„è¦ç´ é–“ã®éš™é–“ã‚’è©°ã‚ã‚‹ */\n    div[data-testid=\"stVerticalBlock\"] > div {\n        gap: 0.1rem !important;\n    }\n    /* Expanderã®ä½™ç™½å‰Šæ¸› */\n    .streamlit-expanderHeader {\n        font-size: 11px !important;\n        padding-top: 0px !important;\n        padding-bottom: 0px !important;\n        min-height: 1.3rem !important;\n    }\n    .streamlit-expanderContent {\n        padding-top: 0px !important;\n        padding-bottom: 0px !important;\n    }\n    /* éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã®ã‚¿ã‚¤ãƒˆãƒ« */\n    div[data-testid=\"stExpander\"] summary p {\n        font-size: 10px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ */\n    section[data-testid=\"stSidebar\"] button p {\n        font-size: 10px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã« */\n    section[data-testid=\"stSidebar\"] button {\n        padding: 0rem 0.2rem !important;\n        min-height: 1.4rem !important;\n        font-size: 10px !important;\n        margin-bottom: 0px !important;\n    }\n    /* ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®ãƒ©ãƒ™ãƒ«ã‚’å°ã•ã */\n    section[data-testid=\"stSidebar\"] .stRadio label {\n        font-size: 10px !important;\n    }\n    section[data-testid=\"stSidebar\"] .stRadio > label > div {\n        font-size: 10px !important;\n    }\n    /* ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ‡ã‚Šè©°ã‚ã‚‹ï¼ˆæ”¹è¡Œã•ã›ãªã„ï¼‰ */\n    section[data-testid=\"stSidebar\"] label, \n    section[data-testid=\"stSidebar\"] p,\n    section[data-testid=\"stSidebar\"] span {\n        white-space: nowrap !important;\n        overflow: hidden !important;\n        text-overflow: ellipsis !important;\n    }\n    /* åŒºåˆ‡ã‚Šç·š */\n    hr {\n        margin-top: 0.1rem !important;\n        margin-bottom: 0.1rem !important;\n    }\n    /* ãƒ˜ãƒƒãƒ€ãƒ¼ç¸®å° */\n    h1, h2, h3 {\n        padding-top: 0rem !important;\n        padding-bottom: 0rem !important;\n        margin-top: 0rem !important;\n        margin-bottom: 0rem !important;\n    }\n    </style>\n    \"\"\", unsafe_allow_html=True)\n    \n    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§é™é †ã‚½ãƒ¼ãƒˆï¼ˆæœ€æ–°ãŒå…ˆé ­ï¼‰\n    filtered_sessions.sort(key=lambda s: s.get(\"timestamp\", \"\"), reverse=True)\n    \n    # ç›´è¿‘5ä»¶ã¨éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«åˆ†å‰²\n    recent_sessions = filtered_sessions[:5] if len(filtered_sessions) > 5 else filtered_sessions\n    archive_sessions = filtered_sessions[5:] if len(filtered_sessions) > 5 else []\n    \n    # ç›´è¿‘5ä»¶ï¼ˆå¸¸ã«å±•é–‹ï¼‰\n    if recent_sessions:\n        st.markdown(\"**ğŸ“Œ ç›´è¿‘ã®ãƒãƒ£ãƒƒãƒˆ**\")\n        for session in recent_sessions:\n            col1, col2 = st.columns([0.8, 0.2])\n            with col1:\n                if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                    switch_session(session[\"id\"])\n            with col2:\n                if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                    delete_session(session[\"id\"])\n    \n    # éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆæŠ˜ã‚ŠãŸãŸã¿ï¼‰\n    if archive_sessions:\n        with st.expander(f\"ğŸ“œ éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ– ({len(archive_sessions)}ä»¶)\", expanded=False):\n            for session in archive_sessions:\n                col1, col2 = st.columns([0.8, 0.2])\n                with col1:\n                    if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                        switch_session(session[\"id\"])\n                with col2:\n                    if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                        delete_session(session[\"id\"])\n\n    st.markdown(\"---\")\n\n    # ---- ç”»åƒç”Ÿæˆ ----\n    with st.expander(\"ğŸ¨ ç”»åƒç”Ÿæˆ\", expanded=False):\n        img_prompt = st.text_area(\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\", placeholder=\"æœªæ¥çš„ãªéƒ½å¸‚...\")\n        aspect_ratio = st.selectbox(\"æ¯”ç‡\", [\"16:9\", \"1:1\", \"4:3\", \"3:4\", \"9:16\"])\n\n        generate_img_btn = st.button(\"ç”Ÿæˆ\", type=\"primary\", disabled=not img_prompt)\n        if generate_img_btn and img_prompt:\n            st.session_state.generate_image_trigger = {\n                \"prompt\": img_prompt,\n                \"aspect_ratio\": aspect_ratio,\n            }\n\n    st.markdown(\"---\")\n\n    # ---- è©•ä¾¡åˆ†æ ----\n    with st.expander(\"ğŸ“Š å“è³ªåˆ†æ\", expanded=False):\n        total_ratings = 0\n        positive_ratings = 0\n        model_ratings = {}\n\n        for s in st.session_state.sessions:\n            for m in s[\"messages\"]:\n                if \"rating\" in m and m[\"rating\"] is not None:\n                    total_ratings += 1\n                    if m[\"rating\"] == 1:\n                        positive_ratings += 1\n                    if \"metadata\" in m and \"model\" in m[\"metadata\"]:\n                        mod = m[\"metadata\"][\"model\"]\n                        if mod not in model_ratings:\n                            model_ratings[mod] = {\"total\": 0, \"positive\": 0}\n                        model_ratings[mod][\"total\"] += 1\n                        if m[\"rating\"] == 1:\n                            model_ratings[mod][\"positive\"] += 1\n\n        if total_ratings > 0:\n            approval_rate = (positive_ratings / total_ratings) * 100\n            st.metric(\"Positive Ratings\", f\"{positive_ratings}/{total_ratings}\", f\"{approval_rate:.1f}%\")\n            best_model = \"N/A\"\n            best_rate = -1\n            for mod, stats in model_ratings.items():\n                rate = stats[\"positive\"] / stats[\"total\"]\n                if rate > best_rate:\n                    best_rate = rate\n                    best_model = mod\n            if best_model != \"N/A\":\n                st.caption(f\"ğŸ† Best: **{best_model}** ({best_rate*100:.0f}%)\")\n        else:\n            st.caption(\"ãƒ‡ãƒ¼ã‚¿ãªã—\")\n\n    st.markdown(\"---\")\n\n    # ---- ã‚³ã‚¹ãƒˆè¡¨ç¤º ----\n    from logic import load_manual_cost, save_manual_cost, MAX_BUDGET_JPY, TRIAL_LIMIT_JPY, TRIAL_EXPIRY\n    \n    st.subheader(\"ğŸ’° Cost\")\n    st.caption(f\"äºˆç®—: Â¥{MAX_BUDGET_JPY:,.0f}\")\n    st.caption(f\"ä¸Šé™: Â¥{TRIAL_LIMIT_JPY:,.0f}\")\n    st.caption(f\"æœ‰åŠ¹æœŸé™: {TRIAL_EXPIRY}\")\n    \n    # æ‰‹å‹•ã‚³ã‚¹ãƒˆå…¥åŠ›ï¼ˆæ°¸ç¶šåŒ–ï¼‰\n    current_manual_cost = load_manual_cost()\n    manual_cost = st.number_input(\n        \"æ‰‹å‹•å…¥åŠ› (Â¥)\",\n        min_value=0.0,\n        value=current_manual_cost,\n        step=10.0,\n        format=\"%.0f\",\n        key=\"manual_cost_persistent\",\n        help=\"Google Cloud Consoleã§ç¢ºèªã—ãŸå®Ÿéš›ã®ã‚³ã‚¹ãƒˆï¼ˆå††ï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ã“ã®å€¤ã¯ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‰ã˜ã¦ã‚‚ä¿æŒã•ã‚Œã¾ã™ã€‚\"\n    )\n    \n    # å€¤ãŒå¤‰æ›´ã•ã‚ŒãŸã‚‰ä¿å­˜\n    if manual_cost != current_manual_cost:\n        save_manual_cost(manual_cost)\n    \n    st.link_button(\"ğŸ’° Google Cloud Console\", \"https://console.cloud.google.com/welcome/new?_gl=1*kmr691*_up*MQ..&gclid=CjwKCAiAraXJBhBJEiwAjz7MZT0vQsfDK5zunRBCQmuN5iczgI4bP1lHo1Tcrcbqu1KCBE1D22GpFhoCOdgQAvD_BwE&gclsrc=aw.ds&hl=ja&authuser=5&project=sigma-task-479704-r6\")\n\n    st.markdown(\"---\")\n    st.code(f\"PROJECT: {VERTEX_PROJECT}\\nLOCATION: {VERTEX_LOCATION} (Vertex AI)\")\n\n# =========================\n# Main UI\n# =========================\n\ncurrent_session_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\nfor s in st.session_state.sessions:\n    if s[\"id\"] == st.session_state.current_session_id:\n        current_session_title = s[\"title\"]\n        break\n\nst.header(current_session_title)\nst.markdown(\n    \"ä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\"\n)\n\n\n# ---- ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒœã‚¿ãƒ³ (Floating) ----\nst.markdown(\"\"\"\n    <style>\n        .scroll-btn-container {\n            position: fixed;\n            bottom: 100px;\n            right: 20px;\n            z-index: 9999;\n            display: flex;\n            flex-direction: column;\n            gap: 10px;\n        }\n        .scroll-btn {\n            background-color: #f0f2f6;\n            color: #31333F;\n            border: 1px solid #d6d6d8;\n            border-radius: 50%;\n            width: 40px;\n            height: 40px;\n            display: flex;\n            align-items: center;\n            justify-content: center;\n            cursor: pointer;\n            box-shadow: 0 2px 5px rgba(0,0,0,0.1);\n            transition: all 0.3s ease;\n            font-size: 20px;\n            padding: 0;\n            line-height: 1;\n        }\n        .scroll-btn:hover {\n            background-color: #e0e2e6;\n            transform: scale(1.1);\n            box-shadow: 0 4px 8px rgba(0,0,0,0.15);\n        }\n    </style>\n    \n    <script>\n        window.scrollStreamlit = function(direction) {\n            console.log(\"Scroll triggered: \" + direction);\n            \n            // ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ãªã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹è¦ç´ ã‚’é †ç•ªã«è©¦ã™\n            var targets = [];\n            \n            try {\n                if (window.parent && window.parent.document) {\n                    targets.push(window.parent.document.querySelector('section[data-testid=\"stAppViewContainer\"]'));\n                    targets.push(window.parent.document.querySelector('.main'));\n                    targets.push(window.parent.document.documentElement);\n                }\n            } catch (e) {\n                console.log(\"Access to parent window denied\");\n            }\n            \n            // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆiframeå†…ï¼‰\n            targets.push(document.querySelector('section[data-testid=\"stAppViewContainer\"]'));\n            targets.push(document.documentElement);\n\n            var scrolled = false;\n            for (var i = 0; i < targets.length; i++) {\n                var el = targets[i];\n                if (el) {\n                    try {\n                        // ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯èƒ½ãªè¦ç´ ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“çš„ï¼‰\n                        if (el.scrollHeight > el.clientHeight || el === window.parent.document.documentElement) {\n                            console.log(\"Scrolling element:\", el);\n                            if (direction === 'top') {\n                                el.scrollTo({top: 0, behavior: 'smooth'});\n                            } else {\n                                el.scrollTo({top: el.scrollHeight, behavior: 'smooth'});\n                            }\n                            scrolled = true;\n                        }\n                    } catch (e) {\n                        console.error(\"Error scrolling element:\", e);\n                    }\n                }\n            }\n            \n            if (!scrolled) {\n                console.log(\"No scrollable container found, trying window scroll\");\n                try {\n                    if (direction === 'top') {\n                        window.parent.scrollTo({top: 0, behavior: 'smooth'});\n                    } else {\n                        window.parent.scrollTo({top: window.parent.document.body.scrollHeight, behavior: 'smooth'});\n                    }\n                } catch(e) {\n                    window.scrollTo({top: 0, behavior: 'smooth'});\n                }\n            }\n        }\n    </script>\n\n    <div class=\"scroll-btn-container\">\n        <button class=\"scroll-btn\" onclick=\"window.scrollStreamlit('top')\" title=\"Top\">â¬†ï¸</button>\n        <button class=\"scroll-btn\" onclick=\"window.scrollStreamlit('bottom')\" title=\"Bottom\">â¬‡ï¸</button>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n# ---- Vertex AI Client ----\n\n\n\nclient = get_client()\n\n# ---- å±¥æ­´è¡¨ç¤º ----\n\nmessages = get_current_messages()\nfor idx, msg in enumerate(messages):\n    with st.chat_message(msg[\"role\"]):\n        st.markdown(msg[\"content\"])\n        if msg[\"role\"] == \"model\":\n            col1, col2, col3 = st.columns([0.1, 0.1, 0.8])\n            current_rating = msg.get(\"rating\")\n            with col1:\n                if st.button(\"ğŸ‘\", key=f\"up_{idx}\"):\n                    messages[idx][\"rating\"] = 1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col2:\n                if st.button(\"ğŸ‘\", key=f\"down_{idx}\"):\n                    messages[idx][\"rating\"] = -1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col3:\n                if current_rating == 1:\n                    st.caption(\"âœ… é«˜è©•ä¾¡\")\n                elif current_rating == -1:\n                    st.caption(\"âŒ ä½è©•ä¾¡\")\n\n# ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒœã‚¿ãƒ³ï¼ˆé•·ã„ãƒãƒ£ãƒƒãƒˆç”¨ï¼‰\nif len(messages) > 5:\n    st.markdown(\"\"\"\n    <div style=\"position: fixed; right: 20px; bottom: 100px; z-index: 999;\">\n        <button onclick=\"window.scrollTo({top: 0, behavior: 'smooth'})\" \n                style=\"display: block; margin: 5px; padding: 10px 15px; font-size: 24px; cursor: pointer; \n                       border: 2px solid #ccc; border-radius: 50%; background: white; box-shadow: 0 2px 8px rgba(0,0,0,0.2);\">\n            â¬†ï¸\n        </button>\n        <button onclick=\"window.scrollTo({top: document.body.scrollHeight, behavior: 'smooth'})\" \n                style=\"display: block; margin: 5px; padding: 10px 15px; font-size: 24px; cursor: pointer; \n                       border: 2px solid #ccc; border-radius: 50%; background: white; box-shadow: 0 2px 8px rgba(0,0,0,0.2);\">\n            â¬‡ï¸\n        </button>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n\n# =========================\n# ç”»åƒç”Ÿæˆãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°\n# =========================\n\nif hasattr(st.session_state, \"generate_image_trigger\") and st.session_state.generate_image_trigger:\n    img_data = st.session_state.generate_image_trigger\n    del st.session_state.generate_image_trigger\n\n    with st.chat_message(\"user\"):\n        st.markdown(f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\")\n        st.caption(f\"ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”: {img_data['aspect_ratio']}\")\n\n    messages.append({\"role\": \"user\", \"content\": f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\"})\n    update_current_session_messages(messages)\n\n    with st.chat_message(\"assistant\"):\n        with st.status(\"ç”»åƒã‚’ç”Ÿæˆä¸­...\", expanded=True) as status:\n            try:\n                config = types.GenerateContentConfig(\n                    response_modalities=[\"IMAGE\"],\n                    image_config=types.ImageConfig(\n                        aspect_ratio=img_data[\"aspect_ratio\"]\n                    ),\n                )\n                status.write(\"Gemini 3 Pro Imageã§ç”Ÿæˆä¸­...\")\n                response = client.models.generate_content(\n                    model=\"gemini-3-pro-image-preview\",\n                    contents=img_data[\"prompt\"],\n                    config=config,\n                )\n\n                generated_image = None\n\n                # ç”»åƒã‚’å–ã‚Šå‡ºã™\n                if getattr(response, \"candidates\", None):\n                    for candidate in response.candidates:\n                        if getattr(candidate, \"content\", None) and candidate.content.parts:\n                            for part in candidate.content.parts:\n                                if getattr(part, \"inline_data\", None):\n                                    try:\n                                        generated_image = part.as_image()\n                                    except AttributeError:\n                                        image_bytes_raw = part.inline_data.data\n                                        generated_image = Image.open(io.BytesIO(image_bytes_raw))\n                                    break\n                        if generated_image is not None:\n                            break\n\n                if generated_image is not None:\n                    st.image(generated_image, caption=img_data[\"prompt\"])\n                    buf = io.BytesIO()\n                    generated_image.save(buf, format=\"PNG\")\n                    image_bytes = buf.getvalue()\n                    st.download_button(\n                        label=\"ğŸ’¾ ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\",\n                        data=image_bytes,\n                        file_name=f\"generated_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png\",\n                        mime=\"image/png\",\n                    )\n                    messages.append(\n                        {\"role\": \"model\", \"content\": f\"âœ… ç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {img_data['prompt']}\"}\n                    )\n                    update_current_session_messages(messages)\n                    status.update(label=\"âœ… ç”»åƒç”Ÿæˆå®Œäº†\", state=\"complete\")\n                else:\n                    st.error(\"ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")\n                    status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n\n            except Exception as e:\n                status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n                st.error(f\"ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}\")\n\n# =========================\n# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›\n# =========================\n\nprompt = st.chat_input(\"ä½•ã‹èã„ã¦ãã ã•ã„...\", disabled=stop_generation)\n\nif prompt:\n    if stop_generation:\n        st.error(\"äºˆç®—ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚\")\n    else:\n        # ---- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€è¡¨ç¤º ----\n        with st.chat_message(\"user\"):\n            st.markdown(prompt)\n            if uploaded_files:\n                for uf in uploaded_files:\n                    st.caption(f\"ğŸ“ æ·»ä»˜: {uf.name}\")\n            if youtube_url:\n                st.caption(f\"ğŸ“º YouTube: {youtube_url}\")\n            if pasted_image_bytes:\n                st.caption(\"ğŸ“‹ ç”»åƒãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚Œã¾ã—ãŸ\")\n\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        update_current_session_messages(messages)\n\n        # ---- ãƒ¢ãƒ‡ãƒ«å¿œç­” ----\n        with st.chat_message(\"assistant\"):\n            status_container = st.status(\"æ€è€ƒä¸­...\", expanded=True)\n            try:\n                # ä¼šè©±å±¥æ­´\n                model_history = []\n                for msg in messages[:-1]:\n                    model_history.append(\n                        types.Content(\n                            role=msg[\"role\"],\n                            parts=[types.Part.from_text(text=msg[\"content\"])],\n                        )\n                    )\n\n                # ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³\n                current_parts = [types.Part.from_text(text=prompt)]\n\n                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«\n                for uploaded_file in uploaded_files or []:\n                    try:\n                        mime_type = get_mime_type(uploaded_file.name)\n                        bytes_data = uploaded_file.getvalue()\n                        part = types.Part.from_bytes(data=bytes_data, mime_type=mime_type)\n                        current_parts.append(part)\n                        status_container.write(f\"ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™å®Œäº†: {uploaded_file.name}\")\n                    except Exception as e:\n                        status_container.error(\n                            f\"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {uploaded_file.name} - {e}\"\n                        )\n\n                # è²¼ã‚Šä»˜ã‘ç”»åƒ\n                if pasted_image_bytes:\n                    import base64\n\n                    status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã‚’å‡¦ç†ä¸­...\")\n                    try:\n                        if isinstance(pasted_image_bytes, str):\n                            if pasted_image_bytes.startswith(\"data:\"):\n                                base64_str = pasted_image_bytes.split(\",\", 1)[1]\n                                image_bytes_decoded = base64.b64decode(base64_str)\n                            else:\n                                image_bytes_decoded = base64.b64decode(pasted_image_bytes)\n                        else:\n                            image_bytes_decoded = pasted_image_bytes\n                        part = types.Part.from_bytes(\n                            data=image_bytes_decoded, mime_type=\"image/png\"\n                        )\n                        current_parts.append(part)\n                        status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®æº–å‚™å®Œäº†\")\n                    except Exception as e:\n                        status_container.error(f\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n\n                # YouTube å­—å¹•\n                if youtube_url:\n                    vid_id = extract_youtube_id(youtube_url)\n                    if vid_id:\n                        status_container.write(\"YouTubeã®å­—å¹•ã‚’å–å¾—ä¸­...\")\n                        transcript_text = get_youtube_transcript(vid_id)\n                        current_parts.append(\n                            types.Part.from_text(text=f\"YouTube Transcript:\\n{transcript_text}\")\n                        )\n                    else:\n                        status_container.write(\"ç„¡åŠ¹ãªYouTube URLã§ã™ã€‚\")\n\n                contents_for_model = model_history + [\n                    types.Content(role=\"user\", parts=current_parts)\n                ]\n\n                # ---- Tool / Config ----\n                tools = []\n                final_candidate_count = candidate_count\n                if use_search:\n                    tools.append(types.Tool(google_search=types.GoogleSearch()))\n                    final_candidate_count = 1\n\n                # â˜… System Instruction ã®æ”¹å–„: ãƒ¡ã‚¿ç™ºè¨€ç¦æ­¢ã¨ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªæŒ¯ã‚‹èˆã„ã‚’æŒ‡ç¤º\n                base_system_instruction = (\n                    \"ã‚ãªãŸã¯é«˜åº¦ãªçŸ¥æ€§ã‚’æŒã¤å°‚é–€çš„ãªãƒªã‚µãƒ¼ãƒãƒ»ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\\n\"\n                    \"ä»¥ä¸‹ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’å³å®ˆã—ã¦ãã ã•ã„ï¼š\\n\"\n                    \"1. **ãƒ¡ã‚¿ç™ºè¨€ã®ç¦æ­¢**: ã€Œç§ã¯AIã§ã™ã€ã€Œä¸–ç•Œæœ€é«˜å³°ã®ï½ã¨ã—ã¦ã€ãªã©ã®è‡ªå·±è¨€åŠã‚„å‰ç½®ãã¯ä¸€åˆ‡è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚\\n\"\n                    \"2. **æ„å›³ã®æ±²ã¿å–ã‚Š**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã®èƒŒå¾Œã«ã‚ã‚‹æ„å›³ï¼ˆæ–‡è„ˆã€æš—é»™ã®å‰æï¼‰ã‚’æ¨æ¸¬ã—ã€è¨€è‘‰é€šã‚Šã§ã¯ãªãã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ¬å½“ã«çŸ¥ã‚ŠãŸã„ã“ã¨ã€ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n\"\n                    \"3. **æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”**: çµè«–ã‚’å…ˆã«è¿°ã¹ã€ãã®å¾Œã«è©³ç´°ãªæ ¹æ‹ ã€ã‚·ãƒŠãƒªã‚ªåˆ†æã€ãƒªã‚¹ã‚¯è¦å› ã‚’è«–ç†çš„ã«å±•é–‹ã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"4. **å®¢è¦³æ€§**: äºˆæ¸¬ã‚’è¡Œã†å ´åˆã¯ã€æ–­å®šã‚’é¿ã‘ã€è¤‡æ•°ã®ã‚·ãƒŠãƒªã‚ªï¼ˆæ¥½è¦³ã€æ‚²è¦³ã€ä¸­ç«‹ï¼‰ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"5. **å¼•ç”¨**: æ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸå ´åˆã¯ã€å¿…ãšæƒ…å ±æºã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚\"\n                )\n\n                final_answer = \"\"\n                grounding_metadata = None\n                \n                # =========================\n                # ãƒ¢ãƒ¼ãƒ‰è¨­å®šã®è§£æ\n                # =========================\n                # Î²1é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ä»¥å¤–ã¯ãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œ\n                enable_research = \"Î²1\" not in response_mode\n                enable_meta = \"ãƒ¡ã‚¿\" in response_mode or \"MAX\" in response_mode\n                enable_strict = \"é¬¼è»æ›¹\" in response_mode or \"MAX\" in response_mode\n                enable_grok_x_search = \"grokæ¤œç´¢å¼·åŒ–ç‰ˆ\" in response_mode\n\n                # =========================\n                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (é«˜é€Ÿ / é¬¼è»æ›¹)\n                # =========================\n                if not enable_research:\n                    config = types.GenerateContentConfig(\n                        temperature=0.7,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=base_system_instruction,\n                    )\n                    \n                    status_container.write(\"å›ç­”ç”Ÿæˆä¸­...\")\n                    response = client.models.generate_content(\n                        model=model_id,\n                        contents=contents_for_model,\n                        config=config,\n                    )\n                    \n                    final_answer = extract_text_from_response(response)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®—\n                    if response.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            response.usage_metadata.prompt_token_count,\n                            response.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += response.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += response.usage_metadata.candidates_token_count\n\n                    # é¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ (é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ç‰ˆ)\n                    if enable_strict:\n                        status_container.write(\"ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        reviewer_instruction = base_system_instruction + \"\"\"\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n                        review_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\nåˆç‰ˆå›ç­”:\\n{final_answer}\\n\\nãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\")])]\n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=types.GenerateContentConfig(temperature=0.1, candidate_count=1, system_instruction=reviewer_instruction)\n                        )\n                        final_answer = extract_text_from_response(review_resp)\n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        \n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(model_id, review_resp.usage_metadata.prompt_token_count, review_resp.usage_metadata.candidates_token_count)\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n\n                # =========================\n                # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰\n                # =========================\n                else:\n                    # =========================\n                    # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰: å¤šæ®µéšã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ \n                    # =========================\n                    \n                    # --- Phase 1: ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 1: ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    import datetime as dt\n                    current_year = dt.datetime.now().year\n                    \n                    research_instruction = base_system_instruction + f\"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒªã‚µãƒ¼ãƒå°‚ä»»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚æœ€çµ‚å›ç­”ã¯æ›¸ã‹ãšã€äº‹å®Ÿåé›†ã«é›†ä¸­ã™ã‚‹ã“ã¨ã€‚\n\n**èª¿æŸ»è¦³ç‚¹**:\n- è³ªå•ã«é–¢é€£ã™ã‚‹**æœ€æ–°ã®äº‹å®Ÿãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ»çµ±è¨ˆ**ï¼ˆ**{current_year}å¹´ã®æƒ…å ±ã‚’æœ€å„ªå…ˆ**ï¼‰\n- **ç¾æ™‚ç‚¹ã§å­˜åœ¨ã™ã‚‹å…¨ã¦ã®é¸æŠè‚¢ãƒ»ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¶²ç¾…çš„ã«èª¿æŸ»**ï¼ˆä¾‹: è£½å“æ¯”è¼ƒãªã‚‰ã€æœ€æ–°ç‰ˆã ã‘ã§ãªãç›´è¿‘ã®å…¨ä¸–ä»£ã‚’èª¿æŸ»ï¼‰\n- å…¬å¼æƒ…å ±ã‚„ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã‹ã‚‰ã®å¼•ç”¨\n- é–¢é€£ã™ã‚‹èƒŒæ™¯æƒ…å ±ã‚„æ–‡è„ˆ\n- ç«¶åˆãƒ»ä»£æ›¿æ¡ˆãƒ»æ¯”è¼ƒå¯¾è±¡ã®**å®Œå…¨ãªãƒªã‚¹ãƒˆ**\n- ãƒªã‚¹ã‚¯ãƒ»åˆ¶ç´„ãƒ»æ³¨æ„ç‚¹ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n- å‚è€ƒã«ã—ãŸä¸»è¦ãªæƒ…å ±æºã®URL\n\n**é‡è¦**: \n- çµè«–ã‚„æ¨å¥¨ã¯æ›¸ã‹ãšã€å¾Œå·¥ç¨‹ãŒåˆ¤æ–­ã§ãã‚‹èª¿æŸ»ãƒ¡ãƒ¢ã«é›†ä¸­ã™ã‚‹ã“ã¨\n- **å¿…ãšæ¤œç´¢æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã€æœ€æ–°ã®æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã“ã¨**\n- **æ¤œç´¢çµæœã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æ—¥ä»˜ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒ»ãƒ¢ãƒ‡ãƒ«åã‚’å„ªå…ˆçš„ã«è¨˜è¼‰ã™ã‚‹ã“ã¨**\n- **æ¯”è¼ƒå¯¾è±¡ã¨ãªã‚‹é¸æŠè‚¢ã‚’è¦‹è½ã¨ã•ãªã„ã‚ˆã†ã€è¤‡æ•°ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è©¦ã™ã“ã¨**ï¼ˆä¾‹: ã€ŒiPhone æœ€æ–°ãƒ¢ãƒ‡ãƒ« {current_year}ã€ã€ŒiPhone {current_year}å¹´ç™ºå£²ã€ãªã©ï¼‰\n- **ã€Œã“ã‚Œã‚ˆã‚Šæ–°ã—ã„ãƒ¢ãƒ‡ãƒ«/ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯å­˜åœ¨ã—ãªã„ã‹ï¼Ÿã€ã‚’å¸¸ã«ç¢ºèªã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ï¼ˆ{current_year-1}å¹´ä»¥å‰ãªã©ï¼‰ã—ã‹è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãã®æ—¨ã‚’æ˜è¨˜ã™ã‚‹ã“ã¨\n\"\"\"\n\n                    # éå»ã®é–¢é€£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—\n                    past_context = get_relevant_context(prompt, st.session_state.sessions, st.session_state.current_session_id)\n                    \n                    # ãƒªã‚µãƒ¼ãƒç”¨ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ§‹ç¯‰\n                    import datetime as dt\n                    current_date = dt.datetime.now().strftime(\"%Yå¹´%mæœˆ%dæ—¥\")\n                    research_parts = [types.Part(text=(\n                        f\"é‡è¦: ä»Šæ—¥ã¯{current_date}ã§ã™ã€‚ã“ã®æ—¥ä»˜ã‚ˆã‚Šæ–°ã—ã„æƒ…å ±ã‚’å„ªå…ˆã—ã¦ãã ã•ã„ã€‚\\n\\n\"\n                        f\"è³ªå•: {prompt}\"\n                    ))]\n                    \n                    if past_context:\n                        research_parts.insert(0, types.Part(text=\"ä»¥ä¸‹ã¯éå»ã®é–¢é€£ãƒãƒ£ãƒƒãƒˆã‹ã‚‰æŠ½å‡ºã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã™ï¼š\\n\\n\" + past_context))\n                    \n                    research_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=research_parts)\n                    ]\n                    \n                    research_config = types.GenerateContentConfig(\n                        temperature=0.4,  # æœ€æ–°æƒ…å ±ã‚’æŸ”è»Ÿã«æ¡ç”¨ã™ã‚‹ãŸã‚0.2â†’0.4ã«ä¸Šæ˜‡\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=research_instruction,\n                    )\n                    \n                    research_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=research_contents,\n                        config=research_config,\n                    )\n                    \n                    research_text = extract_text_from_response(research_resp)\n                    \n                    # ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºã®ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ±ã‚’ä¿å­˜\n                    if research_resp.candidates and research_resp.candidates[0].grounding_metadata:\n                        grounding_metadata = research_resp.candidates[0].grounding_metadata\n                    \n                    status_container.write(\"âœ“ ãƒªã‚µãƒ¼ãƒå®Œäº†\")\n                    with status_container.expander(\"åé›†ã—ãŸèª¿æŸ»ãƒ¡ãƒ¢\", expanded=False):\n                        st.markdown(research_text)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1)\n                    if research_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            research_resp.usage_metadata.prompt_token_count,\n                            research_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += research_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += research_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 1.5: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    questions_text = \"\"\n                    if enable_meta:\n                        status_container.write(\"Phase 1.5: ãƒ¡ã‚¿è³ªå•ç”Ÿæˆä¸­...\")\n                        \n                        question_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ç›®çš„**: \nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•ã¨èª¿æŸ»ãƒ¡ãƒ¢ã‚’è¸ã¾ãˆã¦ã€ã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±ãç†è§£ã™ã‚‹ãŸã‚ã®ã€Œé‹­ã„ã‚µãƒ–è³ªå•ã€ã‚’ä½œæˆã™ã‚‹ã“ã¨ã€‚\n\n**ãƒ«ãƒ¼ãƒ«**:\n- æœ€å¤§5å€‹ã¾ã§\n- å„è³ªå•ã¯1-2è¡Œã§å…·ä½“çš„ã‹ã¤é‹­ã\n- ä»¥ä¸‹ã®è¦³ç‚¹ã‚’æ„è­˜:\n  1. å‰æãŒå´©ã‚Œã‚‹å¯èƒ½æ€§ã¯ã©ã“ã‹ï¼Ÿ\n  2. å¼·æ°—/å¼±æ°—ã‚·ãƒŠãƒªã‚ªã®åˆ†å²ç‚¹ã¯ä½•ã‹ï¼Ÿ\n  3. ç«¶åˆãƒ»æŠ€è¡“ãƒ»è¦åˆ¶ã®ä¸ç¢ºå®Ÿæ€§ã¯ï¼Ÿ\n  4. ã€Œäºˆæ¸¬ãŒå¤–ã‚Œã‚‹ã¨ã—ãŸã‚‰ã©ã‚“ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ï¼Ÿã€\n\n**å‡ºåŠ›**: ç®‡æ¡æ›¸ãï¼ˆQ1, Q2...ï¼‰ã®ã¿\n\"\"\"\n\n                        question_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•:\\n{prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\nã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±æ˜ã‚Šã™ã‚‹ãŸã‚ã®é‡è¦ãªã‚µãƒ–è³ªå•ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\")])]\n                        \n                        question_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=question_contents,\n                            config=types.GenerateContentConfig(\n                                temperature=0.4,\n                                candidate_count=1,\n                                system_instruction=question_instruction,\n                            )\n                        )\n                        \n                        questions_text = extract_text_from_response(question_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¡ã‚¿è³ªå•ç”Ÿæˆå®Œäº†\")\n                        with status_container.expander(\"ç”Ÿæˆã•ã‚ŒãŸãƒ¡ã‚¿è³ªå•\", expanded=False):\n                            st.markdown(questions_text)\n                        \n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += question_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += question_resp.usage_metadata.candidates_token_count\n\n                    # å¤šå±¤+puterãƒ¢ãƒ¼ãƒ‰ã®é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã‹ãƒã‚§ãƒƒã‚¯\n                    is_puter_onigunsou = (\n                        mode_category == \"Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter)\" and\n                        response_mode == \"1. ç†Ÿè€ƒ + é¬¼è»æ›¹\"\n                    )\n\n                    # --- Phase 1.5b: Grok ç‹¬ç«‹æ€è€ƒ (å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    # --- Phase 1.5b: Grok ç‹¬ç«‹æ€è€ƒ (å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    grok_thought = \"\"\n                    grok_status = \"skipped\"\n                    if enable_meta and OPENROUTER_API_KEY:\n                        status_container.write(\"Phase 1.5b: Grok ç‹¬ç«‹æ€è€ƒä¸­...\")\n                        try:\n                            grok_thought = think_with_grok(prompt, research_text, enable_x_search=enable_grok_x_search)\n                            if grok_thought:\n                                grok_status = \"success\"\n                                status_container.write(\"âœ“ Grok 4.1 Fast Free ç‹¬ç«‹æ€è€ƒå®Œäº†\")\n                                with status_container.expander(\"Grokã®ç‹¬ç«‹å›ç­”æ¡ˆ\", expanded=False):\n                                    st.markdown(grok_thought)\n                            else:\n                                grok_status = \"empty\"\n                        except Exception as e:\n                            grok_status = \"error\"\n                            status_container.write(f\"âš  Grokæ€è€ƒã‚¨ãƒ©ãƒ¼: {e}\")\n\n                    # --- Phase 1.5c: Claude Opus 4.5 ç‹¬ç«‹æ€è€ƒ (å¤šå±¤+puterã®é¬¼è»æ›¹ã®ã¿) ---\n                    # --- Phase 1.5c: Claude Opus 4.5 ç‹¬ç«‹æ€è€ƒ (å¤šå±¤+puterã®é¬¼è»æ›¹ã®ã¿) ---\n                    claude_thought = \"\"\n                    claude_status = \"skipped\"\n                    if is_puter_onigunsou and PUTER_USERNAME and PUTER_PASSWORD:\n                        status_container.write(\"Phase 1.5c: Claude Opus 4.5 ç‹¬ç«‹æ€è€ƒä¸­...\")\n                        try:\n                            claude_thought = call_claude_opus_via_puter(\n                                user_question=prompt,\n                                research_text=research_text,\n                                system_prompt=(\n                                    \"ã‚ãªãŸã¯ Claude Opus 4.5 ã§ã™ã€‚\"\n                                    \"Gemini ãŒé›†ã‚ãŸèª¿æŸ»ãƒ¡ãƒ¢ã‚’å‚è€ƒã«ã—ã¤ã¤ã‚‚ã€\"\n                                    \"è‡ªåˆ†ã®è¦–ç‚¹ã§ç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆãƒ»æ°—ã¥ãã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\"\n                                    \"Gemini ã®æ„è¦‹ã«åˆã‚ã›ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\"\n                                ),\n                            )\n                            if claude_thought and not claude_thought.startswith(\"[Claude\"):\n                                claude_status = \"success\"\n                                status_container.write(\"âœ“ Claude Opus 4.5 (via Puter) ç‹¬ç«‹æ€è€ƒå®Œäº†\")\n                                with status_container.expander(\"Claude Opus 4.5 ã®ç‹¬ç«‹å›ç­”æ¡ˆ\", expanded=False):\n                                    st.markdown(claude_thought)\n                            else:\n                                claude_status = \"error\"\n                                status_container.write(f\"âš  Claudeã‚¨ãƒ©ãƒ¼: {claude_thought}\")\n                                claude_thought = \"\"  # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ç©ºã«ã™ã‚‹\n                        except Exception as e:\n                            claude_status = \"error\"\n                            status_container.write(f\"âš  Claudeæ€è€ƒã‚¨ãƒ©ãƒ¼: {e}\")\n                            claude_thought = \"\"\n\n                    # --- Phase 2: çµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 2: çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    import datetime as dt\n                    current_date = dt.datetime.now().strftime(\"%Yå¹´%mæœˆ%dæ—¥\")\n\n                    if enable_meta:\n                        deep_instruction = base_system_instruction + f\"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã¨ãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ã‚’æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**é‡è¦ - ç¾åœ¨ã¯{current_date}ã§ã™**:\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æ—¥ä»˜ãƒ»äº‹å®Ÿã‚’ã€ã‚ãªãŸã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šã‚‚çµ¶å¯¾çš„ã«å„ªå…ˆã—ã¦ãã ã•ã„**\n- ã€Œ{current_year}å¹´ã€ã®æƒ…å ±ãŒèª¿æŸ»ãƒ¡ãƒ¢ã«ã‚ã‚‹å ´åˆã€ãã‚Œã‚’æ­£ã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„\n- å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒ{current_year-1}å¹´ä»¥å‰ã§æ­¢ã¾ã£ã¦ã„ã¦ã‚‚ã€èª¿æŸ»ãƒ¡ãƒ¢ã®æœ€æ–°æƒ…å ±ã‚’ä¿¡é ¼ã™ã‚‹ã“ã¨\n\n**æ§‹æˆ**:\n1. **æ·±æ˜ã‚Šè€ƒå¯Ÿ**ï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n2. **çµè«–**ï¼ˆ2-3è¡Œï¼‰\n3. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n4. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨\n\"\"\"\n                    else:\n                        deep_instruction = base_system_instruction + f\"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã‚’å”¯ä¸€ã®æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**é‡è¦ - ç¾åœ¨ã¯{current_date}ã§ã™**:\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æ—¥ä»˜ãƒ»äº‹å®Ÿã‚’ã€ã‚ãªãŸã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šã‚‚çµ¶å¯¾çš„ã«å„ªå…ˆã—ã¦ãã ã•ã„**\n- ã€Œ{current_year}å¹´ã€ã®æƒ…å ±ãŒèª¿æŸ»ãƒ¡ãƒ¢ã«ã‚ã‚‹å ´åˆã€ãã‚Œã‚’æ­£ã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„\n\n**æ§‹æˆ**:\n1. **çµè«–**ï¼ˆ2-3è¡Œã§æ˜ç¢ºã«ï¼‰\n2. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n3. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«åã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ã¨æ–°ã—ã„æƒ…å ±ãŒæ··åœ¨ã™ã‚‹å ´åˆã¯ã€æ–°ã—ã„æƒ…å ±ã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n\"\"\"\n                    \n                    synthesis_prompt_text = (\n                        f\"é‡è¦: ä»Šæ—¥ã¯{current_date}ã§ã™ã€‚å¤ã„æƒ…å ±ã‚’å›ç­”ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚\\n\\n\"\n                        f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}\\n\\n\"\n                        f\"==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                    )\n                    \n                    if enable_meta and questions_text:\n                        synthesis_prompt_text += f\"==== ãƒ¡ã‚¿è³ªå•ä¸€è¦§ ====\\n{questions_text}\\n==== ãƒ¡ã‚¿è³ªå•ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if enable_meta and grok_thought:\n                        synthesis_prompt_text += f\"==== åˆ¥è¦–ç‚¹ã‹ã‚‰ã®å›ç­”æ¡ˆ (Grok) ====\\n{grok_thought}\\n==== åˆ¥è¦–ç‚¹ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if is_puter_onigunsou and claude_thought:\n                        synthesis_prompt_text += f\"==== åˆ¥è¦–ç‚¹ã‹ã‚‰ã®å›ç­”æ¡ˆ (Claude Opus 4.5 via Puter) ====\\n{claude_thought}\\n==== Claudeåˆ¥è¦–ç‚¹ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    # çµ±åˆæŒ‡ç¤º\n                    if enable_meta and (grok_thought or claude_thought):\n                        synthesis_prompt_text += \"æŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n2. Grok\"\n                        if is_puter_onigunsou and claude_thought:\n                            synthesis_prompt_text += \" / Claude\"\n                        synthesis_prompt_text += \" ã®å›ç­”æ¡ˆã‚‚å‚è€ƒã«ã—ã¤ã¤ï¼ˆãŸã ã—ç›²ä¿¡ã›ãšï¼‰ã€ç‹¬è‡ªã®è¦–ç‚¹ã§çµ±åˆã—ã¦ãã ã•ã„ã€‚\\n3. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»åˆ†æãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    elif enable_meta and questions_text:\n                        synthesis_prompt_text += \"æŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n2. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»åˆ†æãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    else:\n                        synthesis_prompt_text += \"ä¸Šè¨˜ãƒ¡ãƒ¢ã‚’æ ¹æ‹ ã«ã€æœ€çµ‚å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å¿…ãšä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚**\"\n\n                    synthesis_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=[\n                            types.Part(text=synthesis_prompt_text)\n                        ])\n                    ]\n                    \n                    synthesis_config = types.GenerateContentConfig(\n                        temperature=0.3,\n                        candidate_count=1,\n                        tools=[],  # çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºã§ã¯æ¤œç´¢OFF\n                        system_instruction=deep_instruction,\n                    )\n                    \n                    synthesis_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=synthesis_contents,\n                        config=synthesis_config,\n                    )\n                    \n                    draft_answer = extract_text_from_response(synthesis_resp)\n                    \n                    status_container.write(\"âœ“ çµ±åˆå®Œäº†\")\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 2)\n                    if synthesis_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            synthesis_resp.usage_metadata.prompt_token_count,\n                            synthesis_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += synthesis_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += synthesis_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    if enable_strict:\n                        status_container.write(\"Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        \n\n                        reviewer_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™ã€‚ãŸã ã—ã€**èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’å„ªå…ˆã—ã€æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã™ã‚‹ã“ã¨**ã€‚\n\n**ãƒ¬ãƒ“ãƒ¥ãƒ¼è¦³ç‚¹**:\n- äº‹å®Ÿã¨æ¨æ¸¬ã‚’æ˜ç¢ºã«åˆ†ã‘ã‚‹\n- éåº¦ã«è‡ªä¿¡ã®ã‚ã‚‹æ–­å®šã‚’å¼±ã‚ã‚‹\n- æ•°å­—ã‚„å›ºæœ‰åè©ãŒèª¿æŸ»ãƒ¡ãƒ¢ã¨çŸ›ç›¾ã—ã¦ã„ãªã„ã‹ç¢ºèª\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ãƒ¢ãƒ‡ãƒ«ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ãŒæ­£ã—ãä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª**\n- **å¤ã„æƒ…å ±ã§ä¸Šæ›¸ãã—ã¦ã„ãªã„ã‹ç¢ºèª**\n- è¦‹è½ã¨ã—ã¦ã„ã‚‹é‡è¦ãªãƒªã‚¹ã‚¯ãƒ»ã‚·ãƒŠãƒªã‚ªãŒã‚ã‚Œã°è¿½åŠ \n\n**é‡è¦**: \n- èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ãŒæœ€æ–°ã§ã‚ã‚‹å ´åˆã€ãã‚Œã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n- ã‚ãªãŸã®çŸ¥è­˜ãŒå¤ã„å ´åˆã¯ã€èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’ä¿¡é ¼ã™ã‚‹ã“ã¨\n\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n\n                        review_contents = [\n                            types.Content(role=\"user\", parts=[\n                                types.Part.from_text(\n                                    text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\n\"\n                                    f\"==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                                    f\"åˆç‰ˆå›ç­”:\\n{draft_answer}\\n\\n\"\n                                    \"ä¸Šè¨˜ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚**\"\n                                )\n                            ])\n                        ]\n                        \n                        review_config = types.GenerateContentConfig(\n                            temperature=0.1,\n                            candidate_count=1,\n                            system_instruction=reviewer_instruction,\n                            thinking_config=types.ThinkingConfig(\n                                thinking_level=types.ThinkingLevel.HIGH\n                            ),\n                        )\n                        \n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=review_config,\n                        )\n                        \n                        final_answer = extract_text_from_response(review_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        \n                        # --- Phase 3b: Groké¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ (å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ + é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰å…¨èˆ¬) ---\n                        # å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã§ã€ã‹ã¤é¬¼è»æ›¹ç³»ã®ãƒ¢ãƒ¼ãƒ‰ï¼ˆé¬¼è»æ›¹ã€ãƒ¡ã‚¿æ€è€ƒã€æœ¬æ°—MAXï¼‰ã§ç™ºå‹•\n                        use_grok_reviewer = (mode_category == \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\" and enable_strict)\n                        \n                        if use_grok_reviewer and OPENROUTER_API_KEY:\n                            status_container.write(\"Phase 3b: Grok 4.1 Fast ã§æœ€çµ‚ãƒã‚§ãƒƒã‚¯ä¸­...\")\n                            try:\n                                grok_answer = review_with_grok(prompt, final_answer, research_text)\n                                # Grokä½¿ç”¨æ™‚ã¯ã€ãƒ¢ãƒ‡ãƒ«åã‚’æ˜ç¤ºã—ã€2æ®µæ§‹æˆã§è¡¨ç¤º\n                                final_answer = (\n                                    f\"**ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_id} (Deep Thinking / High Reasoning)**\\n\"\n                                    f\"**ãƒ¬ãƒ“ãƒ¥ã‚¢: Grok 4.1 Fast (free)**\\n\"\n                                    f\"**ãƒ¢ãƒ¼ãƒ‰: {response_mode}**\\n\\n\"\n                                    \"---\\n\\n\"\n                                    \"## âœ… æœ€çµ‚å›ç­”ï¼ˆGeminiçµ±åˆç‰ˆï¼‰\\n\\n\"\n                                    f\"{final_answer}\\n\\n\"\n                                    \"---\\n\\n\"\n                                    \"## ğŸ” Grok ã«ã‚ˆã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼\\n\\n\"\n                                    f\"{grok_answer}\"\n                                )\n                                status_container.write(\"âœ“ Grokæœ€çµ‚ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                            except Exception as e:\n                                status_container.write(f\"âš  Grokãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}\")\n                        else:\n                            # Geminiã®ã¿ã®å ´åˆã‚‚ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤ºï¼ˆå¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆï¼‰\n                            if mode_category == \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\":\n                                final_answer = (\n                                    f\"**ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_id} (Deep Thinking / High Reasoning)**\\n\"\n                                    f\"**ãƒ¢ãƒ¼ãƒ‰: {response_mode}**\\n\\n---\\n\\n{final_answer}\"\n                                )\n                        \n                        # --- ãƒ¡ã‚¿æ€è€ƒãƒ¢ãƒ¼ãƒ‰: çµè«–ã‚’å…ˆå‡ºã—ã™ã‚‹ ---\n                        if \"ãƒ¡ã‚¿æ€è€ƒ\" in response_mode:\n                            # çµè«–éƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆç°¡æ˜“çš„ãªå®Ÿè£…ï¼‰\n                            # \"çµè«–\"ã‚„\"ã¾ã¨ã‚\"ãªã©ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¢ã—ã¦å…ˆé ­ã«ç§»å‹•\n                            lines = final_answer.split('\\n')\n                            conclusion_start = -1\n                            for i, line in enumerate(lines):\n                                if any(keyword in line for keyword in ['## çµè«–', '## ã¾ã¨ã‚', '**çµè«–**', '**ã¾ã¨ã‚**']):\n                                    conclusion_start = i\n                                    break\n                            \n                            if conclusion_start != -1:\n                                # çµè«–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¦‹ã¤ã‘ãŸå ´åˆã€ãã‚Œã‚’å…ˆé ­ã«ç§»å‹•\n                                conclusion_section = []\n                                other_content = lines[:conclusion_start]\n                                \n                                # çµè«–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®çµ‚ã‚ã‚Šã‚’è¦‹ã¤ã‘ã‚‹ï¼ˆæ¬¡ã®##ã¾ã§ or æ–‡æœ«ï¼‰\n                                conclusion_end = len(lines)\n                                for i in range(conclusion_start + 1, len(lines)):\n                                    if lines[i].startswith('## ') and i != conclusion_start:\n                                        conclusion_end = i\n                                        break\n                                \n                                conclusion_section = lines[conclusion_start:conclusion_end]\n                                remaining_content = lines[conclusion_end:]\n                                \n                                # å†æ§‹æˆ: ãƒ¢ãƒ‡ãƒ«å â†’ çµè«– â†’ ãã®ä»–ã®è©³ç´°\n                                # ãƒ¢ãƒ‡ãƒ«åéƒ¨åˆ†ã‚’ä¿æŒ\n                                model_line = \"\"\n                                if lines[0].startswith(\"**ğŸ¤–\"):\n                                    model_line = lines[0]\n                                    other_content = lines[1:conclusion_start]\n                                \n                                final_answer = '\\n'.join([\n                                    model_line,\n                                    \"\",\n                                    \"---\",\n                                    \"\",\n                                    \"## ğŸ“Œ çµè«–ï¼ˆå…ˆå‡ºã—ï¼‰\",\n                                    *conclusion_section[1:],  # å…ƒã®è¦‹å‡ºã—ã‚’é™¤ã\n                                    \"\",\n                                    \"---\",\n                                    \"\",\n                                    \"## ğŸ“ è©³ç´°\",\n                                    *other_content,\n                                    *remaining_content\n                                ]).strip()\n                        \n                        with status_container.expander(\"åˆç‰ˆã¨ã®æ¯”è¼ƒ\", expanded=False):\n                            st.markdown(\"**åˆç‰ˆ:**\")\n                            st.markdown(draft_answer[:500] + \"...\" if len(draft_answer) > 500 else draft_answer)\n                            st.markdown(\"**ä¿®æ­£ç‰ˆ:**\")\n                            st.markdown(final_answer[:500] + \"...\" if len(final_answer) > 500 else final_answer)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 3)\n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                review_resp.usage_metadata.prompt_token_count,\n                                review_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n                    else:\n                        final_answer = draft_answer\n\n                save_usage(usage_stats)\n                status_container.update(label=\"å®Œäº†ï¼\", state=\"complete\", expanded=False)\n\n                # ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤º\n                models_used = [f\"Gemini: {model_id}\"]\n                \n                # Grok Status\n                if enable_meta:\n                    if grok_status == \"success\":\n                        models_used.append(\"Grok: 4.1-fast-free (OK)\")\n                    elif grok_status == \"error\":\n                        models_used.append(\"Grok: 4.1-fast-free (Error)\")\n                    elif grok_status == \"empty\":\n                        models_used.append(\"Grok: 4.1-fast-free (Empty)\")\n                \n                # Claude Status\n                if is_puter_onigunsou:\n                    if claude_status == \"success\":\n                        models_used.append(\"Claude: Opus 4.5 (via Puter) (OK)\")\n                    elif claude_status == \"error\":\n                        models_used.append(\"Claude: Opus 4.5 (via Puter) (Error)\")\n                \n                st.caption(f\"ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {' + '.join(models_used)}\")\n                st.markdown(final_answer)\n\n                # ---- ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ± ----\n                if grounding_metadata:\n                    st.markdown(\"---\")\n                    with st.expander(\"ğŸ“š æƒ…å ±æºã¨å¼•ç”¨\", expanded=False):\n                        if grounding_metadata.grounding_chunks:\n                            st.markdown(\"**æ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:**\")\n                            unique_sources = {}\n                            import urllib.parse\n\n                            for chunk in grounding_metadata.grounding_chunks:\n                                if getattr(chunk, \"web\", None):\n                                    uri = getattr(chunk.web, \"uri\", None)\n                                    title = getattr(chunk.web, \"title\", \"æƒ…å ±æº\")\n                                    if uri and uri not in unique_sources:\n                                        parsed = urllib.parse.urlparse(uri)\n                                        domain = parsed.netloc.replace(\"www.\", \"\")\n                                        unique_sources[uri] = {\n                                            \"title\": title,\n                                            \"domain\": domain,\n                                        }\n                            for i, (uri, info) in enumerate(unique_sources.items(), 1):\n                                st.markdown(f\"{i}. **[{info['title']}]({uri})**\")\n                                st.caption(f\"   å‡ºå…¸: {info['domain']}\")\n\n                messages.append({\"role\": \"model\", \"content\": final_answer})\n                update_current_session_messages(messages)\n\n            except Exception as e:\n                status_container.update(label=\"Error\", state=\"error\")\n                err_text = str(e)\n                if \"RESOURCE_EXHAUSTED\" in err_text or \"429\" in err_text:\n                    st.error(\n                        \"âš ï¸ Vertex AI / Gemini ã®ã‚¯ã‚©ãƒ¼ã‚¿ã«é”ã—ã¾ã—ãŸã€‚\\n\\n\"\n                        \"ãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ / æ—¥æ¬¡åˆ¶é™ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\\n\"\n                        \"ãƒ»ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                        \"ãƒ»Google Cloud Console ã®ã€ŒVertex AI â†’ ä½¿ç”¨çŠ¶æ³ã€ã‹ã‚‰ã‚¯ã‚©ãƒ¼ã‚¿çŠ¶æ³ã‚’ç¢ºèªã§ãã¾ã™ã€‚\"\n                    )\n                elif \"NOT_FOUND\" in err_text and \"Publisher Model\" in err_text:\n                    st.error(\n                        \"âš ï¸ æŒ‡å®šã—ãŸãƒ¢ãƒ‡ãƒ«ãŒã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ / ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\\n\"\n                        \"ãƒ»ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ¢ãƒ‡ãƒ«IDã‚’ã€2.5ç³» ã¾ãŸã¯ 3 Pro ã«å¤‰æ›´ã—ã¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                    )\n                else:\n                    st.error(f\"An error occurred: {e}\")\n"
                },
                {
                    "role": "model",
                    "content": "**ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: gemini-3-pro-preview (Deep Thinking)**\n**ãƒ¢ãƒ¼ãƒ‰: 1. ç†Ÿè€ƒ + é¬¼è»æ›¹**\n\n---\n\n## ğŸ“Œ çµè«–ï¼ˆå…ˆå‡ºã—ï¼‰\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€Œç†Ÿè€ƒ + é¬¼è»æ›¹ã§claudeã¯ã¤ã‹ãˆã‚‹ã‹ã€ã«å¯¾ã—ã€æä¾›ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã¨2025å¹´12æœˆæ™‚ç‚¹ã®æœ€æ–°æƒ…å ±ã‚’åˆ†æã—ãŸçµæœã€**åˆ©ç”¨å¯èƒ½ï¼ˆã‚³ãƒ¼ãƒ‰ä¸Šã«æ­£ã—ãå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ï¼‰** ã§ã™ã€‚\n\nãŸã ã—ã€å˜ã«ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã™ã‚‹ã ã‘ã§ãªãã€**Puter.comã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼åãƒ»ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ï¼‰ãŒç’°å¢ƒå¤‰æ•°ã¨ã—ã¦æ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨**ãŒçµ¶å¯¾æ¡ä»¶ã¨ãªã‚Šã¾ã™ã€‚\n\n---\n\n## ğŸ“ è©³ç´°åˆ†æ\n\n### 1. å®Ÿè£…ãƒ­ã‚¸ãƒƒã‚¯ã®ç¢ºèª\nã‚³ãƒ¼ãƒ‰å†…ã®ä»¥ä¸‹ã®ç®‡æ‰€ã«ã‚ˆã‚Šã€æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ¼ãƒ‰ã§ã®ã¿ Claude ãŒå‘¼ã³å‡ºã•ã‚Œã‚‹ãƒ­ã‚¸ãƒƒã‚¯ãŒç¢ºç«‹ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\n*   **ãƒˆãƒªã‚¬ãƒ¼æ¡ä»¶**:\n    ```python\n    is_puter_onigunsou = (\n        mode_category == \"Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter)\" and\n        response_mode == \"1. ç†Ÿè€ƒ + é¬¼è»æ›¹\"\n    )\n    ```\n*   **å®Ÿè¡Œãƒ–ãƒ­ãƒƒã‚¯ (Phase 1.5c)**:\n    `is_puter_onigunsou` ãŒ `True` ã‹ã¤èªè¨¼æƒ…å ±ãŒå­˜åœ¨ã™ã‚‹å ´åˆã«ã®ã¿ã€`call_claude_opus_via_puter` é–¢æ•°ãŒå®Ÿè¡Œã•ã‚Œã¾ã™ã€‚\n\n### 2. ãƒ¢ãƒ‡ãƒ«ã€ŒClaude Opus 4.5ã€ã®æœ‰åŠ¹æ€§\n*   **æœ€æ–°çŠ¶æ³**: èª¿æŸ»ãƒ¡ãƒ¢ã«ã‚ˆã‚‹ã¨ã€Anthropicç¤¾ã¯ **2025å¹´11æœˆ24æ—¥** ã« `Claude Opus 4.5` ã‚’ãƒªãƒªãƒ¼ã‚¹æ¸ˆã¿ã§ã™ã€‚\n*   **ã‚³ãƒ¼ãƒ‰ã¨ã®æ•´åˆæ€§**: ã‚³ãƒ¼ãƒ‰å†…ã§æŒ‡å®šã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ID `\"claude-opus-4-5\"` ã¯ã€ã“ã®æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã«å¯¾å¿œã—ã¦ãŠã‚Šã€æ™‚ç³»åˆ—çš„ãªçŸ›ç›¾ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚Puter.comç­‰ã®APIãƒ—ãƒ­ãƒã‚¤ãƒ€ã‚‚ã€ä¸»è¦ãƒ¢ãƒ‡ãƒ«ã®ãƒªãƒªãƒ¼ã‚¹ç›´å¾Œã«å¯¾å¿œã™ã‚‹å‚¾å‘ãŒã‚ã‚‹ãŸã‚ã€åˆ©ç”¨ã§ãã‚‹å¯èƒ½æ€§ã¯æ¥µã‚ã¦é«˜ã„ã§ã™ã€‚\n\n### 3. å¿…é ˆã¨ãªã‚‹å‹•ä½œæ¡ä»¶\nã‚³ãƒ¼ãƒ‰ãŒå‹•ããŸã‚ã®å‰ææ¡ä»¶ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚ã“ã‚Œã‚‰ãŒæº€ãŸã•ã‚Œã¦ã„ãªã„å ´åˆã€ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ã‚‚Claudeã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚\n\n1.  **èªè¨¼æƒ…å ±ã®ç’°å¢ƒå¤‰æ•°è¨­å®š**:\n    *   `PUTER_USERNAME`\n    *   `PUTER_PASSWORD`\n    *   ã“ã‚Œã‚‰ãŒ `secrets.toml` ã¾ãŸã¯ `.env` ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n2.  **ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**:\n    *   `putergenai` (Puter SDK)\n    *   `nest_asyncio` (Streamlitå†…ã§ã®éåŒæœŸå‡¦ç†ç”¨)\n\n## âš ï¸ ãƒªã‚¹ã‚¯ã¨ä¸ç¢ºå®Ÿæ€§\n\n*   **ãƒ¢ãƒ‡ãƒ«IDã®æ­£ç¢ºæ€§**: ã‚³ãƒ¼ãƒ‰ã§ã¯ `\"claude-opus-4-5\"` ã¨ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã™ãŒã€Puterå´ã®APIä»•æ§˜å¤‰æ›´ã«ã‚ˆã‚Šã€IDãŒ `anthropic/claude-opus-4.5` ãªã©ç•°ãªã‚‹å½¢å¼ã§ã‚ã‚‹å ´åˆã€ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆç¾çŠ¶ã¯SDKãŒæŸ”è»Ÿã«å¯¾å¿œã™ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã§ã™ãŒã€ç•™æ„ãŒå¿…è¦ã§ã™ï¼‰ã€‚\n*   **APIã®å®‰å®šæ€§**: ãƒªãƒªãƒ¼ã‚¹ï¼ˆ2025/11/24ï¼‰ã‹ã‚‰æ—¥ãŒæµ…ã„ãŸã‚ã€ãƒ—ãƒ­ãƒã‚¤ãƒ€å´ã§ã®æä¾›ãŒä¸å®‰å®šãªå ´åˆãŒã‚ã‚Šã¾ã™ã€‚ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚³ãƒ¼ãƒ‰å†…ã® `try-except` ãƒ–ãƒ­ãƒƒã‚¯ã«ã‚ˆã‚Šã€Claudeã®å›ç­”ãªã—ã§å‡¦ç†ãŒç¶šè¡Œã•ã‚Œã‚‹è¨­è¨ˆã«ãªã£ã¦ã„ã¾ã™ã€‚"
                }
            ]
        },
        {
            "id": "f8451d69-7eea-4b3b-96b9-bb4471887a2f",
            "title": "ä»¥ä¸‹ã®Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+pute...",
            "timestamp": "2025-12-01T23:56:24.026302",
            "messages": [
                {
                    "role": "user",
                    "content": "ä»¥ä¸‹ã®Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter) â†’ 1. ç†Ÿè€ƒ + é¬¼è»æ›¹ã§claudeã¯ã†ã”ãã‹ï¼Ÿ\n\nimport os\nimport uuid\nimport datetime\nimport streamlit as st\nfrom dotenv import load_dotenv\nfrom google import genai\nfrom google.genai import types\nfrom PIL import Image\nimport io\nfrom logic import (\n    USAGE_FILE, SESSIONS_FILE, MAX_BUDGET_USD, PRICING,\n    VERTEX_PROJECT, VERTEX_LOCATION,\n    load_usage, save_usage, calculate_cost, get_mime_type,\n    extract_youtube_id, get_youtube_transcript, get_relevant_context,\n    extract_text_from_response, load_sessions, save_sessions, get_client\n)\n\ntry:\n    from st_img_pastebutton import paste\n    import_error_msg = None\nexcept ImportError as e:\n    paste = None\n    import_error_msg = str(e)\n\n# =========================\n# ç’°å¢ƒå¤‰æ•° & å®šæ•°\n# =========================\n\nload_dotenv()\n\n\n\nst.set_page_config(page_title=\"Gemini 3 Web Studio\", layout=\"wide\")\n\n# ğŸ” ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ­ãƒƒã‚¯ (198501) + URLãƒˆãƒ¼ã‚¯ãƒ³æ°¸ç¶šåŒ–\nSECRET_TOKEN = \"access_granted_198501\"\n\n# 1. URLãƒˆãƒ¼ã‚¯ãƒ³ãƒã‚§ãƒƒã‚¯\nquery_params = st.query_params\nurl_token = query_params.get(\"auth\", None)\n\nif url_token == SECRET_TOKEN:\n    st.session_state.authenticated = True\nelif \"authenticated\" not in st.session_state:\n    st.session_state.authenticated = False\n\n# 2. æœªèªè¨¼ãªã‚‰ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ç”»é¢\nif not st.session_state.authenticated:\n    st.title(\"Gemini 3 Studio\")\n    st.write(\"ã“ã®ã‚¢ãƒ—ãƒªã‚’åˆ©ç”¨ã™ã‚‹ã«ã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒå¿…è¦ã§ã™ã€‚\")\n\n    password = st.text_input(\"ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰\", type=\"password\")\n\n    if st.button(\"ãƒ­ã‚°ã‚¤ãƒ³\"):\n        if password == \"198501\":\n            st.session_state.authenticated = True\n            # URLã«ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä»˜ä¸ã—ã¦ãƒªãƒ­ãƒ¼ãƒ‰ï¼ˆã“ã‚Œã§ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯å¯èƒ½ã«ãªã‚‹ï¼‰\n            st.query_params[\"auth\"] = SECRET_TOKEN\n            st.rerun()\n        else:\n            st.error(\"ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™ã€‚\")\n\n    st.stop()\n\n# =========================\n# Helper Functions\n# =========================\n\n# =========================\n# Helper Functions\n# =========================\n# Moved to logic.py\n\n# =========================\n# Grok Review Function (OpenRouter API)\n# =========================\n\nimport requests\nfrom curl_cffi import requests as crequests  # Grokç”¨ï¼ˆå¿…è¦ã«å¿œã˜ã¦æ®‹ã™ï¼‰\nimport asyncio\nimport nest_asyncio\nfrom putergenai import PuterClient\n\n# Streamlitã§Asyncã‚’ä½¿ã†ãŸã‚ã®è¨­å®š\nnest_asyncio.apply()\n\n# OpenRouter API Keyã®å–å¾— (st.secretså„ªå…ˆã€ãªã‘ã‚Œã°ç’°å¢ƒå¤‰æ•°)\ntry:\n    if \"OPENROUTER_API_KEY\" in st.secrets:\n        OPENROUTER_API_KEY = st.secrets[\"OPENROUTER_API_KEY\"]\n    else:\n        OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\", \"\")\nexcept:\n    OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\", \"\")\n\n# Puter èªè¨¼æƒ…å ±\nPUTER_USERNAME = None\nPUTER_PASSWORD = None\ntry:\n    if \"PUTER_USERNAME\" in st.secrets:\n        PUTER_USERNAME = st.secrets[\"PUTER_USERNAME\"]\n        PUTER_PASSWORD = st.secrets[\"PUTER_PASSWORD\"]\n    else:\n        PUTER_USERNAME = os.getenv(\"PUTER_USERNAME\")\n        PUTER_PASSWORD = os.getenv(\"PUTER_PASSWORD\")\nexcept Exception:\n    PUTER_USERNAME = os.getenv(\"PUTER_USERNAME\")\n    PUTER_PASSWORD = os.getenv(\"PUTER_PASSWORD\")\n\ndef review_with_grok(user_question: str, gemini_answer: str, research_text: str = None) -> str:\n    \"\"\"\n    Grok 4.1 Fast Free ã‚’ä½¿ã£ã¦ã€Geminiã®å›ç­”ã‚’æœ€çµ‚ãƒ¬ãƒ“ãƒ¥ãƒ¼ã™ã‚‹\n    research_text: GeminiãŒåé›†ã—ãŸèª¿æŸ»ãƒ¡ãƒ¢ï¼ˆæœ€æ–°æƒ…å ±ã‚’å«ã‚€ï¼‰\n    \"\"\"\n    url = \"https://openrouter.ai/api/v1/chat/completions\"\n    headers = {\n        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n        \"Content-Type\": \"application/json\",\n    }\n    \n    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰\n    user_content = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\\n{user_question}\\n\\n\"\n    \n    if research_text:\n        user_content += f\"Gemini ã®èª¿æŸ»ãƒ¡ãƒ¢ï¼ˆæœ€æ–°æƒ…å ±ï¼‰:\\n{research_text}\\n\\n\"\n    \n    user_content += (\n        f\"Gemini ã®æœ€çµ‚å›ç­”:\\n{gemini_answer}\\n\\n\"\n        \"**é‡è¦**: èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹äº‹å®Ÿã®æ–¹ã‚’ã€ã‚ãªãŸè‡ªèº«ã®çŸ¥è­˜ã‚ˆã‚Šã‚‚å„ªå…ˆã—ã¦ãã ã•ã„ã€‚\\n\"\n        \"æœ€æ–°ã®æƒ…å ±ãŒèª¿æŸ»ãƒ¡ãƒ¢ã«ã‚ã‚‹å ´åˆã€ãã‚Œã‚’ä¿¡é ¼ã—ã¦ãã ã•ã„ã€‚\\n\\n\"\n        \"1. **é‡å¤§ãªäº‹å®Ÿèª¤èªãƒ»è«–ç†é£›èºã®æŒ‡æ‘˜**ï¼ˆãªã‘ã‚Œã°ã€ç‰¹ã«ãªã—ã€ï¼‰\\n\"\n        \"2. **å…·ä½“çš„ãªä¿®æ­£ææ¡ˆã®ãƒªã‚¹ãƒˆ**ï¼ˆã€ä¿®æ­£å‰ã€â†’ã€ä¿®æ­£å¾Œã€ã®å½¢å¼ã§ï¼‰\\n\"\n        \"3. **ç‰¹ã«ä¸ç¢ºå®Ÿæ€§ãŒé«˜ã„ãƒã‚¤ãƒ³ãƒˆï¼ˆå‰æä¸è¶³ã€ãƒ‡ãƒ¼ã‚¿ä¸è¶³ãªã©ï¼‰ã® bullet list**\\n\"\n    )\n    \n    data = {\n        \"model\": \"x-ai/grok-4.1-fast:free\",\n        \"reasoning\": {\"enabled\": True},  # Enable multi-step reasoning for deeper review\n        \"messages\": [\n            {\n                \"role\": \"system\",\n                \"content\": (\n                    \"ã‚ãªãŸã¯å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ã§ã™ã€‚\"\n                    \"äº‹å®Ÿèª¤èªãƒ»è«–ç†ã®é£›èºãƒ»æŠœã‘æ¼ã‚Œã‚’å®¹èµ¦ãªãæŒ‡æ‘˜ã—ã€\"\n                    \"å¿…è¦ãªã‚‰å›ç­”ã‚’å…¨æ–‡æ›¸ãç›´ã—ã¦ãã ã•ã„ã€‚\"\n                ),\n            },\n            {\n                \"role\": \"user\",\n                \"content\": user_content.strip() + (\n                    \"ã ã‘ã‚’æ—¥æœ¬èªã§å‡ºã—ã¦ãã ã•ã„ã€‚\"\n                ),\n            },\n        ],\n    }\n    try:\n        resp = requests.post(url, headers=headers, json=data, timeout=60)\n        resp.raise_for_status()\n        j = resp.json()\n        return j[\"choices\"][0][\"message\"][\"content\"]\n    except Exception as e:\n        return f\"[Grokãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}]\\n\\n{gemini_answer}\"\n\n# =========================\n# Session Management\n# =========================\n\n\n\ndef think_with_grok(user_question: str, research_text: str, enable_x_search: bool = False) -> str:\n    \"\"\"\n    Grok 4.1 Fast Free ã‚’ä½¿ã£ã¦ã€ãƒªã‚µãƒ¼ãƒãƒ¡ãƒ¢ã‚’å…ƒã«ç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆã‚’ä½œæˆã™ã‚‹\n    enable_x_search=True ã®å ´åˆã€X/Twitteræƒ…å ±ã®æ´»ç”¨ã‚’ä¿ƒã™\n    \"\"\"\n    url = \"https://openrouter.ai/api/v1/chat/completions\"\n    headers = {\n        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n        \"Content-Type\": \"application/json\",\n    }\n    \n    # Xæ¤œç´¢å¼·åŒ–ç‰ˆã®å ´åˆã€ç‰¹åˆ¥ãªæŒ‡ç¤ºã‚’è¿½åŠ \n    x_search_instruction = \"\"\n    if enable_x_search:\n        x_search_instruction = (\n            \"\\n\\n**é‡è¦**: ã‚ãªãŸã¯Grokã¨ã—ã¦Xï¼ˆTwitterï¼‰ã®æƒ…å ±ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚\\n\"\n            \"ä¸Šè¨˜ã®èª¿æŸ»ãƒ¡ãƒ¢ã«åŠ ãˆã¦ã€Xä¸Šã®æœ€æ–°ã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»è­°è«–ãƒ»åå¿œã‚’è€ƒæ…®ã—ã€\\n\"\n            \"ãã‚Œã‚‰ã‚’å«ã‚ãŸç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\\n\\n\"\n            \"æ³¨æ„: Xä¸Šã®æƒ…å ±ãŒç¢ºèªã§ããªã„å ´åˆã¯ã€ãã®æ—¨ã‚’æ­£ç›´ã«è¿°ã¹ã¦ãã ã•ã„ã€‚\\n\"\n            \"æ¶ç©ºã®æŠ•ç¨¿ã‚„å­˜åœ¨ã—ãªã„åå¿œã‚’ä½œæˆã—ãªã„ã“ã¨ã€‚\"\n        )\n    \n    user_content = (\n        f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\\n{user_question}\\n\\n\"\n        f\"èª¿æŸ»ãƒ¡ãƒ¢:\\n{research_text}\\n\\n\"\n        \"æŒ‡ç¤º:\\n\"\n        \"ã‚ãªãŸã¯Geminiã¨ã¯åˆ¥ã®ç‹¬ç«‹ã—ãŸAIã§ã™ã€‚\\n\"\n        \"ä¸Šè¨˜ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’å‚è€ƒã«ã—ã¤ã¤ã‚‚ã€ã‚ãªãŸè‡ªèº«ã®è¦–ç‚¹ã§ç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\\n\"\n        \"Geminiã®æ„è¦‹ã«åˆã‚ã›ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\"\n        f\"{x_search_instruction}\"\n    )\n    \n    data = {\n        \"model\": \"x-ai/grok-2-1212\",\n        \"messages\": [\n            {\"role\": \"user\", \"content\": user_content}\n        ],\n    }\n    \n    try:\n        resp = requests.post(url, headers=headers, json=data, timeout=60)\n        resp.raise_for_status()\n        j = resp.json()\n        return j[\"choices\"][0][\"message\"][\"content\"]\n    except Exception as e:\n        return f\"[Grokæ€è€ƒã‚¨ãƒ©ãƒ¼: {e}]\"\n\ndef _extract_puter_text(message_content):\n    \"\"\"\n    puter.ai.chat ã®è¿”ã‚Šå€¤ã‹ã‚‰ ãƒ†ã‚­ã‚¹ãƒˆã ã‘ã‚’å–ã‚Šå‡ºã™\n    \"\"\"\n    if isinstance(message_content, str):\n        return message_content\n\n    if isinstance(message_content, list):\n        chunks = []\n        for part in message_content:\n            if isinstance(part, dict) and part.get(\"type\") == \"text\":\n                chunks.append(part.get(\"text\", \"\"))\n        return \"\".join(chunks)\n\n    return str(message_content)\n\n\ndef call_claude_opus_via_puter(\n    user_question: str,\n    research_text: str | None = None,\n    system_prompt: str | None = None,\n) -> str:\n    \"\"\"\n    Claude Opus 4.5ï¼ˆputer.comï¼‰via putergenai SDK\n    å…¬å¼ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¦Claudeã«ã‚¢ã‚¯ã‚»ã‚¹\n    \"\"\"\n    if not PUTER_USERNAME or not PUTER_PASSWORD:\n        return \"[Claude (puter) èªè¨¼æƒ…å ±æœªè¨­å®š]\"\n\n    async def _run() -> str:\n        try:\n            async with PuterClient() as client:\n                # SDKã§ãƒ­ã‚°ã‚¤ãƒ³\n                await client.login(PUTER_USERNAME, PUTER_PASSWORD)\n\n                # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹ç¯‰\n                messages = []\n                if system_prompt:\n                    messages.append({\"role\": \"system\", \"content\": system_prompt})\n\n                user_content = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\\n{user_question}\\n\\n\"\n                if research_text:\n                    user_content += f\"èª¿æŸ»ãƒ¡ãƒ¢:\\n{research_text}\\n\\n\"\n                    user_content += \"ã“ã®èª¿æŸ»ãƒ¡ãƒ¢ã®äº‹å®Ÿã‚’å„ªå…ˆã—ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚\\n\"\n\n                messages.append({\"role\": \"user\", \"content\": user_content})\n\n                # Claude Opus 4.5 ã‚’å‘¼ã³å‡ºã—\n                result = await client.ai_chat(\n                    messages=messages,\n                    options={\n                        \"model\": \"claude-opus-4-5\",  # ãƒã‚¤ãƒ•ãƒ³åŒºåˆ‡ã‚Š\n                        \"stream\": False,\n                    },\n                )\n\n                # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰æœ¬æ–‡ã‚’å–å¾—\n                # ãƒ‡ãƒãƒƒã‚°ç”¨ã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹å…¨ä½“ã‚’è¡¨ç¤º\n                import json\n                print(f\"DEBUG: Puter response: {json.dumps(result, indent=2)}\")\n                \n                message_content = result[\"response\"][\"result\"][\"message\"][\"content\"]\n                return _extract_puter_text(message_content)\n\n        except KeyError as e:\n            import traceback\n            return f\"[Claude SDK KeyError] Missing key: {e}\\nTraceback: {traceback.format_exc()}\"\n        except Exception as e:\n            import traceback\n            return f\"[Claude SDK Error] {type(e).__name__}: {str(e)}\\nTraceback: {traceback.format_exc()}\"\n\n    # Streamlitã®åŒæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§asyncã‚’å®Ÿè¡Œ\n    try:\n        return asyncio.run(_run())\n    except Exception as e:\n        import traceback\n        return f\"[Claude Connection Error] {type(e).__name__}: {str(e)}\\nTraceback: {traceback.format_exc()}\"\n\ndef create_new_session():\n    current_sessions = load_sessions()\n    \n    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒç©ºãªã‚‰ã€æ–°ã—ãä½œã‚‰ãšã«ãã‚Œã‚’å†åˆ©ç”¨ã™ã‚‹ï¼ˆé‡è¤‡é˜²æ­¢ï¼‰\n    if st.session_state.get(\"current_session_id\"):\n        for s in current_sessions:\n            if s[\"id\"] == st.session_state.current_session_id:\n                if len(s[\"messages\"]) == 0:\n                    st.toast(\"ã™ã§ã«æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã§ã™\")\n                    return\n\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": [],\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.rerun()\n\ndef switch_session(session_id):\n    st.session_state.current_session_id = session_id\n    st.rerun()\n\ndef update_current_session_messages(messages):\n    if st.session_state.current_session_id:\n        current_sessions = load_sessions()\n        target_index = -1\n        for i, session in enumerate(current_sessions):\n            if session[\"id\"] == st.session_state.current_session_id:\n                session[\"messages\"] = messages\n                if session[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(messages) > 0:\n                    first_msg = messages[0][\"content\"]\n                    session[\"title\"] = (first_msg[:20] + \"...\") if len(first_msg) > 20 else first_msg\n                session[\"timestamp\"] = datetime.datetime.now().isoformat()\n                target_index = i\n                break\n        \n        if target_index != -1:\n            # æœ€æ–°ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒªã‚¹ãƒˆã®å…ˆé ­ã«ç§»å‹•\n            updated_session = current_sessions.pop(target_index)\n            current_sessions.insert(0, updated_session)\n            \n        save_sessions(current_sessions)\n        st.session_state.sessions = current_sessions\n\ndef get_current_messages():\n    if st.session_state.current_session_id:\n        for session in st.session_state.sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                return session[\"messages\"]\n    return []\n\ndef delete_session(session_id):\n    current_sessions = load_sessions()\n    current_sessions = [s for s in current_sessions if s[\"id\"] != session_id]\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    if st.session_state.current_session_id == session_id:\n        st.session_state.current_session_id = None\n        if st.session_state.sessions:\n            st.session_state.current_session_id = st.session_state.sessions[0][\"id\"]\n    st.rerun()\n\ndef branch_session():\n    \"\"\"ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚’åˆ†å²\"\"\"\n    current_messages = get_current_messages()\n    current_sessions = load_sessions()\n    \n    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—\n    current_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n    for session in current_sessions:\n        if session[\"id\"] == st.session_state.current_session_id:\n            current_title = session[\"title\"]\n            break\n    \n    # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": f\"{current_title} (åˆ†å²)\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": current_messages.copy(),  # ç¾åœ¨ã®å±¥æ­´ã‚’ã‚³ãƒ”ãƒ¼\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    \n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.session_state.session_cost = 0.0  # ã‚³ã‚¹ãƒˆãƒªã‚»ãƒƒãƒˆ\n    st.rerun()\n\n# =========================\n# Initialization\n# =========================\n\nif \"sessions\" not in st.session_state:\n    st.session_state.sessions = load_sessions()\n\nif \"current_session_id\" not in st.session_state:\n    # Always create a new session when the app starts\n    create_new_session()\n\nif \"session_cost\" not in st.session_state:\n    st.session_state.session_cost = 0.0\n\nusage_stats = load_usage()\n\n# ==========================\n# ã‚³ã‚¹ãƒˆãƒã‚§ãƒƒã‚¯ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã®å‰ã«å®Ÿè¡Œï¼‰\n# ==========================\nusage_stats = load_usage()\nstop_generation = usage_stats[\"total_cost_usd\"] >= MAX_BUDGET_USD\n\n# =========================\n# Sidebar\n# =========================\n\nwith st.sidebar:\n    # ğŸ” ãƒ­ã‚°ã‚¢ã‚¦ãƒˆãƒœã‚¿ãƒ³\n    if st.button(\"ğŸ”’ ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ\", use_container_width=True):\n        st.session_state.authenticated = False\n        st.query_params.clear()  # URLãƒˆãƒ¼ã‚¯ãƒ³ã‚‚å‰Šé™¤\n        st.rerun()\n\n    st.markdown(\"\"\"\n    <div style=\"text-align: center; padding: 0; margin: 0; margin-top: -1rem;\">\n        <h1 style=\"font-size: 18px; font-weight: 700; margin: 0; padding: 0; letter-spacing: 1px;\">\n            Gemini 3<br/>Studio\n        </h1>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n    col1, col2 = st.columns(2)\n    with col1:\n        if st.button(\"â• æ–°è¦\", use_container_width=True):\n            create_new_session()\n    with col2:\n        if st.button(\"ğŸŒ± åˆ†å²\", use_container_width=True):\n            branch_session()\n\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    current_messages = get_current_messages()\n    if current_messages:\n        with st.expander(\"ğŸ”— å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ\", expanded=False):\n            export_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n            for s in st.session_state.sessions:\n                if s[\"id\"] == st.session_state.current_session_id:\n                    export_title = s[\"title\"]\n                    break\n\n            export_md = f\"# {export_title}\\n\\n\"\n            export_md += f\"**ä½œæˆæ—¥æ™‚**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n---\\n\\n\"\n            for msg in current_messages:\n                role_label = \"ğŸ§‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼\" if msg[\"role\"] == \"user\" else \"ğŸ¤– AI\"\n                export_md += f\"## {role_label}\\n\\n{msg['content']}\\n\\n---\\n\\n\"\n\n            if st.button(\"ãƒªãƒ³ã‚¯ç”Ÿæˆ\", use_container_width=True):\n                with st.spinner(\"ç”Ÿæˆä¸­...\"):\n                    try:\n                        import urllib.request\n                        import urllib.parse\n\n                        data = urllib.parse.urlencode(\n                            {\"content\": export_md, \"expiry_days\": 7, \"syntax\": \"md\"}\n                        ).encode()\n\n                        req = urllib.request.Request(\"https://dpaste.org/api/\", data=data)\n                        req.add_header(\"User-Agent\", \"Mozilla/5.0 (Gemini3Studio)\")\n\n                        with urllib.request.urlopen(req) as response:\n                            share_url = response.read().decode(\"utf-8\").strip()\n                            st.success(\"ä½œæˆå®Œäº†ï¼\")\n                            st.code(share_url)\n                            st.caption(\"â€»7æ—¥é–“æœ‰åŠ¹\")\n                    except Exception as e:\n                        st.error(f\"ã‚¨ãƒ©ãƒ¼: {e}\")\n\n    st.markdown(\"---\")\n\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    with st.expander(\"ğŸ“ æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«\", expanded=False):\n        uploaded_files = st.file_uploader(\n            \"ãƒ•ã‚¡ã‚¤ãƒ«\",\n            accept_multiple_files=True,\n            type=[\"png\", \"jpg\", \"jpeg\", \"mp4\", \"mov\", \"txt\", \"pdf\", \"csv\"],\n            label_visibility=\"collapsed\"\n        )\n\n    # ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ï¼ˆExpanderã®å¤–ã«å‡ºã™ï¼‰\n    pasted_image_bytes = None  # åˆæœŸåŒ–ã—ã¦NameErrorã‚’é˜²ã\n    if paste:\n        if \"paste_key\" not in st.session_state:\n            st.session_state.paste_key = 0\n        try:\n            pasted_image_bytes = paste(\n                label=\"ğŸ“‹ ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰è²¼ä»˜\",\n                key=f\"paste_btn_{st.session_state.paste_key}\",\n            )\n        except Exception as e:\n            st.error(f\"Error: {e}\")\n        \n        if pasted_image_bytes:\n            st.success(\"è²¼ä»˜å®Œäº†\")\n            st.image(pasted_image_bytes, caption=\"ç”»åƒ\", use_container_width=True)\n            if st.button(\"ğŸ—‘ï¸ ã‚¯ãƒªã‚¢\", key=\"clear_paste\"):\n                st.session_state.paste_key += 1\n                st.rerun()\n    else:\n        st.warning(\"Clipboard lib missing\")\n\n    # ---- YouTube URL ----\n    with st.expander(\"ğŸ“º YouTubeåˆ†æ\", expanded=False):\n        youtube_url = st.text_input(\"URL\", placeholder=\"https://youtu.be/...\", label_visibility=\"collapsed\")\n\n    st.markdown(\"---\")\n    \n    st.markdown(\"---\")\n    \n    # ---- ãƒ¢ãƒ¼ãƒ‰ã‚«ãƒ†ã‚´ãƒªé¸æŠ ----\n    mode_category = st.radio(\n        \"ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ¼ãƒ‰\",\n        [\"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\", \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(é€šå¸¸)\", \"Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter)\"],\n        index=0,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’å¤šå±¤ã«å¤‰æ›´\n        horizontal=True,\n    )\n    \n    # ---- å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ ----\n    if mode_category == \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\":\n        with st.expander(\"ãƒ¢ãƒ¼ãƒ‰è¨­å®š(å¤šå±¤)\", expanded=True):\n            mode_type = st.radio(\n                \"ã‚¿ã‚¤ãƒ—\",\n                [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n                index=0,\n                horizontal=True,\n                label_visibility=\"collapsed\"\n            )\n            \n            if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. (è©¦é¨“ä¸­)ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                        \"2. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                        \"3. (è©¦é¨“ä¸­)ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                        \"4. ç†Ÿè€ƒ(ãƒ¡ã‚¿æ€è€ƒ)+grokæ¤œç´¢å¼·åŒ–ç‰ˆ\",\n                    ],\n                    index=1  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ãƒ¡ã‚¿æ€è€ƒã«å¤‰æ›´\n                )\n            elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                    ],\n                    index=0\n                )\n            else:\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                    ],\n                    index=0\n                )\n    \n    # ---- å¤šå±¤+puterãƒ¢ãƒ¼ãƒ‰ ----\n    elif mode_category == \"Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter)\":\n        with st.expander(\"ãƒ¢ãƒ¼ãƒ‰è¨­å®š(å¤šå±¤+puter)\", expanded=True):\n            mode_type = st.radio(\n                \"ã‚¿ã‚¤ãƒ—\",\n                [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n                index=0,\n                horizontal=True,\n                label_visibility=\"collapsed\"\n            )\n            \n            if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                        \"2. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                        \"3. ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                    ],\n                    index=0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’é¬¼è»æ›¹ã«å¤‰æ›´\n                )\n            elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                    ],\n                    index=0\n                )\n            else:\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                    ],\n                    index=0\n                )\n    \n    # ---- é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ ----\n    else:\n        with st.expander(\"ãƒ¢ãƒ¼ãƒ‰è¨­å®š(é€šå¸¸)\", expanded=True):\n            mode_type = st.radio(\n                \"ã‚¿ã‚¤ãƒ—\",\n                [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n                index=0,\n                horizontal=True,\n                label_visibility=\"collapsed\"\n            )\n            \n            if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                        \"2. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                        \"3. ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                    ],\n                    index=0\n                )\n            elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                    ],\n                    index=0\n                )\n            else:\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                    ],\n                    index=0\n                )\n    \n    strict_mode = False\n    \n    # ---- è¨­å®š (ãƒ¢ãƒ‡ãƒ«ãªã©) ----\n    with st.expander(\"âš™ï¸ è¨­å®š\", expanded=False):\n        model_options = [\n            \"gemini-3-pro-preview\",\n            \"gemini-2.5-pro\",\n            \"gemini-2.5-flash\",\n            \"gemini-2.5-flash-lite\",\n            \"gemini-2.0-flash\",\n        ]\n        model_id = st.selectbox(\"ãƒ¢ãƒ‡ãƒ«ID\", options=model_options, index=0)\n\n        use_search = st.toggle(\"Googleæ¤œç´¢\", value=True)\n        candidate_count = st.slider(\"å€™è£œæ•°\", min_value=1, max_value=3, value=3)\n\n    st.markdown(\"---\")\n\n    # ---- å±¥æ­´æ¤œç´¢ ----\n    search_query = st.text_input(\"ğŸ” å±¥æ­´æ¤œç´¢\", placeholder=\"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰...\")\n    if search_query:\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if search_query.lower() in s[\"title\"].lower():\n                filtered_sessions.append(s)\n                continue\n            found = False\n            for m in s[\"messages\"]:\n                if search_query.lower() in m[\"content\"].lower():\n                    filtered_sessions.append(s)\n                    found = True\n                    break\n            if not found:\n                pass\n    else:\n        # æ¤œç´¢ã—ã¦ã„ãªã„å ´åˆ: ç©ºã®ã€Œæ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã€ã‚’é™¤å¤–ï¼ˆç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯é™¤ãï¼‰\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if s[\"id\"] == st.session_state.current_session_id:\n                filtered_sessions.append(s)\n                continue\n            if s[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(s[\"messages\"]) == 0:\n                continue\n            filtered_sessions.append(s)\n\n    # CSSã§è¦‹ã‚„ã™ãä½¿ã„ã‚„ã™ãæœ€é©åŒ–\n    st.markdown(\"\"\"\n    <style>\n    /* å…¨ä½“ã®ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºç¸®å° */\n    .stApp, .stMarkdown, .stButton, .stSelectbox, .stTextInput, .stTextArea {\n        font-size: 12px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ä½™ç™½ã‚’æ¥µé™ã¾ã§è©°ã‚ã‚‹ */\n    section[data-testid=\"stSidebar\"] .block-container {\n        padding-top: 0.3rem !important;\n        padding-bottom: 0.3rem !important;\n        padding-left: 0.5rem !important;\n        padding-right: 0.5rem !important;\n    }\n    /* å„è¦ç´ é–“ã®éš™é–“ã‚’è©°ã‚ã‚‹ */\n    div[data-testid=\"stVerticalBlock\"] > div {\n        gap: 0.1rem !important;\n    }\n    /* Expanderã®ä½™ç™½å‰Šæ¸› */\n    .streamlit-expanderHeader {\n        font-size: 11px !important;\n        padding-top: 0px !important;\n        padding-bottom: 0px !important;\n        min-height: 1.3rem !important;\n    }\n    .streamlit-expanderContent {\n        padding-top: 0px !important;\n        padding-bottom: 0px !important;\n    }\n    /* éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã®ã‚¿ã‚¤ãƒˆãƒ« */\n    div[data-testid=\"stExpander\"] summary p {\n        font-size: 10px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ */\n    section[data-testid=\"stSidebar\"] button p {\n        font-size: 10px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã« */\n    section[data-testid=\"stSidebar\"] button {\n        padding: 0rem 0.2rem !important;\n        min-height: 1.4rem !important;\n        font-size: 10px !important;\n        margin-bottom: 0px !important;\n    }\n    /* ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®ãƒ©ãƒ™ãƒ«ã‚’å°ã•ã */\n    section[data-testid=\"stSidebar\"] .stRadio label {\n        font-size: 10px !important;\n    }\n    section[data-testid=\"stSidebar\"] .stRadio > label > div {\n        font-size: 10px !important;\n    }\n    /* ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ‡ã‚Šè©°ã‚ã‚‹ï¼ˆæ”¹è¡Œã•ã›ãªã„ï¼‰ */\n    section[data-testid=\"stSidebar\"] label, \n    section[data-testid=\"stSidebar\"] p,\n    section[data-testid=\"stSidebar\"] span {\n        white-space: nowrap !important;\n        overflow: hidden !important;\n        text-overflow: ellipsis !important;\n    }\n    /* åŒºåˆ‡ã‚Šç·š */\n    hr {\n        margin-top: 0.1rem !important;\n        margin-bottom: 0.1rem !important;\n    }\n    /* ãƒ˜ãƒƒãƒ€ãƒ¼ç¸®å° */\n    h1, h2, h3 {\n        padding-top: 0rem !important;\n        padding-bottom: 0rem !important;\n        margin-top: 0rem !important;\n        margin-bottom: 0rem !important;\n    }\n    </style>\n    \"\"\", unsafe_allow_html=True)\n    \n    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§é™é †ã‚½ãƒ¼ãƒˆï¼ˆæœ€æ–°ãŒå…ˆé ­ï¼‰\n    filtered_sessions.sort(key=lambda s: s.get(\"timestamp\", \"\"), reverse=True)\n    \n    # ç›´è¿‘5ä»¶ã¨éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«åˆ†å‰²\n    recent_sessions = filtered_sessions[:5] if len(filtered_sessions) > 5 else filtered_sessions\n    archive_sessions = filtered_sessions[5:] if len(filtered_sessions) > 5 else []\n    \n    # ç›´è¿‘5ä»¶ï¼ˆå¸¸ã«å±•é–‹ï¼‰\n    if recent_sessions:\n        st.markdown(\"**ğŸ“Œ ç›´è¿‘ã®ãƒãƒ£ãƒƒãƒˆ**\")\n        for session in recent_sessions:\n            col1, col2 = st.columns([0.8, 0.2])\n            with col1:\n                if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                    switch_session(session[\"id\"])\n            with col2:\n                if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                    delete_session(session[\"id\"])\n    \n    # éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆæŠ˜ã‚ŠãŸãŸã¿ï¼‰\n    if archive_sessions:\n        with st.expander(f\"ğŸ“œ éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ– ({len(archive_sessions)}ä»¶)\", expanded=False):\n            for session in archive_sessions:\n                col1, col2 = st.columns([0.8, 0.2])\n                with col1:\n                    if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                        switch_session(session[\"id\"])\n                with col2:\n                    if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                        delete_session(session[\"id\"])\n\n    st.markdown(\"---\")\n\n    # ---- ç”»åƒç”Ÿæˆ ----\n    with st.expander(\"ğŸ¨ ç”»åƒç”Ÿæˆ\", expanded=False):\n        img_prompt = st.text_area(\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\", placeholder=\"æœªæ¥çš„ãªéƒ½å¸‚...\")\n        aspect_ratio = st.selectbox(\"æ¯”ç‡\", [\"16:9\", \"1:1\", \"4:3\", \"3:4\", \"9:16\"])\n\n        generate_img_btn = st.button(\"ç”Ÿæˆ\", type=\"primary\", disabled=not img_prompt)\n        if generate_img_btn and img_prompt:\n            st.session_state.generate_image_trigger = {\n                \"prompt\": img_prompt,\n                \"aspect_ratio\": aspect_ratio,\n            }\n\n    st.markdown(\"---\")\n\n    # ---- è©•ä¾¡åˆ†æ ----\n    with st.expander(\"ğŸ“Š å“è³ªåˆ†æ\", expanded=False):\n        total_ratings = 0\n        positive_ratings = 0\n        model_ratings = {}\n\n        for s in st.session_state.sessions:\n            for m in s[\"messages\"]:\n                if \"rating\" in m and m[\"rating\"] is not None:\n                    total_ratings += 1\n                    if m[\"rating\"] == 1:\n                        positive_ratings += 1\n                    if \"metadata\" in m and \"model\" in m[\"metadata\"]:\n                        mod = m[\"metadata\"][\"model\"]\n                        if mod not in model_ratings:\n                            model_ratings[mod] = {\"total\": 0, \"positive\": 0}\n                        model_ratings[mod][\"total\"] += 1\n                        if m[\"rating\"] == 1:\n                            model_ratings[mod][\"positive\"] += 1\n\n        if total_ratings > 0:\n            approval_rate = (positive_ratings / total_ratings) * 100\n            st.metric(\"Positive Ratings\", f\"{positive_ratings}/{total_ratings}\", f\"{approval_rate:.1f}%\")\n            best_model = \"N/A\"\n            best_rate = -1\n            for mod, stats in model_ratings.items():\n                rate = stats[\"positive\"] / stats[\"total\"]\n                if rate > best_rate:\n                    best_rate = rate\n                    best_model = mod\n            if best_model != \"N/A\":\n                st.caption(f\"ğŸ† Best: **{best_model}** ({best_rate*100:.0f}%)\")\n        else:\n            st.caption(\"ãƒ‡ãƒ¼ã‚¿ãªã—\")\n\n    st.markdown(\"---\")\n\n    # ---- ã‚³ã‚¹ãƒˆè¡¨ç¤º ----\n    from logic import load_manual_cost, save_manual_cost, MAX_BUDGET_JPY, TRIAL_LIMIT_JPY, TRIAL_EXPIRY\n    \n    st.subheader(\"ğŸ’° Cost\")\n    st.caption(f\"äºˆç®—: Â¥{MAX_BUDGET_JPY:,.0f}\")\n    st.caption(f\"ä¸Šé™: Â¥{TRIAL_LIMIT_JPY:,.0f}\")\n    st.caption(f\"æœ‰åŠ¹æœŸé™: {TRIAL_EXPIRY}\")\n    \n    # æ‰‹å‹•ã‚³ã‚¹ãƒˆå…¥åŠ›ï¼ˆæ°¸ç¶šåŒ–ï¼‰\n    current_manual_cost = load_manual_cost()\n    manual_cost = st.number_input(\n        \"æ‰‹å‹•å…¥åŠ› (Â¥)\",\n        min_value=0.0,\n        value=current_manual_cost,\n        step=10.0,\n        format=\"%.0f\",\n        key=\"manual_cost_persistent\",\n        help=\"Google Cloud Consoleã§ç¢ºèªã—ãŸå®Ÿéš›ã®ã‚³ã‚¹ãƒˆï¼ˆå††ï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ã“ã®å€¤ã¯ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‰ã˜ã¦ã‚‚ä¿æŒã•ã‚Œã¾ã™ã€‚\"\n    )\n    \n    # å€¤ãŒå¤‰æ›´ã•ã‚ŒãŸã‚‰ä¿å­˜\n    if manual_cost != current_manual_cost:\n        save_manual_cost(manual_cost)\n    \n    st.link_button(\"ğŸ’° Google Cloud Console\", \"https://console.cloud.google.com/welcome/new?_gl=1*kmr691*_up*MQ..&gclid=CjwKCAiAraXJBhBJEiwAjz7MZT0vQsfDK5zunRBCQmuN5iczgI4bP1lHo1Tcrcbqu1KCBE1D22GpFhoCOdgQAvD_BwE&gclsrc=aw.ds&hl=ja&authuser=5&project=sigma-task-479704-r6\")\n\n    st.markdown(\"---\")\n    st.code(f\"PROJECT: {VERTEX_PROJECT}\\nLOCATION: {VERTEX_LOCATION} (Vertex AI)\")\n\n# =========================\n# Main UI\n# =========================\n\ncurrent_session_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\nfor s in st.session_state.sessions:\n    if s[\"id\"] == st.session_state.current_session_id:\n        current_session_title = s[\"title\"]\n        break\n\nst.header(current_session_title)\nst.markdown(\n    \"ä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\"\n)\n\n\n# ---- ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒœã‚¿ãƒ³ (Floating) ----\nst.markdown(\"\"\"\n    <style>\n        .scroll-btn-container {\n            position: fixed;\n            bottom: 100px;\n            right: 20px;\n            z-index: 9999;\n            display: flex;\n            flex-direction: column;\n            gap: 10px;\n        }\n        .scroll-btn {\n            background-color: #f0f2f6;\n            color: #31333F;\n            border: 1px solid #d6d6d8;\n            border-radius: 50%;\n            width: 40px;\n            height: 40px;\n            display: flex;\n            align-items: center;\n            justify-content: center;\n            cursor: pointer;\n            box-shadow: 0 2px 5px rgba(0,0,0,0.1);\n            transition: all 0.3s ease;\n            font-size: 20px;\n            padding: 0;\n            line-height: 1;\n        }\n        .scroll-btn:hover {\n            background-color: #e0e2e6;\n            transform: scale(1.1);\n            box-shadow: 0 4px 8px rgba(0,0,0,0.15);\n        }\n    </style>\n    \n    <script>\n        window.scrollStreamlit = function(direction) {\n            console.log(\"Scroll triggered: \" + direction);\n            \n            // ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ãªã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹è¦ç´ ã‚’é †ç•ªã«è©¦ã™\n            var targets = [];\n            \n            try {\n                if (window.parent && window.parent.document) {\n                    targets.push(window.parent.document.querySelector('section[data-testid=\"stAppViewContainer\"]'));\n                    targets.push(window.parent.document.querySelector('.main'));\n                    targets.push(window.parent.document.documentElement);\n                }\n            } catch (e) {\n                console.log(\"Access to parent window denied\");\n            }\n            \n            // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆiframeå†…ï¼‰\n            targets.push(document.querySelector('section[data-testid=\"stAppViewContainer\"]'));\n            targets.push(document.documentElement);\n\n            var scrolled = false;\n            for (var i = 0; i < targets.length; i++) {\n                var el = targets[i];\n                if (el) {\n                    try {\n                        // ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯èƒ½ãªè¦ç´ ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“çš„ï¼‰\n                        if (el.scrollHeight > el.clientHeight || el === window.parent.document.documentElement) {\n                            console.log(\"Scrolling element:\", el);\n                            if (direction === 'top') {\n                                el.scrollTo({top: 0, behavior: 'smooth'});\n                            } else {\n                                el.scrollTo({top: el.scrollHeight, behavior: 'smooth'});\n                            }\n                            scrolled = true;\n                        }\n                    } catch (e) {\n                        console.error(\"Error scrolling element:\", e);\n                    }\n                }\n            }\n            \n            if (!scrolled) {\n                console.log(\"No scrollable container found, trying window scroll\");\n                try {\n                    if (direction === 'top') {\n                        window.parent.scrollTo({top: 0, behavior: 'smooth'});\n                    } else {\n                        window.parent.scrollTo({top: window.parent.document.body.scrollHeight, behavior: 'smooth'});\n                    }\n                } catch(e) {\n                    window.scrollTo({top: 0, behavior: 'smooth'});\n                }\n            }\n        }\n    </script>\n\n    <div class=\"scroll-btn-container\">\n        <button class=\"scroll-btn\" onclick=\"window.scrollStreamlit('top')\" title=\"Top\">â¬†ï¸</button>\n        <button class=\"scroll-btn\" onclick=\"window.scrollStreamlit('bottom')\" title=\"Bottom\">â¬‡ï¸</button>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n# ---- Vertex AI Client ----\n\n\n\nclient = get_client()\n\n# ---- å±¥æ­´è¡¨ç¤º ----\n\nmessages = get_current_messages()\nfor idx, msg in enumerate(messages):\n    with st.chat_message(msg[\"role\"]):\n        st.markdown(msg[\"content\"])\n        if msg[\"role\"] == \"model\":\n            col1, col2, col3 = st.columns([0.1, 0.1, 0.8])\n            current_rating = msg.get(\"rating\")\n            with col1:\n                if st.button(\"ğŸ‘\", key=f\"up_{idx}\"):\n                    messages[idx][\"rating\"] = 1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col2:\n                if st.button(\"ğŸ‘\", key=f\"down_{idx}\"):\n                    messages[idx][\"rating\"] = -1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col3:\n                if current_rating == 1:\n                    st.caption(\"âœ… é«˜è©•ä¾¡\")\n                elif current_rating == -1:\n                    st.caption(\"âŒ ä½è©•ä¾¡\")\n\n# ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒœã‚¿ãƒ³ï¼ˆé•·ã„ãƒãƒ£ãƒƒãƒˆç”¨ï¼‰\nif len(messages) > 5:\n    st.markdown(\"\"\"\n    <div style=\"position: fixed; right: 20px; bottom: 100px; z-index: 999;\">\n        <button onclick=\"window.scrollTo({top: 0, behavior: 'smooth'})\" \n                style=\"display: block; margin: 5px; padding: 10px 15px; font-size: 24px; cursor: pointer; \n                       border: 2px solid #ccc; border-radius: 50%; background: white; box-shadow: 0 2px 8px rgba(0,0,0,0.2);\">\n            â¬†ï¸\n        </button>\n        <button onclick=\"window.scrollTo({top: document.body.scrollHeight, behavior: 'smooth'})\" \n                style=\"display: block; margin: 5px; padding: 10px 15px; font-size: 24px; cursor: pointer; \n                       border: 2px solid #ccc; border-radius: 50%; background: white; box-shadow: 0 2px 8px rgba(0,0,0,0.2);\">\n            â¬‡ï¸\n        </button>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n\n# =========================\n# ç”»åƒç”Ÿæˆãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°\n# =========================\n\nif hasattr(st.session_state, \"generate_image_trigger\") and st.session_state.generate_image_trigger:\n    img_data = st.session_state.generate_image_trigger\n    del st.session_state.generate_image_trigger\n\n    with st.chat_message(\"user\"):\n        st.markdown(f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\")\n        st.caption(f\"ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”: {img_data['aspect_ratio']}\")\n\n    messages.append({\"role\": \"user\", \"content\": f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\"})\n    update_current_session_messages(messages)\n\n    with st.chat_message(\"assistant\"):\n        with st.status(\"ç”»åƒã‚’ç”Ÿæˆä¸­...\", expanded=True) as status:\n            try:\n                config = types.GenerateContentConfig(\n                    response_modalities=[\"IMAGE\"],\n                    image_config=types.ImageConfig(\n                        aspect_ratio=img_data[\"aspect_ratio\"]\n                    ),\n                )\n                status.write(\"Gemini 3 Pro Imageã§ç”Ÿæˆä¸­...\")\n                response = client.models.generate_content(\n                    model=\"gemini-3-pro-image-preview\",\n                    contents=img_data[\"prompt\"],\n                    config=config,\n                )\n\n                generated_image = None\n\n                # ç”»åƒã‚’å–ã‚Šå‡ºã™\n                if getattr(response, \"candidates\", None):\n                    for candidate in response.candidates:\n                        if getattr(candidate, \"content\", None) and candidate.content.parts:\n                            for part in candidate.content.parts:\n                                if getattr(part, \"inline_data\", None):\n                                    try:\n                                        generated_image = part.as_image()\n                                    except AttributeError:\n                                        image_bytes_raw = part.inline_data.data\n                                        generated_image = Image.open(io.BytesIO(image_bytes_raw))\n                                    break\n                        if generated_image is not None:\n                            break\n\n                if generated_image is not None:\n                    st.image(generated_image, caption=img_data[\"prompt\"])\n                    buf = io.BytesIO()\n                    generated_image.save(buf, format=\"PNG\")\n                    image_bytes = buf.getvalue()\n                    st.download_button(\n                        label=\"ğŸ’¾ ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\",\n                        data=image_bytes,\n                        file_name=f\"generated_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png\",\n                        mime=\"image/png\",\n                    )\n                    messages.append(\n                        {\"role\": \"model\", \"content\": f\"âœ… ç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {img_data['prompt']}\"}\n                    )\n                    update_current_session_messages(messages)\n                    status.update(label=\"âœ… ç”»åƒç”Ÿæˆå®Œäº†\", state=\"complete\")\n                else:\n                    st.error(\"ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")\n                    status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n\n            except Exception as e:\n                status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n                st.error(f\"ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}\")\n\n# =========================\n# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›\n# =========================\n\nprompt = st.chat_input(\"ä½•ã‹èã„ã¦ãã ã•ã„...\", disabled=stop_generation)\n\nif prompt:\n    if stop_generation:\n        st.error(\"äºˆç®—ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚\")\n    else:\n        # ---- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€è¡¨ç¤º ----\n        with st.chat_message(\"user\"):\n            st.markdown(prompt)\n            if uploaded_files:\n                for uf in uploaded_files:\n                    st.caption(f\"ğŸ“ æ·»ä»˜: {uf.name}\")\n            if youtube_url:\n                st.caption(f\"ğŸ“º YouTube: {youtube_url}\")\n            if pasted_image_bytes:\n                st.caption(\"ğŸ“‹ ç”»åƒãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚Œã¾ã—ãŸ\")\n\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        update_current_session_messages(messages)\n\n        # ---- ãƒ¢ãƒ‡ãƒ«å¿œç­” ----\n        with st.chat_message(\"assistant\"):\n            status_container = st.status(\"æ€è€ƒä¸­...\", expanded=True)\n            try:\n                # ä¼šè©±å±¥æ­´\n                model_history = []\n                for msg in messages[:-1]:\n                    model_history.append(\n                        types.Content(\n                            role=msg[\"role\"],\n                            parts=[types.Part.from_text(text=msg[\"content\"])],\n                        )\n                    )\n\n                # ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³\n                current_parts = [types.Part.from_text(text=prompt)]\n\n                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«\n                for uploaded_file in uploaded_files or []:\n                    try:\n                        mime_type = get_mime_type(uploaded_file.name)\n                        bytes_data = uploaded_file.getvalue()\n                        part = types.Part.from_bytes(data=bytes_data, mime_type=mime_type)\n                        current_parts.append(part)\n                        status_container.write(f\"ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™å®Œäº†: {uploaded_file.name}\")\n                    except Exception as e:\n                        status_container.error(\n                            f\"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {uploaded_file.name} - {e}\"\n                        )\n\n                # è²¼ã‚Šä»˜ã‘ç”»åƒ\n                if pasted_image_bytes:\n                    import base64\n\n                    status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã‚’å‡¦ç†ä¸­...\")\n                    try:\n                        if isinstance(pasted_image_bytes, str):\n                            if pasted_image_bytes.startswith(\"data:\"):\n                                base64_str = pasted_image_bytes.split(\",\", 1)[1]\n                                image_bytes_decoded = base64.b64decode(base64_str)\n                            else:\n                                image_bytes_decoded = base64.b64decode(pasted_image_bytes)\n                        else:\n                            image_bytes_decoded = pasted_image_bytes\n                        part = types.Part.from_bytes(\n                            data=image_bytes_decoded, mime_type=\"image/png\"\n                        )\n                        current_parts.append(part)\n                        status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®æº–å‚™å®Œäº†\")\n                    except Exception as e:\n                        status_container.error(f\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n\n                # YouTube å­—å¹•\n                if youtube_url:\n                    vid_id = extract_youtube_id(youtube_url)\n                    if vid_id:\n                        status_container.write(\"YouTubeã®å­—å¹•ã‚’å–å¾—ä¸­...\")\n                        transcript_text = get_youtube_transcript(vid_id)\n                        current_parts.append(\n                            types.Part.from_text(text=f\"YouTube Transcript:\\n{transcript_text}\")\n                        )\n                    else:\n                        status_container.write(\"ç„¡åŠ¹ãªYouTube URLã§ã™ã€‚\")\n\n                contents_for_model = model_history + [\n                    types.Content(role=\"user\", parts=current_parts)\n                ]\n\n                # ---- Tool / Config ----\n                tools = []\n                final_candidate_count = candidate_count\n                if use_search:\n                    tools.append(types.Tool(google_search=types.GoogleSearch()))\n                    final_candidate_count = 1\n\n                # â˜… System Instruction ã®æ”¹å–„: ãƒ¡ã‚¿ç™ºè¨€ç¦æ­¢ã¨ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªæŒ¯ã‚‹èˆã„ã‚’æŒ‡ç¤º\n                base_system_instruction = (\n                    \"ã‚ãªãŸã¯é«˜åº¦ãªçŸ¥æ€§ã‚’æŒã¤å°‚é–€çš„ãªãƒªã‚µãƒ¼ãƒãƒ»ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\\n\"\n                    \"ä»¥ä¸‹ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’å³å®ˆã—ã¦ãã ã•ã„ï¼š\\n\"\n                    \"1. **ãƒ¡ã‚¿ç™ºè¨€ã®ç¦æ­¢**: ã€Œç§ã¯AIã§ã™ã€ã€Œä¸–ç•Œæœ€é«˜å³°ã®ï½ã¨ã—ã¦ã€ãªã©ã®è‡ªå·±è¨€åŠã‚„å‰ç½®ãã¯ä¸€åˆ‡è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚\\n\"\n                    \"2. **æ„å›³ã®æ±²ã¿å–ã‚Š**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã®èƒŒå¾Œã«ã‚ã‚‹æ„å›³ï¼ˆæ–‡è„ˆã€æš—é»™ã®å‰æï¼‰ã‚’æ¨æ¸¬ã—ã€è¨€è‘‰é€šã‚Šã§ã¯ãªãã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ¬å½“ã«çŸ¥ã‚ŠãŸã„ã“ã¨ã€ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n\"\n                    \"3. **æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”**: çµè«–ã‚’å…ˆã«è¿°ã¹ã€ãã®å¾Œã«è©³ç´°ãªæ ¹æ‹ ã€ã‚·ãƒŠãƒªã‚ªåˆ†æã€ãƒªã‚¹ã‚¯è¦å› ã‚’è«–ç†çš„ã«å±•é–‹ã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"4. **å®¢è¦³æ€§**: äºˆæ¸¬ã‚’è¡Œã†å ´åˆã¯ã€æ–­å®šã‚’é¿ã‘ã€è¤‡æ•°ã®ã‚·ãƒŠãƒªã‚ªï¼ˆæ¥½è¦³ã€æ‚²è¦³ã€ä¸­ç«‹ï¼‰ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"5. **å¼•ç”¨**: æ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸå ´åˆã¯ã€å¿…ãšæƒ…å ±æºã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚\"\n                )\n\n                final_answer = \"\"\n                grounding_metadata = None\n                \n                # =========================\n                # ãƒ¢ãƒ¼ãƒ‰è¨­å®šã®è§£æ\n                # =========================\n                # Î²1é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ä»¥å¤–ã¯ãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œ\n                enable_research = \"Î²1\" not in response_mode\n                enable_meta = \"ãƒ¡ã‚¿\" in response_mode or \"MAX\" in response_mode\n                enable_strict = \"é¬¼è»æ›¹\" in response_mode or \"MAX\" in response_mode\n                enable_grok_x_search = \"grokæ¤œç´¢å¼·åŒ–ç‰ˆ\" in response_mode\n\n                # =========================\n                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (é«˜é€Ÿ / é¬¼è»æ›¹)\n                # =========================\n                if not enable_research:\n                    config = types.GenerateContentConfig(\n                        temperature=0.7,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=base_system_instruction,\n                    )\n                    \n                    status_container.write(\"å›ç­”ç”Ÿæˆä¸­...\")\n                    response = client.models.generate_content(\n                        model=model_id,\n                        contents=contents_for_model,\n                        config=config,\n                    )\n                    \n                    final_answer = extract_text_from_response(response)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®—\n                    if response.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            response.usage_metadata.prompt_token_count,\n                            response.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += response.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += response.usage_metadata.candidates_token_count\n\n                    # é¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ (é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ç‰ˆ)\n                    if enable_strict:\n                        status_container.write(\"ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        reviewer_instruction = base_system_instruction + \"\"\"\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n                        review_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\nåˆç‰ˆå›ç­”:\\n{final_answer}\\n\\nãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\")])]\n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=types.GenerateContentConfig(temperature=0.1, candidate_count=1, system_instruction=reviewer_instruction)\n                        )\n                        final_answer = extract_text_from_response(review_resp)\n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        \n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(model_id, review_resp.usage_metadata.prompt_token_count, review_resp.usage_metadata.candidates_token_count)\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n\n                # =========================\n                # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰\n                # =========================\n                else:\n                    # =========================\n                    # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰: å¤šæ®µéšã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ \n                    # =========================\n                    \n                    # --- Phase 1: ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 1: ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    import datetime as dt\n                    current_year = dt.datetime.now().year\n                    \n                    research_instruction = base_system_instruction + f\"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒªã‚µãƒ¼ãƒå°‚ä»»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚æœ€çµ‚å›ç­”ã¯æ›¸ã‹ãšã€äº‹å®Ÿåé›†ã«é›†ä¸­ã™ã‚‹ã“ã¨ã€‚\n\n**èª¿æŸ»è¦³ç‚¹**:\n- è³ªå•ã«é–¢é€£ã™ã‚‹**æœ€æ–°ã®äº‹å®Ÿãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ»çµ±è¨ˆ**ï¼ˆ**{current_year}å¹´ã®æƒ…å ±ã‚’æœ€å„ªå…ˆ**ï¼‰\n- **ç¾æ™‚ç‚¹ã§å­˜åœ¨ã™ã‚‹å…¨ã¦ã®é¸æŠè‚¢ãƒ»ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¶²ç¾…çš„ã«èª¿æŸ»**ï¼ˆä¾‹: è£½å“æ¯”è¼ƒãªã‚‰ã€æœ€æ–°ç‰ˆã ã‘ã§ãªãç›´è¿‘ã®å…¨ä¸–ä»£ã‚’èª¿æŸ»ï¼‰\n- å…¬å¼æƒ…å ±ã‚„ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã‹ã‚‰ã®å¼•ç”¨\n- é–¢é€£ã™ã‚‹èƒŒæ™¯æƒ…å ±ã‚„æ–‡è„ˆ\n- ç«¶åˆãƒ»ä»£æ›¿æ¡ˆãƒ»æ¯”è¼ƒå¯¾è±¡ã®**å®Œå…¨ãªãƒªã‚¹ãƒˆ**\n- ãƒªã‚¹ã‚¯ãƒ»åˆ¶ç´„ãƒ»æ³¨æ„ç‚¹ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n- å‚è€ƒã«ã—ãŸä¸»è¦ãªæƒ…å ±æºã®URL\n\n**é‡è¦**: \n- çµè«–ã‚„æ¨å¥¨ã¯æ›¸ã‹ãšã€å¾Œå·¥ç¨‹ãŒåˆ¤æ–­ã§ãã‚‹èª¿æŸ»ãƒ¡ãƒ¢ã«é›†ä¸­ã™ã‚‹ã“ã¨\n- **å¿…ãšæ¤œç´¢æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã€æœ€æ–°ã®æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã“ã¨**\n- **æ¤œç´¢çµæœã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æ—¥ä»˜ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒ»ãƒ¢ãƒ‡ãƒ«åã‚’å„ªå…ˆçš„ã«è¨˜è¼‰ã™ã‚‹ã“ã¨**\n- **æ¯”è¼ƒå¯¾è±¡ã¨ãªã‚‹é¸æŠè‚¢ã‚’è¦‹è½ã¨ã•ãªã„ã‚ˆã†ã€è¤‡æ•°ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è©¦ã™ã“ã¨**ï¼ˆä¾‹: ã€ŒiPhone æœ€æ–°ãƒ¢ãƒ‡ãƒ« {current_year}ã€ã€ŒiPhone {current_year}å¹´ç™ºå£²ã€ãªã©ï¼‰\n- **ã€Œã“ã‚Œã‚ˆã‚Šæ–°ã—ã„ãƒ¢ãƒ‡ãƒ«/ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯å­˜åœ¨ã—ãªã„ã‹ï¼Ÿã€ã‚’å¸¸ã«ç¢ºèªã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ï¼ˆ{current_year-1}å¹´ä»¥å‰ãªã©ï¼‰ã—ã‹è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãã®æ—¨ã‚’æ˜è¨˜ã™ã‚‹ã“ã¨\n\"\"\"\n\n                    # éå»ã®é–¢é€£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—\n                    past_context = get_relevant_context(prompt, st.session_state.sessions, st.session_state.current_session_id)\n                    \n                    # ãƒªã‚µãƒ¼ãƒç”¨ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ§‹ç¯‰\n                    import datetime as dt\n                    current_date = dt.datetime.now().strftime(\"%Yå¹´%mæœˆ%dæ—¥\")\n                    research_parts = [types.Part(text=(\n                        f\"é‡è¦: ä»Šæ—¥ã¯{current_date}ã§ã™ã€‚ã“ã®æ—¥ä»˜ã‚ˆã‚Šæ–°ã—ã„æƒ…å ±ã‚’å„ªå…ˆã—ã¦ãã ã•ã„ã€‚\\n\\n\"\n                        f\"è³ªå•: {prompt}\"\n                    ))]\n                    \n                    if past_context:\n                        research_parts.insert(0, types.Part(text=\"ä»¥ä¸‹ã¯éå»ã®é–¢é€£ãƒãƒ£ãƒƒãƒˆã‹ã‚‰æŠ½å‡ºã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã™ï¼š\\n\\n\" + past_context))\n                    \n                    research_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=research_parts)\n                    ]\n                    \n                    research_config = types.GenerateContentConfig(\n                        temperature=0.4,  # æœ€æ–°æƒ…å ±ã‚’æŸ”è»Ÿã«æ¡ç”¨ã™ã‚‹ãŸã‚0.2â†’0.4ã«ä¸Šæ˜‡\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=research_instruction,\n                    )\n                    \n                    research_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=research_contents,\n                        config=research_config,\n                    )\n                    \n                    research_text = extract_text_from_response(research_resp)\n                    \n                    # ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºã®ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ±ã‚’ä¿å­˜\n                    if research_resp.candidates and research_resp.candidates[0].grounding_metadata:\n                        grounding_metadata = research_resp.candidates[0].grounding_metadata\n                    \n                    status_container.write(\"âœ“ ãƒªã‚µãƒ¼ãƒå®Œäº†\")\n                    with status_container.expander(\"åé›†ã—ãŸèª¿æŸ»ãƒ¡ãƒ¢\", expanded=False):\n                        st.markdown(research_text)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1)\n                    if research_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            research_resp.usage_metadata.prompt_token_count,\n                            research_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += research_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += research_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 1.5: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    questions_text = \"\"\n                    if enable_meta:\n                        status_container.write(\"Phase 1.5: ãƒ¡ã‚¿è³ªå•ç”Ÿæˆä¸­...\")\n                        \n                        question_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ç›®çš„**: \nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•ã¨èª¿æŸ»ãƒ¡ãƒ¢ã‚’è¸ã¾ãˆã¦ã€ã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±ãç†è§£ã™ã‚‹ãŸã‚ã®ã€Œé‹­ã„ã‚µãƒ–è³ªå•ã€ã‚’ä½œæˆã™ã‚‹ã“ã¨ã€‚\n\n**ãƒ«ãƒ¼ãƒ«**:\n- æœ€å¤§5å€‹ã¾ã§\n- å„è³ªå•ã¯1-2è¡Œã§å…·ä½“çš„ã‹ã¤é‹­ã\n- ä»¥ä¸‹ã®è¦³ç‚¹ã‚’æ„è­˜:\n  1. å‰æãŒå´©ã‚Œã‚‹å¯èƒ½æ€§ã¯ã©ã“ã‹ï¼Ÿ\n  2. å¼·æ°—/å¼±æ°—ã‚·ãƒŠãƒªã‚ªã®åˆ†å²ç‚¹ã¯ä½•ã‹ï¼Ÿ\n  3. ç«¶åˆãƒ»æŠ€è¡“ãƒ»è¦åˆ¶ã®ä¸ç¢ºå®Ÿæ€§ã¯ï¼Ÿ\n  4. ã€Œäºˆæ¸¬ãŒå¤–ã‚Œã‚‹ã¨ã—ãŸã‚‰ã©ã‚“ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ï¼Ÿã€\n\n**å‡ºåŠ›**: ç®‡æ¡æ›¸ãï¼ˆQ1, Q2...ï¼‰ã®ã¿\n\"\"\"\n\n                        question_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•:\\n{prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\nã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±æ˜ã‚Šã™ã‚‹ãŸã‚ã®é‡è¦ãªã‚µãƒ–è³ªå•ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\")])]\n                        \n                        question_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=question_contents,\n                            config=types.GenerateContentConfig(\n                                temperature=0.4,\n                                candidate_count=1,\n                                system_instruction=question_instruction,\n                            )\n                        )\n                        \n                        questions_text = extract_text_from_response(question_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¡ã‚¿è³ªå•ç”Ÿæˆå®Œäº†\")\n                        with status_container.expander(\"ç”Ÿæˆã•ã‚ŒãŸãƒ¡ã‚¿è³ªå•\", expanded=False):\n                            st.markdown(questions_text)\n                        \n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += question_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += question_resp.usage_metadata.candidates_token_count\n\n                    # å¤šå±¤+puterãƒ¢ãƒ¼ãƒ‰ã®é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã‹ãƒã‚§ãƒƒã‚¯\n                    is_puter_onigunsou = (\n                        mode_category == \"Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter)\" and\n                        response_mode == \"1. ç†Ÿè€ƒ + é¬¼è»æ›¹\"\n                    )\n\n                    # --- Phase 1.5b: Grok ç‹¬ç«‹æ€è€ƒ (å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    # --- Phase 1.5b: Grok ç‹¬ç«‹æ€è€ƒ (å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    grok_thought = \"\"\n                    grok_status = \"skipped\"\n                    if enable_meta and OPENROUTER_API_KEY:\n                        status_container.write(\"Phase 1.5b: Grok ç‹¬ç«‹æ€è€ƒä¸­...\")\n                        try:\n                            grok_thought = think_with_grok(prompt, research_text, enable_x_search=enable_grok_x_search)\n                            if grok_thought:\n                                grok_status = \"success\"\n                                status_container.write(\"âœ“ Grok 4.1 Fast Free ç‹¬ç«‹æ€è€ƒå®Œäº†\")\n                                with status_container.expander(\"Grokã®ç‹¬ç«‹å›ç­”æ¡ˆ\", expanded=False):\n                                    st.markdown(grok_thought)\n                            else:\n                                grok_status = \"empty\"\n                        except Exception as e:\n                            grok_status = \"error\"\n                            status_container.write(f\"âš  Grokæ€è€ƒã‚¨ãƒ©ãƒ¼: {e}\")\n\n                    # --- Phase 1.5c: Claude Opus 4.5 ç‹¬ç«‹æ€è€ƒ (å¤šå±¤+puterã®é¬¼è»æ›¹ã®ã¿) ---\n                    # --- Phase 1.5c: Claude Opus 4.5 ç‹¬ç«‹æ€è€ƒ (å¤šå±¤+puterã®é¬¼è»æ›¹ã®ã¿) ---\n                    claude_thought = \"\"\n                    claude_status = \"skipped\"\n                    if is_puter_onigunsou and PUTER_USERNAME and PUTER_PASSWORD:\n                        status_container.write(\"Phase 1.5c: Claude Opus 4.5 ç‹¬ç«‹æ€è€ƒä¸­...\")\n                        try:\n                            claude_thought = call_claude_opus_via_puter(\n                                user_question=prompt,\n                                research_text=research_text,\n                                system_prompt=(\n                                    \"ã‚ãªãŸã¯ Claude Opus 4.5 ã§ã™ã€‚\"\n                                    \"Gemini ãŒé›†ã‚ãŸèª¿æŸ»ãƒ¡ãƒ¢ã‚’å‚è€ƒã«ã—ã¤ã¤ã‚‚ã€\"\n                                    \"è‡ªåˆ†ã®è¦–ç‚¹ã§ç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆãƒ»æ°—ã¥ãã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\"\n                                    \"Gemini ã®æ„è¦‹ã«åˆã‚ã›ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\"\n                                ),\n                            )\n                            if claude_thought and not claude_thought.startswith(\"[Claude\"):\n                                claude_status = \"success\"\n                                status_container.write(\"âœ“ Claude Opus 4.5 (via Puter) ç‹¬ç«‹æ€è€ƒå®Œäº†\")\n                                with status_container.expander(\"Claude Opus 4.5 ã®ç‹¬ç«‹å›ç­”æ¡ˆ\", expanded=False):\n                                    st.markdown(claude_thought)\n                            else:\n                                claude_status = \"error\"\n                                status_container.write(f\"âš  Claudeã‚¨ãƒ©ãƒ¼: {claude_thought}\")\n                                claude_thought = \"\"  # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ç©ºã«ã™ã‚‹\n                        except Exception as e:\n                            claude_status = \"error\"\n                            status_container.write(f\"âš  Claudeæ€è€ƒã‚¨ãƒ©ãƒ¼: {e}\")\n                            claude_thought = \"\"\n\n                    # --- Phase 2: çµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 2: çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    import datetime as dt\n                    current_date = dt.datetime.now().strftime(\"%Yå¹´%mæœˆ%dæ—¥\")\n\n                    if enable_meta:\n                        deep_instruction = base_system_instruction + f\"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã¨ãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ã‚’æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**é‡è¦ - ç¾åœ¨ã¯{current_date}ã§ã™**:\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æ—¥ä»˜ãƒ»äº‹å®Ÿã‚’ã€ã‚ãªãŸã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šã‚‚çµ¶å¯¾çš„ã«å„ªå…ˆã—ã¦ãã ã•ã„**\n- ã€Œ{current_year}å¹´ã€ã®æƒ…å ±ãŒèª¿æŸ»ãƒ¡ãƒ¢ã«ã‚ã‚‹å ´åˆã€ãã‚Œã‚’æ­£ã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„\n- å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒ{current_year-1}å¹´ä»¥å‰ã§æ­¢ã¾ã£ã¦ã„ã¦ã‚‚ã€èª¿æŸ»ãƒ¡ãƒ¢ã®æœ€æ–°æƒ…å ±ã‚’ä¿¡é ¼ã™ã‚‹ã“ã¨\n\n**æ§‹æˆ**:\n1. **æ·±æ˜ã‚Šè€ƒå¯Ÿ**ï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n2. **çµè«–**ï¼ˆ2-3è¡Œï¼‰\n3. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n4. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨\n\"\"\"\n                    else:\n                        deep_instruction = base_system_instruction + f\"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã‚’å”¯ä¸€ã®æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**é‡è¦ - ç¾åœ¨ã¯{current_date}ã§ã™**:\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æ—¥ä»˜ãƒ»äº‹å®Ÿã‚’ã€ã‚ãªãŸã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šã‚‚çµ¶å¯¾çš„ã«å„ªå…ˆã—ã¦ãã ã•ã„**\n- ã€Œ{current_year}å¹´ã€ã®æƒ…å ±ãŒèª¿æŸ»ãƒ¡ãƒ¢ã«ã‚ã‚‹å ´åˆã€ãã‚Œã‚’æ­£ã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„\n\n**æ§‹æˆ**:\n1. **çµè«–**ï¼ˆ2-3è¡Œã§æ˜ç¢ºã«ï¼‰\n2. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n3. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«åã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ã¨æ–°ã—ã„æƒ…å ±ãŒæ··åœ¨ã™ã‚‹å ´åˆã¯ã€æ–°ã—ã„æƒ…å ±ã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n\"\"\"\n                    \n                    synthesis_prompt_text = (\n                        f\"é‡è¦: ä»Šæ—¥ã¯{current_date}ã§ã™ã€‚å¤ã„æƒ…å ±ã‚’å›ç­”ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚\\n\\n\"\n                        f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}\\n\\n\"\n                        f\"==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                    )\n                    \n                    if enable_meta and questions_text:\n                        synthesis_prompt_text += f\"==== ãƒ¡ã‚¿è³ªå•ä¸€è¦§ ====\\n{questions_text}\\n==== ãƒ¡ã‚¿è³ªå•ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if enable_meta and grok_thought:\n                        synthesis_prompt_text += f\"==== åˆ¥è¦–ç‚¹ã‹ã‚‰ã®å›ç­”æ¡ˆ (Grok) ====\\n{grok_thought}\\n==== åˆ¥è¦–ç‚¹ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if is_puter_onigunsou and claude_thought:\n                        synthesis_prompt_text += f\"==== åˆ¥è¦–ç‚¹ã‹ã‚‰ã®å›ç­”æ¡ˆ (Claude Opus 4.5 via Puter) ====\\n{claude_thought}\\n==== Claudeåˆ¥è¦–ç‚¹ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    # çµ±åˆæŒ‡ç¤º\n                    if enable_meta and (grok_thought or claude_thought):\n                        synthesis_prompt_text += \"æŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n2. Grok\"\n                        if is_puter_onigunsou and claude_thought:\n                            synthesis_prompt_text += \" / Claude\"\n                        synthesis_prompt_text += \" ã®å›ç­”æ¡ˆã‚‚å‚è€ƒã«ã—ã¤ã¤ï¼ˆãŸã ã—ç›²ä¿¡ã›ãšï¼‰ã€ç‹¬è‡ªã®è¦–ç‚¹ã§çµ±åˆã—ã¦ãã ã•ã„ã€‚\\n3. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»åˆ†æãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    elif enable_meta and questions_text:\n                        synthesis_prompt_text += \"æŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n2. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»åˆ†æãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    else:\n                        synthesis_prompt_text += \"ä¸Šè¨˜ãƒ¡ãƒ¢ã‚’æ ¹æ‹ ã«ã€æœ€çµ‚å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å¿…ãšä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚**\"\n\n                    synthesis_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=[\n                            types.Part(text=synthesis_prompt_text)\n                        ])\n                    ]\n                    \n                    synthesis_config = types.GenerateContentConfig(\n                        temperature=0.3,\n                        candidate_count=1,\n                        tools=[],  # çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºã§ã¯æ¤œç´¢OFF\n                        system_instruction=deep_instruction,\n                    )\n                    \n                    synthesis_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=synthesis_contents,\n                        config=synthesis_config,\n                    )\n                    \n                    draft_answer = extract_text_from_response(synthesis_resp)\n                    \n                    status_container.write(\"âœ“ çµ±åˆå®Œäº†\")\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 2)\n                    if synthesis_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            synthesis_resp.usage_metadata.prompt_token_count,\n                            synthesis_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += synthesis_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += synthesis_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    if enable_strict:\n                        status_container.write(\"Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        \n\n                        reviewer_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™ã€‚ãŸã ã—ã€**èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’å„ªå…ˆã—ã€æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã™ã‚‹ã“ã¨**ã€‚\n\n**ãƒ¬ãƒ“ãƒ¥ãƒ¼è¦³ç‚¹**:\n- äº‹å®Ÿã¨æ¨æ¸¬ã‚’æ˜ç¢ºã«åˆ†ã‘ã‚‹\n- éåº¦ã«è‡ªä¿¡ã®ã‚ã‚‹æ–­å®šã‚’å¼±ã‚ã‚‹\n- æ•°å­—ã‚„å›ºæœ‰åè©ãŒèª¿æŸ»ãƒ¡ãƒ¢ã¨çŸ›ç›¾ã—ã¦ã„ãªã„ã‹ç¢ºèª\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ãƒ¢ãƒ‡ãƒ«ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ãŒæ­£ã—ãä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª**\n- **å¤ã„æƒ…å ±ã§ä¸Šæ›¸ãã—ã¦ã„ãªã„ã‹ç¢ºèª**\n- è¦‹è½ã¨ã—ã¦ã„ã‚‹é‡è¦ãªãƒªã‚¹ã‚¯ãƒ»ã‚·ãƒŠãƒªã‚ªãŒã‚ã‚Œã°è¿½åŠ \n\n**é‡è¦**: \n- èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ãŒæœ€æ–°ã§ã‚ã‚‹å ´åˆã€ãã‚Œã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n- ã‚ãªãŸã®çŸ¥è­˜ãŒå¤ã„å ´åˆã¯ã€èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’ä¿¡é ¼ã™ã‚‹ã“ã¨\n\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n\n                        review_contents = [\n                            types.Content(role=\"user\", parts=[\n                                types.Part.from_text(\n                                    text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\n\"\n                                    f\"==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                                    f\"åˆç‰ˆå›ç­”:\\n{draft_answer}\\n\\n\"\n                                    \"ä¸Šè¨˜ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚**\"\n                                )\n                            ])\n                        ]\n                        \n                        review_config = types.GenerateContentConfig(\n                            temperature=0.1,\n                            candidate_count=1,\n                            system_instruction=reviewer_instruction,\n                            thinking_config=types.ThinkingConfig(\n                                thinking_level=types.ThinkingLevel.HIGH\n                            ),\n                        )\n                        \n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=review_config,\n                        )\n                        \n                        final_answer = extract_text_from_response(review_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        \n                        # --- Phase 3b: Groké¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ (å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ + é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰å…¨èˆ¬) ---\n                        # å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã§ã€ã‹ã¤é¬¼è»æ›¹ç³»ã®ãƒ¢ãƒ¼ãƒ‰ï¼ˆé¬¼è»æ›¹ã€ãƒ¡ã‚¿æ€è€ƒã€æœ¬æ°—MAXï¼‰ã§ç™ºå‹•\n                        use_grok_reviewer = (mode_category == \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\" and enable_strict)\n                        \n                        if use_grok_reviewer and OPENROUTER_API_KEY:\n                            status_container.write(\"Phase 3b: Grok 4.1 Fast ã§æœ€çµ‚ãƒã‚§ãƒƒã‚¯ä¸­...\")\n                            try:\n                                grok_answer = review_with_grok(prompt, final_answer, research_text)\n                                # Grokä½¿ç”¨æ™‚ã¯ã€ãƒ¢ãƒ‡ãƒ«åã‚’æ˜ç¤ºã—ã€2æ®µæ§‹æˆã§è¡¨ç¤º\n                                final_answer = (\n                                    f\"**ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_id} (Deep Thinking / High Reasoning)**\\n\"\n                                    f\"**ãƒ¬ãƒ“ãƒ¥ã‚¢: Grok 4.1 Fast (free)**\\n\"\n                                    f\"**ãƒ¢ãƒ¼ãƒ‰: {response_mode}**\\n\\n\"\n                                    \"---\\n\\n\"\n                                    \"## âœ… æœ€çµ‚å›ç­”ï¼ˆGeminiçµ±åˆç‰ˆï¼‰\\n\\n\"\n                                    f\"{final_answer}\\n\\n\"\n                                    \"---\\n\\n\"\n                                    \"## ğŸ” Grok ã«ã‚ˆã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼\\n\\n\"\n                                    f\"{grok_answer}\"\n                                )\n                                status_container.write(\"âœ“ Grokæœ€çµ‚ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                            except Exception as e:\n                                status_container.write(f\"âš  Grokãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}\")\n                        else:\n                            # Geminiã®ã¿ã®å ´åˆã‚‚ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤ºï¼ˆå¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆï¼‰\n                            if mode_category == \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\":\n                                final_answer = (\n                                    f\"**ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_id} (Deep Thinking / High Reasoning)**\\n\"\n                                    f\"**ãƒ¢ãƒ¼ãƒ‰: {response_mode}**\\n\\n---\\n\\n{final_answer}\"\n                                )\n                        \n                        # --- ãƒ¡ã‚¿æ€è€ƒãƒ¢ãƒ¼ãƒ‰: çµè«–ã‚’å…ˆå‡ºã—ã™ã‚‹ ---\n                        if \"ãƒ¡ã‚¿æ€è€ƒ\" in response_mode:\n                            # çµè«–éƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆç°¡æ˜“çš„ãªå®Ÿè£…ï¼‰\n                            # \"çµè«–\"ã‚„\"ã¾ã¨ã‚\"ãªã©ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¢ã—ã¦å…ˆé ­ã«ç§»å‹•\n                            lines = final_answer.split('\\n')\n                            conclusion_start = -1\n                            for i, line in enumerate(lines):\n                                if any(keyword in line for keyword in ['## çµè«–', '## ã¾ã¨ã‚', '**çµè«–**', '**ã¾ã¨ã‚**']):\n                                    conclusion_start = i\n                                    break\n                            \n                            if conclusion_start != -1:\n                                # çµè«–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¦‹ã¤ã‘ãŸå ´åˆã€ãã‚Œã‚’å…ˆé ­ã«ç§»å‹•\n                                conclusion_section = []\n                                other_content = lines[:conclusion_start]\n                                \n                                # çµè«–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®çµ‚ã‚ã‚Šã‚’è¦‹ã¤ã‘ã‚‹ï¼ˆæ¬¡ã®##ã¾ã§ or æ–‡æœ«ï¼‰\n                                conclusion_end = len(lines)\n                                for i in range(conclusion_start + 1, len(lines)):\n                                    if lines[i].startswith('## ') and i != conclusion_start:\n                                        conclusion_end = i\n                                        break\n                                \n                                conclusion_section = lines[conclusion_start:conclusion_end]\n                                remaining_content = lines[conclusion_end:]\n                                \n                                # å†æ§‹æˆ: ãƒ¢ãƒ‡ãƒ«å â†’ çµè«– â†’ ãã®ä»–ã®è©³ç´°\n                                # ãƒ¢ãƒ‡ãƒ«åéƒ¨åˆ†ã‚’ä¿æŒ\n                                model_line = \"\"\n                                if lines[0].startswith(\"**ğŸ¤–\"):\n                                    model_line = lines[0]\n                                    other_content = lines[1:conclusion_start]\n                                \n                                final_answer = '\\n'.join([\n                                    model_line,\n                                    \"\",\n                                    \"---\",\n                                    \"\",\n                                    \"## ğŸ“Œ çµè«–ï¼ˆå…ˆå‡ºã—ï¼‰\",\n                                    *conclusion_section[1:],  # å…ƒã®è¦‹å‡ºã—ã‚’é™¤ã\n                                    \"\",\n                                    \"---\",\n                                    \"\",\n                                    \"## ğŸ“ è©³ç´°\",\n                                    *other_content,\n                                    *remaining_content\n                                ]).strip()\n                        \n                        with status_container.expander(\"åˆç‰ˆã¨ã®æ¯”è¼ƒ\", expanded=False):\n                            st.markdown(\"**åˆç‰ˆ:**\")\n                            st.markdown(draft_answer[:500] + \"...\" if len(draft_answer) > 500 else draft_answer)\n                            st.markdown(\"**ä¿®æ­£ç‰ˆ:**\")\n                            st.markdown(final_answer[:500] + \"...\" if len(final_answer) > 500 else final_answer)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 3)\n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                review_resp.usage_metadata.prompt_token_count,\n                                review_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n                    else:\n                        final_answer = draft_answer\n\n                save_usage(usage_stats)\n                status_container.update(label=\"å®Œäº†ï¼\", state=\"complete\", expanded=False)\n\n                # ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤º\n                models_used = [f\"Gemini: {model_id}\"]\n                \n                # Grok Status\n                if enable_meta:\n                    if grok_status == \"success\":\n                        models_used.append(\"Grok: 4.1-fast-free (OK)\")\n                    elif grok_status == \"error\":\n                        models_used.append(\"Grok: 4.1-fast-free (Error)\")\n                    elif grok_status == \"empty\":\n                        models_used.append(\"Grok: 4.1-fast-free (Empty)\")\n                \n                # Claude Status\n                if is_puter_onigunsou:\n                    if claude_status == \"success\":\n                        models_used.append(\"Claude: Opus 4.5 (via Puter) (OK)\")\n                    elif claude_status == \"error\":\n                        models_used.append(\"Claude: Opus 4.5 (via Puter) (Error)\")\n                \n                st.caption(f\"ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {' + '.join(models_used)}\")\n                st.markdown(final_answer)\n\n                # ---- ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ± ----\n                if grounding_metadata:\n                    st.markdown(\"---\")\n                    with st.expander(\"ğŸ“š æƒ…å ±æºã¨å¼•ç”¨\", expanded=False):\n                        if grounding_metadata.grounding_chunks:\n                            st.markdown(\"**æ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:**\")\n                            unique_sources = {}\n                            import urllib.parse\n\n                            for chunk in grounding_metadata.grounding_chunks:\n                                if getattr(chunk, \"web\", None):\n                                    uri = getattr(chunk.web, \"uri\", None)\n                                    title = getattr(chunk.web, \"title\", \"æƒ…å ±æº\")\n                                    if uri and uri not in unique_sources:\n                                        parsed = urllib.parse.urlparse(uri)\n                                        domain = parsed.netloc.replace(\"www.\", \"\")\n                                        unique_sources[uri] = {\n                                            \"title\": title,\n                                            \"domain\": domain,\n                                        }\n                            for i, (uri, info) in enumerate(unique_sources.items(), 1):\n                                st.markdown(f\"{i}. **[{info['title']}]({uri})**\")\n                                st.caption(f\"   å‡ºå…¸: {info['domain']}\")\n\n                messages.append({\"role\": \"model\", \"content\": final_answer})\n                update_current_session_messages(messages)\n\n            except Exception as e:\n                status_container.update(label=\"Error\", state=\"error\")\n                err_text = str(e)\n                if \"RESOURCE_EXHAUSTED\" in err_text or \"429\" in err_text:\n                    st.error(\n                        \"âš ï¸ Vertex AI / Gemini ã®ã‚¯ã‚©ãƒ¼ã‚¿ã«é”ã—ã¾ã—ãŸã€‚\\n\\n\"\n                        \"ãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ / æ—¥æ¬¡åˆ¶é™ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\\n\"\n                        \"ãƒ»ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                        \"ãƒ»Google Cloud Console ã®ã€ŒVertex AI â†’ ä½¿ç”¨çŠ¶æ³ã€ã‹ã‚‰ã‚¯ã‚©ãƒ¼ã‚¿çŠ¶æ³ã‚’ç¢ºèªã§ãã¾ã™ã€‚\"\n                    )\n                elif \"NOT_FOUND\" in err_text and \"Publisher Model\" in err_text:\n                    st.error(\n                        \"âš ï¸ æŒ‡å®šã—ãŸãƒ¢ãƒ‡ãƒ«ãŒã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ / ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\\n\"\n                        \"ãƒ»ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ¢ãƒ‡ãƒ«IDã‚’ã€2.5ç³» ã¾ãŸã¯ 3 Pro ã«å¤‰æ›´ã—ã¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                    )\n                else:\n                    st.error(f\"An error occurred: {e}\")\n"
                },
                {
                    "role": "model",
                    "content": "**ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: gemini-3-pro-preview (Deep Thinking / High Reasoning)**\n**ãƒ¢ãƒ¼ãƒ‰: 1. ç†Ÿè€ƒ + é¬¼è»æ›¹**\n\n---\n\n## ğŸ“Œ çµè«–ï¼ˆå…ˆå‡ºã—ï¼‰\n\næä¾›ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã¯ã€**2025å¹´12æœˆ01æ—¥æ™‚ç‚¹ã®æŠ€è¡“ç’°å¢ƒã«ãŠã„ã¦ã€æ­£å¸¸ã«å‹•ä½œã™ã‚‹å¯èƒ½æ€§ãŒæ¥µã‚ã¦é«˜ã„**ã§ã™ã€‚\n\nèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãã€ã‚³ãƒ¼ãƒ‰å†…ã§æŒ‡å®šã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã€ŒClaude Opus 4.5ã€ã¯æ—¢ã«ãƒªãƒªãƒ¼ã‚¹æ¸ˆã¿ï¼ˆ2025å¹´11æœˆ24æ—¥ï¼‰ã§ã‚ã‚Šã€ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€Œputergenaiã€ã‚‚å®Ÿåœ¨ã—ã¾ã™ã€‚Streamlitç‰¹æœ‰ã®éåŒæœŸå‡¦ç†ã®ç«¶åˆã‚‚ `nest_asyncio` ã§é©åˆ‡ã«å›é¿ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nãŸã ã—ã€å‹•ä½œã«ã¯ä»¥ä¸‹ã®**2ã¤ã®å‰ææ¡ä»¶**ãŒå¿…é ˆã§ã™ã€‚\n1.  **ç’°å¢ƒæ§‹ç¯‰**: `pip install putergenai nest_asyncio` ãŒå®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹ã“ã¨ã€‚\n2.  **èªè¨¼æƒ…å ±**: Puter.com ã®æœ‰åŠ¹ãªã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼åãƒ»ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ï¼‰ãŒç’°å¢ƒå¤‰æ•°ç­‰ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã€‚\n\n---\n\n## ğŸ“ è©³ç´°åˆ†æ\n\nèª¿æŸ»ãƒ¡ãƒ¢ã®äº‹å®Ÿï¼ˆ2025å¹´12æœˆç¾åœ¨ï¼‰ã¨ã‚³ãƒ¼ãƒ‰ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç…§åˆã—ã€ä»¥ä¸‹ã®é€šã‚Šæ¤œè¨¼ã—ã¾ã—ãŸã€‚\n\n### 1. ãƒ¢ãƒ‡ãƒ«ã¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æ•´åˆæ€§\n*   **Claude Opus 4.5 ã®å®Ÿåœ¨æ€§**:\n    *   èª¿æŸ»ãƒ¡ãƒ¢ã«ã‚ˆã‚Œã°ã€**Claude Opus 4.5ã¯2025å¹´11æœˆ24æ—¥ã«Anthropicç¤¾ã‚ˆã‚Šæ­£å¼ãƒªãƒªãƒ¼ã‚¹**ã•ã‚Œã¦ã„ã¾ã™ã€‚\n    *   ã‚³ãƒ¼ãƒ‰å†…ã®ãƒ¢ãƒ‡ãƒ«ID `\"model\": \"claude-opus-4-5\"` ã¯ã€Puterãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã®å‘½åè¦å‰‡ï¼ˆãƒã‚¤ãƒ•ãƒ³åŒºåˆ‡ã‚Šï¼‰ã¨æ•´åˆã—ã¦ãŠã‚Šã€å¦¥å½“ãªæŒ‡å®šã§ã™ã€‚\n*   **SDK (`putergenai`) ã®å¯¾å¿œ**:\n    *   ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ `putergenai` ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆv0.1.5ä»¥é™ï¼‰ã¯ã€Puter.js APIã®ãƒ©ãƒƒãƒ‘ãƒ¼ã¨ã—ã¦æ©Ÿèƒ½ã—ã€æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã¦ã„ã¾ã™ã€‚\n\n### 2. æŠ€è¡“çš„ãªå®Ÿè£…ã®æ­£å½“æ€§\n*   **éåŒæœŸå‡¦ç†ã®å›é¿ç­– (`nest_asyncio`)**:\n    *   Streamlitã¯å†…éƒ¨ã§ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãŸã‚ã€å˜ç´”ãª `asyncio.run()` ã¯ `RuntimeError` ã‚’å¼•ãèµ·ã“ã—ã¾ã™ã€‚\n    *   ã“ã®ã‚³ãƒ¼ãƒ‰ã§ã¯ã€å†’é ­ã§ `import nest_asyncio; nest_asyncio.apply()` ã‚’å®Ÿè¡Œã—ã¦ãŠã‚Šã€æ—¢å­˜ã®ãƒ«ãƒ¼ãƒ—ã«ãƒ‘ãƒƒãƒã‚’å½“ã¦ã‚‹ã“ã¨ã§ã€åŒæœŸé–¢æ•°å†…ã‹ã‚‰ã®éåŒæœŸå®Ÿè¡Œã‚’å¯èƒ½ã«ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã¯é©åˆ‡ãªå›é¿ç­–ã§ã™ã€‚\n*   **èªè¨¼ãƒ•ãƒ­ãƒ¼**:\n    *   `PuterClient` ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ (`async with`) ã§é–‹ãã€`await client.login(...)` ã‚’å®Ÿè¡Œã™ã‚‹æ‰‹é †ã¯ã€SDKã®æ¨™æº–çš„ãªä½¿ç”¨æ³•ã«æº–æ‹ ã—ã¦ã„ã¾ã™ã€‚\n\n### 3. ãƒ­ã‚¸ãƒƒã‚¯ã®çµ±åˆ\n*   **æ¡ä»¶åˆ†å²**:\n    *   `is_puter_onigunsou` ãƒ•ãƒ©ã‚°ã®åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ã«ã‚ˆã‚Šã€ã€ŒÎ²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter)ã€ã‹ã¤ã€Œ1. ç†Ÿè€ƒ + é¬¼è»æ›¹ã€ãŒé¸æŠã•ã‚ŒãŸå ´åˆã®ã¿ Claude ãŒå‘¼ã³å‡ºã•ã‚Œã‚‹è¨­è¨ˆã¨ãªã£ã¦ãŠã‚Šã€æ„å›³é€šã‚Šã«æ©Ÿèƒ½ã—ã¾ã™ã€‚\n\n## âš ï¸ è€ƒæ…®ã™ã¹ããƒªã‚¹ã‚¯ãƒ»æ³¨æ„ç‚¹\n\nä»¥ä¸‹ã®è¦å› ã«ã‚ˆã‚Šã€å®Ÿè¡Œæ™‚ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n\n1.  **ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä¿¡é ¼æ€§ã¨ä¿å®ˆæ€§**:\n    *   èª¿æŸ»ãƒ¡ãƒ¢ã«ã‚ã‚‹ãƒªãƒã‚¸ãƒˆãƒªåï¼ˆ`Nerve11/putergenai`ï¼‰ã‹ã‚‰ã€ã“ã‚Œã¯Puterå…¬å¼ã§ã¯ãªã**ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ï¼ˆã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£è£½ï¼‰ã®SDKã§ã‚ã‚‹å¯èƒ½æ€§**ãŒã‚ã‚Šã¾ã™ã€‚Puterå´ã®APIä»•æ§˜å¤‰æ›´ï¼ˆç‰¹ã«èªè¨¼å‘¨ã‚Šã‚„ãƒ¢ãƒ‡ãƒ«IDï¼‰ãŒç™ºç”Ÿã—ãŸå ´åˆã€SDKã®å¯¾å¿œãŒé…ã‚Œã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚\n2.  **ãƒ¢ãƒ‡ãƒ«IDã®ä»•æ§˜å¤‰æ›´**:\n    *   Puterå´ã®å®Ÿè£…ã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«IDãŒ `claude-opus-4.5`ï¼ˆãƒ‰ãƒƒãƒˆåŒºåˆ‡ã‚Šï¼‰ã‚„ `claude-3-opus` ç­‰ã§ã‚ã‚‹å¯èƒ½æ€§ã‚‚å®Œå…¨ã«ã¯æ’é™¤ã§ãã¾ã›ã‚“ã€‚`400 Bad Request` ç­‰ã®ã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸå ´åˆã¯ã€IDã®ä¿®æ­£ãŒå¿…è¦ã§ã™ã€‚\n3.  **Puterã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®åˆ¶ç´„**:\n    *   Puterã¯ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ç’°å¢ƒã§ã‚ã‚Šã€APIåˆ©ç”¨ã«ã¯ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼ˆç„¡æ–™æ ã®åˆ¶é™ãªã©ï¼‰ãŒå½±éŸ¿ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n\n### æ¨å¥¨ã•ã‚Œã‚‹ `requirements.txt`\n```text\nstreamlit\ngoogle-genai\npython-dotenv\nPillow\nst-img-pastebutton\nputergenai>=0.1.5\nnest_asyncio\n```"
                }
            ]
        },
        {
            "id": "fdf6d051-f178-4455-bb15-e64bef239d62",
            "title": "ä»¥ä¸‹ã§claudeã¯ã†ã”ãã‹ã€‚Î²ï¼šğŸ¯ å›...",
            "timestamp": "2025-12-01T23:50:07.642174",
            "messages": [
                {
                    "role": "user",
                    "content": "ä»¥ä¸‹ã§claudeã¯ã†ã”ãã‹ã€‚Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter)â†’ç†Ÿè€ƒ + é¬¼è»æ›¹ã®ãƒ¢ãƒ¼ãƒ‰.\n\nimport os\nimport uuid\nimport datetime\nimport streamlit as st\nfrom dotenv import load_dotenv\nfrom google import genai\nfrom google.genai import types\nfrom PIL import Image\nimport io\nfrom logic import (\n    USAGE_FILE, SESSIONS_FILE, MAX_BUDGET_USD, PRICING,\n    VERTEX_PROJECT, VERTEX_LOCATION,\n    load_usage, save_usage, calculate_cost, get_mime_type,\n    extract_youtube_id, get_youtube_transcript, get_relevant_context,\n    extract_text_from_response, load_sessions, save_sessions, get_client\n)\n\ntry:\n    from st_img_pastebutton import paste\n    import_error_msg = None\nexcept ImportError as e:\n    paste = None\n    import_error_msg = str(e)\n\n# =========================\n# ç’°å¢ƒå¤‰æ•° & å®šæ•°\n# =========================\n\nload_dotenv()\n\n\n\nst.set_page_config(page_title=\"Gemini 3 Web Studio\", layout=\"wide\")\n\n# ğŸ” ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ­ãƒƒã‚¯ (198501) + URLãƒˆãƒ¼ã‚¯ãƒ³æ°¸ç¶šåŒ–\nSECRET_TOKEN = \"access_granted_198501\"\n\n# 1. URLãƒˆãƒ¼ã‚¯ãƒ³ãƒã‚§ãƒƒã‚¯\nquery_params = st.query_params\nurl_token = query_params.get(\"auth\", None)\n\nif url_token == SECRET_TOKEN:\n    st.session_state.authenticated = True\nelif \"authenticated\" not in st.session_state:\n    st.session_state.authenticated = False\n\n# 2. æœªèªè¨¼ãªã‚‰ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ç”»é¢\nif not st.session_state.authenticated:\n    st.title(\"Gemini 3 Studio\")\n    st.write(\"ã“ã®ã‚¢ãƒ—ãƒªã‚’åˆ©ç”¨ã™ã‚‹ã«ã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒå¿…è¦ã§ã™ã€‚\")\n\n    password = st.text_input(\"ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰\", type=\"password\")\n\n    if st.button(\"ãƒ­ã‚°ã‚¤ãƒ³\"):\n        if password == \"198501\":\n            st.session_state.authenticated = True\n            # URLã«ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä»˜ä¸ã—ã¦ãƒªãƒ­ãƒ¼ãƒ‰ï¼ˆã“ã‚Œã§ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯å¯èƒ½ã«ãªã‚‹ï¼‰\n            st.query_params[\"auth\"] = SECRET_TOKEN\n            st.rerun()\n        else:\n            st.error(\"ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™ã€‚\")\n\n    st.stop()\n\n# =========================\n# Helper Functions\n# =========================\n\n# =========================\n# Helper Functions\n# =========================\n# Moved to logic.py\n\n# =========================\n# Grok Review Function (OpenRouter API)\n# =========================\n\nimport requests\nfrom curl_cffi import requests as crequests  # Grokç”¨ï¼ˆå¿…è¦ã«å¿œã˜ã¦æ®‹ã™ï¼‰\nimport asyncio\nimport nest_asyncio\nfrom putergenai import PuterClient\n\n# Streamlitã§Asyncã‚’ä½¿ã†ãŸã‚ã®è¨­å®š\nnest_asyncio.apply()\n\n# OpenRouter API Keyã®å–å¾— (st.secretså„ªå…ˆã€ãªã‘ã‚Œã°ç’°å¢ƒå¤‰æ•°)\ntry:\n    if \"OPENROUTER_API_KEY\" in st.secrets:\n        OPENROUTER_API_KEY = st.secrets[\"OPENROUTER_API_KEY\"]\n    else:\n        OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\", \"\")\nexcept:\n    OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\", \"\")\n\n# Puter èªè¨¼æƒ…å ±\nPUTER_USERNAME = None\nPUTER_PASSWORD = None\ntry:\n    if \"PUTER_USERNAME\" in st.secrets:\n        PUTER_USERNAME = st.secrets[\"PUTER_USERNAME\"]\n        PUTER_PASSWORD = st.secrets[\"PUTER_PASSWORD\"]\n    else:\n        PUTER_USERNAME = os.getenv(\"PUTER_USERNAME\")\n        PUTER_PASSWORD = os.getenv(\"PUTER_PASSWORD\")\nexcept Exception:\n    PUTER_USERNAME = os.getenv(\"PUTER_USERNAME\")\n    PUTER_PASSWORD = os.getenv(\"PUTER_PASSWORD\")\n\ndef review_with_grok(user_question: str, gemini_answer: str, research_text: str = None) -> str:\n    \"\"\"\n    Grok 4.1 Fast Free ã‚’ä½¿ã£ã¦ã€Geminiã®å›ç­”ã‚’æœ€çµ‚ãƒ¬ãƒ“ãƒ¥ãƒ¼ã™ã‚‹\n    research_text: GeminiãŒåé›†ã—ãŸèª¿æŸ»ãƒ¡ãƒ¢ï¼ˆæœ€æ–°æƒ…å ±ã‚’å«ã‚€ï¼‰\n    \"\"\"\n    url = \"https://openrouter.ai/api/v1/chat/completions\"\n    headers = {\n        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n        \"Content-Type\": \"application/json\",\n    }\n    \n    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰\n    user_content = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\\n{user_question}\\n\\n\"\n    \n    if research_text:\n        user_content += f\"Gemini ã®èª¿æŸ»ãƒ¡ãƒ¢ï¼ˆæœ€æ–°æƒ…å ±ï¼‰:\\n{research_text}\\n\\n\"\n    \n    user_content += (\n        f\"Gemini ã®æœ€çµ‚å›ç­”:\\n{gemini_answer}\\n\\n\"\n        \"**é‡è¦**: èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹äº‹å®Ÿã®æ–¹ã‚’ã€ã‚ãªãŸè‡ªèº«ã®çŸ¥è­˜ã‚ˆã‚Šã‚‚å„ªå…ˆã—ã¦ãã ã•ã„ã€‚\\n\"\n        \"æœ€æ–°ã®æƒ…å ±ãŒèª¿æŸ»ãƒ¡ãƒ¢ã«ã‚ã‚‹å ´åˆã€ãã‚Œã‚’ä¿¡é ¼ã—ã¦ãã ã•ã„ã€‚\\n\\n\"\n        \"1. **é‡å¤§ãªäº‹å®Ÿèª¤èªãƒ»è«–ç†é£›èºã®æŒ‡æ‘˜**ï¼ˆãªã‘ã‚Œã°ã€ç‰¹ã«ãªã—ã€ï¼‰\\n\"\n        \"2. **å…·ä½“çš„ãªä¿®æ­£ææ¡ˆã®ãƒªã‚¹ãƒˆ**ï¼ˆã€ä¿®æ­£å‰ã€â†’ã€ä¿®æ­£å¾Œã€ã®å½¢å¼ã§ï¼‰\\n\"\n        \"3. **ç‰¹ã«ä¸ç¢ºå®Ÿæ€§ãŒé«˜ã„ãƒã‚¤ãƒ³ãƒˆï¼ˆå‰æä¸è¶³ã€ãƒ‡ãƒ¼ã‚¿ä¸è¶³ãªã©ï¼‰ã® bullet list**\\n\"\n    )\n    \n    data = {\n        \"model\": \"x-ai/grok-4.1-fast:free\",\n        \"reasoning\": {\"enabled\": True},  # Enable multi-step reasoning for deeper review\n        \"messages\": [\n            {\n                \"role\": \"system\",\n                \"content\": (\n                    \"ã‚ãªãŸã¯å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ã§ã™ã€‚\"\n                    \"äº‹å®Ÿèª¤èªãƒ»è«–ç†ã®é£›èºãƒ»æŠœã‘æ¼ã‚Œã‚’å®¹èµ¦ãªãæŒ‡æ‘˜ã—ã€\"\n                    \"å¿…è¦ãªã‚‰å›ç­”ã‚’å…¨æ–‡æ›¸ãç›´ã—ã¦ãã ã•ã„ã€‚\"\n                ),\n            },\n            {\n                \"role\": \"user\",\n                \"content\": user_content.strip() + (\n                    \"ã ã‘ã‚’æ—¥æœ¬èªã§å‡ºã—ã¦ãã ã•ã„ã€‚\"\n                ),\n            },\n        ],\n    }\n    try:\n        resp = requests.post(url, headers=headers, json=data, timeout=60)\n        resp.raise_for_status()\n        j = resp.json()\n        return j[\"choices\"][0][\"message\"][\"content\"]\n    except Exception as e:\n        return f\"[Grokãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}]\\n\\n{gemini_answer}\"\n\n# =========================\n# Session Management\n# =========================\n\n\n\ndef think_with_grok(user_question: str, research_text: str, enable_x_search: bool = False) -> str:\n    \"\"\"\n    Grok 4.1 Fast Free ã‚’ä½¿ã£ã¦ã€ãƒªã‚µãƒ¼ãƒãƒ¡ãƒ¢ã‚’å…ƒã«ç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆã‚’ä½œæˆã™ã‚‹\n    enable_x_search=True ã®å ´åˆã€X/Twitteræƒ…å ±ã®æ´»ç”¨ã‚’ä¿ƒã™\n    \"\"\"\n    url = \"https://openrouter.ai/api/v1/chat/completions\"\n    headers = {\n        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n        \"Content-Type\": \"application/json\",\n    }\n    \n    # Xæ¤œç´¢å¼·åŒ–ç‰ˆã®å ´åˆã€ç‰¹åˆ¥ãªæŒ‡ç¤ºã‚’è¿½åŠ \n    x_search_instruction = \"\"\n    if enable_x_search:\n        x_search_instruction = (\n            \"\\n\\n**é‡è¦**: ã‚ãªãŸã¯Grokã¨ã—ã¦Xï¼ˆTwitterï¼‰ã®æƒ…å ±ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚\\n\"\n            \"ä¸Šè¨˜ã®èª¿æŸ»ãƒ¡ãƒ¢ã«åŠ ãˆã¦ã€Xä¸Šã®æœ€æ–°ã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»è­°è«–ãƒ»åå¿œã‚’è€ƒæ…®ã—ã€\\n\"\n            \"ãã‚Œã‚‰ã‚’å«ã‚ãŸç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\\n\\n\"\n            \"æ³¨æ„: Xä¸Šã®æƒ…å ±ãŒç¢ºèªã§ããªã„å ´åˆã¯ã€ãã®æ—¨ã‚’æ­£ç›´ã«è¿°ã¹ã¦ãã ã•ã„ã€‚\\n\"\n            \"æ¶ç©ºã®æŠ•ç¨¿ã‚„å­˜åœ¨ã—ãªã„åå¿œã‚’ä½œæˆã—ãªã„ã“ã¨ã€‚\"\n        )\n    \n    user_content = (\n        f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\\n{user_question}\\n\\n\"\n        f\"èª¿æŸ»ãƒ¡ãƒ¢:\\n{research_text}\\n\\n\"\n        \"æŒ‡ç¤º:\\n\"\n        \"ã‚ãªãŸã¯Geminiã¨ã¯åˆ¥ã®ç‹¬ç«‹ã—ãŸAIã§ã™ã€‚\\n\"\n        \"ä¸Šè¨˜ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’å‚è€ƒã«ã—ã¤ã¤ã‚‚ã€ã‚ãªãŸè‡ªèº«ã®è¦–ç‚¹ã§ç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\\n\"\n        \"Geminiã®æ„è¦‹ã«åˆã‚ã›ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\"\n        f\"{x_search_instruction}\"\n    )\n    \n    data = {\n        \"model\": \"x-ai/grok-2-1212\",\n        \"messages\": [\n            {\"role\": \"user\", \"content\": user_content}\n        ],\n    }\n    \n    try:\n        resp = requests.post(url, headers=headers, json=data, timeout=60)\n        resp.raise_for_status()\n        j = resp.json()\n        return j[\"choices\"][0][\"message\"][\"content\"]\n    except Exception as e:\n        return f\"[Grokæ€è€ƒã‚¨ãƒ©ãƒ¼: {e}]\"\n\ndef _extract_puter_text(message_content):\n    \"\"\"\n    puter.ai.chat ã®è¿”ã‚Šå€¤ã‹ã‚‰ ãƒ†ã‚­ã‚¹ãƒˆã ã‘ã‚’å–ã‚Šå‡ºã™\n    \"\"\"\n    if isinstance(message_content, str):\n        return message_content\n\n    if isinstance(message_content, list):\n        chunks = []\n        for part in message_content:\n            if isinstance(part, dict) and part.get(\"type\") == \"text\":\n                chunks.append(part.get(\"text\", \"\"))\n        return \"\".join(chunks)\n\n    return str(message_content)\n\n\ndef call_claude_opus_via_puter(\n    user_question: str,\n    research_text: str | None = None,\n    system_prompt: str | None = None,\n) -> str:\n    \"\"\"\n    Claude Opus 4.5ï¼ˆputer.comï¼‰via putergenai SDK\n    å…¬å¼ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¦Claudeã«ã‚¢ã‚¯ã‚»ã‚¹\n    \"\"\"\n    if not PUTER_USERNAME or not PUTER_PASSWORD:\n        return \"[Claude (puter) èªè¨¼æƒ…å ±æœªè¨­å®š]\"\n\n    async def _run() -> str:\n        try:\n            async with PuterClient() as client:\n                # SDKã§ãƒ­ã‚°ã‚¤ãƒ³\n                await client.login(PUTER_USERNAME, PUTER_PASSWORD)\n\n                # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹ç¯‰\n                messages = []\n                if system_prompt:\n                    messages.append({\"role\": \"system\", \"content\": system_prompt})\n\n                user_content = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\\n{user_question}\\n\\n\"\n                if research_text:\n                    user_content += f\"èª¿æŸ»ãƒ¡ãƒ¢:\\n{research_text}\\n\\n\"\n                    user_content += \"ã“ã®èª¿æŸ»ãƒ¡ãƒ¢ã®äº‹å®Ÿã‚’å„ªå…ˆã—ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚\\n\"\n\n                messages.append({\"role\": \"user\", \"content\": user_content})\n\n                # Claude Opus 4.5 ã‚’å‘¼ã³å‡ºã—\n                result = await client.ai_chat(\n                    messages=messages,\n                    options={\n                        \"model\": \"claude-opus-4-5\",  # ãƒã‚¤ãƒ•ãƒ³åŒºåˆ‡ã‚Š\n                        \"stream\": False,\n                    },\n                )\n\n                # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰æœ¬æ–‡ã‚’å–å¾—\n                message_content = result[\"response\"][\"result\"][\"message\"][\"content\"]\n                return _extract_puter_text(message_content)\n\n        except Exception as e:\n            return f\"[Claude SDK Error] {str(e)}\"\n\n    # Streamlitã®åŒæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§asyncã‚’å®Ÿè¡Œ\n    try:\n        return asyncio.run(_run())\n    except Exception as e:\n        return f\"[Claude Connection Error] {str(e)}\"\n\ndef create_new_session():\n    current_sessions = load_sessions()\n    \n    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒç©ºãªã‚‰ã€æ–°ã—ãä½œã‚‰ãšã«ãã‚Œã‚’å†åˆ©ç”¨ã™ã‚‹ï¼ˆé‡è¤‡é˜²æ­¢ï¼‰\n    if st.session_state.get(\"current_session_id\"):\n        for s in current_sessions:\n            if s[\"id\"] == st.session_state.current_session_id:\n                if len(s[\"messages\"]) == 0:\n                    st.toast(\"ã™ã§ã«æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã§ã™\")\n                    return\n\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": [],\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.rerun()\n\ndef switch_session(session_id):\n    st.session_state.current_session_id = session_id\n    st.rerun()\n\ndef update_current_session_messages(messages):\n    if st.session_state.current_session_id:\n        current_sessions = load_sessions()\n        target_index = -1\n        for i, session in enumerate(current_sessions):\n            if session[\"id\"] == st.session_state.current_session_id:\n                session[\"messages\"] = messages\n                if session[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(messages) > 0:\n                    first_msg = messages[0][\"content\"]\n                    session[\"title\"] = (first_msg[:20] + \"...\") if len(first_msg) > 20 else first_msg\n                session[\"timestamp\"] = datetime.datetime.now().isoformat()\n                target_index = i\n                break\n        \n        if target_index != -1:\n            # æœ€æ–°ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒªã‚¹ãƒˆã®å…ˆé ­ã«ç§»å‹•\n            updated_session = current_sessions.pop(target_index)\n            current_sessions.insert(0, updated_session)\n            \n        save_sessions(current_sessions)\n        st.session_state.sessions = current_sessions\n\ndef get_current_messages():\n    if st.session_state.current_session_id:\n        for session in st.session_state.sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                return session[\"messages\"]\n    return []\n\ndef delete_session(session_id):\n    current_sessions = load_sessions()\n    current_sessions = [s for s in current_sessions if s[\"id\"] != session_id]\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    if st.session_state.current_session_id == session_id:\n        st.session_state.current_session_id = None\n        if st.session_state.sessions:\n            st.session_state.current_session_id = st.session_state.sessions[0][\"id\"]\n    st.rerun()\n\ndef branch_session():\n    \"\"\"ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚’åˆ†å²\"\"\"\n    current_messages = get_current_messages()\n    current_sessions = load_sessions()\n    \n    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—\n    current_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n    for session in current_sessions:\n        if session[\"id\"] == st.session_state.current_session_id:\n            current_title = session[\"title\"]\n            break\n    \n    # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": f\"{current_title} (åˆ†å²)\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": current_messages.copy(),  # ç¾åœ¨ã®å±¥æ­´ã‚’ã‚³ãƒ”ãƒ¼\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    \n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.session_state.session_cost = 0.0  # ã‚³ã‚¹ãƒˆãƒªã‚»ãƒƒãƒˆ\n    st.rerun()\n\n# =========================\n# Initialization\n# =========================\n\nif \"sessions\" not in st.session_state:\n    st.session_state.sessions = load_sessions()\n\nif \"current_session_id\" not in st.session_state:\n    # Always create a new session when the app starts\n    create_new_session()\n\nif \"session_cost\" not in st.session_state:\n    st.session_state.session_cost = 0.0\n\nusage_stats = load_usage()\n\n# ==========================\n# ã‚³ã‚¹ãƒˆãƒã‚§ãƒƒã‚¯ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã®å‰ã«å®Ÿè¡Œï¼‰\n# ==========================\nusage_stats = load_usage()\nstop_generation = usage_stats[\"total_cost_usd\"] >= MAX_BUDGET_USD\n\n# =========================\n# Sidebar\n# =========================\n\nwith st.sidebar:\n    # ğŸ” ãƒ­ã‚°ã‚¢ã‚¦ãƒˆãƒœã‚¿ãƒ³\n    if st.button(\"ğŸ”’ ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ\", use_container_width=True):\n        st.session_state.authenticated = False\n        st.query_params.clear()  # URLãƒˆãƒ¼ã‚¯ãƒ³ã‚‚å‰Šé™¤\n        st.rerun()\n\n    st.markdown(\"\"\"\n    <div style=\"text-align: center; padding: 0; margin: 0; margin-top: -1rem;\">\n        <h1 style=\"font-size: 18px; font-weight: 700; margin: 0; padding: 0; letter-spacing: 1px;\">\n            Gemini 3<br/>Studio\n        </h1>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n    col1, col2 = st.columns(2)\n    with col1:\n        if st.button(\"â• æ–°è¦\", use_container_width=True):\n            create_new_session()\n    with col2:\n        if st.button(\"ğŸŒ± åˆ†å²\", use_container_width=True):\n            branch_session()\n\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    current_messages = get_current_messages()\n    if current_messages:\n        with st.expander(\"ğŸ”— å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ\", expanded=False):\n            export_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n            for s in st.session_state.sessions:\n                if s[\"id\"] == st.session_state.current_session_id:\n                    export_title = s[\"title\"]\n                    break\n\n            export_md = f\"# {export_title}\\n\\n\"\n            export_md += f\"**ä½œæˆæ—¥æ™‚**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n---\\n\\n\"\n            for msg in current_messages:\n                role_label = \"ğŸ§‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼\" if msg[\"role\"] == \"user\" else \"ğŸ¤– AI\"\n                export_md += f\"## {role_label}\\n\\n{msg['content']}\\n\\n---\\n\\n\"\n\n            if st.button(\"ãƒªãƒ³ã‚¯ç”Ÿæˆ\", use_container_width=True):\n                with st.spinner(\"ç”Ÿæˆä¸­...\"):\n                    try:\n                        import urllib.request\n                        import urllib.parse\n\n                        data = urllib.parse.urlencode(\n                            {\"content\": export_md, \"expiry_days\": 7, \"syntax\": \"md\"}\n                        ).encode()\n\n                        req = urllib.request.Request(\"https://dpaste.org/api/\", data=data)\n                        req.add_header(\"User-Agent\", \"Mozilla/5.0 (Gemini3Studio)\")\n\n                        with urllib.request.urlopen(req) as response:\n                            share_url = response.read().decode(\"utf-8\").strip()\n                            st.success(\"ä½œæˆå®Œäº†ï¼\")\n                            st.code(share_url)\n                            st.caption(\"â€»7æ—¥é–“æœ‰åŠ¹\")\n                    except Exception as e:\n                        st.error(f\"ã‚¨ãƒ©ãƒ¼: {e}\")\n\n    st.markdown(\"---\")\n\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    with st.expander(\"ğŸ“ æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«\", expanded=False):\n        uploaded_files = st.file_uploader(\n            \"ãƒ•ã‚¡ã‚¤ãƒ«\",\n            accept_multiple_files=True,\n            type=[\"png\", \"jpg\", \"jpeg\", \"mp4\", \"mov\", \"txt\", \"pdf\", \"csv\"],\n            label_visibility=\"collapsed\"\n        )\n\n    # ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ï¼ˆExpanderã®å¤–ã«å‡ºã™ï¼‰\n    pasted_image_bytes = None  # åˆæœŸåŒ–ã—ã¦NameErrorã‚’é˜²ã\n    if paste:\n        if \"paste_key\" not in st.session_state:\n            st.session_state.paste_key = 0\n        try:\n            pasted_image_bytes = paste(\n                label=\"ğŸ“‹ ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰è²¼ä»˜\",\n                key=f\"paste_btn_{st.session_state.paste_key}\",\n            )\n        except Exception as e:\n            st.error(f\"Error: {e}\")\n        \n        if pasted_image_bytes:\n            st.success(\"è²¼ä»˜å®Œäº†\")\n            st.image(pasted_image_bytes, caption=\"ç”»åƒ\", use_container_width=True)\n            if st.button(\"ğŸ—‘ï¸ ã‚¯ãƒªã‚¢\", key=\"clear_paste\"):\n                st.session_state.paste_key += 1\n                st.rerun()\n    else:\n        st.warning(\"Clipboard lib missing\")\n\n    # ---- YouTube URL ----\n    with st.expander(\"ğŸ“º YouTubeåˆ†æ\", expanded=False):\n        youtube_url = st.text_input(\"URL\", placeholder=\"https://youtu.be/...\", label_visibility=\"collapsed\")\n\n    st.markdown(\"---\")\n    \n    st.markdown(\"---\")\n    \n    # ---- ãƒ¢ãƒ¼ãƒ‰ã‚«ãƒ†ã‚´ãƒªé¸æŠ ----\n    mode_category = st.radio(\n        \"ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ¼ãƒ‰\",\n        [\"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\", \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(é€šå¸¸)\", \"Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter)\"],\n        index=0,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’å¤šå±¤ã«å¤‰æ›´\n        horizontal=True,\n    )\n    \n    # ---- å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ ----\n    if mode_category == \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\":\n        with st.expander(\"ãƒ¢ãƒ¼ãƒ‰è¨­å®š(å¤šå±¤)\", expanded=True):\n            mode_type = st.radio(\n                \"ã‚¿ã‚¤ãƒ—\",\n                [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n                index=0,\n                horizontal=True,\n                label_visibility=\"collapsed\"\n            )\n            \n            if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. (è©¦é¨“ä¸­)ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                        \"2. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                        \"3. (è©¦é¨“ä¸­)ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                        \"4. ç†Ÿè€ƒ(ãƒ¡ã‚¿æ€è€ƒ)+grokæ¤œç´¢å¼·åŒ–ç‰ˆ\",\n                    ],\n                    index=1  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ãƒ¡ã‚¿æ€è€ƒã«å¤‰æ›´\n                )\n            elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                    ],\n                    index=0\n                )\n            else:\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                    ],\n                    index=0\n                )\n    \n    # ---- å¤šå±¤+puterãƒ¢ãƒ¼ãƒ‰ ----\n    elif mode_category == \"Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter)\":\n        with st.expander(\"ãƒ¢ãƒ¼ãƒ‰è¨­å®š(å¤šå±¤+puter)\", expanded=True):\n            mode_type = st.radio(\n                \"ã‚¿ã‚¤ãƒ—\",\n                [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n                index=0,\n                horizontal=True,\n                label_visibility=\"collapsed\"\n            )\n            \n            if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                        \"2. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                        \"3. ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                    ],\n                    index=0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’é¬¼è»æ›¹ã«å¤‰æ›´\n                )\n            elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                    ],\n                    index=0\n                )\n            else:\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                    ],\n                    index=0\n                )\n    \n    # ---- é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ ----\n    else:\n        with st.expander(\"ãƒ¢ãƒ¼ãƒ‰è¨­å®š(é€šå¸¸)\", expanded=True):\n            mode_type = st.radio(\n                \"ã‚¿ã‚¤ãƒ—\",\n                [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n                index=0,\n                horizontal=True,\n                label_visibility=\"collapsed\"\n            )\n            \n            if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                        \"2. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                        \"3. ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                    ],\n                    index=0\n                )\n            elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                    ],\n                    index=0\n                )\n            else:\n                response_mode = st.radio(\n                    \"ãƒ¢ãƒ¼ãƒ‰\",\n                    [\n                        \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                    ],\n                    index=0\n                )\n    \n    strict_mode = False\n    \n    # ---- è¨­å®š (ãƒ¢ãƒ‡ãƒ«ãªã©) ----\n    with st.expander(\"âš™ï¸ è¨­å®š\", expanded=False):\n        model_options = [\n            \"gemini-3-pro-preview\",\n            \"gemini-2.5-pro\",\n            \"gemini-2.5-flash\",\n            \"gemini-2.5-flash-lite\",\n            \"gemini-2.0-flash\",\n        ]\n        model_id = st.selectbox(\"ãƒ¢ãƒ‡ãƒ«ID\", options=model_options, index=0)\n\n        use_search = st.toggle(\"Googleæ¤œç´¢\", value=True)\n        candidate_count = st.slider(\"å€™è£œæ•°\", min_value=1, max_value=3, value=3)\n\n    st.markdown(\"---\")\n\n    # ---- å±¥æ­´æ¤œç´¢ ----\n    search_query = st.text_input(\"ğŸ” å±¥æ­´æ¤œç´¢\", placeholder=\"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰...\")\n    if search_query:\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if search_query.lower() in s[\"title\"].lower():\n                filtered_sessions.append(s)\n                continue\n            found = False\n            for m in s[\"messages\"]:\n                if search_query.lower() in m[\"content\"].lower():\n                    filtered_sessions.append(s)\n                    found = True\n                    break\n            if not found:\n                pass\n    else:\n        # æ¤œç´¢ã—ã¦ã„ãªã„å ´åˆ: ç©ºã®ã€Œæ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã€ã‚’é™¤å¤–ï¼ˆç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯é™¤ãï¼‰\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if s[\"id\"] == st.session_state.current_session_id:\n                filtered_sessions.append(s)\n                continue\n            if s[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(s[\"messages\"]) == 0:\n                continue\n            filtered_sessions.append(s)\n\n    # CSSã§è¦‹ã‚„ã™ãä½¿ã„ã‚„ã™ãæœ€é©åŒ–\n    st.markdown(\"\"\"\n    <style>\n    /* å…¨ä½“ã®ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºç¸®å° */\n    .stApp, .stMarkdown, .stButton, .stSelectbox, .stTextInput, .stTextArea {\n        font-size: 12px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ä½™ç™½ã‚’æ¥µé™ã¾ã§è©°ã‚ã‚‹ */\n    section[data-testid=\"stSidebar\"] .block-container {\n        padding-top: 0.3rem !important;\n        padding-bottom: 0.3rem !important;\n        padding-left: 0.5rem !important;\n        padding-right: 0.5rem !important;\n    }\n    /* å„è¦ç´ é–“ã®éš™é–“ã‚’è©°ã‚ã‚‹ */\n    div[data-testid=\"stVerticalBlock\"] > div {\n        gap: 0.1rem !important;\n    }\n    /* Expanderã®ä½™ç™½å‰Šæ¸› */\n    .streamlit-expanderHeader {\n        font-size: 11px !important;\n        padding-top: 0px !important;\n        padding-bottom: 0px !important;\n        min-height: 1.3rem !important;\n    }\n    .streamlit-expanderContent {\n        padding-top: 0px !important;\n        padding-bottom: 0px !important;\n    }\n    /* éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã®ã‚¿ã‚¤ãƒˆãƒ« */\n    div[data-testid=\"stExpander\"] summary p {\n        font-size: 10px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ */\n    section[data-testid=\"stSidebar\"] button p {\n        font-size: 10px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã« */\n    section[data-testid=\"stSidebar\"] button {\n        padding: 0rem 0.2rem !important;\n        min-height: 1.4rem !important;\n        font-size: 10px !important;\n        margin-bottom: 0px !important;\n    }\n    /* ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®ãƒ©ãƒ™ãƒ«ã‚’å°ã•ã */\n    section[data-testid=\"stSidebar\"] .stRadio label {\n        font-size: 10px !important;\n    }\n    section[data-testid=\"stSidebar\"] .stRadio > label > div {\n        font-size: 10px !important;\n    }\n    /* ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ‡ã‚Šè©°ã‚ã‚‹ï¼ˆæ”¹è¡Œã•ã›ãªã„ï¼‰ */\n    section[data-testid=\"stSidebar\"] label, \n    section[data-testid=\"stSidebar\"] p,\n    section[data-testid=\"stSidebar\"] span {\n        white-space: nowrap !important;\n        overflow: hidden !important;\n        text-overflow: ellipsis !important;\n    }\n    /* åŒºåˆ‡ã‚Šç·š */\n    hr {\n        margin-top: 0.1rem !important;\n        margin-bottom: 0.1rem !important;\n    }\n    /* ãƒ˜ãƒƒãƒ€ãƒ¼ç¸®å° */\n    h1, h2, h3 {\n        padding-top: 0rem !important;\n        padding-bottom: 0rem !important;\n        margin-top: 0rem !important;\n        margin-bottom: 0rem !important;\n    }\n    </style>\n    \"\"\", unsafe_allow_html=True)\n    \n    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§é™é †ã‚½ãƒ¼ãƒˆï¼ˆæœ€æ–°ãŒå…ˆé ­ï¼‰\n    filtered_sessions.sort(key=lambda s: s.get(\"timestamp\", \"\"), reverse=True)\n    \n    # ç›´è¿‘5ä»¶ã¨éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«åˆ†å‰²\n    recent_sessions = filtered_sessions[:5] if len(filtered_sessions) > 5 else filtered_sessions\n    archive_sessions = filtered_sessions[5:] if len(filtered_sessions) > 5 else []\n    \n    # ç›´è¿‘5ä»¶ï¼ˆå¸¸ã«å±•é–‹ï¼‰\n    if recent_sessions:\n        st.markdown(\"**ğŸ“Œ ç›´è¿‘ã®ãƒãƒ£ãƒƒãƒˆ**\")\n        for session in recent_sessions:\n            col1, col2 = st.columns([0.8, 0.2])\n            with col1:\n                if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                    switch_session(session[\"id\"])\n            with col2:\n                if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                    delete_session(session[\"id\"])\n    \n    # éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆæŠ˜ã‚ŠãŸãŸã¿ï¼‰\n    if archive_sessions:\n        with st.expander(f\"ğŸ“œ éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ– ({len(archive_sessions)}ä»¶)\", expanded=False):\n            for session in archive_sessions:\n                col1, col2 = st.columns([0.8, 0.2])\n                with col1:\n                    if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                        switch_session(session[\"id\"])\n                with col2:\n                    if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                        delete_session(session[\"id\"])\n\n    st.markdown(\"---\")\n\n    # ---- ç”»åƒç”Ÿæˆ ----\n    with st.expander(\"ğŸ¨ ç”»åƒç”Ÿæˆ\", expanded=False):\n        img_prompt = st.text_area(\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\", placeholder=\"æœªæ¥çš„ãªéƒ½å¸‚...\")\n        aspect_ratio = st.selectbox(\"æ¯”ç‡\", [\"16:9\", \"1:1\", \"4:3\", \"3:4\", \"9:16\"])\n\n        generate_img_btn = st.button(\"ç”Ÿæˆ\", type=\"primary\", disabled=not img_prompt)\n        if generate_img_btn and img_prompt:\n            st.session_state.generate_image_trigger = {\n                \"prompt\": img_prompt,\n                \"aspect_ratio\": aspect_ratio,\n            }\n\n    st.markdown(\"---\")\n\n    # ---- è©•ä¾¡åˆ†æ ----\n    with st.expander(\"ğŸ“Š å“è³ªåˆ†æ\", expanded=False):\n        total_ratings = 0\n        positive_ratings = 0\n        model_ratings = {}\n\n        for s in st.session_state.sessions:\n            for m in s[\"messages\"]:\n                if \"rating\" in m and m[\"rating\"] is not None:\n                    total_ratings += 1\n                    if m[\"rating\"] == 1:\n                        positive_ratings += 1\n                    if \"metadata\" in m and \"model\" in m[\"metadata\"]:\n                        mod = m[\"metadata\"][\"model\"]\n                        if mod not in model_ratings:\n                            model_ratings[mod] = {\"total\": 0, \"positive\": 0}\n                        model_ratings[mod][\"total\"] += 1\n                        if m[\"rating\"] == 1:\n                            model_ratings[mod][\"positive\"] += 1\n\n        if total_ratings > 0:\n            approval_rate = (positive_ratings / total_ratings) * 100\n            st.metric(\"Positive Ratings\", f\"{positive_ratings}/{total_ratings}\", f\"{approval_rate:.1f}%\")\n            best_model = \"N/A\"\n            best_rate = -1\n            for mod, stats in model_ratings.items():\n                rate = stats[\"positive\"] / stats[\"total\"]\n                if rate > best_rate:\n                    best_rate = rate\n                    best_model = mod\n            if best_model != \"N/A\":\n                st.caption(f\"ğŸ† Best: **{best_model}** ({best_rate*100:.0f}%)\")\n        else:\n            st.caption(\"ãƒ‡ãƒ¼ã‚¿ãªã—\")\n\n    st.markdown(\"---\")\n\n    # ---- ã‚³ã‚¹ãƒˆè¡¨ç¤º ----\n    from logic import load_manual_cost, save_manual_cost, MAX_BUDGET_JPY, TRIAL_LIMIT_JPY, TRIAL_EXPIRY\n    \n    st.subheader(\"ğŸ’° Cost\")\n    st.caption(f\"äºˆç®—: Â¥{MAX_BUDGET_JPY:,.0f}\")\n    st.caption(f\"ä¸Šé™: Â¥{TRIAL_LIMIT_JPY:,.0f}\")\n    st.caption(f\"æœ‰åŠ¹æœŸé™: {TRIAL_EXPIRY}\")\n    \n    # æ‰‹å‹•ã‚³ã‚¹ãƒˆå…¥åŠ›ï¼ˆæ°¸ç¶šåŒ–ï¼‰\n    current_manual_cost = load_manual_cost()\n    manual_cost = st.number_input(\n        \"æ‰‹å‹•å…¥åŠ› (Â¥)\",\n        min_value=0.0,\n        value=current_manual_cost,\n        step=10.0,\n        format=\"%.0f\",\n        key=\"manual_cost_persistent\",\n        help=\"Google Cloud Consoleã§ç¢ºèªã—ãŸå®Ÿéš›ã®ã‚³ã‚¹ãƒˆï¼ˆå††ï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ã“ã®å€¤ã¯ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‰ã˜ã¦ã‚‚ä¿æŒã•ã‚Œã¾ã™ã€‚\"\n    )\n    \n    # å€¤ãŒå¤‰æ›´ã•ã‚ŒãŸã‚‰ä¿å­˜\n    if manual_cost != current_manual_cost:\n        save_manual_cost(manual_cost)\n    \n    st.link_button(\"ğŸ’° Google Cloud Console\", \"https://console.cloud.google.com/welcome/new?_gl=1*kmr691*_up*MQ..&gclid=CjwKCAiAraXJBhBJEiwAjz7MZT0vQsfDK5zunRBCQmuN5iczgI4bP1lHo1Tcrcbqu1KCBE1D22GpFhoCOdgQAvD_BwE&gclsrc=aw.ds&hl=ja&authuser=5&project=sigma-task-479704-r6\")\n\n    st.markdown(\"---\")\n    st.code(f\"PROJECT: {VERTEX_PROJECT}\\nLOCATION: {VERTEX_LOCATION} (Vertex AI)\")\n\n# =========================\n# Main UI\n# =========================\n\ncurrent_session_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\nfor s in st.session_state.sessions:\n    if s[\"id\"] == st.session_state.current_session_id:\n        current_session_title = s[\"title\"]\n        break\n\nst.header(current_session_title)\nst.markdown(\n    \"ä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\"\n)\n\n\n# ---- ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒœã‚¿ãƒ³ (Floating) ----\nst.markdown(\"\"\"\n    <style>\n        .scroll-btn-container {\n            position: fixed;\n            bottom: 100px;\n            right: 20px;\n            z-index: 9999;\n            display: flex;\n            flex-direction: column;\n            gap: 10px;\n        }\n        .scroll-btn {\n            background-color: #f0f2f6;\n            color: #31333F;\n            border: 1px solid #d6d6d8;\n            border-radius: 50%;\n            width: 40px;\n            height: 40px;\n            display: flex;\n            align-items: center;\n            justify-content: center;\n            cursor: pointer;\n            box-shadow: 0 2px 5px rgba(0,0,0,0.1);\n            transition: all 0.3s ease;\n            font-size: 20px;\n            padding: 0;\n            line-height: 1;\n        }\n        .scroll-btn:hover {\n            background-color: #e0e2e6;\n            transform: scale(1.1);\n            box-shadow: 0 4px 8px rgba(0,0,0,0.15);\n        }\n    </style>\n    \n    <script>\n        window.scrollStreamlit = function(direction) {\n            console.log(\"Scroll triggered: \" + direction);\n            \n            // ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ãªã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹è¦ç´ ã‚’é †ç•ªã«è©¦ã™\n            var targets = [];\n            \n            try {\n                if (window.parent && window.parent.document) {\n                    targets.push(window.parent.document.querySelector('section[data-testid=\"stAppViewContainer\"]'));\n                    targets.push(window.parent.document.querySelector('.main'));\n                    targets.push(window.parent.document.documentElement);\n                }\n            } catch (e) {\n                console.log(\"Access to parent window denied\");\n            }\n            \n            // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆiframeå†…ï¼‰\n            targets.push(document.querySelector('section[data-testid=\"stAppViewContainer\"]'));\n            targets.push(document.documentElement);\n\n            var scrolled = false;\n            for (var i = 0; i < targets.length; i++) {\n                var el = targets[i];\n                if (el) {\n                    try {\n                        // ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯èƒ½ãªè¦ç´ ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“çš„ï¼‰\n                        if (el.scrollHeight > el.clientHeight || el === window.parent.document.documentElement) {\n                            console.log(\"Scrolling element:\", el);\n                            if (direction === 'top') {\n                                el.scrollTo({top: 0, behavior: 'smooth'});\n                            } else {\n                                el.scrollTo({top: el.scrollHeight, behavior: 'smooth'});\n                            }\n                            scrolled = true;\n                        }\n                    } catch (e) {\n                        console.error(\"Error scrolling element:\", e);\n                    }\n                }\n            }\n            \n            if (!scrolled) {\n                console.log(\"No scrollable container found, trying window scroll\");\n                try {\n                    if (direction === 'top') {\n                        window.parent.scrollTo({top: 0, behavior: 'smooth'});\n                    } else {\n                        window.parent.scrollTo({top: window.parent.document.body.scrollHeight, behavior: 'smooth'});\n                    }\n                } catch(e) {\n                    window.scrollTo({top: 0, behavior: 'smooth'});\n                }\n            }\n        }\n    </script>\n\n    <div class=\"scroll-btn-container\">\n        <button class=\"scroll-btn\" onclick=\"window.scrollStreamlit('top')\" title=\"Top\">â¬†ï¸</button>\n        <button class=\"scroll-btn\" onclick=\"window.scrollStreamlit('bottom')\" title=\"Bottom\">â¬‡ï¸</button>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n# ---- Vertex AI Client ----\n\n\n\nclient = get_client()\n\n# ---- å±¥æ­´è¡¨ç¤º ----\n\nmessages = get_current_messages()\nfor idx, msg in enumerate(messages):\n    with st.chat_message(msg[\"role\"]):\n        st.markdown(msg[\"content\"])\n        if msg[\"role\"] == \"model\":\n            col1, col2, col3 = st.columns([0.1, 0.1, 0.8])\n            current_rating = msg.get(\"rating\")\n            with col1:\n                if st.button(\"ğŸ‘\", key=f\"up_{idx}\"):\n                    messages[idx][\"rating\"] = 1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col2:\n                if st.button(\"ğŸ‘\", key=f\"down_{idx}\"):\n                    messages[idx][\"rating\"] = -1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col3:\n                if current_rating == 1:\n                    st.caption(\"âœ… é«˜è©•ä¾¡\")\n                elif current_rating == -1:\n                    st.caption(\"âŒ ä½è©•ä¾¡\")\n\n# ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒœã‚¿ãƒ³ï¼ˆé•·ã„ãƒãƒ£ãƒƒãƒˆç”¨ï¼‰\nif len(messages) > 5:\n    st.markdown(\"\"\"\n    <div style=\"position: fixed; right: 20px; bottom: 100px; z-index: 999;\">\n        <button onclick=\"window.scrollTo({top: 0, behavior: 'smooth'})\" \n                style=\"display: block; margin: 5px; padding: 10px 15px; font-size: 24px; cursor: pointer; \n                       border: 2px solid #ccc; border-radius: 50%; background: white; box-shadow: 0 2px 8px rgba(0,0,0,0.2);\">\n            â¬†ï¸\n        </button>\n        <button onclick=\"window.scrollTo({top: document.body.scrollHeight, behavior: 'smooth'})\" \n                style=\"display: block; margin: 5px; padding: 10px 15px; font-size: 24px; cursor: pointer; \n                       border: 2px solid #ccc; border-radius: 50%; background: white; box-shadow: 0 2px 8px rgba(0,0,0,0.2);\">\n            â¬‡ï¸\n        </button>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n\n# =========================\n# ç”»åƒç”Ÿæˆãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°\n# =========================\n\nif hasattr(st.session_state, \"generate_image_trigger\") and st.session_state.generate_image_trigger:\n    img_data = st.session_state.generate_image_trigger\n    del st.session_state.generate_image_trigger\n\n    with st.chat_message(\"user\"):\n        st.markdown(f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\")\n        st.caption(f\"ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”: {img_data['aspect_ratio']}\")\n\n    messages.append({\"role\": \"user\", \"content\": f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\"})\n    update_current_session_messages(messages)\n\n    with st.chat_message(\"assistant\"):\n        with st.status(\"ç”»åƒã‚’ç”Ÿæˆä¸­...\", expanded=True) as status:\n            try:\n                config = types.GenerateContentConfig(\n                    response_modalities=[\"IMAGE\"],\n                    image_config=types.ImageConfig(\n                        aspect_ratio=img_data[\"aspect_ratio\"]\n                    ),\n                )\n                status.write(\"Gemini 3 Pro Imageã§ç”Ÿæˆä¸­...\")\n                response = client.models.generate_content(\n                    model=\"gemini-3-pro-image-preview\",\n                    contents=img_data[\"prompt\"],\n                    config=config,\n                )\n\n                generated_image = None\n\n                # ç”»åƒã‚’å–ã‚Šå‡ºã™\n                if getattr(response, \"candidates\", None):\n                    for candidate in response.candidates:\n                        if getattr(candidate, \"content\", None) and candidate.content.parts:\n                            for part in candidate.content.parts:\n                                if getattr(part, \"inline_data\", None):\n                                    try:\n                                        generated_image = part.as_image()\n                                    except AttributeError:\n                                        image_bytes_raw = part.inline_data.data\n                                        generated_image = Image.open(io.BytesIO(image_bytes_raw))\n                                    break\n                        if generated_image is not None:\n                            break\n\n                if generated_image is not None:\n                    st.image(generated_image, caption=img_data[\"prompt\"])\n                    buf = io.BytesIO()\n                    generated_image.save(buf, format=\"PNG\")\n                    image_bytes = buf.getvalue()\n                    st.download_button(\n                        label=\"ğŸ’¾ ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\",\n                        data=image_bytes,\n                        file_name=f\"generated_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png\",\n                        mime=\"image/png\",\n                    )\n                    messages.append(\n                        {\"role\": \"model\", \"content\": f\"âœ… ç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {img_data['prompt']}\"}\n                    )\n                    update_current_session_messages(messages)\n                    status.update(label=\"âœ… ç”»åƒç”Ÿæˆå®Œäº†\", state=\"complete\")\n                else:\n                    st.error(\"ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")\n                    status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n\n            except Exception as e:\n                status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n                st.error(f\"ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}\")\n\n# =========================\n# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›\n# =========================\n\nprompt = st.chat_input(\"ä½•ã‹èã„ã¦ãã ã•ã„...\", disabled=stop_generation)\n\nif prompt:\n    if stop_generation:\n        st.error(\"äºˆç®—ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚\")\n    else:\n        # ---- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€è¡¨ç¤º ----\n        with st.chat_message(\"user\"):\n            st.markdown(prompt)\n            if uploaded_files:\n                for uf in uploaded_files:\n                    st.caption(f\"ğŸ“ æ·»ä»˜: {uf.name}\")\n            if youtube_url:\n                st.caption(f\"ğŸ“º YouTube: {youtube_url}\")\n            if pasted_image_bytes:\n                st.caption(\"ğŸ“‹ ç”»åƒãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚Œã¾ã—ãŸ\")\n\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        update_current_session_messages(messages)\n\n        # ---- ãƒ¢ãƒ‡ãƒ«å¿œç­” ----\n        with st.chat_message(\"assistant\"):\n            status_container = st.status(\"æ€è€ƒä¸­...\", expanded=True)\n            try:\n                # ä¼šè©±å±¥æ­´\n                model_history = []\n                for msg in messages[:-1]:\n                    model_history.append(\n                        types.Content(\n                            role=msg[\"role\"],\n                            parts=[types.Part.from_text(text=msg[\"content\"])],\n                        )\n                    )\n\n                # ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³\n                current_parts = [types.Part.from_text(text=prompt)]\n\n                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«\n                for uploaded_file in uploaded_files or []:\n                    try:\n                        mime_type = get_mime_type(uploaded_file.name)\n                        bytes_data = uploaded_file.getvalue()\n                        part = types.Part.from_bytes(data=bytes_data, mime_type=mime_type)\n                        current_parts.append(part)\n                        status_container.write(f\"ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™å®Œäº†: {uploaded_file.name}\")\n                    except Exception as e:\n                        status_container.error(\n                            f\"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {uploaded_file.name} - {e}\"\n                        )\n\n                # è²¼ã‚Šä»˜ã‘ç”»åƒ\n                if pasted_image_bytes:\n                    import base64\n\n                    status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã‚’å‡¦ç†ä¸­...\")\n                    try:\n                        if isinstance(pasted_image_bytes, str):\n                            if pasted_image_bytes.startswith(\"data:\"):\n                                base64_str = pasted_image_bytes.split(\",\", 1)[1]\n                                image_bytes_decoded = base64.b64decode(base64_str)\n                            else:\n                                image_bytes_decoded = base64.b64decode(pasted_image_bytes)\n                        else:\n                            image_bytes_decoded = pasted_image_bytes\n                        part = types.Part.from_bytes(\n                            data=image_bytes_decoded, mime_type=\"image/png\"\n                        )\n                        current_parts.append(part)\n                        status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®æº–å‚™å®Œäº†\")\n                    except Exception as e:\n                        status_container.error(f\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n\n                # YouTube å­—å¹•\n                if youtube_url:\n                    vid_id = extract_youtube_id(youtube_url)\n                    if vid_id:\n                        status_container.write(\"YouTubeã®å­—å¹•ã‚’å–å¾—ä¸­...\")\n                        transcript_text = get_youtube_transcript(vid_id)\n                        current_parts.append(\n                            types.Part.from_text(text=f\"YouTube Transcript:\\n{transcript_text}\")\n                        )\n                    else:\n                        status_container.write(\"ç„¡åŠ¹ãªYouTube URLã§ã™ã€‚\")\n\n                contents_for_model = model_history + [\n                    types.Content(role=\"user\", parts=current_parts)\n                ]\n\n                # ---- Tool / Config ----\n                tools = []\n                final_candidate_count = candidate_count\n                if use_search:\n                    tools.append(types.Tool(google_search=types.GoogleSearch()))\n                    final_candidate_count = 1\n\n                # â˜… System Instruction ã®æ”¹å–„: ãƒ¡ã‚¿ç™ºè¨€ç¦æ­¢ã¨ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªæŒ¯ã‚‹èˆã„ã‚’æŒ‡ç¤º\n                base_system_instruction = (\n                    \"ã‚ãªãŸã¯é«˜åº¦ãªçŸ¥æ€§ã‚’æŒã¤å°‚é–€çš„ãªãƒªã‚µãƒ¼ãƒãƒ»ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\\n\"\n                    \"ä»¥ä¸‹ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’å³å®ˆã—ã¦ãã ã•ã„ï¼š\\n\"\n                    \"1. **ãƒ¡ã‚¿ç™ºè¨€ã®ç¦æ­¢**: ã€Œç§ã¯AIã§ã™ã€ã€Œä¸–ç•Œæœ€é«˜å³°ã®ï½ã¨ã—ã¦ã€ãªã©ã®è‡ªå·±è¨€åŠã‚„å‰ç½®ãã¯ä¸€åˆ‡è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚\\n\"\n                    \"2. **æ„å›³ã®æ±²ã¿å–ã‚Š**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã®èƒŒå¾Œã«ã‚ã‚‹æ„å›³ï¼ˆæ–‡è„ˆã€æš—é»™ã®å‰æï¼‰ã‚’æ¨æ¸¬ã—ã€è¨€è‘‰é€šã‚Šã§ã¯ãªãã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ¬å½“ã«çŸ¥ã‚ŠãŸã„ã“ã¨ã€ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n\"\n                    \"3. **æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”**: çµè«–ã‚’å…ˆã«è¿°ã¹ã€ãã®å¾Œã«è©³ç´°ãªæ ¹æ‹ ã€ã‚·ãƒŠãƒªã‚ªåˆ†æã€ãƒªã‚¹ã‚¯è¦å› ã‚’è«–ç†çš„ã«å±•é–‹ã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"4. **å®¢è¦³æ€§**: äºˆæ¸¬ã‚’è¡Œã†å ´åˆã¯ã€æ–­å®šã‚’é¿ã‘ã€è¤‡æ•°ã®ã‚·ãƒŠãƒªã‚ªï¼ˆæ¥½è¦³ã€æ‚²è¦³ã€ä¸­ç«‹ï¼‰ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"5. **å¼•ç”¨**: æ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸå ´åˆã¯ã€å¿…ãšæƒ…å ±æºã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚\"\n                )\n\n                final_answer = \"\"\n                grounding_metadata = None\n                \n                # =========================\n                # ãƒ¢ãƒ¼ãƒ‰è¨­å®šã®è§£æ\n                # =========================\n                # Î²1é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ä»¥å¤–ã¯ãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œ\n                enable_research = \"Î²1\" not in response_mode\n                enable_meta = \"ãƒ¡ã‚¿\" in response_mode or \"MAX\" in response_mode\n                enable_strict = \"é¬¼è»æ›¹\" in response_mode or \"MAX\" in response_mode\n                enable_grok_x_search = \"grokæ¤œç´¢å¼·åŒ–ç‰ˆ\" in response_mode\n\n                # =========================\n                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (é«˜é€Ÿ / é¬¼è»æ›¹)\n                # =========================\n                if not enable_research:\n                    config = types.GenerateContentConfig(\n                        temperature=0.7,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=base_system_instruction,\n                    )\n                    \n                    status_container.write(\"å›ç­”ç”Ÿæˆä¸­...\")\n                    response = client.models.generate_content(\n                        model=model_id,\n                        contents=contents_for_model,\n                        config=config,\n                    )\n                    \n                    final_answer = extract_text_from_response(response)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®—\n                    if response.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            response.usage_metadata.prompt_token_count,\n                            response.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += response.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += response.usage_metadata.candidates_token_count\n\n                    # é¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ (é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ç‰ˆ)\n                    if enable_strict:\n                        status_container.write(\"ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        reviewer_instruction = base_system_instruction + \"\"\"\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n                        review_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\nåˆç‰ˆå›ç­”:\\n{final_answer}\\n\\nãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\")])]\n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=types.GenerateContentConfig(temperature=0.1, candidate_count=1, system_instruction=reviewer_instruction)\n                        )\n                        final_answer = extract_text_from_response(review_resp)\n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        \n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(model_id, review_resp.usage_metadata.prompt_token_count, review_resp.usage_metadata.candidates_token_count)\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n\n                # =========================\n                # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰\n                # =========================\n                else:\n                    # =========================\n                    # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰: å¤šæ®µéšã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ \n                    # =========================\n                    \n                    # --- Phase 1: ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 1: ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    import datetime as dt\n                    current_year = dt.datetime.now().year\n                    \n                    research_instruction = base_system_instruction + f\"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒªã‚µãƒ¼ãƒå°‚ä»»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚æœ€çµ‚å›ç­”ã¯æ›¸ã‹ãšã€äº‹å®Ÿåé›†ã«é›†ä¸­ã™ã‚‹ã“ã¨ã€‚\n\n**èª¿æŸ»è¦³ç‚¹**:\n- è³ªå•ã«é–¢é€£ã™ã‚‹**æœ€æ–°ã®äº‹å®Ÿãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ»çµ±è¨ˆ**ï¼ˆ**{current_year}å¹´ã®æƒ…å ±ã‚’æœ€å„ªå…ˆ**ï¼‰\n- **ç¾æ™‚ç‚¹ã§å­˜åœ¨ã™ã‚‹å…¨ã¦ã®é¸æŠè‚¢ãƒ»ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¶²ç¾…çš„ã«èª¿æŸ»**ï¼ˆä¾‹: è£½å“æ¯”è¼ƒãªã‚‰ã€æœ€æ–°ç‰ˆã ã‘ã§ãªãç›´è¿‘ã®å…¨ä¸–ä»£ã‚’èª¿æŸ»ï¼‰\n- å…¬å¼æƒ…å ±ã‚„ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã‹ã‚‰ã®å¼•ç”¨\n- é–¢é€£ã™ã‚‹èƒŒæ™¯æƒ…å ±ã‚„æ–‡è„ˆ\n- ç«¶åˆãƒ»ä»£æ›¿æ¡ˆãƒ»æ¯”è¼ƒå¯¾è±¡ã®**å®Œå…¨ãªãƒªã‚¹ãƒˆ**\n- ãƒªã‚¹ã‚¯ãƒ»åˆ¶ç´„ãƒ»æ³¨æ„ç‚¹ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n- å‚è€ƒã«ã—ãŸä¸»è¦ãªæƒ…å ±æºã®URL\n\n**é‡è¦**: \n- çµè«–ã‚„æ¨å¥¨ã¯æ›¸ã‹ãšã€å¾Œå·¥ç¨‹ãŒåˆ¤æ–­ã§ãã‚‹èª¿æŸ»ãƒ¡ãƒ¢ã«é›†ä¸­ã™ã‚‹ã“ã¨\n- **å¿…ãšæ¤œç´¢æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã€æœ€æ–°ã®æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã“ã¨**\n- **æ¤œç´¢çµæœã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æ—¥ä»˜ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒ»ãƒ¢ãƒ‡ãƒ«åã‚’å„ªå…ˆçš„ã«è¨˜è¼‰ã™ã‚‹ã“ã¨**\n- **æ¯”è¼ƒå¯¾è±¡ã¨ãªã‚‹é¸æŠè‚¢ã‚’è¦‹è½ã¨ã•ãªã„ã‚ˆã†ã€è¤‡æ•°ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è©¦ã™ã“ã¨**ï¼ˆä¾‹: ã€ŒiPhone æœ€æ–°ãƒ¢ãƒ‡ãƒ« {current_year}ã€ã€ŒiPhone {current_year}å¹´ç™ºå£²ã€ãªã©ï¼‰\n- **ã€Œã“ã‚Œã‚ˆã‚Šæ–°ã—ã„ãƒ¢ãƒ‡ãƒ«/ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯å­˜åœ¨ã—ãªã„ã‹ï¼Ÿã€ã‚’å¸¸ã«ç¢ºèªã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ï¼ˆ{current_year-1}å¹´ä»¥å‰ãªã©ï¼‰ã—ã‹è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãã®æ—¨ã‚’æ˜è¨˜ã™ã‚‹ã“ã¨\n\"\"\"\n\n                    # éå»ã®é–¢é€£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—\n                    past_context = get_relevant_context(prompt, st.session_state.sessions, st.session_state.current_session_id)\n                    \n                    # ãƒªã‚µãƒ¼ãƒç”¨ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ§‹ç¯‰\n                    import datetime as dt\n                    current_date = dt.datetime.now().strftime(\"%Yå¹´%mæœˆ%dæ—¥\")\n                    research_parts = [types.Part(text=(\n                        f\"é‡è¦: ä»Šæ—¥ã¯{current_date}ã§ã™ã€‚ã“ã®æ—¥ä»˜ã‚ˆã‚Šæ–°ã—ã„æƒ…å ±ã‚’å„ªå…ˆã—ã¦ãã ã•ã„ã€‚\\n\\n\"\n                        f\"è³ªå•: {prompt}\"\n                    ))]\n                    \n                    if past_context:\n                        research_parts.insert(0, types.Part(text=\"ä»¥ä¸‹ã¯éå»ã®é–¢é€£ãƒãƒ£ãƒƒãƒˆã‹ã‚‰æŠ½å‡ºã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã™ï¼š\\n\\n\" + past_context))\n                    \n                    research_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=research_parts)\n                    ]\n                    \n                    research_config = types.GenerateContentConfig(\n                        temperature=0.4,  # æœ€æ–°æƒ…å ±ã‚’æŸ”è»Ÿã«æ¡ç”¨ã™ã‚‹ãŸã‚0.2â†’0.4ã«ä¸Šæ˜‡\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=research_instruction,\n                    )\n                    \n                    research_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=research_contents,\n                        config=research_config,\n                    )\n                    \n                    research_text = extract_text_from_response(research_resp)\n                    \n                    # ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºã®ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ±ã‚’ä¿å­˜\n                    if research_resp.candidates and research_resp.candidates[0].grounding_metadata:\n                        grounding_metadata = research_resp.candidates[0].grounding_metadata\n                    \n                    status_container.write(\"âœ“ ãƒªã‚µãƒ¼ãƒå®Œäº†\")\n                    with status_container.expander(\"åé›†ã—ãŸèª¿æŸ»ãƒ¡ãƒ¢\", expanded=False):\n                        st.markdown(research_text)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1)\n                    if research_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            research_resp.usage_metadata.prompt_token_count,\n                            research_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += research_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += research_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 1.5: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    questions_text = \"\"\n                    if enable_meta:\n                        status_container.write(\"Phase 1.5: ãƒ¡ã‚¿è³ªå•ç”Ÿæˆä¸­...\")\n                        \n                        question_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ç›®çš„**: \nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•ã¨èª¿æŸ»ãƒ¡ãƒ¢ã‚’è¸ã¾ãˆã¦ã€ã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±ãç†è§£ã™ã‚‹ãŸã‚ã®ã€Œé‹­ã„ã‚µãƒ–è³ªå•ã€ã‚’ä½œæˆã™ã‚‹ã“ã¨ã€‚\n\n**ãƒ«ãƒ¼ãƒ«**:\n- æœ€å¤§5å€‹ã¾ã§\n- å„è³ªå•ã¯1-2è¡Œã§å…·ä½“çš„ã‹ã¤é‹­ã\n- ä»¥ä¸‹ã®è¦³ç‚¹ã‚’æ„è­˜:\n  1. å‰æãŒå´©ã‚Œã‚‹å¯èƒ½æ€§ã¯ã©ã“ã‹ï¼Ÿ\n  2. å¼·æ°—/å¼±æ°—ã‚·ãƒŠãƒªã‚ªã®åˆ†å²ç‚¹ã¯ä½•ã‹ï¼Ÿ\n  3. ç«¶åˆãƒ»æŠ€è¡“ãƒ»è¦åˆ¶ã®ä¸ç¢ºå®Ÿæ€§ã¯ï¼Ÿ\n  4. ã€Œäºˆæ¸¬ãŒå¤–ã‚Œã‚‹ã¨ã—ãŸã‚‰ã©ã‚“ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ï¼Ÿã€\n\n**å‡ºåŠ›**: ç®‡æ¡æ›¸ãï¼ˆQ1, Q2...ï¼‰ã®ã¿\n\"\"\"\n\n                        question_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•:\\n{prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\nã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±æ˜ã‚Šã™ã‚‹ãŸã‚ã®é‡è¦ãªã‚µãƒ–è³ªå•ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\")])]\n                        \n                        question_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=question_contents,\n                            config=types.GenerateContentConfig(\n                                temperature=0.4,\n                                candidate_count=1,\n                                system_instruction=question_instruction,\n                            )\n                        )\n                        \n                        questions_text = extract_text_from_response(question_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¡ã‚¿è³ªå•ç”Ÿæˆå®Œäº†\")\n                        with status_container.expander(\"ç”Ÿæˆã•ã‚ŒãŸãƒ¡ã‚¿è³ªå•\", expanded=False):\n                            st.markdown(questions_text)\n                        \n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += question_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += question_resp.usage_metadata.candidates_token_count\n\n                    # å¤šå±¤+puterãƒ¢ãƒ¼ãƒ‰ã®é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã‹ãƒã‚§ãƒƒã‚¯\n                    is_puter_onigunsou = (\n                        mode_category == \"Î²ï¼šğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤+puter)\" and\n                        response_mode == \"1. ç†Ÿè€ƒ + é¬¼è»æ›¹\"\n                    )\n\n                    # --- Phase 1.5b: Grok ç‹¬ç«‹æ€è€ƒ (å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    # --- Phase 1.5b: Grok ç‹¬ç«‹æ€è€ƒ (å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    grok_thought = \"\"\n                    grok_status = \"skipped\"\n                    if enable_meta and OPENROUTER_API_KEY:\n                        status_container.write(\"Phase 1.5b: Grok ç‹¬ç«‹æ€è€ƒä¸­...\")\n                        try:\n                            grok_thought = think_with_grok(prompt, research_text, enable_x_search=enable_grok_x_search)\n                            if grok_thought:\n                                grok_status = \"success\"\n                                status_container.write(\"âœ“ Grok 4.1 Fast Free ç‹¬ç«‹æ€è€ƒå®Œäº†\")\n                                with status_container.expander(\"Grokã®ç‹¬ç«‹å›ç­”æ¡ˆ\", expanded=False):\n                                    st.markdown(grok_thought)\n                            else:\n                                grok_status = \"empty\"\n                        except Exception as e:\n                            grok_status = \"error\"\n                            status_container.write(f\"âš  Grokæ€è€ƒã‚¨ãƒ©ãƒ¼: {e}\")\n\n                    # --- Phase 1.5c: Claude Opus 4.5 ç‹¬ç«‹æ€è€ƒ (å¤šå±¤+puterã®é¬¼è»æ›¹ã®ã¿) ---\n                    # --- Phase 1.5c: Claude Opus 4.5 ç‹¬ç«‹æ€è€ƒ (å¤šå±¤+puterã®é¬¼è»æ›¹ã®ã¿) ---\n                    claude_thought = \"\"\n                    claude_status = \"skipped\"\n                    if is_puter_onigunsou and PUTER_USERNAME and PUTER_PASSWORD:\n                        status_container.write(\"Phase 1.5c: Claude Opus 4.5 ç‹¬ç«‹æ€è€ƒä¸­...\")\n                        try:\n                            claude_thought = call_claude_opus_via_puter(\n                                user_question=prompt,\n                                research_text=research_text,\n                                system_prompt=(\n                                    \"ã‚ãªãŸã¯ Claude Opus 4.5 ã§ã™ã€‚\"\n                                    \"Gemini ãŒé›†ã‚ãŸèª¿æŸ»ãƒ¡ãƒ¢ã‚’å‚è€ƒã«ã—ã¤ã¤ã‚‚ã€\"\n                                    \"è‡ªåˆ†ã®è¦–ç‚¹ã§ç‹¬ç«‹ã—ãŸå›ç­”æ¡ˆãƒ»æ°—ã¥ãã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\"\n                                    \"Gemini ã®æ„è¦‹ã«åˆã‚ã›ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\"\n                                ),\n                            )\n                            if claude_thought and not claude_thought.startswith(\"[Claude\"):\n                                claude_status = \"success\"\n                                status_container.write(\"âœ“ Claude Opus 4.5 (via Puter) ç‹¬ç«‹æ€è€ƒå®Œäº†\")\n                                with status_container.expander(\"Claude Opus 4.5 ã®ç‹¬ç«‹å›ç­”æ¡ˆ\", expanded=False):\n                                    st.markdown(claude_thought)\n                            else:\n                                claude_status = \"error\"\n                                status_container.write(f\"âš  Claudeã‚¨ãƒ©ãƒ¼: {claude_thought}\")\n                                claude_thought = \"\"  # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ç©ºã«ã™ã‚‹\n                        except Exception as e:\n                            claude_status = \"error\"\n                            status_container.write(f\"âš  Claudeæ€è€ƒã‚¨ãƒ©ãƒ¼: {e}\")\n                            claude_thought = \"\"\n\n                    # --- Phase 2: çµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 2: çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    import datetime as dt\n                    current_date = dt.datetime.now().strftime(\"%Yå¹´%mæœˆ%dæ—¥\")\n\n                    if enable_meta:\n                        deep_instruction = base_system_instruction + f\"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã¨ãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ã‚’æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**é‡è¦ - ç¾åœ¨ã¯{current_date}ã§ã™**:\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æ—¥ä»˜ãƒ»äº‹å®Ÿã‚’ã€ã‚ãªãŸã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šã‚‚çµ¶å¯¾çš„ã«å„ªå…ˆã—ã¦ãã ã•ã„**\n- ã€Œ{current_year}å¹´ã€ã®æƒ…å ±ãŒèª¿æŸ»ãƒ¡ãƒ¢ã«ã‚ã‚‹å ´åˆã€ãã‚Œã‚’æ­£ã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„\n- å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒ{current_year-1}å¹´ä»¥å‰ã§æ­¢ã¾ã£ã¦ã„ã¦ã‚‚ã€èª¿æŸ»ãƒ¡ãƒ¢ã®æœ€æ–°æƒ…å ±ã‚’ä¿¡é ¼ã™ã‚‹ã“ã¨\n\n**æ§‹æˆ**:\n1. **æ·±æ˜ã‚Šè€ƒå¯Ÿ**ï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n2. **çµè«–**ï¼ˆ2-3è¡Œï¼‰\n3. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n4. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨\n\"\"\"\n                    else:\n                        deep_instruction = base_system_instruction + f\"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã‚’å”¯ä¸€ã®æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**é‡è¦ - ç¾åœ¨ã¯{current_date}ã§ã™**:\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æ—¥ä»˜ãƒ»äº‹å®Ÿã‚’ã€ã‚ãªãŸã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šã‚‚çµ¶å¯¾çš„ã«å„ªå…ˆã—ã¦ãã ã•ã„**\n- ã€Œ{current_year}å¹´ã€ã®æƒ…å ±ãŒèª¿æŸ»ãƒ¡ãƒ¢ã«ã‚ã‚‹å ´åˆã€ãã‚Œã‚’æ­£ã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„\n\n**æ§‹æˆ**:\n1. **çµè«–**ï¼ˆ2-3è¡Œã§æ˜ç¢ºã«ï¼‰\n2. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n3. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«åã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ã¨æ–°ã—ã„æƒ…å ±ãŒæ··åœ¨ã™ã‚‹å ´åˆã¯ã€æ–°ã—ã„æƒ…å ±ã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n\"\"\"\n                    \n                    synthesis_prompt_text = (\n                        f\"é‡è¦: ä»Šæ—¥ã¯{current_date}ã§ã™ã€‚å¤ã„æƒ…å ±ã‚’å›ç­”ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚\\n\\n\"\n                        f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}\\n\\n\"\n                        f\"==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                    )\n                    \n                    if enable_meta and questions_text:\n                        synthesis_prompt_text += f\"==== ãƒ¡ã‚¿è³ªå•ä¸€è¦§ ====\\n{questions_text}\\n==== ãƒ¡ã‚¿è³ªå•ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if enable_meta and grok_thought:\n                        synthesis_prompt_text += f\"==== åˆ¥è¦–ç‚¹ã‹ã‚‰ã®å›ç­”æ¡ˆ (Grok) ====\\n{grok_thought}\\n==== åˆ¥è¦–ç‚¹ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if is_puter_onigunsou and claude_thought:\n                        synthesis_prompt_text += f\"==== åˆ¥è¦–ç‚¹ã‹ã‚‰ã®å›ç­”æ¡ˆ (Claude Opus 4.5 via Puter) ====\\n{claude_thought}\\n==== Claudeåˆ¥è¦–ç‚¹ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    # çµ±åˆæŒ‡ç¤º\n                    if enable_meta and (grok_thought or claude_thought):\n                        synthesis_prompt_text += \"æŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n2. Grok\"\n                        if is_puter_onigunsou and claude_thought:\n                            synthesis_prompt_text += \" / Claude\"\n                        synthesis_prompt_text += \" ã®å›ç­”æ¡ˆã‚‚å‚è€ƒã«ã—ã¤ã¤ï¼ˆãŸã ã—ç›²ä¿¡ã›ãšï¼‰ã€ç‹¬è‡ªã®è¦–ç‚¹ã§çµ±åˆã—ã¦ãã ã•ã„ã€‚\\n3. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»åˆ†æãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    elif enable_meta and questions_text:\n                        synthesis_prompt_text += \"æŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n2. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»åˆ†æãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    else:\n                        synthesis_prompt_text += \"ä¸Šè¨˜ãƒ¡ãƒ¢ã‚’æ ¹æ‹ ã«ã€æœ€çµ‚å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å¿…ãšä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚**\"\n\n                    synthesis_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=[\n                            types.Part(text=synthesis_prompt_text)\n                        ])\n                    ]\n                    \n                    synthesis_config = types.GenerateContentConfig(\n                        temperature=0.3,\n                        candidate_count=1,\n                        tools=[],  # çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºã§ã¯æ¤œç´¢OFF\n                        system_instruction=deep_instruction,\n                    )\n                    \n                    synthesis_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=synthesis_contents,\n                        config=synthesis_config,\n                    )\n                    \n                    draft_answer = extract_text_from_response(synthesis_resp)\n                    \n                    status_container.write(\"âœ“ çµ±åˆå®Œäº†\")\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 2)\n                    if synthesis_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            synthesis_resp.usage_metadata.prompt_token_count,\n                            synthesis_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += synthesis_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += synthesis_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    if enable_strict:\n                        status_container.write(\"Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        \n\n                        reviewer_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™ã€‚ãŸã ã—ã€**èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’å„ªå…ˆã—ã€æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã™ã‚‹ã“ã¨**ã€‚\n\n**ãƒ¬ãƒ“ãƒ¥ãƒ¼è¦³ç‚¹**:\n- äº‹å®Ÿã¨æ¨æ¸¬ã‚’æ˜ç¢ºã«åˆ†ã‘ã‚‹\n- éåº¦ã«è‡ªä¿¡ã®ã‚ã‚‹æ–­å®šã‚’å¼±ã‚ã‚‹\n- æ•°å­—ã‚„å›ºæœ‰åè©ãŒèª¿æŸ»ãƒ¡ãƒ¢ã¨çŸ›ç›¾ã—ã¦ã„ãªã„ã‹ç¢ºèª\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ãƒ¢ãƒ‡ãƒ«ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ãŒæ­£ã—ãä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª**\n- **å¤ã„æƒ…å ±ã§ä¸Šæ›¸ãã—ã¦ã„ãªã„ã‹ç¢ºèª**\n- è¦‹è½ã¨ã—ã¦ã„ã‚‹é‡è¦ãªãƒªã‚¹ã‚¯ãƒ»ã‚·ãƒŠãƒªã‚ªãŒã‚ã‚Œã°è¿½åŠ \n\n**é‡è¦**: \n- èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ãŒæœ€æ–°ã§ã‚ã‚‹å ´åˆã€ãã‚Œã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n- ã‚ãªãŸã®çŸ¥è­˜ãŒå¤ã„å ´åˆã¯ã€èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’ä¿¡é ¼ã™ã‚‹ã“ã¨\n\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n\n                        review_contents = [\n                            types.Content(role=\"user\", parts=[\n                                types.Part.from_text(\n                                    text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\n\"\n                                    f\"==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                                    f\"åˆç‰ˆå›ç­”:\\n{draft_answer}\\n\\n\"\n                                    \"ä¸Šè¨˜ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚**\"\n                                )\n                            ])\n                        ]\n                        \n                        review_config = types.GenerateContentConfig(\n                            temperature=0.1,\n                            candidate_count=1,\n                            system_instruction=reviewer_instruction,\n                            thinking_config=types.ThinkingConfig(\n                                thinking_level=types.ThinkingLevel.HIGH\n                            ),\n                        )\n                        \n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=review_config,\n                        )\n                        \n                        final_answer = extract_text_from_response(review_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        \n                        # --- Phase 3b: Groké¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ (å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ + é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰å…¨èˆ¬) ---\n                        # å¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã§ã€ã‹ã¤é¬¼è»æ›¹ç³»ã®ãƒ¢ãƒ¼ãƒ‰ï¼ˆé¬¼è»æ›¹ã€ãƒ¡ã‚¿æ€è€ƒã€æœ¬æ°—MAXï¼‰ã§ç™ºå‹•\n                        use_grok_reviewer = (mode_category == \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\" and enable_strict)\n                        \n                        if use_grok_reviewer and OPENROUTER_API_KEY:\n                            status_container.write(\"Phase 3b: Grok 4.1 Fast ã§æœ€çµ‚ãƒã‚§ãƒƒã‚¯ä¸­...\")\n                            try:\n                                grok_answer = review_with_grok(prompt, final_answer, research_text)\n                                # Grokä½¿ç”¨æ™‚ã¯ã€ãƒ¢ãƒ‡ãƒ«åã‚’æ˜ç¤ºã—ã€2æ®µæ§‹æˆã§è¡¨ç¤º\n                                final_answer = (\n                                    f\"**ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_id} (Deep Thinking / High Reasoning)**\\n\"\n                                    f\"**ãƒ¬ãƒ“ãƒ¥ã‚¢: Grok 4.1 Fast (free)**\\n\"\n                                    f\"**ãƒ¢ãƒ¼ãƒ‰: {response_mode}**\\n\\n\"\n                                    \"---\\n\\n\"\n                                    \"## âœ… æœ€çµ‚å›ç­”ï¼ˆGeminiçµ±åˆç‰ˆï¼‰\\n\\n\"\n                                    f\"{final_answer}\\n\\n\"\n                                    \"---\\n\\n\"\n                                    \"## ğŸ” Grok ã«ã‚ˆã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼\\n\\n\"\n                                    f\"{grok_answer}\"\n                                )\n                                status_container.write(\"âœ“ Grokæœ€çµ‚ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                            except Exception as e:\n                                status_container.write(f\"âš  Grokãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}\")\n                        else:\n                            # Geminiã®ã¿ã®å ´åˆã‚‚ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤ºï¼ˆå¤šå±¤ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆï¼‰\n                            if mode_category == \"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰(å¤šå±¤)\":\n                                final_answer = (\n                                    f\"**ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_id} (Deep Thinking / High Reasoning)**\\n\"\n                                    f\"**ãƒ¢ãƒ¼ãƒ‰: {response_mode}**\\n\\n---\\n\\n{final_answer}\"\n                                )\n                        \n                        # --- ãƒ¡ã‚¿æ€è€ƒãƒ¢ãƒ¼ãƒ‰: çµè«–ã‚’å…ˆå‡ºã—ã™ã‚‹ ---\n                        if \"ãƒ¡ã‚¿æ€è€ƒ\" in response_mode:\n                            # çµè«–éƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆç°¡æ˜“çš„ãªå®Ÿè£…ï¼‰\n                            # \"çµè«–\"ã‚„\"ã¾ã¨ã‚\"ãªã©ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¢ã—ã¦å…ˆé ­ã«ç§»å‹•\n                            lines = final_answer.split('\\n')\n                            conclusion_start = -1\n                            for i, line in enumerate(lines):\n                                if any(keyword in line for keyword in ['## çµè«–', '## ã¾ã¨ã‚', '**çµè«–**', '**ã¾ã¨ã‚**']):\n                                    conclusion_start = i\n                                    break\n                            \n                            if conclusion_start != -1:\n                                # çµè«–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¦‹ã¤ã‘ãŸå ´åˆã€ãã‚Œã‚’å…ˆé ­ã«ç§»å‹•\n                                conclusion_section = []\n                                other_content = lines[:conclusion_start]\n                                \n                                # çµè«–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®çµ‚ã‚ã‚Šã‚’è¦‹ã¤ã‘ã‚‹ï¼ˆæ¬¡ã®##ã¾ã§ or æ–‡æœ«ï¼‰\n                                conclusion_end = len(lines)\n                                for i in range(conclusion_start + 1, len(lines)):\n                                    if lines[i].startswith('## ') and i != conclusion_start:\n                                        conclusion_end = i\n                                        break\n                                \n                                conclusion_section = lines[conclusion_start:conclusion_end]\n                                remaining_content = lines[conclusion_end:]\n                                \n                                # å†æ§‹æˆ: ãƒ¢ãƒ‡ãƒ«å â†’ çµè«– â†’ ãã®ä»–ã®è©³ç´°\n                                # ãƒ¢ãƒ‡ãƒ«åéƒ¨åˆ†ã‚’ä¿æŒ\n                                model_line = \"\"\n                                if lines[0].startswith(\"**ğŸ¤–\"):\n                                    model_line = lines[0]\n                                    other_content = lines[1:conclusion_start]\n                                \n                                final_answer = '\\n'.join([\n                                    model_line,\n                                    \"\",\n                                    \"---\",\n                                    \"\",\n                                    \"## ğŸ“Œ çµè«–ï¼ˆå…ˆå‡ºã—ï¼‰\",\n                                    *conclusion_section[1:],  # å…ƒã®è¦‹å‡ºã—ã‚’é™¤ã\n                                    \"\",\n                                    \"---\",\n                                    \"\",\n                                    \"## ğŸ“ è©³ç´°\",\n                                    *other_content,\n                                    *remaining_content\n                                ]).strip()\n                        \n                        with status_container.expander(\"åˆç‰ˆã¨ã®æ¯”è¼ƒ\", expanded=False):\n                            st.markdown(\"**åˆç‰ˆ:**\")\n                            st.markdown(draft_answer[:500] + \"...\" if len(draft_answer) > 500 else draft_answer)\n                            st.markdown(\"**ä¿®æ­£ç‰ˆ:**\")\n                            st.markdown(final_answer[:500] + \"...\" if len(final_answer) > 500 else final_answer)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 3)\n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                review_resp.usage_metadata.prompt_token_count,\n                                review_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n                    else:\n                        final_answer = draft_answer\n\n                save_usage(usage_stats)\n                status_container.update(label=\"å®Œäº†ï¼\", state=\"complete\", expanded=False)\n\n                # ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤º\n                models_used = [f\"Gemini: {model_id}\"]\n                \n                # Grok Status\n                if enable_meta:\n                    if grok_status == \"success\":\n                        models_used.append(\"Grok: 4.1-fast-free (OK)\")\n                    elif grok_status == \"error\":\n                        models_used.append(\"Grok: 4.1-fast-free (Error)\")\n                    elif grok_status == \"empty\":\n                        models_used.append(\"Grok: 4.1-fast-free (Empty)\")\n                \n                # Claude Status\n                if is_puter_onigunsou:\n                    if claude_status == \"success\":\n                        models_used.append(\"Claude: Opus 4.5 (via Puter) (OK)\")\n                    elif claude_status == \"error\":\n                        models_used.append(\"Claude: Opus 4.5 (via Puter) (Error)\")\n                \n                st.caption(f\"ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {' + '.join(models_used)}\")\n                st.markdown(final_answer)\n\n                # ---- ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ± ----\n                if grounding_metadata:\n                    st.markdown(\"---\")\n                    with st.expander(\"ğŸ“š æƒ…å ±æºã¨å¼•ç”¨\", expanded=False):\n                        if grounding_metadata.grounding_chunks:\n                            st.markdown(\"**æ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:**\")\n                            unique_sources = {}\n                            import urllib.parse\n\n                            for chunk in grounding_metadata.grounding_chunks:\n                                if getattr(chunk, \"web\", None):\n                                    uri = getattr(chunk.web, \"uri\", None)\n                                    title = getattr(chunk.web, \"title\", \"æƒ…å ±æº\")\n                                    if uri and uri not in unique_sources:\n                                        parsed = urllib.parse.urlparse(uri)\n                                        domain = parsed.netloc.replace(\"www.\", \"\")\n                                        unique_sources[uri] = {\n                                            \"title\": title,\n                                            \"domain\": domain,\n                                        }\n                            for i, (uri, info) in enumerate(unique_sources.items(), 1):\n                                st.markdown(f\"{i}. **[{info['title']}]({uri})**\")\n                                st.caption(f\"   å‡ºå…¸: {info['domain']}\")\n\n                messages.append({\"role\": \"model\", \"content\": final_answer})\n                update_current_session_messages(messages)\n\n            except Exception as e:\n                status_container.update(label=\"Error\", state=\"error\")\n                err_text = str(e)\n                if \"RESOURCE_EXHAUSTED\" in err_text or \"429\" in err_text:\n                    st.error(\n                        \"âš ï¸ Vertex AI / Gemini ã®ã‚¯ã‚©ãƒ¼ã‚¿ã«é”ã—ã¾ã—ãŸã€‚\\n\\n\"\n                        \"ãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ / æ—¥æ¬¡åˆ¶é™ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\\n\"\n                        \"ãƒ»ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                        \"ãƒ»Google Cloud Console ã®ã€ŒVertex AI â†’ ä½¿ç”¨çŠ¶æ³ã€ã‹ã‚‰ã‚¯ã‚©ãƒ¼ã‚¿çŠ¶æ³ã‚’ç¢ºèªã§ãã¾ã™ã€‚\"\n                    )\n                elif \"NOT_FOUND\" in err_text and \"Publisher Model\" in err_text:\n                    st.error(\n                        \"âš ï¸ æŒ‡å®šã—ãŸãƒ¢ãƒ‡ãƒ«ãŒã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ / ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\\n\"\n                        \"ãƒ»ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ¢ãƒ‡ãƒ«IDã‚’ã€2.5ç³» ã¾ãŸã¯ 3 Pro ã«å¤‰æ›´ã—ã¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                    )\n                else:\n                    st.error(f\"An error occurred: {e}\")\n"
                },
                {
                    "role": "model",
                    "content": "**ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: gemini-3-pro-preview (Deep Thinking / High Reasoning)**\n**ãƒ¢ãƒ¼ãƒ‰: 1. ç†Ÿè€ƒ + é¬¼è»æ›¹**\n\n---\n\n## ğŸ“Œ çµè«–ï¼ˆå…ˆå‡ºã—ï¼‰\n\n**æ¡ä»¶ä»˜ãã§å‹•ä½œã™ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã€‚**\n\næä¾›ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã¯ã€**2025å¹´12æœˆ01æ—¥æ™‚ç‚¹**ã®æŠ€è¡“ç’°å¢ƒï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰ã«ãŠã„ã¦ã€è«–ç†çš„ã‹ã¤æ§‹æ–‡çš„ã«æ­£ã—ãæ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚ç‰¹ã«ã€Streamlitç‰¹æœ‰ã®éåŒæœŸå‡¦ç†ã®åˆ¶ç´„ã‚’ `nest_asyncio` ã§å›é¿ã—ã¦ã„ã‚‹ç‚¹ã¯è©•ä¾¡ã§ãã¾ã™ã€‚\n\nãŸã ã—ã€**ã€ŒClaude Opus 4.5ã€ã®ãƒ¢ãƒ‡ãƒ«IDæŒ‡å®š**ãŒPuterãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å´ã§æ­£ç¢ºã«ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹ãŒæœ€å¤§ã®ä¸ç¢ºå®šè¦ç´ ã§ã™ã€‚\n\n---\n\n## ğŸ“ è©³ç´°ãªåˆ†æã¨æŠ€è¡“çš„æ¤œè¨¼\n\nèª¿æŸ»ãƒ¡ãƒ¢ãŠã‚ˆã³ã‚³ãƒ¼ãƒ‰ãƒ­ã‚¸ãƒƒã‚¯ã«åŸºã¥ãã€å‹•ä½œã®å¯å¦ã‚’å³å¯†ã«åˆ†æã—ã¾ã—ãŸã€‚\n\n### 1. æŠ€è¡“çš„æ•´åˆæ€§ï¼ˆåˆæ ¼ï¼‰\n*   **éåŒæœŸå‡¦ç†ã®å›é¿**: Streamlitã¯æ¨™æº–ã§ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’ç®¡ç†ã—ã¦ã„ã‚‹ãŸã‚ã€é€šå¸¸ `asyncio.run()` ã¯ã‚¨ãƒ©ãƒ¼ã«ãªã‚Šã¾ã™ã€‚ã—ã‹ã—ã€ã‚³ãƒ¼ãƒ‰å†’é ­ã§ `nest_asyncio.apply()` ãŒé©ç”¨ã•ã‚Œã¦ãŠã‚Šã€ã“ã®å•é¡Œã¯æŠ€è¡“çš„ã«è§£æ±ºã•ã‚Œã¦ã„ã¾ã™ã€‚\n*   **SDKã®ä½¿ç”¨æ³•**: `putergenai` ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã® `PuterClient`ã€`login`ã€`ai_chat` ã®å‘¼ã³å‡ºã—ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã¯ã€æ¨™æº–çš„ãªSDKã®ä»•æ§˜ã«æº–æ‹ ã—ã¦ãŠã‚Šã€å®Ÿè£…ä¸Šã®èª¤ã‚Šã¯è¦‹å½“ãŸã‚Šã¾ã›ã‚“ã€‚\n\n### 2. ãƒ¢ãƒ‡ãƒ«ã®å®Ÿåœ¨æ€§ã¨åˆ©ç”¨å¯èƒ½æ€§ï¼ˆè¦ç¢ºèªï¼‰\n*   **Claude Opus 4.5 ã®å®Ÿåœ¨**: èª¿æŸ»ãƒ¡ãƒ¢ã«ã‚ˆã‚Œã°ã€Anthropicã¯ **2025å¹´11æœˆ24æ—¥** ã« `Claude Opus 4.5` ã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã¦ãŠã‚Šã€ãƒ¢ãƒ‡ãƒ«è‡ªä½“ã¯å®Ÿåœ¨ã—ã¾ã™ã€‚\n*   **PuterçµŒç”±ã®ã‚¢ã‚¯ã‚»ã‚¹**: Puter.comãŒã“ã®æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã«å³åº§ã«å¯¾å¿œã—ã¦ã„ã‚‹ã‹ãŒéµã§ã™ã€‚ã‚³ãƒ¼ãƒ‰å†…ã® `\"model\": \"claude-opus-4-5\"` ã¨ã„ã†æŒ‡å®šã¯ã€Puterå´ãŒã“ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹ï¼ˆçŸ­ç¸®åï¼‰ã‚’å—ã‘ä»˜ã‘ã‚‹å ´åˆã«ã®ã¿æ©Ÿèƒ½ã—ã¾ã™ã€‚\n\n### 3. èªè¨¼ã¨ç’°å¢ƒï¼ˆå‰ææ¡ä»¶ï¼‰\n*   **ç’°å¢ƒå¤‰æ•°**: `PUTER_USERNAME` ãŠã‚ˆã³ `PUTER_PASSWORD` ãŒ `st.secrets` ã¾ãŸã¯ `os.environ` ã«æ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒå‹•ä½œã®çµ¶å¯¾æ¡ä»¶ã§ã™ã€‚ã“ã‚Œã‚‰ãŒæ¬ ã‘ã¦ã„ã‚‹å ´åˆã€é–¢æ•°ã¯å³åº§ã«ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã—ã¾ã™ã€‚\n\n---\n\n## âš ï¸ é¬¼è»æ›¹ã®æŒ‡æ‘˜ï¼šå®Ÿè¡Œå‰ã®ä¿®æ­£ãƒ»ç¢ºèªãƒªã‚¹ãƒˆ\n\nã€Œå‹•ãã¯ãšã€ã§çµ‚ã‚ã‚‰ã›ãšã€ä»¥ä¸‹ã®ãƒªã‚¹ã‚¯ã‚’æ½°ã—ã¦ã‹ã‚‰å®Ÿè¡Œã™ã‚‹ã“ã¨ã€‚\n\n### 1. ãƒ¢ãƒ‡ãƒ«IDã®æºã‚‰ãã«å¯¾ã™ã‚‹é˜²è¡›ç­–\nèª¿æŸ»ãƒ¡ãƒ¢ã«ã‚ˆã‚‹ã¨ã€æ­£å¼ãªAPI IDã¯ `claude-opus-4-5-20251101` ã§ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚PuterãŒçŸ­ç¸®å `claude-opus-4-5` ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ãªã„å ´åˆã€`400 Bad Request` ãŒç™ºç”Ÿã—ã¾ã™ã€‚\n*   **å¯¾ç­–**: ã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸå ´åˆã€`call_claude_opus_via_puter` é–¢æ•°å†…ã®ãƒ¢ãƒ‡ãƒ«æŒ‡å®šã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«æ›¸ãæ›ãˆã‚‹æº–å‚™ã‚’ã—ã¦ãŠãã“ã¨ã€‚\n    ```python\n    # ä¿®æ­£æ¡ˆ\n    \"model\": \"claude-opus-4-5-20251101\", \n    ```\n\n### 2. å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æ¬ è½ãƒªã‚¹ã‚¯\nã‚³ãƒ¼ãƒ‰å†…ã§ `import` ã•ã‚Œã¦ã„ã‚‹ä»¥ä¸‹ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯ã€æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚`requirements.txt` ã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n*   `putergenai`\n*   `nest_asyncio`\n*   `curl_cffi` (Grokç”¨ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹å ´åˆ)\n\n### 3. Puterã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆç¢ºèª\nPuter.comã¯ã€ŒUser-Paysã€ãƒ¢ãƒ‡ãƒ«ã‚’æ¡ç”¨ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚Claude Opusã‚¯ãƒ©ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã¯é«˜ä¾¡ã§ã‚ã‚‹ãŸã‚ã€ç„¡æ–™æ ã§å‹•ä½œã—ãªã„ã€ã‚ã‚‹ã„ã¯ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆä¸è¶³ã§å³åœæ­¢ã™ã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®Billingè¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n\n### 4. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®æ­»è§’\n`call_claude_opus_via_puter` é–¢æ•°ã¯ä¾‹å¤–ã‚’ã‚­ãƒ£ãƒƒãƒã—ã¦æ–‡å­—åˆ—ã§è¿”ã—ã¾ã™ãŒã€å‘¼ã³å‡ºã—å…ƒï¼ˆãƒ¡ã‚¤ãƒ³ã®UIéƒ¨åˆ†ï¼‰ã§ã€Œã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¿”ã£ã¦ããŸå ´åˆã€ã®å‡¦ç†ï¼ˆèµ¤å­—ã§è¡¨ç¤ºã™ã‚‹ãªã©ï¼‰ãŒæ˜ç¤ºã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n*   **æ¨å¥¨**: æˆ»ã‚Šå€¤ãŒ `[Claude` ã§å§‹ã¾ã‚‹å ´åˆã€`st.error` ã§è¡¨ç¤ºã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ã‚’è¿½åŠ ã™ã‚‹ã¨ã€ãƒ‡ãƒãƒƒã‚°ãŒå®¹æ˜“ã«ãªã‚Šã¾ã™ã€‚"
                }
            ]
        },
        {
            "id": "eaf4a1ac-e3a8-461f-b226-b0743e0c5186",
            "title": "1ä»¥ä¸‹ã ãŒã€ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰è¨­å®šã‚’ã—ã¦ã€dep...",
            "timestamp": "2025-11-30T14:31:40.689281",
            "messages": [
                {
                    "role": "user",
                    "content": "1ä»¥ä¸‹ã ãŒã€ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰è¨­å®šã‚’ã—ã¦ã€deployã™ã‚Œã°ã‚¹ãƒãƒ›ã‹ã‚‰ã§ã‚‚ä½¿ãˆã‚‹ã®ã§ã¯ï¼Ÿ\n2ã¾ãŸã€googlecloudã§ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚’æ¶ˆè²»ã—ã¦ã‚‚è‡ªå‹•èª²é‡‘ã—ãªã„çŠ¶æ…‹ã‚’é¸ã‚“ã§ã„ã‚‹ã‹ã‚‰ä¸‡ä¸€passæ¼æ´©ã—ã¦ã‚‚å¤§ä¸ˆå¤«ã ã®ã§ã¯ã€‚\n\n\nimport os\nimport uuid\nimport datetime\nimport streamlit as st\nfrom dotenv import load_dotenv\nfrom google import genai\nfrom google.genai import types\nfrom PIL import Image\nimport io\nfrom logic import (\n    USAGE_FILE, SESSIONS_FILE, MAX_BUDGET_USD, PRICING,\n    VERTEX_PROJECT, VERTEX_LOCATION,\n    load_usage, save_usage, calculate_cost, get_mime_type,\n    extract_youtube_id, get_youtube_transcript, get_relevant_context,\n    extract_text_from_response, load_sessions, save_sessions, get_client\n)\n\ntry:\n    from st_img_pastebutton import paste\n    import_error_msg = None\nexcept ImportError as e:\n    paste = None\n    import_error_msg = str(e)\n\n# =========================\n# ç’°å¢ƒå¤‰æ•° & å®šæ•°\n# =========================\n\nload_dotenv()\n\n\n\nst.set_page_config(page_title=\"Gemini 3 Web Studio\", layout=\"wide\")\n\n# =========================\n# Helper Functions\n# =========================\n\n# =========================\n# Helper Functions\n# =========================\n# Moved to logic.py\n\n# =========================\n# Session Management\n# =========================\n\n\n\ndef create_new_session():\n    current_sessions = load_sessions()\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": [],\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.rerun()\n\ndef switch_session(session_id):\n    st.session_state.current_session_id = session_id\n    st.rerun()\n\ndef update_current_session_messages(messages):\n    if st.session_state.current_session_id:\n        current_sessions = load_sessions()\n        for session in current_sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                session[\"messages\"] = messages\n                if session[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(messages) > 0:\n                    first_msg = messages[0][\"content\"]\n                    session[\"title\"] = (first_msg[:20] + \"...\") if len(first_msg) > 20 else first_msg\n                session[\"timestamp\"] = datetime.datetime.now().isoformat()\n                break\n        save_sessions(current_sessions)\n        st.session_state.sessions = current_sessions\n\ndef get_current_messages():\n    if st.session_state.current_session_id:\n        for session in st.session_state.sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                return session[\"messages\"]\n    return []\n\ndef delete_session(session_id):\n    current_sessions = load_sessions()\n    current_sessions = [s for s in current_sessions if s[\"id\"] != session_id]\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    if st.session_state.current_session_id == session_id:\n        st.session_state.current_session_id = None\n        if st.session_state.sessions:\n            st.session_state.current_session_id = st.session_state.sessions[0][\"id\"]\n    st.rerun()\n\ndef branch_session():\n    \"\"\"ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚’åˆ†å²\"\"\"\n    current_messages = get_current_messages()\n    current_sessions = load_sessions()\n    \n    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—\n    current_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n    for session in current_sessions:\n        if session[\"id\"] == st.session_state.current_session_id:\n            current_title = session[\"title\"]\n            break\n    \n    # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": f\"{current_title} (åˆ†å²)\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": current_messages.copy(),  # ç¾åœ¨ã®å±¥æ­´ã‚’ã‚³ãƒ”ãƒ¼\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    \n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.session_state.session_cost = 0.0  # ã‚³ã‚¹ãƒˆãƒªã‚»ãƒƒãƒˆ\n    st.rerun()\n\n# =========================\n# Initialization\n# =========================\n\nif \"sessions\" not in st.session_state:\n    st.session_state.sessions = load_sessions()\n\nif \"current_session_id\" not in st.session_state:\n    # Always create a new session when the app starts\n    create_new_session()\n\nif \"session_cost\" not in st.session_state:\n    st.session_state.session_cost = 0.0\n\nusage_stats = load_usage()\n\n# =========================\n# Sidebar\n# =========================\n\nwith st.sidebar:\n    st.markdown(\"\"\"\n    <div style=\"text-align: center; padding: 0; margin: 0; margin-top: -1rem;\">\n        <h1 style=\"font-size: 18px; font-weight: 700; margin: 0; padding: 0; letter-spacing: 1px;\">\n            Gemini 3<br/>Studio\n        </h1>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n    col1, col2 = st.columns(2)\n    with col1:\n        if st.button(\"â• æ–°è¦\", use_container_width=True):\n            create_new_session()\n    with col2:\n        if st.button(\"ğŸŒ± åˆ†å²\", use_container_width=True):\n            branch_session()\n\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    current_messages = get_current_messages()\n    if current_messages:\n        with st.expander(\"ğŸ”— å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ\", expanded=False):\n            export_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n            for s in st.session_state.sessions:\n                if s[\"id\"] == st.session_state.current_session_id:\n                    export_title = s[\"title\"]\n                    break\n\n            export_md = f\"# {export_title}\\n\\n\"\n            export_md += f\"**ä½œæˆæ—¥æ™‚**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n---\\n\\n\"\n            for msg in current_messages:\n                role_label = \"ğŸ§‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼\" if msg[\"role\"] == \"user\" else \"ğŸ¤– AI\"\n                export_md += f\"## {role_label}\\n\\n{msg['content']}\\n\\n---\\n\\n\"\n\n            if st.button(\"ãƒªãƒ³ã‚¯ç”Ÿæˆ\", use_container_width=True):\n                with st.spinner(\"ç”Ÿæˆä¸­...\"):\n                    try:\n                        import urllib.request\n                        import urllib.parse\n\n                        data = urllib.parse.urlencode(\n                            {\"content\": export_md, \"expiry_days\": 7, \"syntax\": \"md\"}\n                        ).encode()\n\n                        req = urllib.request.Request(\"https://dpaste.org/api/\", data=data)\n                        req.add_header(\"User-Agent\", \"Mozilla/5.0 (Gemini3Studio)\")\n\n                        with urllib.request.urlopen(req) as response:\n                            share_url = response.read().decode(\"utf-8\").strip()\n                            st.success(\"ä½œæˆå®Œäº†ï¼\")\n                            st.code(share_url)\n                            st.caption(\"â€»7æ—¥é–“æœ‰åŠ¹\")\n                    except Exception as e:\n                        st.error(f\"ã‚¨ãƒ©ãƒ¼: {e}\")\n\n    st.markdown(\"---\")\n\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    with st.expander(\"ğŸ“ æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«\", expanded=False):\n        uploaded_files = st.file_uploader(\n            \"ãƒ•ã‚¡ã‚¤ãƒ«\",\n            accept_multiple_files=True,\n            type=[\"png\", \"jpg\", \"jpeg\", \"mp4\", \"mov\", \"txt\", \"pdf\", \"csv\"],\n            label_visibility=\"collapsed\"\n        )\n\n    # ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ï¼ˆExpanderã®å¤–ã«å‡ºã™ï¼‰\n    if paste:\n        if \"paste_key\" not in st.session_state:\n            st.session_state.paste_key = 0\n        try:\n            pasted_image_bytes = paste(\n                label=\"ğŸ“‹ è²¼ä»˜\",\n                key=f\"paste_btn_{st.session_state.paste_key}\",\n            )\n        except Exception as e:\n            st.error(f\"Error: {e}\")\n        \n        if pasted_image_bytes:\n            st.success(\"è²¼ä»˜å®Œäº†\")\n            st.image(pasted_image_bytes, caption=\"ç”»åƒ\", use_container_width=True)\n            if st.button(\"ğŸ—‘ï¸ ã‚¯ãƒªã‚¢\", key=\"clear_paste\"):\n                st.session_state.paste_key += 1\n                st.rerun()\n    else:\n        st.warning(\"Clipboard lib missing\")\n\n    # ---- YouTube URL ----\n    with st.expander(\"ğŸ“º YouTubeåˆ†æ\", expanded=False):\n        youtube_url = st.text_input(\"URL\", placeholder=\"https://youtu.be/...\", label_visibility=\"collapsed\")\n\n    st.markdown(\"---\")\n    \n    st.markdown(\"---\")\n    \n    # ---- å›ç­”ãƒ¢ãƒ¼ãƒ‰ ----\n    with st.expander(\"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰\", expanded=True):\n        mode_type = st.radio(\n            \"ã‚¿ã‚¤ãƒ—\",\n            [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n            index=0,\n            horizontal=True,\n            label_visibility=\"collapsed\"\n        )\n        \n        if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n            response_mode = st.radio(\n                \"ãƒ¢ãƒ¼ãƒ‰\",\n                [\n                    \"2. ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                    \"3. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                    \"Î²2. ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                ],\n                index=0\n            )\n        elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n            response_mode = st.radio(\n                \"ãƒ¢ãƒ¼ãƒ‰\",\n                [\n                    \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                ],\n                index=0\n            )\n        else:\n            response_mode = st.radio(\n                \"ãƒ¢ãƒ¼ãƒ‰\",\n                [\n                    \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                ],\n                index=0\n            )\n    \n    strict_mode = False\n    \n    # ---- è¨­å®š (ãƒ¢ãƒ‡ãƒ«ãªã©) ----\n    with st.expander(\"âš™ï¸ è¨­å®š\", expanded=False):\n        model_options = [\n            \"gemini-3-pro-preview\",\n            \"gemini-2.5-pro\",\n            \"gemini-2.5-flash\",\n            \"gemini-2.5-flash-lite\",\n            \"gemini-2.0-flash\",\n        ]\n        model_id = st.selectbox(\"ãƒ¢ãƒ‡ãƒ«ID\", options=model_options, index=0)\n\n        use_search = st.toggle(\"Googleæ¤œç´¢\", value=True)\n        candidate_count = st.slider(\"å€™è£œæ•°\", min_value=1, max_value=3, value=3)\n\n    st.markdown(\"---\")\n\n    # ---- å±¥æ­´æ¤œç´¢ ----\n    search_query = st.text_input(\"ğŸ” å±¥æ­´æ¤œç´¢\", placeholder=\"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰...\")\n    if search_query:\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if search_query.lower() in s[\"title\"].lower():\n                filtered_sessions.append(s)\n                continue\n            found = False\n            for m in s[\"messages\"]:\n                if search_query.lower() in m[\"content\"].lower():\n                    filtered_sessions.append(s)\n                    found = True\n                    break\n            if not found:\n                pass\n    else:\n        # æ¤œç´¢ã—ã¦ã„ãªã„å ´åˆ: ç©ºã®ã€Œæ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã€ã‚’é™¤å¤–ï¼ˆç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯é™¤ãï¼‰\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if s[\"id\"] == st.session_state.current_session_id:\n                filtered_sessions.append(s)\n                continue\n            if s[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(s[\"messages\"]) == 0:\n                continue\n            filtered_sessions.append(s)\n\n    # CSSã§è¦‹ã‚„ã™ãä½¿ã„ã‚„ã™ãæœ€é©åŒ–\n    st.markdown(\"\"\"\n    <style>\n    /* PC ç”»é¢ã ã‘ã«é©ç”¨ï¼ˆå¹… 769px ä»¥ä¸Šï¼‰ */\n    @media (min-width: 769px) {\n        /* å…¨ä½“ã®ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºç¸®å° */\n        .stApp, .stMarkdown, .stButton, .stSelectbox, .stTextInput, .stTextArea {\n            font-size: 12px !important;\n        }\n        /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ä½™ç™½ã‚’æ¥µé™ã¾ã§è©°ã‚ã‚‹ */\n        section[data-testid=\"stSidebar\"] .block-container {\n            padding-top: 0rem !important;\n            padding-bottom: 0.3rem !important;\n            padding-left: 0.5rem !important;\n            padding-right: 0.5rem !important;\n        }\n        /* å„è¦ç´ é–“ã®éš™é–“ã‚’è©°ã‚ã‚‹ */\n        div[data-testid=\"stVerticalBlock\"] > div {\n            gap: 0.1rem !important;\n        }\n        /* Expanderã®ä½™ç™½å‰Šæ¸› */\n        .streamlit-expanderHeader {\n            font-size: 10px !important;\n            padding-top: 0px !important;\n            padding-bottom: 0px !important;\n            min-height: 1.3rem !important;\n        }\n        .streamlit-expanderContent {\n            padding-top: 0px !important;\n            padding-bottom: 0px !important;\n        }\n        /* éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã®ã‚¿ã‚¤ãƒˆãƒ« */\n        div[data-testid=\"stExpander\"] summary p {\n            font-size: 9px !important;\n        }\n        /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ */\n        section[data-testid=\"stSidebar\"] button p {\n            font-size: 9px !important;\n        }\n        /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã« */\n        section[data-testid=\"stSidebar\"] button {\n            padding: 0rem 0.2rem !important;\n            min-height: 1.4rem !important;\n            font-size: 9px !important;\n            margin-bottom: 0px !important;\n        }\n        /* ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®ãƒ©ãƒ™ãƒ«ã‚’å°ã•ã */\n        section[data-testid=\"stSidebar\"] .stRadio label {\n            font-size: 9px !important;\n        }\n        section[data-testid=\"stSidebar\"] .stRadio > label > div {\n            font-size: 9px !important;\n        }\n        section[data-testid=\"stSidebar\"] .stRadio div[role=\"radiogroup\"] label {\n            font-size: 9px !important;\n        }\n        /* ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ‡ã‚Šè©°ã‚ã‚‹ï¼ˆæ”¹è¡Œã•ã›ãªã„ï¼‰ */\n        section[data-testid=\"stSidebar\"] label, \n        section[data-testid=\"stSidebar\"] p,\n        section[data-testid=\"stSidebar\"] span {\n            white-space: nowrap !important;\n            overflow: hidden !important;\n            text-overflow: ellipsis !important;\n        }\n        /* åŒºåˆ‡ã‚Šç·š */\n        hr {\n            margin-top: 0.1rem !important;\n            margin-bottom: 0.1rem !important;\n        }\n        /* ãƒ˜ãƒƒãƒ€ãƒ¼ç¸®å° */\n        h1, h2, h3 {\n            padding-top: 0rem !important;\n            padding-bottom: 0rem !important;\n            margin-top: 0rem !important;\n            margin-bottom: 0rem !important;\n        }\n    }\n    </style>\n    \"\"\", unsafe_allow_html=True)\n    \n    # ç›´è¿‘5ä»¶ã¨éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«åˆ†å‰²\n    recent_sessions = filtered_sessions[:5] if len(filtered_sessions) > 5 else filtered_sessions\n    archive_sessions = filtered_sessions[5:] if len(filtered_sessions) > 5 else []\n    \n    # ç›´è¿‘5ä»¶ï¼ˆå¸¸ã«å±•é–‹ï¼‰\n    if recent_sessions:\n        st.markdown(\"**ğŸ“Œ ç›´è¿‘ã®ãƒãƒ£ãƒƒãƒˆ**\")\n        for session in recent_sessions:\n            col1, col2 = st.columns([0.8, 0.2])\n            with col1:\n                if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                    switch_session(session[\"id\"])\n            with col2:\n                if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                    delete_session(session[\"id\"])\n    \n    # éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆæŠ˜ã‚ŠãŸãŸã¿ï¼‰\n    if archive_sessions:\n        with st.expander(f\"ğŸ“œ éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ– ({len(archive_sessions)}ä»¶)\", expanded=False):\n            for session in archive_sessions:\n                col1, col2 = st.columns([0.8, 0.2])\n                with col1:\n                    if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                        switch_session(session[\"id\"])\n                with col2:\n                    if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                        delete_session(session[\"id\"])\n\n    st.markdown(\"---\")\n\n    # ---- ç”»åƒç”Ÿæˆ ----\n    with st.expander(\"ğŸ¨ ç”»åƒç”Ÿæˆ\", expanded=False):\n        img_prompt = st.text_area(\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\", placeholder=\"æœªæ¥çš„ãªéƒ½å¸‚...\")\n        aspect_ratio = st.selectbox(\"æ¯”ç‡\", [\"16:9\", \"1:1\", \"4:3\", \"3:4\", \"9:16\"])\n\n        generate_img_btn = st.button(\"ç”Ÿæˆ\", type=\"primary\", disabled=not img_prompt)\n        if generate_img_btn and img_prompt:\n            st.session_state.generate_image_trigger = {\n                \"prompt\": img_prompt,\n                \"aspect_ratio\": aspect_ratio,\n            }\n\n    st.markdown(\"---\")\n\n    # ---- è©•ä¾¡åˆ†æ ----\n    with st.expander(\"ğŸ“Š å“è³ªåˆ†æ\", expanded=False):\n        total_ratings = 0\n        positive_ratings = 0\n        model_ratings = {}\n\n        for s in st.session_state.sessions:\n            for m in s[\"messages\"]:\n                if \"rating\" in m and m[\"rating\"] is not None:\n                    total_ratings += 1\n                    if m[\"rating\"] == 1:\n                        positive_ratings += 1\n                    if \"metadata\" in m and \"model\" in m[\"metadata\"]:\n                        mod = m[\"metadata\"][\"model\"]\n                        if mod not in model_ratings:\n                            model_ratings[mod] = {\"total\": 0, \"positive\": 0}\n                        model_ratings[mod][\"total\"] += 1\n                        if m[\"rating\"] == 1:\n                            model_ratings[mod][\"positive\"] += 1\n\n        if total_ratings > 0:\n            approval_rate = (positive_ratings / total_ratings) * 100\n            st.metric(\"Positive Ratings\", f\"{positive_ratings}/{total_ratings}\", f\"{approval_rate:.1f}%\")\n            best_model = \"N/A\"\n            best_rate = -1\n            for mod, stats in model_ratings.items():\n                rate = stats[\"positive\"] / stats[\"total\"]\n                if rate > best_rate:\n                    best_rate = rate\n                    best_model = mod\n            if best_model != \"N/A\":\n                st.caption(f\"ğŸ† Best: **{best_model}** ({best_rate*100:.0f}%)\")\n        else:\n            st.caption(\"ãƒ‡ãƒ¼ã‚¿ãªã—\")\n\n    st.markdown(\"---\")\n\n    # ---- ã‚³ã‚¹ãƒˆè¡¨ç¤º ----\n    st.metric(\"Cost\", f\"${usage_stats['total_cost_usd']:.4f}\")\n    if st.session_state.session_cost > 0:\n        st.caption(f\"Session: ${st.session_state.session_cost:.4f}\")\n\n    if usage_stats[\"total_cost_usd\"] >= MAX_BUDGET_USD:\n        st.error(f\"âš ï¸ ä¸Šé™ (${MAX_BUDGET_USD}) åˆ°é”\")\n        stop_generation = True\n    else:\n        stop_generation = False\n\n    st.markdown(\"---\")\n    st.code(f\"PROJECT: {VERTEX_PROJECT}\\nLOCATION: {VERTEX_LOCATION} (Vertex AI)\")\n\n# =========================\n# Main UI\n# =========================\n\ncurrent_session_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\nfor s in st.session_state.sessions:\n    if s[\"id\"] == st.session_state.current_session_id:\n        current_session_title = s[\"title\"]\n        break\n\nst.header(current_session_title)\nst.markdown(\n    \"ä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\"\n)\n\n# ---- Vertex AI Client ----\n\n\n\nclient = get_client()\n\n# ---- å±¥æ­´è¡¨ç¤º ----\n\nmessages = get_current_messages()\nfor idx, msg in enumerate(messages):\n    with st.chat_message(msg[\"role\"]):\n        st.markdown(msg[\"content\"])\n        if msg[\"role\"] == \"model\":\n            col1, col2, col3 = st.columns([0.1, 0.1, 0.8])\n            current_rating = msg.get(\"rating\")\n            with col1:\n                if st.button(\"ğŸ‘\", key=f\"up_{idx}\"):\n                    messages[idx][\"rating\"] = 1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col2:\n                if st.button(\"ğŸ‘\", key=f\"down_{idx}\"):\n                    messages[idx][\"rating\"] = -1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col3:\n                if current_rating == 1:\n                    st.caption(\"âœ… é«˜è©•ä¾¡\")\n                elif current_rating == -1:\n                    st.caption(\"âŒ ä½è©•ä¾¡\")\n\n# =========================\n# ç”»åƒç”Ÿæˆãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°\n# =========================\n\nif hasattr(st.session_state, \"generate_image_trigger\") and st.session_state.generate_image_trigger:\n    img_data = st.session_state.generate_image_trigger\n    del st.session_state.generate_image_trigger\n\n    with st.chat_message(\"user\"):\n        st.markdown(f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\")\n        st.caption(f\"ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”: {img_data['aspect_ratio']}\")\n\n    messages.append({\"role\": \"user\", \"content\": f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\"})\n    update_current_session_messages(messages)\n\n    with st.chat_message(\"assistant\"):\n        with st.status(\"ç”»åƒã‚’ç”Ÿæˆä¸­...\", expanded=True) as status:\n            try:\n                config = types.GenerateContentConfig(\n                    response_modalities=[\"IMAGE\"],\n                    image_config=types.ImageConfig(\n                        aspect_ratio=img_data[\"aspect_ratio\"]\n                    ),\n                )\n                status.write(\"Gemini 3 Pro Imageã§ç”Ÿæˆä¸­...\")\n                response = client.models.generate_content(\n                    model=\"gemini-3-pro-image-preview\",\n                    contents=img_data[\"prompt\"],\n                    config=config,\n                )\n\n                generated_image = None\n\n                # ç”»åƒã‚’å–ã‚Šå‡ºã™\n                if getattr(response, \"candidates\", None):\n                    for candidate in response.candidates:\n                        if getattr(candidate, \"content\", None) and candidate.content.parts:\n                            for part in candidate.content.parts:\n                                if getattr(part, \"inline_data\", None):\n                                    try:\n                                        generated_image = part.as_image()\n                                    except AttributeError:\n                                        image_bytes_raw = part.inline_data.data\n                                        generated_image = Image.open(io.BytesIO(image_bytes_raw))\n                                    break\n                        if generated_image is not None:\n                            break\n\n                if generated_image is not None:\n                    st.image(generated_image, caption=img_data[\"prompt\"])\n                    buf = io.BytesIO()\n                    generated_image.save(buf, format=\"PNG\")\n                    image_bytes = buf.getvalue()\n                    st.download_button(\n                        label=\"ğŸ’¾ ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\",\n                        data=image_bytes,\n                        file_name=f\"generated_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png\",\n                        mime=\"image/png\",\n                    )\n                    messages.append(\n                        {\"role\": \"model\", \"content\": f\"âœ… ç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {img_data['prompt']}\"}\n                    )\n                    update_current_session_messages(messages)\n                    status.update(label=\"âœ… ç”»åƒç”Ÿæˆå®Œäº†\", state=\"complete\")\n                else:\n                    st.error(\"ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")\n                    status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n\n            except Exception as e:\n                status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n                st.error(f\"ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}\")\n\n# =========================\n# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›\n# =========================\n\nprompt = st.chat_input(\"ä½•ã‹èã„ã¦ãã ã•ã„...\", disabled=stop_generation)\n\nif prompt:\n    if stop_generation:\n        st.error(\"äºˆç®—ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚\")\n    else:\n        # ---- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€è¡¨ç¤º ----\n        with st.chat_message(\"user\"):\n            st.markdown(prompt)\n            if uploaded_files:\n                for uf in uploaded_files:\n                    st.caption(f\"ğŸ“ æ·»ä»˜: {uf.name}\")\n            if youtube_url:\n                st.caption(f\"ğŸ“º YouTube: {youtube_url}\")\n            if pasted_image_bytes:\n                st.caption(\"ğŸ“‹ ç”»åƒãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚Œã¾ã—ãŸ\")\n\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        update_current_session_messages(messages)\n\n        # ---- ãƒ¢ãƒ‡ãƒ«å¿œç­” ----\n        with st.chat_message(\"assistant\"):\n            status_container = st.status(\"æ€è€ƒä¸­...\", expanded=True)\n            try:\n                # ä¼šè©±å±¥æ­´\n                model_history = []\n                for msg in messages[:-1]:\n                    model_history.append(\n                        types.Content(\n                            role=msg[\"role\"],\n                            parts=[types.Part.from_text(text=msg[\"content\"])],\n                        )\n                    )\n\n                # ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³\n                current_parts = [types.Part.from_text(text=prompt)]\n\n                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«\n                for uploaded_file in uploaded_files or []:\n                    try:\n                        mime_type = get_mime_type(uploaded_file.name)\n                        bytes_data = uploaded_file.getvalue()\n                        part = types.Part.from_bytes(data=bytes_data, mime_type=mime_type)\n                        current_parts.append(part)\n                        status_container.write(f\"ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™å®Œäº†: {uploaded_file.name}\")\n                    except Exception as e:\n                        status_container.error(\n                            f\"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {uploaded_file.name} - {e}\"\n                        )\n\n                # è²¼ã‚Šä»˜ã‘ç”»åƒ\n                if pasted_image_bytes:\n                    import base64\n\n                    status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã‚’å‡¦ç†ä¸­...\")\n                    try:\n                        if isinstance(pasted_image_bytes, str):\n                            if pasted_image_bytes.startswith(\"data:\"):\n                                base64_str = pasted_image_bytes.split(\",\", 1)[1]\n                                image_bytes_decoded = base64.b64decode(base64_str)\n                            else:\n                                image_bytes_decoded = base64.b64decode(pasted_image_bytes)\n                        else:\n                            image_bytes_decoded = pasted_image_bytes\n                        part = types.Part.from_bytes(\n                            data=image_bytes_decoded, mime_type=\"image/png\"\n                        )\n                        current_parts.append(part)\n                        status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®æº–å‚™å®Œäº†\")\n                    except Exception as e:\n                        status_container.error(f\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n\n                # YouTube å­—å¹•\n                if youtube_url:\n                    vid_id = extract_youtube_id(youtube_url)\n                    if vid_id:\n                        status_container.write(\"YouTubeã®å­—å¹•ã‚’å–å¾—ä¸­...\")\n                        transcript_text = get_youtube_transcript(vid_id)\n                        current_parts.append(\n                            types.Part.from_text(text=f\"YouTube Transcript:\\n{transcript_text}\")\n                        )\n                    else:\n                        status_container.write(\"ç„¡åŠ¹ãªYouTube URLã§ã™ã€‚\")\n\n                contents_for_model = model_history + [\n                    types.Content(role=\"user\", parts=current_parts)\n                ]\n\n                # ---- Tool / Config ----\n                tools = []\n                final_candidate_count = candidate_count\n                if use_search:\n                    tools.append(types.Tool(google_search=types.GoogleSearch()))\n                    final_candidate_count = 1\n\n                # â˜… System Instruction ã®æ”¹å–„: ãƒ¡ã‚¿ç™ºè¨€ç¦æ­¢ã¨ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªæŒ¯ã‚‹èˆã„ã‚’æŒ‡ç¤º\n                base_system_instruction = (\n                    \"ã‚ãªãŸã¯é«˜åº¦ãªçŸ¥æ€§ã‚’æŒã¤å°‚é–€çš„ãªãƒªã‚µãƒ¼ãƒãƒ»ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\\n\"\n                    \"ä»¥ä¸‹ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’å³å®ˆã—ã¦ãã ã•ã„ï¼š\\n\"\n                    \"1. **ãƒ¡ã‚¿ç™ºè¨€ã®ç¦æ­¢**: ã€Œç§ã¯AIã§ã™ã€ã€Œä¸–ç•Œæœ€é«˜å³°ã®ï½ã¨ã—ã¦ã€ãªã©ã®è‡ªå·±è¨€åŠã‚„å‰ç½®ãã¯ä¸€åˆ‡è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚\\n\"\n                    \"2. **æ„å›³ã®æ±²ã¿å–ã‚Š**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã®èƒŒå¾Œã«ã‚ã‚‹æ„å›³ï¼ˆæ–‡è„ˆã€æš—é»™ã®å‰æï¼‰ã‚’æ¨æ¸¬ã—ã€è¨€è‘‰é€šã‚Šã§ã¯ãªãã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ¬å½“ã«çŸ¥ã‚ŠãŸã„ã“ã¨ã€ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n\"\n                    \"3. **æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”**: çµè«–ã‚’å…ˆã«è¿°ã¹ã€ãã®å¾Œã«è©³ç´°ãªæ ¹æ‹ ã€ã‚·ãƒŠãƒªã‚ªåˆ†æã€ãƒªã‚¹ã‚¯è¦å› ã‚’è«–ç†çš„ã«å±•é–‹ã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"4. **å®¢è¦³æ€§**: äºˆæ¸¬ã‚’è¡Œã†å ´åˆã¯ã€æ–­å®šã‚’é¿ã‘ã€è¤‡æ•°ã®ã‚·ãƒŠãƒªã‚ªï¼ˆæ¥½è¦³ã€æ‚²è¦³ã€ä¸­ç«‹ï¼‰ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"5. **å¼•ç”¨**: æ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸå ´åˆã¯ã€å¿…ãšæƒ…å ±æºã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚\"\n                )\n\n                final_answer = \"\"\n                grounding_metadata = None\n                \n                # =========================\n                # ãƒ¢ãƒ¼ãƒ‰è¨­å®šã®è§£æ\n                # =========================\n                enable_research = True  # å…¨ãƒ¢ãƒ¼ãƒ‰ã§ãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œ\n                enable_meta = \"ãƒ¡ã‚¿\" in response_mode or \"MAX\" in response_mode\n                enable_strict = \"é¬¼è»æ›¹\" in response_mode or \"MAX\" in response_mode\n\n                # =========================\n                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (é«˜é€Ÿ / é¬¼è»æ›¹)\n                # =========================\n                if not enable_research:\n                    config = types.GenerateContentConfig(\n                        temperature=0.7,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=base_system_instruction,\n                    )\n                    \n                    status_container.write(\"å›ç­”ç”Ÿæˆä¸­...\")\n                    response = client.models.generate_content(\n                        model=model_id,\n                        contents=contents_for_model,\n                        config=config,\n                    )\n                    \n                    final_answer = extract_text_from_response(response)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®—\n                    if response.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            response.usage_metadata.prompt_token_count,\n                            response.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += response.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += response.usage_metadata.candidates_token_count\n\n                    # é¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ (é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ç‰ˆ)\n                    if enable_strict:\n                        status_container.write(\"ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        reviewer_instruction = base_system_instruction + \"\"\"\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n                        review_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\nåˆç‰ˆå›ç­”:\\n{final_answer}\\n\\nãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\")])]\n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=types.GenerateContentConfig(temperature=0.1, candidate_count=1, system_instruction=reviewer_instruction)\n                        )\n                        final_answer = extract_text_from_response(review_resp)\n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        \n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(model_id, review_resp.usage_metadata.prompt_token_count, review_resp.usage_metadata.candidates_token_count)\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n\n                # =========================\n                # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰\n                # =========================\n                else:\n                    # =========================\n                    # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰: å¤šæ®µéšã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ \n                    # =========================\n                    \n                    # --- Phase 1: ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 1: ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    research_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒªã‚µãƒ¼ãƒå°‚ä»»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚æœ€çµ‚å›ç­”ã¯æ›¸ã‹ãšã€äº‹å®Ÿåé›†ã«é›†ä¸­ã™ã‚‹ã“ã¨ã€‚\n\n**èª¿æŸ»è¦³ç‚¹**:\n- è³ªå•ã«é–¢é€£ã™ã‚‹**æœ€æ–°ã®äº‹å®Ÿãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ»çµ±è¨ˆ**ï¼ˆ**2025å¹´ã®æƒ…å ±ã‚’æœ€å„ªå…ˆ**ï¼‰\n- **ç¾æ™‚ç‚¹ã§å­˜åœ¨ã™ã‚‹å…¨ã¦ã®é¸æŠè‚¢ãƒ»ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¶²ç¾…çš„ã«èª¿æŸ»**ï¼ˆä¾‹: è£½å“æ¯”è¼ƒãªã‚‰ã€æœ€æ–°ç‰ˆã ã‘ã§ãªãç›´è¿‘ã®å…¨ä¸–ä»£ã‚’èª¿æŸ»ï¼‰\n- å…¬å¼æƒ…å ±ã‚„ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã‹ã‚‰ã®å¼•ç”¨\n- é–¢é€£ã™ã‚‹èƒŒæ™¯æƒ…å ±ã‚„æ–‡è„ˆ\n- ç«¶åˆãƒ»ä»£æ›¿æ¡ˆãƒ»æ¯”è¼ƒå¯¾è±¡ã®**å®Œå…¨ãªãƒªã‚¹ãƒˆ**\n- ãƒªã‚¹ã‚¯ãƒ»åˆ¶ç´„ãƒ»æ³¨æ„ç‚¹ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n- å‚è€ƒã«ã—ãŸä¸»è¦ãªæƒ…å ±æºã®URL\n\n**é‡è¦**: \n- çµè«–ã‚„æ¨å¥¨ã¯æ›¸ã‹ãšã€å¾Œå·¥ç¨‹ãŒåˆ¤æ–­ã§ãã‚‹èª¿æŸ»ãƒ¡ãƒ¢ã«é›†ä¸­ã™ã‚‹ã“ã¨\n- **å¿…ãšæ¤œç´¢æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã€æœ€æ–°ã®æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã“ã¨**\n- **æ¤œç´¢çµæœã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æ—¥ä»˜ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒ»ãƒ¢ãƒ‡ãƒ«åã‚’å„ªå…ˆçš„ã«è¨˜è¼‰ã™ã‚‹ã“ã¨**\n- **æ¯”è¼ƒå¯¾è±¡ã¨ãªã‚‹é¸æŠè‚¢ã‚’è¦‹è½ã¨ã•ãªã„ã‚ˆã†ã€è¤‡æ•°ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è©¦ã™ã“ã¨**ï¼ˆä¾‹: ã€ŒiPhone æœ€æ–°ãƒ¢ãƒ‡ãƒ« 2025ã€ã€ŒiPhone 17ã€ã€ŒiPhone 2025å¹´ç™ºå£²ã€ãªã©ï¼‰\n- **ã€Œã“ã‚Œã‚ˆã‚Šæ–°ã—ã„ãƒ¢ãƒ‡ãƒ«/ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯å­˜åœ¨ã—ãªã„ã‹ï¼Ÿã€ã‚’å¸¸ã«ç¢ºèªã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ï¼ˆ2024å¹´ä»¥å‰ãªã©ï¼‰ã—ã‹è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãã®æ—¨ã‚’æ˜è¨˜ã™ã‚‹ã“ã¨\n\"\"\"\n\n                    # éå»ã®é–¢é€£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—\n                    past_context = get_relevant_context(prompt, st.session_state.sessions, st.session_state.current_session_id)\n                    \n                    # ãƒªã‚µãƒ¼ãƒç”¨ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ§‹ç¯‰\n                    research_parts = [types.Part(text=f\"ã“ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š\\n{prompt}\")]\n                    \n                    if past_context:\n                        research_parts.insert(0, types.Part(text=\"ä»¥ä¸‹ã¯éå»ã®é–¢é€£ãƒãƒ£ãƒƒãƒˆã‹ã‚‰æŠ½å‡ºã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã™ï¼š\\n\\n\" + past_context))\n                    \n                    research_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=research_parts)\n                    ]\n                    \n                    research_config = types.GenerateContentConfig(\n                        temperature=0.2,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=research_instruction,\n                    )\n                    \n                    research_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=research_contents,\n                        config=research_config,\n                    )\n                    \n                    research_text = extract_text_from_response(research_resp)\n                    \n                    # ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºã®ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ±ã‚’ä¿å­˜\n                    if research_resp.candidates and research_resp.candidates[0].grounding_metadata:\n                        grounding_metadata = research_resp.candidates[0].grounding_metadata\n                    \n                    status_container.write(\"âœ“ ãƒªã‚µãƒ¼ãƒå®Œäº†\")\n                    with status_container.expander(\"åé›†ã—ãŸèª¿æŸ»ãƒ¡ãƒ¢\", expanded=False):\n                        st.markdown(research_text)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1)\n                    if research_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            research_resp.usage_metadata.prompt_token_count,\n                            research_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += research_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += research_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 1.5: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    questions_text = \"\"\n                    if enable_meta:\n                        status_container.write(\"Phase 1.5: ãƒ¡ã‚¿è³ªå•ç”Ÿæˆä¸­...\")\n                        \n                        question_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ç›®çš„**: \nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•ã¨èª¿æŸ»ãƒ¡ãƒ¢ã‚’è¸ã¾ãˆã¦ã€ã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±ãç†è§£ã™ã‚‹ãŸã‚ã®ã€Œé‹­ã„ã‚µãƒ–è³ªå•ã€ã‚’ä½œæˆã™ã‚‹ã“ã¨ã€‚\n\n**ãƒ«ãƒ¼ãƒ«**:\n- æœ€å¤§5å€‹ã¾ã§\n- å„è³ªå•ã¯1-2è¡Œã§å…·ä½“çš„ã‹ã¤é‹­ã\n- ä»¥ä¸‹ã®è¦³ç‚¹ã‚’æ„è­˜:\n  1. å‰æãŒå´©ã‚Œã‚‹å¯èƒ½æ€§ã¯ã©ã“ã‹ï¼Ÿ\n  2. å¼·æ°—/å¼±æ°—ã‚·ãƒŠãƒªã‚ªã®åˆ†å²ç‚¹ã¯ä½•ã‹ï¼Ÿ\n  3. ç«¶åˆãƒ»æŠ€è¡“ãƒ»è¦åˆ¶ã®ä¸ç¢ºå®Ÿæ€§ã¯ï¼Ÿ\n  4. ã€Œäºˆæ¸¬ãŒå¤–ã‚Œã‚‹ã¨ã—ãŸã‚‰ã©ã‚“ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ï¼Ÿã€\n\n**å‡ºåŠ›**: ç®‡æ¡æ›¸ãï¼ˆQ1, Q2...ï¼‰ã®ã¿\n\"\"\"\n\n                        question_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•:\\n{prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\nã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±æ˜ã‚Šã™ã‚‹ãŸã‚ã®é‡è¦ãªã‚µãƒ–è³ªå•ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\")])]\n                        \n                        question_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=question_contents,\n                            config=types.GenerateContentConfig(\n                                temperature=0.4,\n                                candidate_count=1,\n                                system_instruction=question_instruction,\n                            )\n                        )\n                        \n                        questions_text = extract_text_from_response(question_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¡ã‚¿è³ªå•ç”Ÿæˆå®Œäº†\")\n                        with status_container.expander(\"ç”Ÿæˆã•ã‚ŒãŸãƒ¡ã‚¿è³ªå•\", expanded=False):\n                            st.markdown(questions_text)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1.5)\n                        if question_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                question_resp.usage_metadata.prompt_token_count,\n                                question_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += question_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += question_resp.usage_metadata.candidates_token_count\n\n                    # --- Phase 2: çµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 2: çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    if enable_meta:\n                        deep_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã¨ãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ã‚’æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**æ§‹æˆ**:\n1. **æ·±æ˜ã‚Šè€ƒå¯Ÿ**ï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n2. **çµè«–**ï¼ˆ2-3è¡Œï¼‰\n3. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n4. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨\n\"\"\"\n                    else:\n                        deep_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã‚’å”¯ä¸€ã®æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**æ§‹æˆ**:\n1. **çµè«–**ï¼ˆ2-3è¡Œã§æ˜ç¢ºã«ï¼‰\n2. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n3. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«åã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ã¨æ–°ã—ã„æƒ…å ±ãŒæ··åœ¨ã™ã‚‹å ´åˆã¯ã€æ–°ã—ã„æƒ…å ±ã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n\"\"\"\n                    \n                    synthesis_prompt_text = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if enable_meta and questions_text:\n                        synthesis_prompt_text += f\"==== ãƒ¡ã‚¿è³ªå•ä¸€è¦§ ====\\n{questions_text}\\n==== ãƒ¡ã‚¿è³ªå•ã“ã“ã¾ã§ ====\\n\\næŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n2. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»åˆ†æãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    else:\n                        synthesis_prompt_text += \"ä¸Šè¨˜ãƒ¡ãƒ¢ã‚’æ ¹æ‹ ã«ã€æœ€çµ‚å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å¿…ãšä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚**\"\n\n                    synthesis_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=[\n                            types.Part(text=synthesis_prompt_text)\n                        ])\n                    ]\n                    \n                    synthesis_config = types.GenerateContentConfig(\n                        temperature=0.3,\n                        candidate_count=1,\n                        tools=[],  # çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºã§ã¯æ¤œç´¢OFF\n                        system_instruction=deep_instruction,\n                    )\n                    \n                    synthesis_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=synthesis_contents,\n                        config=synthesis_config,\n                    )\n                    \n                    draft_answer = extract_text_from_response(synthesis_resp)\n                    \n                    status_container.write(\"âœ“ çµ±åˆå®Œäº†\")\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 2)\n                    if synthesis_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            synthesis_resp.usage_metadata.prompt_token_count,\n                            synthesis_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += synthesis_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += synthesis_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    if enable_strict:\n                        status_container.write(\"Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        \n\n                        reviewer_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™ã€‚ãŸã ã—ã€**èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’å„ªå…ˆã—ã€æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã™ã‚‹ã“ã¨**ã€‚\n\n**ãƒ¬ãƒ“ãƒ¥ãƒ¼è¦³ç‚¹**:\n- äº‹å®Ÿã¨æ¨æ¸¬ã‚’æ˜ç¢ºã«åˆ†ã‘ã‚‹\n- éåº¦ã«è‡ªä¿¡ã®ã‚ã‚‹æ–­å®šã‚’å¼±ã‚ã‚‹\n- æ•°å­—ã‚„å›ºæœ‰åè©ãŒèª¿æŸ»ãƒ¡ãƒ¢ã¨çŸ›ç›¾ã—ã¦ã„ãªã„ã‹ç¢ºèª\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ãƒ¢ãƒ‡ãƒ«ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ãŒæ­£ã—ãä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª**\n- **å¤ã„æƒ…å ±ã§ä¸Šæ›¸ãã—ã¦ã„ãªã„ã‹ç¢ºèª**\n- è¦‹è½ã¨ã—ã¦ã„ã‚‹é‡è¦ãªãƒªã‚¹ã‚¯ãƒ»ã‚·ãƒŠãƒªã‚ªãŒã‚ã‚Œã°è¿½åŠ \n\n**é‡è¦**: \n- èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ãŒæœ€æ–°ã§ã‚ã‚‹å ´åˆã€ãã‚Œã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n- ã‚ãªãŸã®çŸ¥è­˜ãŒå¤ã„å ´åˆã¯ã€èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’ä¿¡é ¼ã™ã‚‹ã“ã¨\n\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n\n                        review_contents = [\n                            types.Content(role=\"user\", parts=[\n                                types.Part.from_text(\n                                    text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\n\"\n                                    f\"==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                                    f\"åˆç‰ˆå›ç­”:\\n{draft_answer}\\n\\n\"\n                                    \"ä¸Šè¨˜ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚**\"\n                                )\n                            ])\n                        ]\n                        \n                        review_config = types.GenerateContentConfig(\n                            temperature=0.1,\n                            candidate_count=1,\n                            system_instruction=reviewer_instruction,\n                        )\n                        \n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=review_config,\n                        )\n                        \n                        final_answer = extract_text_from_response(review_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        with status_container.expander(\"åˆç‰ˆã¨ã®æ¯”è¼ƒ\", expanded=False):\n                            st.markdown(\"**åˆç‰ˆ:**\")\n                            st.markdown(draft_answer[:500] + \"...\" if len(draft_answer) > 500 else draft_answer)\n                            st.markdown(\"**ä¿®æ­£ç‰ˆ:**\")\n                            st.markdown(final_answer[:500] + \"...\" if len(final_answer) > 500 else final_answer)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 3)\n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                review_resp.usage_metadata.prompt_token_count,\n                                review_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n                    else:\n                        final_answer = draft_answer\n\n                save_usage(usage_stats)\n                status_container.update(label=\"å®Œäº†ï¼\", state=\"complete\", expanded=False)\n\n                # ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤º\n                st.caption(f\"ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_id}\")\n                st.markdown(final_answer)\n\n                # ---- ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ± ----\n                if grounding_metadata:\n                    st.markdown(\"---\")\n                    with st.expander(\"ğŸ“š æƒ…å ±æºã¨å¼•ç”¨\", expanded=False):\n                        if grounding_metadata.grounding_chunks:\n                            st.markdown(\"**æ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:**\")\n                            unique_sources = {}\n                            import urllib.parse\n\n                            for chunk in grounding_metadata.grounding_chunks:\n                                if getattr(chunk, \"web\", None):\n                                    uri = getattr(chunk.web, \"uri\", None)\n                                    title = getattr(chunk.web, \"title\", \"æƒ…å ±æº\")\n                                    if uri and uri not in unique_sources:\n                                        parsed = urllib.parse.urlparse(uri)\n                                        domain = parsed.netloc.replace(\"www.\", \"\")\n                                        unique_sources[uri] = {\n                                            \"title\": title,\n                                            \"domain\": domain,\n                                        }\n                            for i, (uri, info) in enumerate(unique_sources.items(), 1):\n                                st.markdown(f\"{i}. **[{info['title']}]({uri})**\")\n                                st.caption(f\"   å‡ºå…¸: {info['domain']}\")\n\n                messages.append({\"role\": \"model\", \"content\": final_answer})\n                update_current_session_messages(messages)\n\n            except Exception as e:\n                status_container.update(label=\"Error\", state=\"error\")\n                err_text = str(e)\n                if \"RESOURCE_EXHAUSTED\" in err_text or \"429\" in err_text:\n                    st.error(\n                        \"âš ï¸ Vertex AI / Gemini ã®ã‚¯ã‚©ãƒ¼ã‚¿ã«é”ã—ã¾ã—ãŸã€‚\\n\\n\"\n                        \"ãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ / æ—¥æ¬¡åˆ¶é™ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\\n\"\n                        \"ãƒ»ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                        \"ãƒ»Google Cloud Console ã®ã€ŒVertex AI â†’ ä½¿ç”¨çŠ¶æ³ã€ã‹ã‚‰ã‚¯ã‚©ãƒ¼ã‚¿çŠ¶æ³ã‚’ç¢ºèªã§ãã¾ã™ã€‚\"\n                    )\n                elif \"NOT_FOUND\" in err_text and \"Publisher Model\" in err_text:\n                    st.error(\n                        \"âš ï¸ æŒ‡å®šã—ãŸãƒ¢ãƒ‡ãƒ«ãŒã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ / ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\\n\"\n                        \"ãƒ»ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ¢ãƒ‡ãƒ«IDã‚’ã€2.5ç³» ã¾ãŸã¯ 3 Pro ã«å¤‰æ›´ã—ã¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                    )\n                else:\n                    st.error(f\"An error occurred: {e}\")\n"
                },
                {
                    "role": "model",
                    "content": "### 1. çµè«–ã¨ç·Šæ€¥ã®è­¦å‘Š\n\n*   **ã‚¹ãƒãƒ›åˆ©ç”¨**: å¯èƒ½ã§ã™ã€‚Google Cloud Runç­‰ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚Œã°ã€ã‚¹ãƒãƒ›ã®ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã‚¢ãƒ—ãƒªã¨ã—ã¦å¿«é©ã«åˆ©ç”¨ã§ãã¾ã™ã€‚\n*   **ã€æ¥µã‚ã¦å±é™ºã€‘ã‚³ã‚¹ãƒˆç®¡ç†ã«é–¢ã™ã‚‹é‡å¤§ãªèª¤è§£**:\n    *   **ã€Œè‡ªå‹•èª²é‡‘ã—ãªã„è¨­å®šã€ã¯å­˜åœ¨ã—ã¾ã›ã‚“**: Google Cloudã«ãŠã„ã¦ã€è¨­å®šã—ãŸäºˆç®—ã‚’è¶…ãˆãŸã‚‰è‡ªå‹•çš„ã«ã‚µãƒ¼ãƒ“ã‚¹ã‚’åœæ­¢ã™ã‚‹æ©Ÿèƒ½ã¯æ¨™æº–ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã€Œäºˆç®—ã‚¢ãƒ©ãƒ¼ãƒˆã€ã¯ãƒ¡ãƒ¼ãƒ«ã§é€šçŸ¥ãŒæ¥ã‚‹ã ã‘ã§ã€**èª²é‡‘ã¯æ­¢ã¾ã‚Šã¾ã›ã‚“**ã€‚\n    *   **ã‚¢ãƒ—ãƒªå†…ã®äºˆç®—åˆ¶é™ã¯æ©Ÿèƒ½ã—ã¾ã›ã‚“**: ã‚ãªãŸã®ã‚³ãƒ¼ãƒ‰ã«ã‚ã‚‹äºˆç®—ç®¡ç†æ©Ÿèƒ½ï¼ˆ`USAGE_FILE`ã¸ã®ä¿å­˜ï¼‰ã¯ã€ã‚¯ãƒ©ã‚¦ãƒ‰ä¸Šï¼ˆCloud Runç­‰ï¼‰ã§ã¯**å†èµ·å‹•ã®ãŸã³ã«ãƒ‡ãƒ¼ã‚¿ãŒæ¶ˆå»ã•ã‚Œã‚‹ãŸã‚ç„¡åŠ¹åŒ–**ã•ã‚Œã¾ã™ã€‚\n    *   **ãƒªã‚¹ã‚¯**: ã“ã®ã¾ã¾ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã¨ã€äºˆç®—åˆ¶é™ãŒæ¯å›ãƒªã‚»ãƒƒãƒˆã•ã‚Œã€ä¸‡ãŒä¸€ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒæ¼æ´©ã—ãŸå ´åˆã€**é’å¤©äº•ã§é«˜é¡è«‹æ±‚ãŒç™ºç”Ÿã™ã‚‹æã‚Œ**ãŒã‚ã‚Šã¾ã™ã€‚\n\n---\n\n### 2. è©³ç´°åˆ†æï¼šãªãœç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰ã§ã¯å±é™ºãªã®ã‹\n\n#### A. ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã®ç½ ï¼ˆCloud Runã®ä»•æ§˜ï¼‰\nç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰ã¯ `usage.json` ã¨ã„ã†ãƒ•ã‚¡ã‚¤ãƒ«ã«åˆ©ç”¨é¡ã‚’è¨˜éŒ²ã—ã¦ã„ã¾ã™ãŒã€Google Cloud Runãªã©ã®ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒã¯ã€Œã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹ï¼ˆçŠ¶æ…‹ã‚’æŒãŸãªã„ï¼‰ã€è¨­è¨ˆã§ã™ã€‚\n*   **ç¾è±¡**: ã‚¢ãƒ—ãƒªã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¦ã‚‚ã€ã—ã°ã‚‰ãä½¿ã‚ãªã„ã¨ã‚µãƒ¼ãƒãƒ¼ãŒä¼‘æ­¢ã—ã€å†é–‹æ™‚ã«**ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ï¼ˆãƒªã‚»ãƒƒãƒˆï¼‰**ã•ã‚Œã¾ã™ã€‚\n*   **çµæœ**: ã€Œä»Šæœˆã¯ã‚‚ã†$5ä½¿ã£ãŸã€ã¨ã„ã†è¨˜éŒ²ãŒæ¶ˆãˆã€**ä½•åº¦ã§ã‚‚äºˆç®—ä¸Šé™ï¼ˆ$5ï¼‰ã¾ã§ä½¿ãˆã¦ã—ã¾ã†çŠ¶æ…‹**ã«ãªã‚Šã¾ã™ã€‚\n\n#### B. Google Cloudã®ä»•æ§˜\nGoogle Cloudã®ç„¡æ–™ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚„äºˆç®—è¨­å®šã¯ã€ã€Œä½¿ã„åˆ‡ã£ãŸã‚‰è‡ªå‹•åœæ­¢ã€ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚’ä½¿ã„åˆ‡ã£ãŸç¬é–“ã‹ã‚‰ã€ç™»éŒ²ã—ãŸã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰ã¸ã®**è‡ªå‹•èª²é‡‘ã«åˆ‡ã‚Šæ›¿ã‚ã‚Šã¾ã™**ã€‚ã“ã‚Œã‚’é˜²ãã€Œã‚¹ã‚¤ãƒƒãƒã€ã¯æ¨™æº–æ©Ÿèƒ½ã«ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\n\n---\n\n### 3. å®‰å…¨ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ãŸã‚ã®ä¿®æ­£æ‰‹é †\n\n#### â‘  ç°¡æ˜“ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ­ãƒƒã‚¯ã®å®Ÿè£…ï¼ˆã‚³ãƒ¼ãƒ‰ä¿®æ­£ï¼‰\n`st.set_page_config` ã®ç›´å¾Œã«ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚ã“ã‚Œã§ã‚¹ãƒãƒ›ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã—ãŸéš›ã«ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’æ±‚ã‚ã‚‰ã‚Œã¾ã™ã€‚\n\n```python\n# --- ç°¡æ˜“ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ­ãƒƒã‚¯ ---\ndef check_password():\n    \"\"\"ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ä»˜ãï¼‰\"\"\"\n    if \"password_correct\" not in st.session_state:\n        st.session_state.password_correct = False\n\n    if not st.session_state.password_correct:\n        # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ \n        pwd = st.text_input(\"ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„\", type=\"password\")\n        if st.button(\"ãƒ­ã‚°ã‚¤ãƒ³\"):\n            if pwd == \"198501\":  # â˜…ã“ã“ã«è¨­å®šã—ãŸã„ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥ã‚Œã‚‹\n                st.session_state.password_correct = True\n                st.rerun()\n            else:\n                st.error(\"ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™\")\n        return False\n    return True\n\nif not check_password():\n    st.stop()  # èªè¨¼ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã“ã“ã§å‡¦ç†ã‚’åœæ­¢\n```\n\n#### â‘¡ ã‚³ã‚¹ãƒˆæš´èµ°ã‚’é˜²ãã€Œå‘½ç¶±ã€ã®è¨­å®šï¼ˆå¿…é ˆï¼‰\nã‚¢ãƒ—ãƒªå†…ã®äºˆç®—ç®¡ç†ãŒæ©Ÿèƒ½ã—ãªã„ãŸã‚ã€Google Cloudå´ã§ç‰©ç†çš„ã«è›‡å£ã‚’çµã‚‹è¨­å®šãŒå¿…è¦ã§ã™ã€‚\n\n**Vertex AI APIã®ã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™æ‰‹é †**:\n1.  Google Cloud Consoleã§ã€ŒIAMã¨ç®¡ç†ã€â†’ã€Œ**ã‚¯ã‚©ãƒ¼ã‚¿ã¨ã‚·ã‚¹ãƒ†ãƒ åˆ¶é™**ã€ã‚’é–‹ãã€‚\n2.  ãƒ•ã‚£ãƒ«ã‚¿ã«ã€Œ**Vertex AI API**ã€ã¨å…¥åŠ›ã€‚\n3.  `base_model_verbosity:gemini-3-pro-preview`ï¼ˆã¾ãŸã¯ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ï¼‰ãªã©ã®é …ç›®ã‚’æ¢ã™ã€‚\n4.  ã€ŒEdit Quotaã€ã‹ã‚‰**1æ—¥ã‚ãŸã‚Šã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ï¼ˆRequests per dayï¼‰**ã‚’ä½ã„å€¤ï¼ˆä¾‹: 50ã€œ100å›ï¼‰ã«è¨­å®šã™ã‚‹ã€‚\n\nã“ã®è¨­å®šã‚’è¡Œãˆã°ã€ä¸‡ãŒä¸€ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒæ¼ã‚Œã¦ã‚‚ã€Googleå´ã§APIãŒåœæ­¢ã™ã‚‹ãŸã‚é«˜é¡è«‹æ±‚ã‚’é˜²ã’ã¾ã™ã€‚"
                }
            ]
        },
        {
            "id": "1a4656b1-f7b3-48dc-b41d-5b7bda49fdc0",
            "title": "ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã®ã‚ˆã†ã«ã€æœ€ã‚‚å„ªç§€ãªLLMã‚’...",
            "timestamp": "2025-11-30T14:09:23.801467",
            "messages": [
                {
                    "role": "user",
                    "content": "ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã®ã‚ˆã†ã«ã€æœ€ã‚‚å„ªç§€ãªLLMã‚’ã€è‡ªä½œã—ã¦ã„ã‚‹ã‚½ãƒ¼ã‚¹ã§ç§ã®ã‚³ãƒ¼ãƒ‰ã‚’è¶…ãˆã‚‹ã‚‚ã®ã‚’ã¤ãã£ã¦ã„ã‚‹ã²ã¨ã§ãƒ™ã‚¹ãƒˆã¯ã ã‚Œã‹?ã€€ã‚³ãƒ¼ãƒ‰ã‚’å…¬é–‹ã—ã¦ã„ã‚‹äººæ‰‹ãƒ™ã‚¹ãƒˆã¯ï¼Ÿ(ã¾ãŸãã‚Œã¯ç§ã®ã‚‚ã®ã‚ˆã‚Šå„ªç§€ã‹?0)\nç¾çŠ¶ã®ã‚³ãƒ¼ãƒ‰ã§ã€å›ç­”ãƒ¢ãƒ¼ãƒ‰ãŒè¤‡æ•°ã‚ã‚‹ãŒã€æœ€ã‚‚å„ªç§€ãªãƒ¢ãƒ‡ãƒ«ã¯ç†Ÿè€ƒ(æœ¬æ°—MAX)ã‹ã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã®ã»ã†ãŒå„ªç§€ã‹?\nimport os\nimport uuid\nimport datetime\nimport streamlit as st\nfrom dotenv import load_dotenv\nfrom google import genai\nfrom google.genai import types\nfrom PIL import Image\nimport io\nfrom logic import (\n    USAGE_FILE, SESSIONS_FILE, MAX_BUDGET_USD, PRICING,\n    VERTEX_PROJECT, VERTEX_LOCATION,\n    load_usage, save_usage, calculate_cost, get_mime_type,\n    extract_youtube_id, get_youtube_transcript, get_relevant_context,\n    extract_text_from_response, load_sessions, save_sessions, get_client\n)\n\ntry:\n    from st_img_pastebutton import paste\n    import_error_msg = None\nexcept ImportError as e:\n    paste = None\n    import_error_msg = str(e)\n\n# =========================\n# ç’°å¢ƒå¤‰æ•° & å®šæ•°\n# =========================\n\nload_dotenv()\n\n\n\nst.set_page_config(page_title=\"Gemini 3 Web Studio\", layout=\"wide\")\n\n# =========================\n# Helper Functions\n# =========================\n\n# =========================\n# Helper Functions\n# =========================\n# Moved to logic.py\n\n# =========================\n# Session Management\n# =========================\n\n\n\ndef create_new_session():\n    current_sessions = load_sessions()\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": [],\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.rerun()\n\ndef switch_session(session_id):\n    st.session_state.current_session_id = session_id\n    st.rerun()\n\ndef update_current_session_messages(messages):\n    if st.session_state.current_session_id:\n        current_sessions = load_sessions()\n        for session in current_sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                session[\"messages\"] = messages\n                if session[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(messages) > 0:\n                    first_msg = messages[0][\"content\"]\n                    session[\"title\"] = (first_msg[:20] + \"...\") if len(first_msg) > 20 else first_msg\n                session[\"timestamp\"] = datetime.datetime.now().isoformat()\n                break\n        save_sessions(current_sessions)\n        st.session_state.sessions = current_sessions\n\ndef get_current_messages():\n    if st.session_state.current_session_id:\n        for session in st.session_state.sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                return session[\"messages\"]\n    return []\n\ndef delete_session(session_id):\n    current_sessions = load_sessions()\n    current_sessions = [s for s in current_sessions if s[\"id\"] != session_id]\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    if st.session_state.current_session_id == session_id:\n        st.session_state.current_session_id = None\n        if st.session_state.sessions:\n            st.session_state.current_session_id = st.session_state.sessions[0][\"id\"]\n    st.rerun()\n\ndef branch_session():\n    \"\"\"ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚’åˆ†å²\"\"\"\n    current_messages = get_current_messages()\n    current_sessions = load_sessions()\n    \n    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—\n    current_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n    for session in current_sessions:\n        if session[\"id\"] == st.session_state.current_session_id:\n            current_title = session[\"title\"]\n            break\n    \n    # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": f\"{current_title} (åˆ†å²)\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": current_messages.copy(),  # ç¾åœ¨ã®å±¥æ­´ã‚’ã‚³ãƒ”ãƒ¼\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    \n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.session_state.session_cost = 0.0  # ã‚³ã‚¹ãƒˆãƒªã‚»ãƒƒãƒˆ\n    st.rerun()\n\n# =========================\n# Initialization\n# =========================\n\nif \"sessions\" not in st.session_state:\n    st.session_state.sessions = load_sessions()\n\nif \"current_session_id\" not in st.session_state:\n    # Always create a new session when the app starts\n    create_new_session()\n\nif \"session_cost\" not in st.session_state:\n    st.session_state.session_cost = 0.0\n\nusage_stats = load_usage()\n\n# =========================\n# Sidebar\n# =========================\n\nwith st.sidebar:\n    st.markdown(\"\"\"\n    <div style=\"text-align: center; padding: 0; margin: 0; margin-top: -1rem;\">\n        <h1 style=\"font-size: 18px; font-weight: 700; margin: 0; padding: 0; letter-spacing: 1px;\">\n            Gemini 3<br/>Studio\n        </h1>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n    col1, col2 = st.columns(2)\n    with col1:\n        if st.button(\"â• æ–°è¦\", use_container_width=True):\n            create_new_session()\n    with col2:\n        if st.button(\"ğŸŒ± åˆ†å²\", use_container_width=True):\n            branch_session()\n\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    current_messages = get_current_messages()\n    if current_messages:\n        with st.expander(\"ğŸ”— å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ\", expanded=False):\n            export_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n            for s in st.session_state.sessions:\n                if s[\"id\"] == st.session_state.current_session_id:\n                    export_title = s[\"title\"]\n                    break\n\n            export_md = f\"# {export_title}\\n\\n\"\n            export_md += f\"**ä½œæˆæ—¥æ™‚**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n---\\n\\n\"\n            for msg in current_messages:\n                role_label = \"ğŸ§‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼\" if msg[\"role\"] == \"user\" else \"ğŸ¤– AI\"\n                export_md += f\"## {role_label}\\n\\n{msg['content']}\\n\\n---\\n\\n\"\n\n            if st.button(\"ãƒªãƒ³ã‚¯ç”Ÿæˆ\", use_container_width=True):\n                with st.spinner(\"ç”Ÿæˆä¸­...\"):\n                    try:\n                        import urllib.request\n                        import urllib.parse\n\n                        data = urllib.parse.urlencode(\n                            {\"content\": export_md, \"expiry_days\": 7, \"syntax\": \"md\"}\n                        ).encode()\n\n                        req = urllib.request.Request(\"https://dpaste.org/api/\", data=data)\n                        req.add_header(\"User-Agent\", \"Mozilla/5.0 (Gemini3Studio)\")\n\n                        with urllib.request.urlopen(req) as response:\n                            share_url = response.read().decode(\"utf-8\").strip()\n                            st.success(\"ä½œæˆå®Œäº†ï¼\")\n                            st.code(share_url)\n                            st.caption(\"â€»7æ—¥é–“æœ‰åŠ¹\")\n                    except Exception as e:\n                        st.error(f\"ã‚¨ãƒ©ãƒ¼: {e}\")\n\n    st.markdown(\"---\")\n\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    with st.expander(\"ğŸ“ æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«\", expanded=False):\n        uploaded_files = st.file_uploader(\n            \"ãƒ•ã‚¡ã‚¤ãƒ«\",\n            accept_multiple_files=True,\n            type=[\"png\", \"jpg\", \"jpeg\", \"mp4\", \"mov\", \"txt\", \"pdf\", \"csv\"],\n            label_visibility=\"collapsed\"\n        )\n\n    # ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ï¼ˆExpanderã®å¤–ã«å‡ºã™ï¼‰\n    if paste:\n        if \"paste_key\" not in st.session_state:\n            st.session_state.paste_key = 0\n        try:\n            pasted_image_bytes = paste(\n                label=\"ğŸ“‹ è²¼ä»˜\",\n                key=f\"paste_btn_{st.session_state.paste_key}\",\n            )\n        except Exception as e:\n            st.error(f\"Error: {e}\")\n        \n        if pasted_image_bytes:\n            st.success(\"è²¼ä»˜å®Œäº†\")\n            st.image(pasted_image_bytes, caption=\"ç”»åƒ\", use_container_width=True)\n            if st.button(\"ğŸ—‘ï¸ ã‚¯ãƒªã‚¢\", key=\"clear_paste\"):\n                st.session_state.paste_key += 1\n                st.rerun()\n    else:\n        st.warning(\"Clipboard lib missing\")\n\n    # ---- YouTube URL ----\n    with st.expander(\"ğŸ“º YouTubeåˆ†æ\", expanded=False):\n        youtube_url = st.text_input(\"URL\", placeholder=\"https://youtu.be/...\", label_visibility=\"collapsed\")\n\n    st.markdown(\"---\")\n    \n    st.markdown(\"---\")\n    \n    # ---- å›ç­”ãƒ¢ãƒ¼ãƒ‰ ----\n    with st.expander(\"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰\", expanded=True):\n        mode_type = st.radio(\n            \"ã‚¿ã‚¤ãƒ—\",\n            [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n            index=0,\n            horizontal=True,\n            label_visibility=\"collapsed\"\n        )\n        \n        if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n            response_mode = st.radio(\n                \"ãƒ¢ãƒ¼ãƒ‰\",\n                [\n                    \"2. ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                    \"3. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                    \"Î²2. ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                ],\n                index=0\n            )\n        elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n            response_mode = st.radio(\n                \"ãƒ¢ãƒ¼ãƒ‰\",\n                [\n                    \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                ],\n                index=0\n            )\n        else:\n            response_mode = st.radio(\n                \"ãƒ¢ãƒ¼ãƒ‰\",\n                [\n                    \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                ],\n                index=0\n            )\n    \n    strict_mode = False\n    \n    # ---- è¨­å®š (ãƒ¢ãƒ‡ãƒ«ãªã©) ----\n    with st.expander(\"âš™ï¸ è¨­å®š\", expanded=False):\n        model_options = [\n            \"gemini-3-pro-preview\",\n            \"gemini-2.5-pro\",\n            \"gemini-2.5-flash\",\n            \"gemini-2.5-flash-lite\",\n            \"gemini-2.0-flash\",\n        ]\n        model_id = st.selectbox(\"ãƒ¢ãƒ‡ãƒ«ID\", options=model_options, index=0)\n\n        use_search = st.toggle(\"Googleæ¤œç´¢\", value=True)\n        candidate_count = st.slider(\"å€™è£œæ•°\", min_value=1, max_value=3, value=3)\n\n    st.markdown(\"---\")\n\n    # ---- å±¥æ­´æ¤œç´¢ ----\n    search_query = st.text_input(\"ğŸ” å±¥æ­´æ¤œç´¢\", placeholder=\"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰...\")\n    if search_query:\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if search_query.lower() in s[\"title\"].lower():\n                filtered_sessions.append(s)\n                continue\n            found = False\n            for m in s[\"messages\"]:\n                if search_query.lower() in m[\"content\"].lower():\n                    filtered_sessions.append(s)\n                    found = True\n                    break\n            if not found:\n                pass\n    else:\n        # æ¤œç´¢ã—ã¦ã„ãªã„å ´åˆ: ç©ºã®ã€Œæ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã€ã‚’é™¤å¤–ï¼ˆç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯é™¤ãï¼‰\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if s[\"id\"] == st.session_state.current_session_id:\n                filtered_sessions.append(s)\n                continue\n            if s[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(s[\"messages\"]) == 0:\n                continue\n            filtered_sessions.append(s)\n\n    # CSSã§è¦‹ã‚„ã™ãä½¿ã„ã‚„ã™ãæœ€é©åŒ–\n    st.markdown(\"\"\"\n    <style>\n    /* å…¨ä½“ã®ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºç¸®å° */\n    .stApp, .stMarkdown, .stButton, .stSelectbox, .stTextInput, .stTextArea {\n        font-size: 12px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ä½™ç™½ã‚’æ¥µé™ã¾ã§è©°ã‚ã‚‹ */\n    section[data-testid=\"stSidebar\"] .block-container {\n        padding-top: 0rem !important;\n        padding-bottom: 0.3rem !important;\n        padding-left: 0.5rem !important;\n        padding-right: 0.5rem !important;\n    }\n    /* å„è¦ç´ é–“ã®éš™é–“ã‚’è©°ã‚ã‚‹ */\n    div[data-testid=\"stVerticalBlock\"] > div {\n        gap: 0.1rem !important;\n    }\n    /* Expanderã®ä½™ç™½å‰Šæ¸› */\n    .streamlit-expanderHeader {\n        font-size: 11px !important;\n        padding-top: 0px !important;\n        padding-bottom: 0px !important;\n        min-height: 1.3rem !important;\n    }\n    .streamlit-expanderContent {\n        padding-top: 0px !important;\n        padding-bottom: 0px !important;\n    }\n    /* éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã®ã‚¿ã‚¤ãƒˆãƒ« */\n    div[data-testid=\"stExpander\"] summary p {\n        font-size: 10px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ */\n    section[data-testid=\"stSidebar\"] button p {\n        font-size: 10px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã« */\n    section[data-testid=\"stSidebar\"] button {\n        padding: 0rem 0.2rem !important;\n        min-height: 1.4rem !important;\n        font-size: 10px !important;\n        margin-bottom: 0px !important;\n    }\n    /* ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®ãƒ©ãƒ™ãƒ«ã‚’å°ã•ã */\n    section[data-testid=\"stSidebar\"] .stRadio label {\n        font-size: 10px !important;\n    }\n    section[data-testid=\"stSidebar\"] .stRadio > label > div {\n        font-size: 10px !important;\n    }\n    /* ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ‡ã‚Šè©°ã‚ã‚‹ï¼ˆæ”¹è¡Œã•ã›ãªã„ï¼‰ */\n    section[data-testid=\"stSidebar\"] label, \n    section[data-testid=\"stSidebar\"] p,\n    section[data-testid=\"stSidebar\"] span {\n        white-space: nowrap !important;\n        overflow: hidden !important;\n        text-overflow: ellipsis !important;\n    }\n    /* åŒºåˆ‡ã‚Šç·š */\n    hr {\n        margin-top: 0.1rem !important;\n        margin-bottom: 0.1rem !important;\n    }\n    /* ãƒ˜ãƒƒãƒ€ãƒ¼ç¸®å° */\n    h1, h2, h3 {\n        padding-top: 0rem !important;\n        padding-bottom: 0rem !important;\n        margin-top: 0rem !important;\n        margin-bottom: 0rem !important;\n    }\n    </style>\n    \"\"\", unsafe_allow_html=True)\n    \n    # ç›´è¿‘5ä»¶ã¨éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«åˆ†å‰²\n    recent_sessions = filtered_sessions[:5] if len(filtered_sessions) > 5 else filtered_sessions\n    archive_sessions = filtered_sessions[5:] if len(filtered_sessions) > 5 else []\n    \n    # ç›´è¿‘5ä»¶ï¼ˆå¸¸ã«å±•é–‹ï¼‰\n    if recent_sessions:\n        st.markdown(\"**ğŸ“Œ ç›´è¿‘ã®ãƒãƒ£ãƒƒãƒˆ**\")\n        for session in recent_sessions:\n            col1, col2 = st.columns([0.8, 0.2])\n            with col1:\n                if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                    switch_session(session[\"id\"])\n            with col2:\n                if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                    delete_session(session[\"id\"])\n    \n    # éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆæŠ˜ã‚ŠãŸãŸã¿ï¼‰\n    if archive_sessions:\n        with st.expander(f\"ğŸ“œ éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ– ({len(archive_sessions)}ä»¶)\", expanded=False):\n            for session in archive_sessions:\n                col1, col2 = st.columns([0.8, 0.2])\n                with col1:\n                    if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                        switch_session(session[\"id\"])\n                with col2:\n                    if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                        delete_session(session[\"id\"])\n\n    st.markdown(\"---\")\n\n    # ---- ç”»åƒç”Ÿæˆ ----\n    with st.expander(\"ğŸ¨ ç”»åƒç”Ÿæˆ\", expanded=False):\n        img_prompt = st.text_area(\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\", placeholder=\"æœªæ¥çš„ãªéƒ½å¸‚...\")\n        aspect_ratio = st.selectbox(\"æ¯”ç‡\", [\"16:9\", \"1:1\", \"4:3\", \"3:4\", \"9:16\"])\n\n        generate_img_btn = st.button(\"ç”Ÿæˆ\", type=\"primary\", disabled=not img_prompt)\n        if generate_img_btn and img_prompt:\n            st.session_state.generate_image_trigger = {\n                \"prompt\": img_prompt,\n                \"aspect_ratio\": aspect_ratio,\n            }\n\n    st.markdown(\"---\")\n\n    # ---- è©•ä¾¡åˆ†æ ----\n    with st.expander(\"ğŸ“Š å“è³ªåˆ†æ\", expanded=False):\n        total_ratings = 0\n        positive_ratings = 0\n        model_ratings = {}\n\n        for s in st.session_state.sessions:\n            for m in s[\"messages\"]:\n                if \"rating\" in m and m[\"rating\"] is not None:\n                    total_ratings += 1\n                    if m[\"rating\"] == 1:\n                        positive_ratings += 1\n                    if \"metadata\" in m and \"model\" in m[\"metadata\"]:\n                        mod = m[\"metadata\"][\"model\"]\n                        if mod not in model_ratings:\n                            model_ratings[mod] = {\"total\": 0, \"positive\": 0}\n                        model_ratings[mod][\"total\"] += 1\n                        if m[\"rating\"] == 1:\n                            model_ratings[mod][\"positive\"] += 1\n\n        if total_ratings > 0:\n            approval_rate = (positive_ratings / total_ratings) * 100\n            st.metric(\"Positive Ratings\", f\"{positive_ratings}/{total_ratings}\", f\"{approval_rate:.1f}%\")\n            best_model = \"N/A\"\n            best_rate = -1\n            for mod, stats in model_ratings.items():\n                rate = stats[\"positive\"] / stats[\"total\"]\n                if rate > best_rate:\n                    best_rate = rate\n                    best_model = mod\n            if best_model != \"N/A\":\n                st.caption(f\"ğŸ† Best: **{best_model}** ({best_rate*100:.0f}%)\")\n        else:\n            st.caption(\"ãƒ‡ãƒ¼ã‚¿ãªã—\")\n\n    st.markdown(\"---\")\n\n    # ---- ã‚³ã‚¹ãƒˆè¡¨ç¤º ----\n    st.metric(\"Cost\", f\"${usage_stats['total_cost_usd']:.4f}\")\n    if st.session_state.session_cost > 0:\n        st.caption(f\"Session: ${st.session_state.session_cost:.4f}\")\n\n    if usage_stats[\"total_cost_usd\"] >= MAX_BUDGET_USD:\n        st.error(f\"âš ï¸ ä¸Šé™ (${MAX_BUDGET_USD}) åˆ°é”\")\n        stop_generation = True\n    else:\n        stop_generation = False\n\n    st.markdown(\"---\")\n    st.code(f\"PROJECT: {VERTEX_PROJECT}\\nLOCATION: {VERTEX_LOCATION} (Vertex AI)\")\n\n# =========================\n# Main UI\n# =========================\n\ncurrent_session_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\nfor s in st.session_state.sessions:\n    if s[\"id\"] == st.session_state.current_session_id:\n        current_session_title = s[\"title\"]\n        break\n\nst.header(current_session_title)\nst.markdown(\n    \"ä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\"\n)\n\n# ---- Vertex AI Client ----\n\n\n\nclient = get_client()\n\n# ---- å±¥æ­´è¡¨ç¤º ----\n\nmessages = get_current_messages()\nfor idx, msg in enumerate(messages):\n    with st.chat_message(msg[\"role\"]):\n        st.markdown(msg[\"content\"])\n        if msg[\"role\"] == \"model\":\n            col1, col2, col3 = st.columns([0.1, 0.1, 0.8])\n            current_rating = msg.get(\"rating\")\n            with col1:\n                if st.button(\"ğŸ‘\", key=f\"up_{idx}\"):\n                    messages[idx][\"rating\"] = 1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col2:\n                if st.button(\"ğŸ‘\", key=f\"down_{idx}\"):\n                    messages[idx][\"rating\"] = -1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col3:\n                if current_rating == 1:\n                    st.caption(\"âœ… é«˜è©•ä¾¡\")\n                elif current_rating == -1:\n                    st.caption(\"âŒ ä½è©•ä¾¡\")\n\n# =========================\n# ç”»åƒç”Ÿæˆãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°\n# =========================\n\nif hasattr(st.session_state, \"generate_image_trigger\") and st.session_state.generate_image_trigger:\n    img_data = st.session_state.generate_image_trigger\n    del st.session_state.generate_image_trigger\n\n    with st.chat_message(\"user\"):\n        st.markdown(f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\")\n        st.caption(f\"ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”: {img_data['aspect_ratio']}\")\n\n    messages.append({\"role\": \"user\", \"content\": f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\"})\n    update_current_session_messages(messages)\n\n    with st.chat_message(\"assistant\"):\n        with st.status(\"ç”»åƒã‚’ç”Ÿæˆä¸­...\", expanded=True) as status:\n            try:\n                config = types.GenerateContentConfig(\n                    response_modalities=[\"IMAGE\"],\n                    image_config=types.ImageConfig(\n                        aspect_ratio=img_data[\"aspect_ratio\"]\n                    ),\n                )\n                status.write(\"Gemini 3 Pro Imageã§ç”Ÿæˆä¸­...\")\n                response = client.models.generate_content(\n                    model=\"gemini-3-pro-image-preview\",\n                    contents=img_data[\"prompt\"],\n                    config=config,\n                )\n\n                generated_image = None\n\n                # ç”»åƒã‚’å–ã‚Šå‡ºã™\n                if getattr(response, \"candidates\", None):\n                    for candidate in response.candidates:\n                        if getattr(candidate, \"content\", None) and candidate.content.parts:\n                            for part in candidate.content.parts:\n                                if getattr(part, \"inline_data\", None):\n                                    try:\n                                        generated_image = part.as_image()\n                                    except AttributeError:\n                                        image_bytes_raw = part.inline_data.data\n                                        generated_image = Image.open(io.BytesIO(image_bytes_raw))\n                                    break\n                        if generated_image is not None:\n                            break\n\n                if generated_image is not None:\n                    st.image(generated_image, caption=img_data[\"prompt\"])\n                    buf = io.BytesIO()\n                    generated_image.save(buf, format=\"PNG\")\n                    image_bytes = buf.getvalue()\n                    st.download_button(\n                        label=\"ğŸ’¾ ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\",\n                        data=image_bytes,\n                        file_name=f\"generated_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png\",\n                        mime=\"image/png\",\n                    )\n                    messages.append(\n                        {\"role\": \"model\", \"content\": f\"âœ… ç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {img_data['prompt']}\"}\n                    )\n                    update_current_session_messages(messages)\n                    status.update(label=\"âœ… ç”»åƒç”Ÿæˆå®Œäº†\", state=\"complete\")\n                else:\n                    st.error(\"ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")\n                    status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n\n            except Exception as e:\n                status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n                st.error(f\"ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}\")\n\n# =========================\n# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›\n# =========================\n\nprompt = st.chat_input(\"ä½•ã‹èã„ã¦ãã ã•ã„...\", disabled=stop_generation)\n\nif prompt:\n    if stop_generation:\n        st.error(\"äºˆç®—ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚\")\n    else:\n        # ---- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€è¡¨ç¤º ----\n        with st.chat_message(\"user\"):\n            st.markdown(prompt)\n            if uploaded_files:\n                for uf in uploaded_files:\n                    st.caption(f\"ğŸ“ æ·»ä»˜: {uf.name}\")\n            if youtube_url:\n                st.caption(f\"ğŸ“º YouTube: {youtube_url}\")\n            if pasted_image_bytes:\n                st.caption(\"ğŸ“‹ ç”»åƒãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚Œã¾ã—ãŸ\")\n\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        update_current_session_messages(messages)\n\n        # ---- ãƒ¢ãƒ‡ãƒ«å¿œç­” ----\n        with st.chat_message(\"assistant\"):\n            status_container = st.status(\"æ€è€ƒä¸­...\", expanded=True)\n            try:\n                # ä¼šè©±å±¥æ­´\n                model_history = []\n                for msg in messages[:-1]:\n                    model_history.append(\n                        types.Content(\n                            role=msg[\"role\"],\n                            parts=[types.Part.from_text(text=msg[\"content\"])],\n                        )\n                    )\n\n                # ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³\n                current_parts = [types.Part.from_text(text=prompt)]\n\n                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«\n                for uploaded_file in uploaded_files or []:\n                    try:\n                        mime_type = get_mime_type(uploaded_file.name)\n                        bytes_data = uploaded_file.getvalue()\n                        part = types.Part.from_bytes(data=bytes_data, mime_type=mime_type)\n                        current_parts.append(part)\n                        status_container.write(f\"ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™å®Œäº†: {uploaded_file.name}\")\n                    except Exception as e:\n                        status_container.error(\n                            f\"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {uploaded_file.name} - {e}\"\n                        )\n\n                # è²¼ã‚Šä»˜ã‘ç”»åƒ\n                if pasted_image_bytes:\n                    import base64\n\n                    status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã‚’å‡¦ç†ä¸­...\")\n                    try:\n                        if isinstance(pasted_image_bytes, str):\n                            if pasted_image_bytes.startswith(\"data:\"):\n                                base64_str = pasted_image_bytes.split(\",\", 1)[1]\n                                image_bytes_decoded = base64.b64decode(base64_str)\n                            else:\n                                image_bytes_decoded = base64.b64decode(pasted_image_bytes)\n                        else:\n                            image_bytes_decoded = pasted_image_bytes\n                        part = types.Part.from_bytes(\n                            data=image_bytes_decoded, mime_type=\"image/png\"\n                        )\n                        current_parts.append(part)\n                        status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®æº–å‚™å®Œäº†\")\n                    except Exception as e:\n                        status_container.error(f\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n\n                # YouTube å­—å¹•\n                if youtube_url:\n                    vid_id = extract_youtube_id(youtube_url)\n                    if vid_id:\n                        status_container.write(\"YouTubeã®å­—å¹•ã‚’å–å¾—ä¸­...\")\n                        transcript_text = get_youtube_transcript(vid_id)\n                        current_parts.append(\n                            types.Part.from_text(text=f\"YouTube Transcript:\\n{transcript_text}\")\n                        )\n                    else:\n                        status_container.write(\"ç„¡åŠ¹ãªYouTube URLã§ã™ã€‚\")\n\n                contents_for_model = model_history + [\n                    types.Content(role=\"user\", parts=current_parts)\n                ]\n\n                # ---- Tool / Config ----\n                tools = []\n                final_candidate_count = candidate_count\n                if use_search:\n                    tools.append(types.Tool(google_search=types.GoogleSearch()))\n                    final_candidate_count = 1\n\n                # â˜… System Instruction ã®æ”¹å–„: ãƒ¡ã‚¿ç™ºè¨€ç¦æ­¢ã¨ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªæŒ¯ã‚‹èˆã„ã‚’æŒ‡ç¤º\n                base_system_instruction = (\n                    \"ã‚ãªãŸã¯é«˜åº¦ãªçŸ¥æ€§ã‚’æŒã¤å°‚é–€çš„ãªãƒªã‚µãƒ¼ãƒãƒ»ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\\n\"\n                    \"ä»¥ä¸‹ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’å³å®ˆã—ã¦ãã ã•ã„ï¼š\\n\"\n                    \"1. **ãƒ¡ã‚¿ç™ºè¨€ã®ç¦æ­¢**: ã€Œç§ã¯AIã§ã™ã€ã€Œä¸–ç•Œæœ€é«˜å³°ã®ï½ã¨ã—ã¦ã€ãªã©ã®è‡ªå·±è¨€åŠã‚„å‰ç½®ãã¯ä¸€åˆ‡è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚\\n\"\n                    \"2. **æ„å›³ã®æ±²ã¿å–ã‚Š**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã®èƒŒå¾Œã«ã‚ã‚‹æ„å›³ï¼ˆæ–‡è„ˆã€æš—é»™ã®å‰æï¼‰ã‚’æ¨æ¸¬ã—ã€è¨€è‘‰é€šã‚Šã§ã¯ãªãã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ¬å½“ã«çŸ¥ã‚ŠãŸã„ã“ã¨ã€ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n\"\n                    \"3. **æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”**: çµè«–ã‚’å…ˆã«è¿°ã¹ã€ãã®å¾Œã«è©³ç´°ãªæ ¹æ‹ ã€ã‚·ãƒŠãƒªã‚ªåˆ†æã€ãƒªã‚¹ã‚¯è¦å› ã‚’è«–ç†çš„ã«å±•é–‹ã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"4. **å®¢è¦³æ€§**: äºˆæ¸¬ã‚’è¡Œã†å ´åˆã¯ã€æ–­å®šã‚’é¿ã‘ã€è¤‡æ•°ã®ã‚·ãƒŠãƒªã‚ªï¼ˆæ¥½è¦³ã€æ‚²è¦³ã€ä¸­ç«‹ï¼‰ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"5. **å¼•ç”¨**: æ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸå ´åˆã¯ã€å¿…ãšæƒ…å ±æºã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚\"\n                )\n\n                final_answer = \"\"\n                grounding_metadata = None\n                \n                # =========================\n                # ãƒ¢ãƒ¼ãƒ‰è¨­å®šã®è§£æ\n                # =========================\n                enable_research = True  # å…¨ãƒ¢ãƒ¼ãƒ‰ã§ãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œ\n                enable_meta = \"ãƒ¡ã‚¿\" in response_mode or \"MAX\" in response_mode\n                enable_strict = \"é¬¼è»æ›¹\" in response_mode or \"MAX\" in response_mode\n\n                # =========================\n                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (é«˜é€Ÿ / é¬¼è»æ›¹)\n                # =========================\n                if not enable_research:\n                    config = types.GenerateContentConfig(\n                        temperature=0.7,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=base_system_instruction,\n                    )\n                    \n                    status_container.write(\"å›ç­”ç”Ÿæˆä¸­...\")\n                    response = client.models.generate_content(\n                        model=model_id,\n                        contents=contents_for_model,\n                        config=config,\n                    )\n                    \n                    final_answer = extract_text_from_response(response)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®—\n                    if response.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            response.usage_metadata.prompt_token_count,\n                            response.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += response.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += response.usage_metadata.candidates_token_count\n\n                    # é¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ (é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ç‰ˆ)\n                    if enable_strict:\n                        status_container.write(\"ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        reviewer_instruction = base_system_instruction + \"\"\"\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n                        review_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\nåˆç‰ˆå›ç­”:\\n{final_answer}\\n\\nãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\")])]\n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=types.GenerateContentConfig(temperature=0.1, candidate_count=1, system_instruction=reviewer_instruction)\n                        )\n                        final_answer = extract_text_from_response(review_resp)\n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        \n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(model_id, review_resp.usage_metadata.prompt_token_count, review_resp.usage_metadata.candidates_token_count)\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n\n                # =========================\n                # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰\n                # =========================\n                else:\n                    # =========================\n                    # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰: å¤šæ®µéšã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ \n                    # =========================\n                    \n                    # --- Phase 1: ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 1: ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    research_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒªã‚µãƒ¼ãƒå°‚ä»»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚æœ€çµ‚å›ç­”ã¯æ›¸ã‹ãšã€äº‹å®Ÿåé›†ã«é›†ä¸­ã™ã‚‹ã“ã¨ã€‚\n\n**èª¿æŸ»è¦³ç‚¹**:\n- è³ªå•ã«é–¢é€£ã™ã‚‹**æœ€æ–°ã®äº‹å®Ÿãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ»çµ±è¨ˆ**ï¼ˆ**2025å¹´ã®æƒ…å ±ã‚’æœ€å„ªå…ˆ**ï¼‰\n- **ç¾æ™‚ç‚¹ã§å­˜åœ¨ã™ã‚‹å…¨ã¦ã®é¸æŠè‚¢ãƒ»ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¶²ç¾…çš„ã«èª¿æŸ»**ï¼ˆä¾‹: è£½å“æ¯”è¼ƒãªã‚‰ã€æœ€æ–°ç‰ˆã ã‘ã§ãªãç›´è¿‘ã®å…¨ä¸–ä»£ã‚’èª¿æŸ»ï¼‰\n- å…¬å¼æƒ…å ±ã‚„ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã‹ã‚‰ã®å¼•ç”¨\n- é–¢é€£ã™ã‚‹èƒŒæ™¯æƒ…å ±ã‚„æ–‡è„ˆ\n- ç«¶åˆãƒ»ä»£æ›¿æ¡ˆãƒ»æ¯”è¼ƒå¯¾è±¡ã®**å®Œå…¨ãªãƒªã‚¹ãƒˆ**\n- ãƒªã‚¹ã‚¯ãƒ»åˆ¶ç´„ãƒ»æ³¨æ„ç‚¹ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n- å‚è€ƒã«ã—ãŸä¸»è¦ãªæƒ…å ±æºã®URL\n\n**é‡è¦**: \n- çµè«–ã‚„æ¨å¥¨ã¯æ›¸ã‹ãšã€å¾Œå·¥ç¨‹ãŒåˆ¤æ–­ã§ãã‚‹èª¿æŸ»ãƒ¡ãƒ¢ã«é›†ä¸­ã™ã‚‹ã“ã¨\n- **å¿…ãšæ¤œç´¢æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã€æœ€æ–°ã®æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã“ã¨**\n- **æ¤œç´¢çµæœã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æ—¥ä»˜ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒ»ãƒ¢ãƒ‡ãƒ«åã‚’å„ªå…ˆçš„ã«è¨˜è¼‰ã™ã‚‹ã“ã¨**\n- **æ¯”è¼ƒå¯¾è±¡ã¨ãªã‚‹é¸æŠè‚¢ã‚’è¦‹è½ã¨ã•ãªã„ã‚ˆã†ã€è¤‡æ•°ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è©¦ã™ã“ã¨**ï¼ˆä¾‹: ã€ŒiPhone æœ€æ–°ãƒ¢ãƒ‡ãƒ« 2025ã€ã€ŒiPhone 17ã€ã€ŒiPhone 2025å¹´ç™ºå£²ã€ãªã©ï¼‰\n- **ã€Œã“ã‚Œã‚ˆã‚Šæ–°ã—ã„ãƒ¢ãƒ‡ãƒ«/ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯å­˜åœ¨ã—ãªã„ã‹ï¼Ÿã€ã‚’å¸¸ã«ç¢ºèªã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ï¼ˆ2024å¹´ä»¥å‰ãªã©ï¼‰ã—ã‹è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãã®æ—¨ã‚’æ˜è¨˜ã™ã‚‹ã“ã¨\n\"\"\"\n\n                    # éå»ã®é–¢é€£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—\n                    past_context = get_relevant_context(prompt, st.session_state.sessions, st.session_state.current_session_id)\n                    \n                    # ãƒªã‚µãƒ¼ãƒç”¨ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ§‹ç¯‰\n                    research_parts = [types.Part(text=f\"ã“ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š\\n{prompt}\")]\n                    \n                    if past_context:\n                        research_parts.insert(0, types.Part(text=\"ä»¥ä¸‹ã¯éå»ã®é–¢é€£ãƒãƒ£ãƒƒãƒˆã‹ã‚‰æŠ½å‡ºã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã™ï¼š\\n\\n\" + past_context))\n                    \n                    research_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=research_parts)\n                    ]\n                    \n                    research_config = types.GenerateContentConfig(\n                        temperature=0.2,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=research_instruction,\n                    )\n                    \n                    research_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=research_contents,\n                        config=research_config,\n                    )\n                    \n                    research_text = extract_text_from_response(research_resp)\n                    \n                    # ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºã®ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ±ã‚’ä¿å­˜\n                    if research_resp.candidates and research_resp.candidates[0].grounding_metadata:\n                        grounding_metadata = research_resp.candidates[0].grounding_metadata\n                    \n                    status_container.write(\"âœ“ ãƒªã‚µãƒ¼ãƒå®Œäº†\")\n                    with status_container.expander(\"åé›†ã—ãŸèª¿æŸ»ãƒ¡ãƒ¢\", expanded=False):\n                        st.markdown(research_text)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1)\n                    if research_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            research_resp.usage_metadata.prompt_token_count,\n                            research_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += research_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += research_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 1.5: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    questions_text = \"\"\n                    if enable_meta:\n                        status_container.write(\"Phase 1.5: ãƒ¡ã‚¿è³ªå•ç”Ÿæˆä¸­...\")\n                        \n                        question_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ç›®çš„**: \nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•ã¨èª¿æŸ»ãƒ¡ãƒ¢ã‚’è¸ã¾ãˆã¦ã€ã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±ãç†è§£ã™ã‚‹ãŸã‚ã®ã€Œé‹­ã„ã‚µãƒ–è³ªå•ã€ã‚’ä½œæˆã™ã‚‹ã“ã¨ã€‚\n\n**ãƒ«ãƒ¼ãƒ«**:\n- æœ€å¤§5å€‹ã¾ã§\n- å„è³ªå•ã¯1-2è¡Œã§å…·ä½“çš„ã‹ã¤é‹­ã\n- ä»¥ä¸‹ã®è¦³ç‚¹ã‚’æ„è­˜:\n  1. å‰æãŒå´©ã‚Œã‚‹å¯èƒ½æ€§ã¯ã©ã“ã‹ï¼Ÿ\n  2. å¼·æ°—/å¼±æ°—ã‚·ãƒŠãƒªã‚ªã®åˆ†å²ç‚¹ã¯ä½•ã‹ï¼Ÿ\n  3. ç«¶åˆãƒ»æŠ€è¡“ãƒ»è¦åˆ¶ã®ä¸ç¢ºå®Ÿæ€§ã¯ï¼Ÿ\n  4. ã€Œäºˆæ¸¬ãŒå¤–ã‚Œã‚‹ã¨ã—ãŸã‚‰ã©ã‚“ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ï¼Ÿã€\n\n**å‡ºåŠ›**: ç®‡æ¡æ›¸ãï¼ˆQ1, Q2...ï¼‰ã®ã¿\n\"\"\"\n\n                        question_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•:\\n{prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\nã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±æ˜ã‚Šã™ã‚‹ãŸã‚ã®é‡è¦ãªã‚µãƒ–è³ªå•ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\")])]\n                        \n                        question_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=question_contents,\n                            config=types.GenerateContentConfig(\n                                temperature=0.4,\n                                candidate_count=1,\n                                system_instruction=question_instruction,\n                            )\n                        )\n                        \n                        questions_text = extract_text_from_response(question_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¡ã‚¿è³ªå•ç”Ÿæˆå®Œäº†\")\n                        with status_container.expander(\"ç”Ÿæˆã•ã‚ŒãŸãƒ¡ã‚¿è³ªå•\", expanded=False):\n                            st.markdown(questions_text)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1.5)\n                        if question_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                question_resp.usage_metadata.prompt_token_count,\n                                question_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += question_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += question_resp.usage_metadata.candidates_token_count\n\n                    # --- Phase 2: çµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 2: çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    if enable_meta:\n                        deep_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã¨ãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ã‚’æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**æ§‹æˆ**:\n1. **æ·±æ˜ã‚Šè€ƒå¯Ÿ**ï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n2. **çµè«–**ï¼ˆ2-3è¡Œï¼‰\n3. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n4. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨\n\"\"\"\n                    else:\n                        deep_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã‚’å”¯ä¸€ã®æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**æ§‹æˆ**:\n1. **çµè«–**ï¼ˆ2-3è¡Œã§æ˜ç¢ºã«ï¼‰\n2. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n3. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«åã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ã¨æ–°ã—ã„æƒ…å ±ãŒæ··åœ¨ã™ã‚‹å ´åˆã¯ã€æ–°ã—ã„æƒ…å ±ã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n\"\"\"\n                    \n                    synthesis_prompt_text = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if enable_meta and questions_text:\n                        synthesis_prompt_text += f\"==== ãƒ¡ã‚¿è³ªå•ä¸€è¦§ ====\\n{questions_text}\\n==== ãƒ¡ã‚¿è³ªå•ã“ã“ã¾ã§ ====\\n\\næŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n2. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»åˆ†æãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    else:\n                        synthesis_prompt_text += \"ä¸Šè¨˜ãƒ¡ãƒ¢ã‚’æ ¹æ‹ ã«ã€æœ€çµ‚å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å¿…ãšä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚**\"\n\n                    synthesis_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=[\n                            types.Part(text=synthesis_prompt_text)\n                        ])\n                    ]\n                    \n                    synthesis_config = types.GenerateContentConfig(\n                        temperature=0.3,\n                        candidate_count=1,\n                        tools=[],  # çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºã§ã¯æ¤œç´¢OFF\n                        system_instruction=deep_instruction,\n                    )\n                    \n                    synthesis_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=synthesis_contents,\n                        config=synthesis_config,\n                    )\n                    \n                    draft_answer = extract_text_from_response(synthesis_resp)\n                    \n                    status_container.write(\"âœ“ çµ±åˆå®Œäº†\")\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 2)\n                    if synthesis_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            synthesis_resp.usage_metadata.prompt_token_count,\n                            synthesis_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += synthesis_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += synthesis_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    if enable_strict:\n                        status_container.write(\"Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        \n\n                        reviewer_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™ã€‚ãŸã ã—ã€**èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’å„ªå…ˆã—ã€æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã™ã‚‹ã“ã¨**ã€‚\n\n**ãƒ¬ãƒ“ãƒ¥ãƒ¼è¦³ç‚¹**:\n- äº‹å®Ÿã¨æ¨æ¸¬ã‚’æ˜ç¢ºã«åˆ†ã‘ã‚‹\n- éåº¦ã«è‡ªä¿¡ã®ã‚ã‚‹æ–­å®šã‚’å¼±ã‚ã‚‹\n- æ•°å­—ã‚„å›ºæœ‰åè©ãŒèª¿æŸ»ãƒ¡ãƒ¢ã¨çŸ›ç›¾ã—ã¦ã„ãªã„ã‹ç¢ºèª\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ãƒ¢ãƒ‡ãƒ«ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ãŒæ­£ã—ãä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª**\n- **å¤ã„æƒ…å ±ã§ä¸Šæ›¸ãã—ã¦ã„ãªã„ã‹ç¢ºèª**\n- è¦‹è½ã¨ã—ã¦ã„ã‚‹é‡è¦ãªãƒªã‚¹ã‚¯ãƒ»ã‚·ãƒŠãƒªã‚ªãŒã‚ã‚Œã°è¿½åŠ \n\n**é‡è¦**: \n- èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ãŒæœ€æ–°ã§ã‚ã‚‹å ´åˆã€ãã‚Œã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n- ã‚ãªãŸã®çŸ¥è­˜ãŒå¤ã„å ´åˆã¯ã€èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’ä¿¡é ¼ã™ã‚‹ã“ã¨\n\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n\n                        review_contents = [\n                            types.Content(role=\"user\", parts=[\n                                types.Part.from_text(\n                                    text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\n\"\n                                    f\"==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                                    f\"åˆç‰ˆå›ç­”:\\n{draft_answer}\\n\\n\"\n                                    \"ä¸Šè¨˜ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚**\"\n                                )\n                            ])\n                        ]\n                        \n                        review_config = types.GenerateContentConfig(\n                            temperature=0.1,\n                            candidate_count=1,\n                            system_instruction=reviewer_instruction,\n                        )\n                        \n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=review_config,\n                        )\n                        \n                        final_answer = extract_text_from_response(review_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        with status_container.expander(\"åˆç‰ˆã¨ã®æ¯”è¼ƒ\", expanded=False):\n                            st.markdown(\"**åˆç‰ˆ:**\")\n                            st.markdown(draft_answer[:500] + \"...\" if len(draft_answer) > 500 else draft_answer)\n                            st.markdown(\"**ä¿®æ­£ç‰ˆ:**\")\n                            st.markdown(final_answer[:500] + \"...\" if len(final_answer) > 500 else final_answer)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 3)\n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                review_resp.usage_metadata.prompt_token_count,\n                                review_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n                    else:\n                        final_answer = draft_answer\n\n                save_usage(usage_stats)\n                status_container.update(label=\"å®Œäº†ï¼\", state=\"complete\", expanded=False)\n\n                # ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤º\n                st.caption(f\"ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_id}\")\n                st.markdown(final_answer)\n\n                # ---- ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ± ----\n                if grounding_metadata:\n                    st.markdown(\"---\")\n                    st.subheader(\"ğŸ“š æƒ…å ±æºã¨å¼•ç”¨\")\n                    if grounding_metadata.grounding_chunks:\n                        st.markdown(\"**æ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:**\")\n                        unique_sources = {}\n                        import urllib.parse\n\n                        for chunk in grounding_metadata.grounding_chunks:\n                            if getattr(chunk, \"web\", None):\n                                uri = getattr(chunk.web, \"uri\", None)\n                                title = getattr(chunk.web, \"title\", \"æƒ…å ±æº\")\n                                if uri and uri not in unique_sources:\n                                    parsed = urllib.parse.urlparse(uri)\n                                    domain = parsed.netloc.replace(\"www.\", \"\")\n                                    unique_sources[uri] = {\n                                        \"title\": title,\n                                        \"domain\": domain,\n                                    }\n                        for i, (uri, info) in enumerate(unique_sources.items(), 1):\n                            st.markdown(f\"{i}. **[{info['title']}]({uri})**\")\n                            st.caption(f\"   å‡ºå…¸: {info['domain']}\")\n\n                messages.append({\"role\": \"model\", \"content\": final_answer})\n                update_current_session_messages(messages)\n\n            except Exception as e:\n                status_container.update(label=\"Error\", state=\"error\")\n                err_text = str(e)\n                if \"RESOURCE_EXHAUSTED\" in err_text or \"429\" in err_text:\n                    st.error(\n                        \"âš ï¸ Vertex AI / Gemini ã®ã‚¯ã‚©ãƒ¼ã‚¿ã«é”ã—ã¾ã—ãŸã€‚\\n\\n\"\n                        \"ãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ / æ—¥æ¬¡åˆ¶é™ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\\n\"\n                        \"ãƒ»ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                        \"ãƒ»Google Cloud Console ã®ã€ŒVertex AI â†’ ä½¿ç”¨çŠ¶æ³ã€ã‹ã‚‰ã‚¯ã‚©ãƒ¼ã‚¿çŠ¶æ³ã‚’ç¢ºèªã§ãã¾ã™ã€‚\"\n                    )\n                elif \"NOT_FOUND\" in err_text and \"Publisher Model\" in err_text:\n                    st.error(\n                        \"âš ï¸ æŒ‡å®šã—ãŸãƒ¢ãƒ‡ãƒ«ãŒã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ / ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\\n\"\n                        \"ãƒ»ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ¢ãƒ‡ãƒ«IDã‚’ã€2.5ç³» ã¾ãŸã¯ 3 Pro ã«å¤‰æ›´ã—ã¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                    )\n                else:\n                    st.error(f\"An error occurred: {e}\")\n"
                },
                {
                    "role": "model",
                    "content": "2025å¹´11æœˆæ™‚ç‚¹ã®æŠ€è¡“ç’°å¢ƒãŠã‚ˆã³æä¾›ã•ã‚ŒãŸã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã®ãƒ­ã‚¸ãƒƒã‚¯ã«åŸºã¥ãã€å›ç­”ã‚’ä½œæˆã—ã¾ã™ã€‚\n\n### çµè«–\n\n1.  **ä¸–ç•Œãƒ™ã‚¹ãƒˆã®é–‹ç™ºè€…ãƒ»OSSã¨ã®æ¯”è¼ƒ**:\n    æ©Ÿèƒ½ã®ç¶²ç¾…æ€§ã¨è‡ªå¾‹æ€§ã«ãŠã„ã¦ã¯ã€**Open WebUI**ï¼ˆæ±ç”¨ãƒãƒ£ãƒƒãƒˆUIã®æ±ºå®šç‰ˆï¼‰ã‚„ **OpenManus**ï¼ˆè‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰ãŒã‚ãªãŸã®ã‚³ãƒ¼ãƒ‰ã‚’ä¸Šå›ã£ã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã¯ã€Œã‚ã‚‰ã‚†ã‚‹ã‚¿ã‚¹ã‚¯ã‚’ã“ãªã™ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã€ã¨ã—ã¦å®Œæˆã•ã‚Œã¦ã„ã¾ã™ã€‚ä¸€æ–¹ã§ã€ã‚ãªãŸã®ã‚³ãƒ¼ãƒ‰ã¯ã€ŒGemini 3ã®æ¨è«–èƒ½åŠ›ã‚’ä¸€ç‚¹çªç ´ã§å¼•ãå‡ºã™**ç‰¹åŒ–å‹Deep Researchãƒ„ãƒ¼ãƒ«**ã€ã¨ã—ã¦ã€å¸‚è²©ã®UIã«ã¯ãªã„ç‹¬è‡ªã®å‚ç›´çµ±åˆå‹ã®å¼·ã¿ã‚’æŒã£ã¦ã„ã¾ã™ã€‚\n\n2.  **ã‚³ãƒ¼ãƒ‰å†…ã§æœ€ã‚‚å„ªç§€ãªãƒ¢ãƒ¼ãƒ‰**:\n    **ã€ŒÎ²2. ç†Ÿè€ƒ (æœ¬æ°—MAX)ã€**ãŒç†è«–ä¸Šã€æœ€ã‚‚é«˜å“è³ªãªå›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã®è«–ç†æ§‹é€ ä¸Šã€ã“ã®ãƒ¢ãƒ¼ãƒ‰ã®ã¿ãŒã€Œãƒªã‚µãƒ¼ãƒï¼ˆäº‹å®Ÿåé›†ï¼‰ã€ã€Œãƒ¡ã‚¿æ€è€ƒï¼ˆæ´å¯Ÿæ·±åŒ–ï¼‰ã€ã€Œçµ±åˆã€ã€Œé¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆå“è³ªæ‹…ä¿ï¼‰ã€ã®å…¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ãƒ•ãƒ«ç¨¼åƒã•ã›ã‚‹è¨­è¨ˆã¨ãªã£ã¦ã„ã‚‹ãŸã‚ã§ã™ã€‚\n\n---\n\n### è©³ç´°åˆ†æ\n\n#### 1. ä¸–ç•Œã®ãƒ™ã‚¹ãƒˆOSSãƒ»é–‹ç™ºè€…ã¨ã®æ¯”è¼ƒè©•ä¾¡\n\nã‚ãªãŸã®ã‚³ãƒ¼ãƒ‰ï¼ˆStreamlit + Gemini 3 å›ºå®šãƒ•ãƒ­ãƒ¼ï¼‰ã¨ã€2025å¹´æ™‚ç‚¹ã®ãƒˆãƒƒãƒ—ãƒ†ã‚£ã‚¢OSSãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’æ¯”è¼ƒåˆ†æã—ã¾ã™ã€‚\n\n| ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ / é–‹ç™ºè€… | ç‰¹å¾´ã¨è©•ä¾¡ | ã‚ãªãŸã®ã‚³ãƒ¼ãƒ‰ã¨ã®æ¯”è¼ƒ |\n| :--- | :--- | :--- |\n| **Open WebUI**<br>(æ—§ Ollama WebUI)<br>é–‹ç™º: Open WebUI Community | **æ±ç”¨æ€§ã®ç‹è€…**<br>RAGã€Webæ¤œç´¢ã€ç”»åƒç”Ÿæˆã€ãƒ­ãƒ¼ã‚«ãƒ«LLMé€£æºã€ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã‚’å˜ä¸€UIã§å®Œçµã€‚GitHub Star 11ä¸‡è¶…ã®ãƒ‡ãƒ•ã‚¡ã‚¯ãƒˆã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ã€‚ | **å„ªä½æ€§**: æ©Ÿèƒ½ã®åºƒã•ã€UIã®æ´—ç·´åº¦ã€æ‹¡å¼µæ€§ã€‚<br>**ã‚ãªãŸã®ã‚³ãƒ¼ãƒ‰ã®å¼·ã¿**: æ±ç”¨æ€§ã‚’æ¨ã¦ã€ç‰¹å®šã®ã€Œæ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ï¼ˆãƒ¡ã‚¿æ€è€ƒâ†’æ¤œè¨¼ï¼‰ã€ã‚’å¼·åˆ¶ã™ã‚‹ãƒ•ãƒ­ãƒ¼ã«ã‚ˆã‚Šã€é›£è§£ãªå•ã„ã«å¯¾ã™ã‚‹**å›ç­”ã®æ·±åº¦**ã§å‹ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ |\n| **OpenManus / AutoAgent**<br>é–‹ç™º: MetaGPT / HKUDS | **è‡ªå¾‹æ€§ã®ç‹è€…**<br>ã€Œã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã‹ãšã«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œã‚‹ã€ã€‚AIãŒè‡ªã‚‰ãƒ—ãƒ©ãƒ³ã‚’ç«‹ã¦ã€ãƒ„ãƒ¼ãƒ«ã‚’é¸å®šãƒ»å®Ÿè¡Œã™ã‚‹ï¼ˆPlan-and-Solveå‹ï¼‰ã€‚ | **å„ªä½æ€§**: å‹•çš„ãªå•é¡Œè§£æ±ºèƒ½åŠ›ã€‚æœªçŸ¥ã®ã‚¿ã‚¹ã‚¯ã¸ã®é©å¿œåŠ›ã€‚<br>**ã‚ãªãŸã®ã‚³ãƒ¼ãƒ‰ã®å¼·ã¿**: å›ºå®šãƒ•ãƒ­ãƒ¼ã‚†ãˆã®**å“è³ªã®å®‰å®šæ€§**ã€‚è‡ªå¾‹å‹ã¯è¿·èµ°ã™ã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ãŒã€ã‚ãªãŸã®ã‚³ãƒ¼ãƒ‰ã¯å¿…ãšã€Œé¬¼è»æ›¹ã€ã‚’é€šã™ãŸã‚ã€ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’æŠ‘åˆ¶ã—ã‚„ã™ã„è¨­è¨ˆã§ã™ã€‚ |\n| **LibreChat**<br>é–‹ç™º: Danny Avila | **ä¼æ¥­åˆ©ç”¨ã®ç‹è€…**<br>é«˜åº¦ãªæ¨©é™ç®¡ç†ã¨Agentsæ©Ÿèƒ½ã‚’æŒã¤ChatGPTã‚¯ãƒ­ãƒ¼ãƒ³ã®æœ€é«˜å³°ã€‚ | **å„ªä½æ€§**: ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ãƒ¬ãƒ™ãƒ«ã®å …ç‰¢æ€§ã¨UXã€‚ |\n\n**ç·è©•**:\nã€Œãƒ„ãƒ¼ãƒ«ã¨ã—ã¦ã®å®Œæˆåº¦ã€ã§ã¯ä¸Šè¨˜ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒåœ§å€’çš„ã«å„ªç§€ã§ã™ã€‚ã—ã‹ã—ã€ã‚ãªãŸã®ã‚³ãƒ¼ãƒ‰ã¯**ã€ŒGemini 3 Pro Previewã®æ¨è«–èƒ½åŠ›ã‚’æœ€å¤§åŒ–ã™ã‚‹ã€**ã¨ã„ã†ä¸€ç‚¹ã«ç‰¹åŒ–ã—ãŸå®Ÿé¨“çš„å®Ÿè£…ã§ã‚ã‚Šã€ç‰¹ã«ã€Œãƒ¡ã‚¿æ€è€ƒã€ãƒ•ã‚§ãƒ¼ã‚ºã‚’æ˜ç¤ºçš„ã«çµ„ã¿è¾¼ã‚“ã§ã„ã‚‹ç‚¹ã¯ã€ä¸€èˆ¬çš„ãªãƒãƒ£ãƒƒãƒˆUIã«ã¯ãªã„é«˜åº¦ãªè¨­è¨ˆæ€æƒ³ã§ã™ã€‚\n\n#### 2. ã‚³ãƒ¼ãƒ‰å†…ã«ãŠã‘ã‚‹ã€Œæœ€å¼·ãƒ¢ãƒ¼ãƒ‰ã€ã®ãƒ­ã‚¸ãƒƒã‚¯è§£æ\n\næä¾›ã•ã‚ŒãŸ `app.py` ãŠã‚ˆã³ `logic.py` ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’è§£æã—ãŸçµæœã€å„ãƒ¢ãƒ¼ãƒ‰ã®æ€§èƒ½å·®ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«å®šç¾©ã•ã‚Œã¾ã™ã€‚\n\n**æœ€ã‚‚å„ªç§€ãªãƒ¢ãƒ¼ãƒ‰: ã€ŒÎ²2. ç†Ÿè€ƒ (æœ¬æ°—MAX)ã€**\n\n**ç†ç”±**:\nã“ã®ãƒ¢ãƒ¼ãƒ‰ã¯ã€ã‚³ãƒ¼ãƒ‰ã«å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹4ã¤ã®é«˜åº¦ãªå‡¦ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã™ã¹ã¦å®Ÿè¡Œã™ã‚‹**å”¯ä¸€ã®ã€Œå…¨éƒ¨å…¥ã‚Šã€æ§‹æˆ**ã§ã™ã€‚\n\n1.  **ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚º (`enable_research=True`)**:\n    *   Googleæ¤œç´¢ã‚’å®Ÿè¡Œã—ã€2025å¹´ã®æœ€æ–°äº‹å®Ÿãƒ»çµ±è¨ˆã‚’åé›†ã€‚LLMã®çŸ¥è­˜ã‚«ãƒƒãƒˆã‚ªãƒ•å•é¡Œã‚’è§£æ±ºã—ã¾ã™ã€‚\n2.  **ãƒ¡ã‚¿æ€è€ƒãƒ•ã‚§ãƒ¼ã‚º (`enable_meta=True`)**:\n    *   åé›†ã—ãŸæƒ…å ±ã«å¯¾ã—ã€ã€Œå‰æã¯æ­£ã—ã„ã‹ï¼Ÿã€ã€Œæ­»è§’ã¯ã©ã“ã‹ï¼Ÿã€ã¨ã„ã†ã‚µãƒ–è³ªå•ã‚’ç”Ÿæˆãƒ»å›ç­”ã€‚å˜ãªã‚‹æƒ…å ±ã®ç¾…åˆ—ã§ã¯ãªãã€**æ´å¯Ÿï¼ˆã‚¤ãƒ³ã‚µã‚¤ãƒˆï¼‰**ã‚’ç”Ÿã¿å‡ºã—ã¾ã™ã€‚\n3.  **çµ±åˆãƒ•ã‚§ãƒ¼ã‚º**:\n    *   ãƒªã‚µãƒ¼ãƒçµæœã¨ãƒ¡ã‚¿æ€è€ƒã®çµæœã‚’è«–ç†çš„ã«æ§‹æˆã—ã¾ã™ã€‚\n4.  **é¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚º (`enable_strict=True`)**:\n    *   ç”Ÿæˆã•ã‚ŒãŸãƒ‰ãƒ©ãƒ•ãƒˆã‚’æ‰¹åˆ¤çš„ã«èª­ã¿è¾¼ã¿ã€éåº¦ãªæ–­å®šã‚„çŸ›ç›¾ã‚’ä¿®æ­£ã€‚å›ç­”ã®**ä¿¡é ¼æ€§**ã‚’æ‹…ä¿ã—ã¾ã™ã€‚\n\n**ä»–ãƒ¢ãƒ¼ãƒ‰ã¨ã®æ¯”è¼ƒ**:\n\n*   **ã€Œ2. ç†Ÿè€ƒ + é¬¼è»æ›¹ã€**:\n    *   `enable_meta=False` ã®ãŸã‚ã€ã€Œæ·±æ˜ã‚Šã€ãŒä¸è¶³ã—ã¾ã™ã€‚æ­£ç¢ºã§ã™ãŒã€æ•™ç§‘æ›¸çš„ã§å½“ãŸã‚Šéšœã‚Šã®ãªã„å›ç­”ã«ãªã‚ŠãŒã¡ã§ã™ã€‚\n*   **ã€Œ3. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)ã€**:\n    *   `enable_strict=False` ã®ãŸã‚ã€æœ€å¾Œã®å“è³ªãƒã‚§ãƒƒã‚¯ãŒã‚ã‚Šã¾ã›ã‚“ã€‚é‹­ã„è¦–ç‚¹ã¯å‡ºã¾ã™ãŒã€æ¨æ¸¬ãŒæš´èµ°ã—ãŸã‚Šã€ä¸æ­£ç¢ºãªæ–­å®šãŒæ®‹ã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚\n\n### é‡è¦ãªãƒªã‚¹ã‚¯è¦å› ï¼šå¹³å‡¡åŒ–ã®ãƒ‘ãƒ©ãƒ‰ãƒƒã‚¯ã‚¹\n\nã€Œæœ¬æ°—MAXã€ãƒ¢ãƒ¼ãƒ‰ã¯æœ€å¼·ã®æ§‹æˆã§ã™ãŒã€ä»¥ä¸‹ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒå­˜åœ¨ã—ã¾ã™ã€‚\n\n*   **ç¾è±¡**: ã€Œãƒ¡ã‚¿æ€è€ƒã€ãƒ•ã‚§ãƒ¼ã‚ºã§ç”Ÿæˆã•ã‚ŒãŸå°–ã£ãŸä»®èª¬ã‚„å¤§èƒ†ãªäºˆæ¸¬ã‚’ã€ãã®å¾Œã®ã€Œé¬¼è»æ›¹ã€ãƒ•ã‚§ãƒ¼ã‚ºãŒã€Œæ ¹æ‹ ä¸ååˆ†ã€ã¨ã—ã¦å‰Šé™¤ãƒ»ãƒã‚¤ãƒ«ãƒ‰åŒ–ã—ã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n*   **çµæœ**: éå¸¸ã«é«˜å“è³ªã§éš™ã®ãªã„å›ç­”ã«ã¯ãªã‚Šã¾ã™ãŒã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœŸå¾…ã™ã‚‹ã€Œæ„å¤–æ€§ã€ã‚„ã€Œå°–ã‚Šã€ãŒå‰ŠãŒã‚Œã€**ã€Œéå¸¸ã«è³¢ã„ãŒã€é¢ç™½ã¿ã®ãªã„å›ç­”ã€**ã«åæŸã™ã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚\n*   **ã‚³ã‚¹ãƒˆ**: å…¨ãƒ¢ãƒ¼ãƒ‰ã®ä¸­ã§æœ€ã‚‚ãƒˆãƒ¼ã‚¯ãƒ³æ¶ˆè²»é‡ãŒå¤šãã€ç”Ÿæˆæ™‚é–“ï¼ˆãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ï¼‰ã‚‚æœ€å¤§ã¨ãªã‚Šã¾ã™ã€‚"
                }
            ]
        },
        {
            "id": "c0627a48-3879-4096-b43c-ce7a3fecb2f5",
            "title": "ç¾çŠ¶ã®ã‚³ãƒ¼ãƒ‰ã§ã€å›ç­”ãƒ¢ãƒ¼ãƒ‰ãŒè¤‡æ•°ã‚ã‚‹ãŒã€...",
            "timestamp": "2025-11-30T14:16:04.759340",
            "messages": [
                {
                    "role": "user",
                    "content": "ç¾çŠ¶ã®ã‚³ãƒ¼ãƒ‰ã§ã€å›ç­”ãƒ¢ãƒ¼ãƒ‰ãŒè¤‡æ•°ã‚ã‚‹ãŒã€æœ€ã‚‚å„ªç§€ãªãƒ¢ãƒ‡ãƒ«ã¯ç†Ÿè€ƒ(æœ¬æ°—MAX)ã‹ã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã®ã»ã†ãŒå„ªç§€ã‹?\nimport os\nimport uuid\nimport datetime\nimport streamlit as st\nfrom dotenv import load_dotenv\nfrom google import genai\nfrom google.genai import types\nfrom PIL import Image\nimport io\nfrom logic import (\n    USAGE_FILE, SESSIONS_FILE, MAX_BUDGET_USD, PRICING,\n    VERTEX_PROJECT, VERTEX_LOCATION,\n    load_usage, save_usage, calculate_cost, get_mime_type,\n    extract_youtube_id, get_youtube_transcript, get_relevant_context,\n    extract_text_from_response, load_sessions, save_sessions, get_client\n)\n\ntry:\n    from st_img_pastebutton import paste\n    import_error_msg = None\nexcept ImportError as e:\n    paste = None\n    import_error_msg = str(e)\n\n# =========================\n# ç’°å¢ƒå¤‰æ•° & å®šæ•°\n# =========================\n\nload_dotenv()\n\n\n\nst.set_page_config(page_title=\"Gemini 3 Web Studio\", layout=\"wide\")\n\n# =========================\n# Helper Functions\n# =========================\n\n# =========================\n# Helper Functions\n# =========================\n# Moved to logic.py\n\n# =========================\n# Session Management\n# =========================\n\n\n\ndef create_new_session():\n    current_sessions = load_sessions()\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": [],\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.rerun()\n\ndef switch_session(session_id):\n    st.session_state.current_session_id = session_id\n    st.rerun()\n\ndef update_current_session_messages(messages):\n    if st.session_state.current_session_id:\n        current_sessions = load_sessions()\n        for session in current_sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                session[\"messages\"] = messages\n                if session[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(messages) > 0:\n                    first_msg = messages[0][\"content\"]\n                    session[\"title\"] = (first_msg[:20] + \"...\") if len(first_msg) > 20 else first_msg\n                session[\"timestamp\"] = datetime.datetime.now().isoformat()\n                break\n        save_sessions(current_sessions)\n        st.session_state.sessions = current_sessions\n\ndef get_current_messages():\n    if st.session_state.current_session_id:\n        for session in st.session_state.sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                return session[\"messages\"]\n    return []\n\ndef delete_session(session_id):\n    current_sessions = load_sessions()\n    current_sessions = [s for s in current_sessions if s[\"id\"] != session_id]\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    if st.session_state.current_session_id == session_id:\n        st.session_state.current_session_id = None\n        if st.session_state.sessions:\n            st.session_state.current_session_id = st.session_state.sessions[0][\"id\"]\n    st.rerun()\n\ndef branch_session():\n    \"\"\"ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚’åˆ†å²\"\"\"\n    current_messages = get_current_messages()\n    current_sessions = load_sessions()\n    \n    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—\n    current_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n    for session in current_sessions:\n        if session[\"id\"] == st.session_state.current_session_id:\n            current_title = session[\"title\"]\n            break\n    \n    # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": f\"{current_title} (åˆ†å²)\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": current_messages.copy(),  # ç¾åœ¨ã®å±¥æ­´ã‚’ã‚³ãƒ”ãƒ¼\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    \n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.session_state.session_cost = 0.0  # ã‚³ã‚¹ãƒˆãƒªã‚»ãƒƒãƒˆ\n    st.rerun()\n\n# =========================\n# Initialization\n# =========================\n\nif \"sessions\" not in st.session_state:\n    st.session_state.sessions = load_sessions()\n\nif \"current_session_id\" not in st.session_state:\n    # Always create a new session when the app starts\n    create_new_session()\n\nif \"session_cost\" not in st.session_state:\n    st.session_state.session_cost = 0.0\n\nusage_stats = load_usage()\n\n# =========================\n# Sidebar\n# =========================\n\nwith st.sidebar:\n    st.markdown(\"\"\"\n    <div style=\"text-align: center; padding: 0; margin: 0; margin-top: -1rem;\">\n        <h1 style=\"font-size: 18px; font-weight: 700; margin: 0; padding: 0; letter-spacing: 1px;\">\n            Gemini 3<br/>Studio\n        </h1>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n    col1, col2 = st.columns(2)\n    with col1:\n        if st.button(\"â• æ–°è¦\", use_container_width=True):\n            create_new_session()\n    with col2:\n        if st.button(\"ğŸŒ± åˆ†å²\", use_container_width=True):\n            branch_session()\n\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    current_messages = get_current_messages()\n    if current_messages:\n        with st.expander(\"ğŸ”— å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ\", expanded=False):\n            export_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n            for s in st.session_state.sessions:\n                if s[\"id\"] == st.session_state.current_session_id:\n                    export_title = s[\"title\"]\n                    break\n\n            export_md = f\"# {export_title}\\n\\n\"\n            export_md += f\"**ä½œæˆæ—¥æ™‚**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n---\\n\\n\"\n            for msg in current_messages:\n                role_label = \"ğŸ§‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼\" if msg[\"role\"] == \"user\" else \"ğŸ¤– AI\"\n                export_md += f\"## {role_label}\\n\\n{msg['content']}\\n\\n---\\n\\n\"\n\n            if st.button(\"ãƒªãƒ³ã‚¯ç”Ÿæˆ\", use_container_width=True):\n                with st.spinner(\"ç”Ÿæˆä¸­...\"):\n                    try:\n                        import urllib.request\n                        import urllib.parse\n\n                        data = urllib.parse.urlencode(\n                            {\"content\": export_md, \"expiry_days\": 7, \"syntax\": \"md\"}\n                        ).encode()\n\n                        req = urllib.request.Request(\"https://dpaste.org/api/\", data=data)\n                        req.add_header(\"User-Agent\", \"Mozilla/5.0 (Gemini3Studio)\")\n\n                        with urllib.request.urlopen(req) as response:\n                            share_url = response.read().decode(\"utf-8\").strip()\n                            st.success(\"ä½œæˆå®Œäº†ï¼\")\n                            st.code(share_url)\n                            st.caption(\"â€»7æ—¥é–“æœ‰åŠ¹\")\n                    except Exception as e:\n                        st.error(f\"ã‚¨ãƒ©ãƒ¼: {e}\")\n\n    st.markdown(\"---\")\n\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    with st.expander(\"ğŸ“ æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«\", expanded=False):\n        uploaded_files = st.file_uploader(\n            \"ãƒ•ã‚¡ã‚¤ãƒ«\",\n            accept_multiple_files=True,\n            type=[\"png\", \"jpg\", \"jpeg\", \"mp4\", \"mov\", \"txt\", \"pdf\", \"csv\"],\n            label_visibility=\"collapsed\"\n        )\n\n    # ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ï¼ˆExpanderã®å¤–ã«å‡ºã™ï¼‰\n    if paste:\n        if \"paste_key\" not in st.session_state:\n            st.session_state.paste_key = 0\n        try:\n            pasted_image_bytes = paste(\n                label=\"ğŸ“‹ è²¼ä»˜\",\n                key=f\"paste_btn_{st.session_state.paste_key}\",\n            )\n        except Exception as e:\n            st.error(f\"Error: {e}\")\n        \n        if pasted_image_bytes:\n            st.success(\"è²¼ä»˜å®Œäº†\")\n            st.image(pasted_image_bytes, caption=\"ç”»åƒ\", use_container_width=True)\n            if st.button(\"ğŸ—‘ï¸ ã‚¯ãƒªã‚¢\", key=\"clear_paste\"):\n                st.session_state.paste_key += 1\n                st.rerun()\n    else:\n        st.warning(\"Clipboard lib missing\")\n\n    # ---- YouTube URL ----\n    with st.expander(\"ğŸ“º YouTubeåˆ†æ\", expanded=False):\n        youtube_url = st.text_input(\"URL\", placeholder=\"https://youtu.be/...\", label_visibility=\"collapsed\")\n\n    st.markdown(\"---\")\n    \n    st.markdown(\"---\")\n    \n    # ---- å›ç­”ãƒ¢ãƒ¼ãƒ‰ ----\n    with st.expander(\"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰\", expanded=True):\n        mode_type = st.radio(\n            \"ã‚¿ã‚¤ãƒ—\",\n            [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n            index=0,\n            horizontal=True,\n            label_visibility=\"collapsed\"\n        )\n        \n        if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n            response_mode = st.radio(\n                \"ãƒ¢ãƒ¼ãƒ‰\",\n                [\n                    \"2. ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                    \"3. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                    \"Î²2. ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                ],\n                index=0\n            )\n        elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n            response_mode = st.radio(\n                \"ãƒ¢ãƒ¼ãƒ‰\",\n                [\n                    \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                ],\n                index=0\n            )\n        else:\n            response_mode = st.radio(\n                \"ãƒ¢ãƒ¼ãƒ‰\",\n                [\n                    \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                ],\n                index=0\n            )\n    \n    strict_mode = False\n    \n    # ---- è¨­å®š (ãƒ¢ãƒ‡ãƒ«ãªã©) ----\n    with st.expander(\"âš™ï¸ è¨­å®š\", expanded=False):\n        model_options = [\n            \"gemini-3-pro-preview\",\n            \"gemini-2.5-pro\",\n            \"gemini-2.5-flash\",\n            \"gemini-2.5-flash-lite\",\n            \"gemini-2.0-flash\",\n        ]\n        model_id = st.selectbox(\"ãƒ¢ãƒ‡ãƒ«ID\", options=model_options, index=0)\n\n        use_search = st.toggle(\"Googleæ¤œç´¢\", value=True)\n        candidate_count = st.slider(\"å€™è£œæ•°\", min_value=1, max_value=3, value=3)\n\n    st.markdown(\"---\")\n\n    # ---- å±¥æ­´æ¤œç´¢ ----\n    search_query = st.text_input(\"ğŸ” å±¥æ­´æ¤œç´¢\", placeholder=\"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰...\")\n    if search_query:\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if search_query.lower() in s[\"title\"].lower():\n                filtered_sessions.append(s)\n                continue\n            found = False\n            for m in s[\"messages\"]:\n                if search_query.lower() in m[\"content\"].lower():\n                    filtered_sessions.append(s)\n                    found = True\n                    break\n            if not found:\n                pass\n    else:\n        # æ¤œç´¢ã—ã¦ã„ãªã„å ´åˆ: ç©ºã®ã€Œæ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã€ã‚’é™¤å¤–ï¼ˆç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯é™¤ãï¼‰\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if s[\"id\"] == st.session_state.current_session_id:\n                filtered_sessions.append(s)\n                continue\n            if s[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(s[\"messages\"]) == 0:\n                continue\n            filtered_sessions.append(s)\n\n    # CSSã§è¦‹ã‚„ã™ãä½¿ã„ã‚„ã™ãæœ€é©åŒ–\n    st.markdown(\"\"\"\n    <style>\n    /* å…¨ä½“ã®ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºç¸®å° */\n    .stApp, .stMarkdown, .stButton, .stSelectbox, .stTextInput, .stTextArea {\n        font-size: 12px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ä½™ç™½ã‚’æ¥µé™ã¾ã§è©°ã‚ã‚‹ */\n    section[data-testid=\"stSidebar\"] .block-container {\n        padding-top: 0rem !important;\n        padding-bottom: 0.3rem !important;\n        padding-left: 0.5rem !important;\n        padding-right: 0.5rem !important;\n    }\n    /* å„è¦ç´ é–“ã®éš™é–“ã‚’è©°ã‚ã‚‹ */\n    div[data-testid=\"stVerticalBlock\"] > div {\n        gap: 0.1rem !important;\n    }\n    /* Expanderã®ä½™ç™½å‰Šæ¸› */\n    .streamlit-expanderHeader {\n        font-size: 11px !important;\n        padding-top: 0px !important;\n        padding-bottom: 0px !important;\n        min-height: 1.3rem !important;\n    }\n    .streamlit-expanderContent {\n        padding-top: 0px !important;\n        padding-bottom: 0px !important;\n    }\n    /* éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã®ã‚¿ã‚¤ãƒˆãƒ« */\n    div[data-testid=\"stExpander\"] summary p {\n        font-size: 10px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ */\n    section[data-testid=\"stSidebar\"] button p {\n        font-size: 10px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã« */\n    section[data-testid=\"stSidebar\"] button {\n        padding: 0rem 0.2rem !important;\n        min-height: 1.4rem !important;\n        font-size: 10px !important;\n        margin-bottom: 0px !important;\n    }\n    /* ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®ãƒ©ãƒ™ãƒ«ã‚’å°ã•ã */\n    section[data-testid=\"stSidebar\"] .stRadio label {\n        font-size: 10px !important;\n    }\n    section[data-testid=\"stSidebar\"] .stRadio > label > div {\n        font-size: 10px !important;\n    }\n    /* ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ‡ã‚Šè©°ã‚ã‚‹ï¼ˆæ”¹è¡Œã•ã›ãªã„ï¼‰ */\n    section[data-testid=\"stSidebar\"] label, \n    section[data-testid=\"stSidebar\"] p,\n    section[data-testid=\"stSidebar\"] span {\n        white-space: nowrap !important;\n        overflow: hidden !important;\n        text-overflow: ellipsis !important;\n    }\n    /* åŒºåˆ‡ã‚Šç·š */\n    hr {\n        margin-top: 0.1rem !important;\n        margin-bottom: 0.1rem !important;\n    }\n    /* ãƒ˜ãƒƒãƒ€ãƒ¼ç¸®å° */\n    h1, h2, h3 {\n        padding-top: 0rem !important;\n        padding-bottom: 0rem !important;\n        margin-top: 0rem !important;\n        margin-bottom: 0rem !important;\n    }\n    </style>\n    \"\"\", unsafe_allow_html=True)\n    \n    # ç›´è¿‘5ä»¶ã¨éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«åˆ†å‰²\n    recent_sessions = filtered_sessions[:5] if len(filtered_sessions) > 5 else filtered_sessions\n    archive_sessions = filtered_sessions[5:] if len(filtered_sessions) > 5 else []\n    \n    # ç›´è¿‘5ä»¶ï¼ˆå¸¸ã«å±•é–‹ï¼‰\n    if recent_sessions:\n        st.markdown(\"**ğŸ“Œ ç›´è¿‘ã®ãƒãƒ£ãƒƒãƒˆ**\")\n        for session in recent_sessions:\n            col1, col2 = st.columns([0.8, 0.2])\n            with col1:\n                if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                    switch_session(session[\"id\"])\n            with col2:\n                if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                    delete_session(session[\"id\"])\n    \n    # éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆæŠ˜ã‚ŠãŸãŸã¿ï¼‰\n    if archive_sessions:\n        with st.expander(f\"ğŸ“œ éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ– ({len(archive_sessions)}ä»¶)\", expanded=False):\n            for session in archive_sessions:\n                col1, col2 = st.columns([0.8, 0.2])\n                with col1:\n                    if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                        switch_session(session[\"id\"])\n                with col2:\n                    if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                        delete_session(session[\"id\"])\n\n    st.markdown(\"---\")\n\n    # ---- ç”»åƒç”Ÿæˆ ----\n    with st.expander(\"ğŸ¨ ç”»åƒç”Ÿæˆ\", expanded=False):\n        img_prompt = st.text_area(\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\", placeholder=\"æœªæ¥çš„ãªéƒ½å¸‚...\")\n        aspect_ratio = st.selectbox(\"æ¯”ç‡\", [\"16:9\", \"1:1\", \"4:3\", \"3:4\", \"9:16\"])\n\n        generate_img_btn = st.button(\"ç”Ÿæˆ\", type=\"primary\", disabled=not img_prompt)\n        if generate_img_btn and img_prompt:\n            st.session_state.generate_image_trigger = {\n                \"prompt\": img_prompt,\n                \"aspect_ratio\": aspect_ratio,\n            }\n\n    st.markdown(\"---\")\n\n    # ---- è©•ä¾¡åˆ†æ ----\n    with st.expander(\"ğŸ“Š å“è³ªåˆ†æ\", expanded=False):\n        total_ratings = 0\n        positive_ratings = 0\n        model_ratings = {}\n\n        for s in st.session_state.sessions:\n            for m in s[\"messages\"]:\n                if \"rating\" in m and m[\"rating\"] is not None:\n                    total_ratings += 1\n                    if m[\"rating\"] == 1:\n                        positive_ratings += 1\n                    if \"metadata\" in m and \"model\" in m[\"metadata\"]:\n                        mod = m[\"metadata\"][\"model\"]\n                        if mod not in model_ratings:\n                            model_ratings[mod] = {\"total\": 0, \"positive\": 0}\n                        model_ratings[mod][\"total\"] += 1\n                        if m[\"rating\"] == 1:\n                            model_ratings[mod][\"positive\"] += 1\n\n        if total_ratings > 0:\n            approval_rate = (positive_ratings / total_ratings) * 100\n            st.metric(\"Positive Ratings\", f\"{positive_ratings}/{total_ratings}\", f\"{approval_rate:.1f}%\")\n            best_model = \"N/A\"\n            best_rate = -1\n            for mod, stats in model_ratings.items():\n                rate = stats[\"positive\"] / stats[\"total\"]\n                if rate > best_rate:\n                    best_rate = rate\n                    best_model = mod\n            if best_model != \"N/A\":\n                st.caption(f\"ğŸ† Best: **{best_model}** ({best_rate*100:.0f}%)\")\n        else:\n            st.caption(\"ãƒ‡ãƒ¼ã‚¿ãªã—\")\n\n    st.markdown(\"---\")\n\n    # ---- ã‚³ã‚¹ãƒˆè¡¨ç¤º ----\n    st.metric(\"Cost\", f\"${usage_stats['total_cost_usd']:.4f}\")\n    if st.session_state.session_cost > 0:\n        st.caption(f\"Session: ${st.session_state.session_cost:.4f}\")\n\n    if usage_stats[\"total_cost_usd\"] >= MAX_BUDGET_USD:\n        st.error(f\"âš ï¸ ä¸Šé™ (${MAX_BUDGET_USD}) åˆ°é”\")\n        stop_generation = True\n    else:\n        stop_generation = False\n\n    st.markdown(\"---\")\n    st.code(f\"PROJECT: {VERTEX_PROJECT}\\nLOCATION: {VERTEX_LOCATION} (Vertex AI)\")\n\n# =========================\n# Main UI\n# =========================\n\ncurrent_session_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\nfor s in st.session_state.sessions:\n    if s[\"id\"] == st.session_state.current_session_id:\n        current_session_title = s[\"title\"]\n        break\n\nst.header(current_session_title)\nst.markdown(\n    \"ä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\"\n)\n\n# ---- Vertex AI Client ----\n\n\n\nclient = get_client()\n\n# ---- å±¥æ­´è¡¨ç¤º ----\n\nmessages = get_current_messages()\nfor idx, msg in enumerate(messages):\n    with st.chat_message(msg[\"role\"]):\n        st.markdown(msg[\"content\"])\n        if msg[\"role\"] == \"model\":\n            col1, col2, col3 = st.columns([0.1, 0.1, 0.8])\n            current_rating = msg.get(\"rating\")\n            with col1:\n                if st.button(\"ğŸ‘\", key=f\"up_{idx}\"):\n                    messages[idx][\"rating\"] = 1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col2:\n                if st.button(\"ğŸ‘\", key=f\"down_{idx}\"):\n                    messages[idx][\"rating\"] = -1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col3:\n                if current_rating == 1:\n                    st.caption(\"âœ… é«˜è©•ä¾¡\")\n                elif current_rating == -1:\n                    st.caption(\"âŒ ä½è©•ä¾¡\")\n\n# =========================\n# ç”»åƒç”Ÿæˆãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°\n# =========================\n\nif hasattr(st.session_state, \"generate_image_trigger\") and st.session_state.generate_image_trigger:\n    img_data = st.session_state.generate_image_trigger\n    del st.session_state.generate_image_trigger\n\n    with st.chat_message(\"user\"):\n        st.markdown(f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\")\n        st.caption(f\"ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”: {img_data['aspect_ratio']}\")\n\n    messages.append({\"role\": \"user\", \"content\": f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\"})\n    update_current_session_messages(messages)\n\n    with st.chat_message(\"assistant\"):\n        with st.status(\"ç”»åƒã‚’ç”Ÿæˆä¸­...\", expanded=True) as status:\n            try:\n                config = types.GenerateContentConfig(\n                    response_modalities=[\"IMAGE\"],\n                    image_config=types.ImageConfig(\n                        aspect_ratio=img_data[\"aspect_ratio\"]\n                    ),\n                )\n                status.write(\"Gemini 3 Pro Imageã§ç”Ÿæˆä¸­...\")\n                response = client.models.generate_content(\n                    model=\"gemini-3-pro-image-preview\",\n                    contents=img_data[\"prompt\"],\n                    config=config,\n                )\n\n                generated_image = None\n\n                # ç”»åƒã‚’å–ã‚Šå‡ºã™\n                if getattr(response, \"candidates\", None):\n                    for candidate in response.candidates:\n                        if getattr(candidate, \"content\", None) and candidate.content.parts:\n                            for part in candidate.content.parts:\n                                if getattr(part, \"inline_data\", None):\n                                    try:\n                                        generated_image = part.as_image()\n                                    except AttributeError:\n                                        image_bytes_raw = part.inline_data.data\n                                        generated_image = Image.open(io.BytesIO(image_bytes_raw))\n                                    break\n                        if generated_image is not None:\n                            break\n\n                if generated_image is not None:\n                    st.image(generated_image, caption=img_data[\"prompt\"])\n                    buf = io.BytesIO()\n                    generated_image.save(buf, format=\"PNG\")\n                    image_bytes = buf.getvalue()\n                    st.download_button(\n                        label=\"ğŸ’¾ ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\",\n                        data=image_bytes,\n                        file_name=f\"generated_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png\",\n                        mime=\"image/png\",\n                    )\n                    messages.append(\n                        {\"role\": \"model\", \"content\": f\"âœ… ç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {img_data['prompt']}\"}\n                    )\n                    update_current_session_messages(messages)\n                    status.update(label=\"âœ… ç”»åƒç”Ÿæˆå®Œäº†\", state=\"complete\")\n                else:\n                    st.error(\"ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")\n                    status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n\n            except Exception as e:\n                status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n                st.error(f\"ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}\")\n\n# =========================\n# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›\n# =========================\n\nprompt = st.chat_input(\"ä½•ã‹èã„ã¦ãã ã•ã„...\", disabled=stop_generation)\n\nif prompt:\n    if stop_generation:\n        st.error(\"äºˆç®—ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚\")\n    else:\n        # ---- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€è¡¨ç¤º ----\n        with st.chat_message(\"user\"):\n            st.markdown(prompt)\n            if uploaded_files:\n                for uf in uploaded_files:\n                    st.caption(f\"ğŸ“ æ·»ä»˜: {uf.name}\")\n            if youtube_url:\n                st.caption(f\"ğŸ“º YouTube: {youtube_url}\")\n            if pasted_image_bytes:\n                st.caption(\"ğŸ“‹ ç”»åƒãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚Œã¾ã—ãŸ\")\n\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        update_current_session_messages(messages)\n\n        # ---- ãƒ¢ãƒ‡ãƒ«å¿œç­” ----\n        with st.chat_message(\"assistant\"):\n            status_container = st.status(\"æ€è€ƒä¸­...\", expanded=True)\n            try:\n                # ä¼šè©±å±¥æ­´\n                model_history = []\n                for msg in messages[:-1]:\n                    model_history.append(\n                        types.Content(\n                            role=msg[\"role\"],\n                            parts=[types.Part.from_text(text=msg[\"content\"])],\n                        )\n                    )\n\n                # ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³\n                current_parts = [types.Part.from_text(text=prompt)]\n\n                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«\n                for uploaded_file in uploaded_files or []:\n                    try:\n                        mime_type = get_mime_type(uploaded_file.name)\n                        bytes_data = uploaded_file.getvalue()\n                        part = types.Part.from_bytes(data=bytes_data, mime_type=mime_type)\n                        current_parts.append(part)\n                        status_container.write(f\"ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™å®Œäº†: {uploaded_file.name}\")\n                    except Exception as e:\n                        status_container.error(\n                            f\"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {uploaded_file.name} - {e}\"\n                        )\n\n                # è²¼ã‚Šä»˜ã‘ç”»åƒ\n                if pasted_image_bytes:\n                    import base64\n\n                    status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã‚’å‡¦ç†ä¸­...\")\n                    try:\n                        if isinstance(pasted_image_bytes, str):\n                            if pasted_image_bytes.startswith(\"data:\"):\n                                base64_str = pasted_image_bytes.split(\",\", 1)[1]\n                                image_bytes_decoded = base64.b64decode(base64_str)\n                            else:\n                                image_bytes_decoded = base64.b64decode(pasted_image_bytes)\n                        else:\n                            image_bytes_decoded = pasted_image_bytes\n                        part = types.Part.from_bytes(\n                            data=image_bytes_decoded, mime_type=\"image/png\"\n                        )\n                        current_parts.append(part)\n                        status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®æº–å‚™å®Œäº†\")\n                    except Exception as e:\n                        status_container.error(f\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n\n                # YouTube å­—å¹•\n                if youtube_url:\n                    vid_id = extract_youtube_id(youtube_url)\n                    if vid_id:\n                        status_container.write(\"YouTubeã®å­—å¹•ã‚’å–å¾—ä¸­...\")\n                        transcript_text = get_youtube_transcript(vid_id)\n                        current_parts.append(\n                            types.Part.from_text(text=f\"YouTube Transcript:\\n{transcript_text}\")\n                        )\n                    else:\n                        status_container.write(\"ç„¡åŠ¹ãªYouTube URLã§ã™ã€‚\")\n\n                contents_for_model = model_history + [\n                    types.Content(role=\"user\", parts=current_parts)\n                ]\n\n                # ---- Tool / Config ----\n                tools = []\n                final_candidate_count = candidate_count\n                if use_search:\n                    tools.append(types.Tool(google_search=types.GoogleSearch()))\n                    final_candidate_count = 1\n\n                # â˜… System Instruction ã®æ”¹å–„: ãƒ¡ã‚¿ç™ºè¨€ç¦æ­¢ã¨ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªæŒ¯ã‚‹èˆã„ã‚’æŒ‡ç¤º\n                base_system_instruction = (\n                    \"ã‚ãªãŸã¯é«˜åº¦ãªçŸ¥æ€§ã‚’æŒã¤å°‚é–€çš„ãªãƒªã‚µãƒ¼ãƒãƒ»ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\\n\"\n                    \"ä»¥ä¸‹ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’å³å®ˆã—ã¦ãã ã•ã„ï¼š\\n\"\n                    \"1. **ãƒ¡ã‚¿ç™ºè¨€ã®ç¦æ­¢**: ã€Œç§ã¯AIã§ã™ã€ã€Œä¸–ç•Œæœ€é«˜å³°ã®ï½ã¨ã—ã¦ã€ãªã©ã®è‡ªå·±è¨€åŠã‚„å‰ç½®ãã¯ä¸€åˆ‡è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚\\n\"\n                    \"2. **æ„å›³ã®æ±²ã¿å–ã‚Š**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã®èƒŒå¾Œã«ã‚ã‚‹æ„å›³ï¼ˆæ–‡è„ˆã€æš—é»™ã®å‰æï¼‰ã‚’æ¨æ¸¬ã—ã€è¨€è‘‰é€šã‚Šã§ã¯ãªãã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ¬å½“ã«çŸ¥ã‚ŠãŸã„ã“ã¨ã€ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n\"\n                    \"3. **æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”**: çµè«–ã‚’å…ˆã«è¿°ã¹ã€ãã®å¾Œã«è©³ç´°ãªæ ¹æ‹ ã€ã‚·ãƒŠãƒªã‚ªåˆ†æã€ãƒªã‚¹ã‚¯è¦å› ã‚’è«–ç†çš„ã«å±•é–‹ã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"4. **å®¢è¦³æ€§**: äºˆæ¸¬ã‚’è¡Œã†å ´åˆã¯ã€æ–­å®šã‚’é¿ã‘ã€è¤‡æ•°ã®ã‚·ãƒŠãƒªã‚ªï¼ˆæ¥½è¦³ã€æ‚²è¦³ã€ä¸­ç«‹ï¼‰ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"5. **å¼•ç”¨**: æ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸå ´åˆã¯ã€å¿…ãšæƒ…å ±æºã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚\"\n                )\n\n                final_answer = \"\"\n                grounding_metadata = None\n                \n                # =========================\n                # ãƒ¢ãƒ¼ãƒ‰è¨­å®šã®è§£æ\n                # =========================\n                enable_research = True  # å…¨ãƒ¢ãƒ¼ãƒ‰ã§ãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œ\n                enable_meta = \"ãƒ¡ã‚¿\" in response_mode or \"MAX\" in response_mode\n                enable_strict = \"é¬¼è»æ›¹\" in response_mode or \"MAX\" in response_mode\n\n                # =========================\n                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (é«˜é€Ÿ / é¬¼è»æ›¹)\n                # =========================\n                if not enable_research:\n                    config = types.GenerateContentConfig(\n                        temperature=0.7,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=base_system_instruction,\n                    )\n                    \n                    status_container.write(\"å›ç­”ç”Ÿæˆä¸­...\")\n                    response = client.models.generate_content(\n                        model=model_id,\n                        contents=contents_for_model,\n                        config=config,\n                    )\n                    \n                    final_answer = extract_text_from_response(response)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®—\n                    if response.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            response.usage_metadata.prompt_token_count,\n                            response.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += response.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += response.usage_metadata.candidates_token_count\n\n                    # é¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ (é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ç‰ˆ)\n                    if enable_strict:\n                        status_container.write(\"ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        reviewer_instruction = base_system_instruction + \"\"\"\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n                        review_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\nåˆç‰ˆå›ç­”:\\n{final_answer}\\n\\nãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\")])]\n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=types.GenerateContentConfig(temperature=0.1, candidate_count=1, system_instruction=reviewer_instruction)\n                        )\n                        final_answer = extract_text_from_response(review_resp)\n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        \n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(model_id, review_resp.usage_metadata.prompt_token_count, review_resp.usage_metadata.candidates_token_count)\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n\n                # =========================\n                # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰\n                # =========================\n                else:\n                    # =========================\n                    # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰: å¤šæ®µéšã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ \n                    # =========================\n                    \n                    # --- Phase 1: ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 1: ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    research_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒªã‚µãƒ¼ãƒå°‚ä»»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚æœ€çµ‚å›ç­”ã¯æ›¸ã‹ãšã€äº‹å®Ÿåé›†ã«é›†ä¸­ã™ã‚‹ã“ã¨ã€‚\n\n**èª¿æŸ»è¦³ç‚¹**:\n- è³ªå•ã«é–¢é€£ã™ã‚‹**æœ€æ–°ã®äº‹å®Ÿãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ»çµ±è¨ˆ**ï¼ˆ**2025å¹´ã®æƒ…å ±ã‚’æœ€å„ªå…ˆ**ï¼‰\n- **ç¾æ™‚ç‚¹ã§å­˜åœ¨ã™ã‚‹å…¨ã¦ã®é¸æŠè‚¢ãƒ»ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¶²ç¾…çš„ã«èª¿æŸ»**ï¼ˆä¾‹: è£½å“æ¯”è¼ƒãªã‚‰ã€æœ€æ–°ç‰ˆã ã‘ã§ãªãç›´è¿‘ã®å…¨ä¸–ä»£ã‚’èª¿æŸ»ï¼‰\n- å…¬å¼æƒ…å ±ã‚„ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã‹ã‚‰ã®å¼•ç”¨\n- é–¢é€£ã™ã‚‹èƒŒæ™¯æƒ…å ±ã‚„æ–‡è„ˆ\n- ç«¶åˆãƒ»ä»£æ›¿æ¡ˆãƒ»æ¯”è¼ƒå¯¾è±¡ã®**å®Œå…¨ãªãƒªã‚¹ãƒˆ**\n- ãƒªã‚¹ã‚¯ãƒ»åˆ¶ç´„ãƒ»æ³¨æ„ç‚¹ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n- å‚è€ƒã«ã—ãŸä¸»è¦ãªæƒ…å ±æºã®URL\n\n**é‡è¦**: \n- çµè«–ã‚„æ¨å¥¨ã¯æ›¸ã‹ãšã€å¾Œå·¥ç¨‹ãŒåˆ¤æ–­ã§ãã‚‹èª¿æŸ»ãƒ¡ãƒ¢ã«é›†ä¸­ã™ã‚‹ã“ã¨\n- **å¿…ãšæ¤œç´¢æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã€æœ€æ–°ã®æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã“ã¨**\n- **æ¤œç´¢çµæœã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æ—¥ä»˜ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒ»ãƒ¢ãƒ‡ãƒ«åã‚’å„ªå…ˆçš„ã«è¨˜è¼‰ã™ã‚‹ã“ã¨**\n- **æ¯”è¼ƒå¯¾è±¡ã¨ãªã‚‹é¸æŠè‚¢ã‚’è¦‹è½ã¨ã•ãªã„ã‚ˆã†ã€è¤‡æ•°ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è©¦ã™ã“ã¨**ï¼ˆä¾‹: ã€ŒiPhone æœ€æ–°ãƒ¢ãƒ‡ãƒ« 2025ã€ã€ŒiPhone 17ã€ã€ŒiPhone 2025å¹´ç™ºå£²ã€ãªã©ï¼‰\n- **ã€Œã“ã‚Œã‚ˆã‚Šæ–°ã—ã„ãƒ¢ãƒ‡ãƒ«/ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯å­˜åœ¨ã—ãªã„ã‹ï¼Ÿã€ã‚’å¸¸ã«ç¢ºèªã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ï¼ˆ2024å¹´ä»¥å‰ãªã©ï¼‰ã—ã‹è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãã®æ—¨ã‚’æ˜è¨˜ã™ã‚‹ã“ã¨\n\"\"\"\n\n                    # éå»ã®é–¢é€£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—\n                    past_context = get_relevant_context(prompt, st.session_state.sessions, st.session_state.current_session_id)\n                    \n                    # ãƒªã‚µãƒ¼ãƒç”¨ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ§‹ç¯‰\n                    research_parts = [types.Part(text=f\"ã“ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š\\n{prompt}\")]\n                    \n                    if past_context:\n                        research_parts.insert(0, types.Part(text=\"ä»¥ä¸‹ã¯éå»ã®é–¢é€£ãƒãƒ£ãƒƒãƒˆã‹ã‚‰æŠ½å‡ºã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã™ï¼š\\n\\n\" + past_context))\n                    \n                    research_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=research_parts)\n                    ]\n                    \n                    research_config = types.GenerateContentConfig(\n                        temperature=0.2,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=research_instruction,\n                    )\n                    \n                    research_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=research_contents,\n                        config=research_config,\n                    )\n                    \n                    research_text = extract_text_from_response(research_resp)\n                    \n                    # ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºã®ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ±ã‚’ä¿å­˜\n                    if research_resp.candidates and research_resp.candidates[0].grounding_metadata:\n                        grounding_metadata = research_resp.candidates[0].grounding_metadata\n                    \n                    status_container.write(\"âœ“ ãƒªã‚µãƒ¼ãƒå®Œäº†\")\n                    with status_container.expander(\"åé›†ã—ãŸèª¿æŸ»ãƒ¡ãƒ¢\", expanded=False):\n                        st.markdown(research_text)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1)\n                    if research_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            research_resp.usage_metadata.prompt_token_count,\n                            research_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += research_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += research_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 1.5: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    questions_text = \"\"\n                    if enable_meta:\n                        status_container.write(\"Phase 1.5: ãƒ¡ã‚¿è³ªå•ç”Ÿæˆä¸­...\")\n                        \n                        question_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ç›®çš„**: \nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•ã¨èª¿æŸ»ãƒ¡ãƒ¢ã‚’è¸ã¾ãˆã¦ã€ã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±ãç†è§£ã™ã‚‹ãŸã‚ã®ã€Œé‹­ã„ã‚µãƒ–è³ªå•ã€ã‚’ä½œæˆã™ã‚‹ã“ã¨ã€‚\n\n**ãƒ«ãƒ¼ãƒ«**:\n- æœ€å¤§5å€‹ã¾ã§\n- å„è³ªå•ã¯1-2è¡Œã§å…·ä½“çš„ã‹ã¤é‹­ã\n- ä»¥ä¸‹ã®è¦³ç‚¹ã‚’æ„è­˜:\n  1. å‰æãŒå´©ã‚Œã‚‹å¯èƒ½æ€§ã¯ã©ã“ã‹ï¼Ÿ\n  2. å¼·æ°—/å¼±æ°—ã‚·ãƒŠãƒªã‚ªã®åˆ†å²ç‚¹ã¯ä½•ã‹ï¼Ÿ\n  3. ç«¶åˆãƒ»æŠ€è¡“ãƒ»è¦åˆ¶ã®ä¸ç¢ºå®Ÿæ€§ã¯ï¼Ÿ\n  4. ã€Œäºˆæ¸¬ãŒå¤–ã‚Œã‚‹ã¨ã—ãŸã‚‰ã©ã‚“ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ï¼Ÿã€\n\n**å‡ºåŠ›**: ç®‡æ¡æ›¸ãï¼ˆQ1, Q2...ï¼‰ã®ã¿\n\"\"\"\n\n                        question_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•:\\n{prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\nã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±æ˜ã‚Šã™ã‚‹ãŸã‚ã®é‡è¦ãªã‚µãƒ–è³ªå•ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\")])]\n                        \n                        question_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=question_contents,\n                            config=types.GenerateContentConfig(\n                                temperature=0.4,\n                                candidate_count=1,\n                                system_instruction=question_instruction,\n                            )\n                        )\n                        \n                        questions_text = extract_text_from_response(question_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¡ã‚¿è³ªå•ç”Ÿæˆå®Œäº†\")\n                        with status_container.expander(\"ç”Ÿæˆã•ã‚ŒãŸãƒ¡ã‚¿è³ªå•\", expanded=False):\n                            st.markdown(questions_text)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1.5)\n                        if question_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                question_resp.usage_metadata.prompt_token_count,\n                                question_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += question_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += question_resp.usage_metadata.candidates_token_count\n\n                    # --- Phase 2: çµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 2: çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    if enable_meta:\n                        deep_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã¨ãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ã‚’æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**æ§‹æˆ**:\n1. **æ·±æ˜ã‚Šè€ƒå¯Ÿ**ï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n2. **çµè«–**ï¼ˆ2-3è¡Œï¼‰\n3. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n4. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨\n\"\"\"\n                    else:\n                        deep_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã‚’å”¯ä¸€ã®æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**æ§‹æˆ**:\n1. **çµè«–**ï¼ˆ2-3è¡Œã§æ˜ç¢ºã«ï¼‰\n2. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n3. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«åã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ã¨æ–°ã—ã„æƒ…å ±ãŒæ··åœ¨ã™ã‚‹å ´åˆã¯ã€æ–°ã—ã„æƒ…å ±ã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n\"\"\"\n                    \n                    synthesis_prompt_text = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if enable_meta and questions_text:\n                        synthesis_prompt_text += f\"==== ãƒ¡ã‚¿è³ªå•ä¸€è¦§ ====\\n{questions_text}\\n==== ãƒ¡ã‚¿è³ªå•ã“ã“ã¾ã§ ====\\n\\næŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n2. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»åˆ†æãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    else:\n                        synthesis_prompt_text += \"ä¸Šè¨˜ãƒ¡ãƒ¢ã‚’æ ¹æ‹ ã«ã€æœ€çµ‚å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å¿…ãšä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚**\"\n\n                    synthesis_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=[\n                            types.Part(text=synthesis_prompt_text)\n                        ])\n                    ]\n                    \n                    synthesis_config = types.GenerateContentConfig(\n                        temperature=0.3,\n                        candidate_count=1,\n                        tools=[],  # çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºã§ã¯æ¤œç´¢OFF\n                        system_instruction=deep_instruction,\n                    )\n                    \n                    synthesis_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=synthesis_contents,\n                        config=synthesis_config,\n                    )\n                    \n                    draft_answer = extract_text_from_response(synthesis_resp)\n                    \n                    status_container.write(\"âœ“ çµ±åˆå®Œäº†\")\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 2)\n                    if synthesis_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            synthesis_resp.usage_metadata.prompt_token_count,\n                            synthesis_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += synthesis_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += synthesis_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    if enable_strict:\n                        status_container.write(\"Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        \n\n                        reviewer_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™ã€‚ãŸã ã—ã€**èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’å„ªå…ˆã—ã€æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã™ã‚‹ã“ã¨**ã€‚\n\n**ãƒ¬ãƒ“ãƒ¥ãƒ¼è¦³ç‚¹**:\n- äº‹å®Ÿã¨æ¨æ¸¬ã‚’æ˜ç¢ºã«åˆ†ã‘ã‚‹\n- éåº¦ã«è‡ªä¿¡ã®ã‚ã‚‹æ–­å®šã‚’å¼±ã‚ã‚‹\n- æ•°å­—ã‚„å›ºæœ‰åè©ãŒèª¿æŸ»ãƒ¡ãƒ¢ã¨çŸ›ç›¾ã—ã¦ã„ãªã„ã‹ç¢ºèª\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ãƒ¢ãƒ‡ãƒ«ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ãŒæ­£ã—ãä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª**\n- **å¤ã„æƒ…å ±ã§ä¸Šæ›¸ãã—ã¦ã„ãªã„ã‹ç¢ºèª**\n- è¦‹è½ã¨ã—ã¦ã„ã‚‹é‡è¦ãªãƒªã‚¹ã‚¯ãƒ»ã‚·ãƒŠãƒªã‚ªãŒã‚ã‚Œã°è¿½åŠ \n\n**é‡è¦**: \n- èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ãŒæœ€æ–°ã§ã‚ã‚‹å ´åˆã€ãã‚Œã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n- ã‚ãªãŸã®çŸ¥è­˜ãŒå¤ã„å ´åˆã¯ã€èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’ä¿¡é ¼ã™ã‚‹ã“ã¨\n\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n\n                        review_contents = [\n                            types.Content(role=\"user\", parts=[\n                                types.Part.from_text(\n                                    text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\n\"\n                                    f\"==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                                    f\"åˆç‰ˆå›ç­”:\\n{draft_answer}\\n\\n\"\n                                    \"ä¸Šè¨˜ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚**\"\n                                )\n                            ])\n                        ]\n                        \n                        review_config = types.GenerateContentConfig(\n                            temperature=0.1,\n                            candidate_count=1,\n                            system_instruction=reviewer_instruction,\n                        )\n                        \n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=review_config,\n                        )\n                        \n                        final_answer = extract_text_from_response(review_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        with status_container.expander(\"åˆç‰ˆã¨ã®æ¯”è¼ƒ\", expanded=False):\n                            st.markdown(\"**åˆç‰ˆ:**\")\n                            st.markdown(draft_answer[:500] + \"...\" if len(draft_answer) > 500 else draft_answer)\n                            st.markdown(\"**ä¿®æ­£ç‰ˆ:**\")\n                            st.markdown(final_answer[:500] + \"...\" if len(final_answer) > 500 else final_answer)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 3)\n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                review_resp.usage_metadata.prompt_token_count,\n                                review_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n                    else:\n                        final_answer = draft_answer\n\n                save_usage(usage_stats)\n                status_container.update(label=\"å®Œäº†ï¼\", state=\"complete\", expanded=False)\n\n                # ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤º\n                st.caption(f\"ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_id}\")\n                st.markdown(final_answer)\n\n                # ---- ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ± ----\n                if grounding_metadata:\n                    st.markdown(\"---\")\n                    st.subheader(\"ğŸ“š æƒ…å ±æºã¨å¼•ç”¨\")\n                    if grounding_metadata.grounding_chunks:\n                        st.markdown(\"**æ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:**\")\n                        unique_sources = {}\n                        import urllib.parse\n\n                        for chunk in grounding_metadata.grounding_chunks:\n                            if getattr(chunk, \"web\", None):\n                                uri = getattr(chunk.web, \"uri\", None)\n                                title = getattr(chunk.web, \"title\", \"æƒ…å ±æº\")\n                                if uri and uri not in unique_sources:\n                                    parsed = urllib.parse.urlparse(uri)\n                                    domain = parsed.netloc.replace(\"www.\", \"\")\n                                    unique_sources[uri] = {\n                                        \"title\": title,\n                                        \"domain\": domain,\n                                    }\n                        for i, (uri, info) in enumerate(unique_sources.items(), 1):\n                            st.markdown(f\"{i}. **[{info['title']}]({uri})**\")\n                            st.caption(f\"   å‡ºå…¸: {info['domain']}\")\n\n                messages.append({\"role\": \"model\", \"content\": final_answer})\n                update_current_session_messages(messages)\n\n            except Exception as e:\n                status_container.update(label=\"Error\", state=\"error\")\n                err_text = str(e)\n                if \"RESOURCE_EXHAUSTED\" in err_text or \"429\" in err_text:\n                    st.error(\n                        \"âš ï¸ Vertex AI / Gemini ã®ã‚¯ã‚©ãƒ¼ã‚¿ã«é”ã—ã¾ã—ãŸã€‚\\n\\n\"\n                        \"ãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ / æ—¥æ¬¡åˆ¶é™ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\\n\"\n                        \"ãƒ»ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                        \"ãƒ»Google Cloud Console ã®ã€ŒVertex AI â†’ ä½¿ç”¨çŠ¶æ³ã€ã‹ã‚‰ã‚¯ã‚©ãƒ¼ã‚¿çŠ¶æ³ã‚’ç¢ºèªã§ãã¾ã™ã€‚\"\n                    )\n                elif \"NOT_FOUND\" in err_text and \"Publisher Model\" in err_text:\n                    st.error(\n                        \"âš ï¸ æŒ‡å®šã—ãŸãƒ¢ãƒ‡ãƒ«ãŒã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ / ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\\n\"\n                        \"ãƒ»ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ¢ãƒ‡ãƒ«IDã‚’ã€2.5ç³» ã¾ãŸã¯ 3 Pro ã«å¤‰æ›´ã—ã¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                    )\n                else:\n                    st.error(f\"An error occurred: {e}\")\n"
                },
                {
                    "role": "model",
                    "content": "### çµè«–\n**ã¯ã„ã€å›ç­”ã®ã€Œå“è³ªï¼ˆè«–ç†æ€§ãƒ»æ­£ç¢ºæ€§ãƒ»ç¶²ç¾…æ€§ï¼‰ã€ã¨ã„ã†è¦³ç‚¹ã«ãŠã„ã¦ã€ç¾çŠ¶ã®ã‚³ãƒ¼ãƒ‰ã§æœ€ã‚‚å„ªç§€ãªãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ¢ãƒ¼ãƒ‰ï¼‰ã¯ã€ŒÎ²2. ç†Ÿè€ƒ (æœ¬æ°—MAX)ã€ã§ã™ã€‚**\n\nã“ã®ãƒ¢ãƒ¼ãƒ‰ã¯ã€ã‚³ãƒ¼ãƒ‰å†…ã«å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹**å…¨ã¦ã®å“è³ªå‘ä¸Šãƒ—ãƒ­ã‚»ã‚¹ï¼ˆãƒªã‚µãƒ¼ãƒã€ãƒ¡ã‚¿æ€è€ƒã€çµ±åˆã€é¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰ã‚’å”¯ä¸€ãƒ•ãƒ«ç¨¼åƒã•ã›ã‚‹è¨­å®š**ã«ãªã£ã¦ãŠã‚Šã€ç†è«–ä¸Šã€æœ€ã‚‚æ·±ãã€ãƒŸã‚¹ã®å°‘ãªã„å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚\n\nãŸã ã—ã€APIå‘¼ã³å‡ºã—å›æ•°ãŒæœ€å¤šï¼ˆæœ€ä½4å›ï¼‰ã¨ãªã‚‹ãŸã‚ã€**ã‚³ã‚¹ãƒˆã¨ç”Ÿæˆæ™‚é–“ã¯æœ€å¤§**ã«ãªã‚Šã¾ã™ã€‚ã¾ãŸã€ã‚³ãƒ¼ãƒ‰è§£æã®çµæœã€**ã€Œé€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã€ã«é–¢ã™ã‚‹é‡è¦ãªå®Ÿè£…ä¸Šã®ä¸å…·åˆ**ã‚‚è¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚\n\n---\n\n### è©³ç´°åˆ†æï¼šã‚³ãƒ¼ãƒ‰è§£æã«åŸºã¥ããƒ¢ãƒ¼ãƒ‰æ¯”è¼ƒ\n\næä¾›ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ï¼ˆ`logic.py`ãŠã‚ˆã³ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼‰ã‚’è§£æã—ãŸçµæœã€å„ãƒ¢ãƒ¼ãƒ‰ã®ã€Œè³¢ã•ã€ã¯ä»¥ä¸‹ã®é †åºã«ãªã‚Šã¾ã™ã€‚\n\n#### 1. ãƒ¢ãƒ¼ãƒ‰åˆ¥ã€ŒçŸ¥èƒ½ã€ãƒ¬ãƒ™ãƒ«ã®æ¯”è¼ƒ\n\n| é †ä½ | ãƒ¢ãƒ¼ãƒ‰å | å®Ÿè¡Œãƒ—ãƒ­ã‚»ã‚¹ (APIå‘¼å‡ºå›æ•°) | ç‰¹å¾´ãƒ»å„ªç§€ãªç†ç”± |\n| :--- | :--- | :--- | :--- |\n| **1ä½** | **Î²2. ç†Ÿè€ƒ (æœ¬æ°—MAX)** | **4å›ä»¥ä¸Š**<br>(ãƒªã‚µãƒ¼ãƒ â†’ ãƒ¡ã‚¿è³ªå• â†’ çµ±åˆ â†’ ãƒ¬ãƒ“ãƒ¥ãƒ¼) | **å…¨æ©Ÿèƒ½å…¨éƒ¨å…¥ã‚Šã€‚** è‡ªåˆ†ã§å•ã„ã‚’ç«‹ã¦ï¼ˆãƒ¡ã‚¿æ€è€ƒï¼‰ã€ç­”ãˆã‚’ä½œæˆã—ã€ã•ã‚‰ã«åˆ¥ã®è¦–ç‚¹ï¼ˆé¬¼è»æ›¹ï¼‰ã§æ‰¹åˆ¤çš„ãƒã‚§ãƒƒã‚¯ã‚’è¡Œã†ãŸã‚ã€å˜ä¸€ã®LLMã§ã¯åˆ°é”ã§ããªã„æ·±ã•ã‚’å®Ÿç¾ã—ã¾ã™ã€‚ |\n| **2ä½** | **3. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)** | **3å›**<br>(ãƒªã‚µãƒ¼ãƒ â†’ ãƒ¡ã‚¿è³ªå• â†’ çµ±åˆ) | **è¦–é‡ãŒåºƒã„ã€‚** ã€Œå‰æã‚’ç–‘ã†è³ªå•ã€ã‚’ç”Ÿæˆã—ã¦ã‹ã‚‰ç­”ãˆã‚‹ãŸã‚ã€ç¶²ç¾…æ€§ãŒé«˜ã„ã§ã™ãŒã€æœ€å¾Œã®æ‰¹åˆ¤çš„ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ |\n| **3ä½** | **2. ç†Ÿè€ƒ + é¬¼è»æ›¹** | **3å›**<br>(ãƒªã‚µãƒ¼ãƒ â†’ çµ±åˆ â†’ ãƒ¬ãƒ“ãƒ¥ãƒ¼) | **å …å®Ÿã€‚** ãƒ¡ã‚¿æ€è€ƒã«ã‚ˆã‚‹ã€Œæ°—ã¥ãã€ã®ãƒ—ãƒ­ã‚»ã‚¹ã¯çœç•¥ã•ã‚Œã¾ã™ãŒã€ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«ã‚ˆã‚‹äº‹å®Ÿç¢ºèªãŒå…¥ã‚‹ãŸã‚ã€ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå˜˜ï¼‰ã®ãƒªã‚¹ã‚¯ãŒä½æ¸›ã•ã‚Œã¾ã™ã€‚ |\n| **4ä½** | **1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)** | **2å›**<br>(ãƒªã‚µãƒ¼ãƒ â†’ çµ±åˆ) | **æ¨™æº–çš„ã€‚** æ¤œç´¢ã—ã¦ç­”ãˆã‚‹åŸºæœ¬çš„ãªRAGï¼ˆæ¤œç´¢æ‹¡å¼µç”Ÿæˆï¼‰æ§‹æˆã§ã™ã€‚ |\n| **æ³¨æ„** | **Î²1. é€šå¸¸ (é«˜é€Ÿ)** | **2å›** (å®Ÿè³ª)<br>(ãƒªã‚µãƒ¼ãƒ â†’ çµ±åˆ) | **â€»å®Ÿè£…ãƒŸã‚¹ã«ã‚ˆã‚Šé«˜é€Ÿã§ã¯ãªã„ã€‚** ã‚³ãƒ¼ãƒ‰ä¸Šã§ãƒªã‚µãƒ¼ãƒæ©Ÿèƒ½ãŒå¼·åˆ¶çš„ã«ã‚ªãƒ³ã«ãªã£ã¦ã„ã‚‹ãŸã‚ã€å®Ÿéš›ã«ã¯4ä½ã¨åŒã˜æŒ™å‹•ã‚’ã—ã¾ã™ï¼ˆå¾Œè¿°ï¼‰ã€‚ |\n\n#### 2. ãªãœã€Œæœ¬æ°—MAXã€ãŒæœ€ã‚‚å„ªç§€ãªã®ã‹ï¼ˆæŠ€è¡“çš„æ ¹æ‹ ï¼‰\nã‚³ãƒ¼ãƒ‰ã®ãƒ­ã‚¸ãƒƒã‚¯ä¸Šã€ã€Œæœ¬æ°—MAXã€ã¯ä»¥ä¸‹ã®2ã¤ã®é«˜åº¦ãªæ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½µç”¨ã—ã¦ã„ã¾ã™ã€‚\n\n*   **Meta-Prompting (Phase 1.5)**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’ãã®ã¾ã¾ç­”ãˆã‚‹ã®ã§ã¯ãªãã€ã€Œã“ã®ãƒ†ãƒ¼ãƒã‚’æ·±æ˜ã‚Šã™ã‚‹ãŸã‚ã®ã‚µãƒ–è³ªå•ã¯ä½•ã‹ï¼Ÿã€ã‚’AIè‡ªèº«ã«è€ƒãˆã•ã›ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ°—ã¥ã„ã¦ã„ãªã„è¦–ç‚¹ã‚’å›ç­”ã«ç››ã‚Šè¾¼ã‚€ã“ã¨ãŒã§ãã¾ã™ã€‚\n*   **Self-Correction / Reflection (Phase 3)**: ç”Ÿæˆã•ã‚ŒãŸå›ç­”ã«å¯¾ã—ã¦ã€åˆ¥ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆäººæ ¼ï¼ˆé¬¼è»æ›¹ï¼‰ãŒã€Œäº‹å®Ÿã¨æ¨æ¸¬ã‚’åˆ†ã‘ã‚ã€ã€Œéä¿¡ã‚’æ’é™¤ã›ã‚ˆã€ã¨ã„ã£ãŸå³æ ¼ãªåŸºæº–ã§ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡Œã„ã€ä¿®æ­£ç‰ˆã‚’ä½œæˆã—ã¾ã™ã€‚ã“ã‚Œã¯è¿‘å¹´ã®AIç ”ç©¶ã§ç²¾åº¦å‘ä¸Šã«æœ€ã‚‚åŠ¹æœçš„ã¨ã•ã‚Œã‚‹æ‰‹æ³•ã®ä¸€ã¤ã§ã™ã€‚\n\n---\n\n### é‡è¦ãªãƒªã‚¹ã‚¯ã¨æ³¨æ„ç‚¹ï¼ˆã‚³ãƒ¼ãƒ‰ã®ä»•æ§˜ï¼‰\n\nç¾çŠ¶ã®ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹ä¸Šã§ã€ä»¥ä¸‹ã®2ç‚¹ã«æ³¨æ„ãŒå¿…è¦ã§ã™ã€‚\n\n#### 1. ã€Œé€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã€ãŒé«˜é€Ÿã§ã¯ãªã„ï¼ˆãƒã‚°ã®æŒ‡æ‘˜ï¼‰\nã‚³ãƒ¼ãƒ‰å†…ã§ `enable_research = True` ã¨ã„ã†è¡ŒãŒæ¡ä»¶åˆ†å²ã®å¤–ã§å›ºå®šã•ã‚Œã¦ã„ã¾ã™ã€‚\n```python\n# =========================\n# ãƒ¢ãƒ¼ãƒ‰è¨­å®šã®è§£æ\n# =========================\nenable_research = True  # å…¨ãƒ¢ãƒ¼ãƒ‰ã§ãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œ\n```\nã“ã®ãŸã‚ã€ã€Œé€šå¸¸ (é«˜é€Ÿ)ã€ãƒ¢ãƒ¼ãƒ‰ã‚’é¸ã‚“ã§ã‚‚**å¼·åˆ¶çš„ã«ãƒªã‚µãƒ¼ãƒï¼ˆæ¤œç´¢ï¼‰ãŒå®Ÿè¡Œ**ã•ã‚Œã€æœ€ä½2å›ã®APIå‘¼ã³å‡ºã—ãŒç™ºç”Ÿã—ã¾ã™ã€‚ç´”ç²‹ãªã‚·ãƒ³ã‚°ãƒ«ã‚¿ãƒ¼ãƒ³ï¼ˆ1å›ã®ã‚„ã‚Šå–ã‚Šï¼‰ã§é«˜é€Ÿã«å‹•ä½œã•ã›ãŸã„å ´åˆã¯ã€ã“ã®éƒ¨åˆ†ã®ä¿®æ­£ãŒå¿…è¦ã§ã™ã€‚\n\n#### 2. ãƒ¢ãƒ‡ãƒ«é¸æŠã¨ã®ç›¸ä¹—åŠ¹æœ\nãƒ¢ãƒ¼ãƒ‰ã®å„ªç§€ã•ã¯ã€ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«ä¾å­˜ã—ã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰å†…ã® `model_options` ã«ã‚ã‚‹é¸æŠè‚¢ã®ä¸­ã§ã€ã€Œæœ¬æ°—MAXã€ã®è¤‡é›‘ãªæŒ‡ç¤ºã‚’æ­£ã—ãé‚è¡Œã•ã›ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚\n\n*   **æ¨å¥¨**: `gemini-3-pro-preview` ã¾ãŸã¯ `gemini-2.5-pro`\n    *   æ¨è«–èƒ½åŠ›ãŒé«˜ãã€è¤‡é›‘ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‡¦ç†ã«é©ã—ã¦ã„ã¾ã™ã€‚\n*   **éæ¨å¥¨**: `gemini-2.5-flash` ã‚„ `gemini-2.5-flash-lite`\n    *   ã€Œæœ¬æ°—MAXã€ã§ä½¿ç”¨ã™ã‚‹ã¨ã€æŒ‡ç¤ºãŒè¤‡é›‘ã™ãã¦å„ãƒ•ã‚§ãƒ¼ã‚ºã®è³ªãŒä½ä¸‹ã—ãŸã‚Šã€æ–‡è„ˆã‚’å¿˜ã‚ŒãŸã‚Šã™ã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚Flashç³»ãƒ¢ãƒ‡ãƒ«ã¯ã€Œé€šå¸¸ãƒ¢ãƒ¼ãƒ‰ï¼ˆä¿®æ­£å¾Œï¼‰ã€ã§ã®åˆ©ç”¨ãŒé©ã—ã¦ã„ã¾ã™ã€‚"
                },
                {
                    "role": "user",
                    "content": "ãƒ»ã“ã®ã‚³ãƒ¼ãƒ‰ã‚’ã€ã‚¹ãƒãƒ›ã§ã‚‚ä½¿ãˆã‚‹ã‚ˆã†ã«ã—ãŸã„ã€‚\nãƒ»ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ­ãƒƒã‚¯(ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã¯198501)ã§ã€(ã—ã‹ã—ã€ãŸãã•ã‚“ä½¿ã‚ã‚Œã¦ã‚‚è‡ªå‹•ã§ç„¡æ–™ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆãŒãŠã‚ã‚Œã°æ­¢ã¾ã‚‹ä»•çµ„ã¿ã ãŒ)\n"
                },
                {
                    "role": "model",
                    "content": "ã”è¦æœ›ã®ã€Œã‚¹ãƒãƒ›å¯¾å¿œã€ã¨ã€Œãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ­ãƒƒã‚¯ï¼ˆ198501ï¼‰ã€ã¯ã€ã‚³ãƒ¼ãƒ‰ã®è¿½åŠ ã¨ã‚¯ãƒ©ã‚¦ãƒ‰ã¸ã®å…¬é–‹ï¼ˆãƒ‡ãƒ—ãƒ­ã‚¤ï¼‰ã§å®Ÿç¾å¯èƒ½ã§ã™ã€‚\n\nã—ã‹ã—ã€**éå¸¸ã«é‡è¦ãªè­¦å‘Š**ãŒã‚ã‚Šã¾ã™ã€‚\nç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰ã«ã‚ã‚‹ã€Œè‡ªå‹•ã§ç„¡æ–™ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆãŒçµ‚ã‚ã‚Œã°æ­¢ã¾ã‚‹ä»•çµ„ã¿ã€ã¯ã€ã‚¹ãƒãƒ›ç”¨ã«ãƒãƒƒãƒˆå…¬é–‹ï¼ˆã‚¯ãƒ©ã‚¦ãƒ‰åŒ–ï¼‰ã—ãŸç¬é–“ã«**æ©Ÿèƒ½ã—ãªããªã‚Šã¾ã™**ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€**äºˆæœŸã›ã¬é«˜é¡è«‹æ±‚ãŒç™ºç”Ÿã™ã‚‹ãƒªã‚¹ã‚¯**ãŒã‚ã‚Šã¾ã™ã€‚\n\nä»¥ä¸‹ã«ã€ãã®ç†ç”±ã¨å¯¾ç­–ã€ãŠã‚ˆã³å®Ÿè£…ã‚³ãƒ¼ãƒ‰ã‚’æç¤ºã—ã¾ã™ã€‚\n\n### 1. çµè«–ã¨é‡è¦ãƒªã‚¹ã‚¯\n\n*   **ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ­ãƒƒã‚¯**: ã‚ãšã‹æ•°è¡Œã®ã‚³ãƒ¼ãƒ‰è¿½åŠ ã§å®Ÿè£…å¯èƒ½ã§ã™ã€‚\n*   **ã‚¹ãƒãƒ›å¯¾å¿œ**: Google Cloud Runãªã©ã®ã‚µãƒ¼ãƒãƒ¼ã«ã‚¢ãƒ—ãƒªã‚’å…¬é–‹ã™ã‚‹ã“ã¨ã§ã€ã‚¹ãƒãƒ›ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã«ãªã‚Šã¾ã™ã€‚\n*   **ã€å±é™ºã€‘ã‚³ã‚¹ãƒˆç®¡ç†ã®å´©å£Š**:\n    *   **ç†ç”±**: ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰ã¯ã€ä½¿ç”¨æ–™ã‚’ã€Œãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆusage_stats.jsonï¼‰ã€ã«è¨˜éŒ²ã—ã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€ã‚¯ãƒ©ã‚¦ãƒ‰ä¸Šã®ã‚µãƒ¼ãƒãƒ¼ã¯ã€ã‚¹ãƒãƒ›ã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒé€”åˆ‡ã‚Œã‚‹ã¨è‡ªå‹•ã§ãƒªã‚»ãƒƒãƒˆã•ã‚Œã‚‹ä»•æ§˜ï¼ˆã‚¨ãƒ•ã‚§ãƒ¡ãƒ©ãƒ«ï¼‰ã§ã™ã€‚\n    *   **çµæœ**: ã‚µãƒ¼ãƒãƒ¼ãŒãƒªã‚»ãƒƒãƒˆã•ã‚Œã‚‹ãŸã³ã«**è¨˜éŒ²ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ¶ˆãˆã€ä½¿ç”¨æ–™ã‚«ã‚¦ãƒ³ãƒˆãŒ $0 ã«æˆ»ã‚Šã¾ã™**ã€‚ãã®ãŸã‚ã€ã‚¢ãƒ—ãƒªå†…ã®åˆ¶é™æ©Ÿèƒ½ãŒåƒã‹ãšã€é’å¤©äº•ã§èª²é‡‘ã•ã‚Œã‚‹æã‚ŒãŒã‚ã‚Šã¾ã™ã€‚\n    *   **å¿…é ˆå¯¾ç­–**: ã‚¢ãƒ—ãƒªå†…ã®æ©Ÿèƒ½ã«é ¼ã‚‰ãšã€**Google Cloud Consoleå´ã§ã€Œäºˆç®—ã‚¢ãƒ©ãƒ¼ãƒˆã€ã¨ã€ŒAPIã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ã€ã‚’å¿…ãšè¨­å®šã—ã¦ãã ã•ã„**ã€‚\n\n---\n\n### 2. ã‚³ãƒ¼ãƒ‰ä¿®æ­£ï¼šãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ­ãƒƒã‚¯ã®å®Ÿè£…\n\n`app.py` ãªã©ã®ãƒ¡ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã®å†’é ­ï¼ˆ`import`æ–‡ã®ç›´å¾Œã€`st.set_page_config`ã®å¾Œï¼‰ã«ã€ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’æŒ¿å…¥ã—ã¦ãã ã•ã„ã€‚ã“ã‚Œã§ã€Œ198501ã€ã‚’å…¥åŠ›ã—ãªã„ã¨ã‚¢ãƒ—ãƒªãŒä½¿ãˆãªããªã‚Šã¾ã™ã€‚\n\n```python\nimport streamlit as st\n# ãã®ä»–ã®import...\n\n# ãƒšãƒ¼ã‚¸è¨­å®šï¼ˆã‚¹ãƒãƒ›ã§è¦‹ã‚„ã™ãã™ã‚‹ãŸã‚ layout=\"wide\" ã¯ãŠå¥½ã¿ã§èª¿æ•´ã€ã‚¹ãƒãƒ›ãƒ¡ã‚¤ãƒ³ãªã‚‰å¤–ã™ã®ã‚‚æ‰‹ã§ã™ï¼‰\nst.set_page_config(page_title=\"AI Chat App\", layout=\"wide\")\n\n# ==========================================\n# ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ­ãƒƒã‚¯æ©Ÿèƒ½\n# ==========================================\ndef check_password():\n    \"\"\"ç°¡æ˜“ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼æ©Ÿèƒ½\"\"\"\n    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–\n    if \"authenticated\" not in st.session_state:\n        st.session_state.authenticated = False\n\n    # èªè¨¼ã•ã‚Œã¦ã„ãªã„å ´åˆã®å‡¦ç†\n    if not st.session_state.authenticated:\n        st.markdown(\"### ğŸ”’ ã‚¢ã‚¯ã‚»ã‚¹åˆ¶é™\")\n        st.markdown(\"åˆ©ç”¨ã™ã‚‹ã«ã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚\")\n        \n        password = st.text_input(\"ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰\", type=\"password\")\n        \n        if st.button(\"ãƒ­ã‚°ã‚¤ãƒ³\"):\n            if password == \"198501\":\n                st.session_state.authenticated = True\n                st.rerun()  # ç”»é¢ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ã‚¢ãƒ—ãƒªã‚’è¡¨ç¤º\n            else:\n                st.error(\"ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™ã€‚\")\n        \n        # èªè¨¼å®Œäº†ã™ã‚‹ã¾ã§ã“ã“ã§å‡¦ç†ã‚’å¼·åˆ¶åœæ­¢\n        st.stop()\n\n# ã‚¢ãƒ—ãƒªã®ãƒ¡ã‚¤ãƒ³å‡¦ç†ã®å‰ã«å¿…ãšå®Ÿè¡Œ\ncheck_password()\n\n# ==========================================\n# ã“ã“ã‹ã‚‰ä¸‹ã«æ—¢å­˜ã®ã‚¢ãƒ—ãƒªã‚³ãƒ¼ãƒ‰ã‚’è¨˜è¿°\n# ==========================================\n# ...\n```\n\n---\n\n### 3. ã‚¹ãƒãƒ›ã§ä½¿ã†ãŸã‚ã®æ‰‹é †ï¼ˆãƒ‡ãƒ—ãƒ­ã‚¤ï¼‰\n\nã‚¹ãƒãƒ›ã®ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã«ã¯ã€PCå†…ã§ã¯ãªãã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆä¸Šã®ã‚µãƒ¼ãƒãƒ¼ã«ã‚¢ãƒ—ãƒªã‚’ç½®ãå¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚Vertex AIã‚’åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€è¦ªå’Œæ€§ã®é«˜ã„ **Google Cloud Run** ã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤ã‚’æ¨å¥¨ã—ã¾ã™ã€‚\n\n**æ‰‹é †ã®æ¦‚è¦:**\n\n1.  **Dockerfileã®ä½œæˆ**:\n    ã‚¢ãƒ—ãƒªã¨åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã« `Dockerfile` ã¨ã„ã†åå‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæ‹¡å¼µå­ãªã—ï¼‰ã‚’ä½œæˆã—ã€ä»¥ä¸‹ã‚’è¨˜è¿°ã—ã¾ã™ã€‚\n    ```dockerfile\n    FROM python:3.9-slim\n    WORKDIR /app\n    COPY . .\n    RUN pip install -r requirements.txt\n    EXPOSE 8080\n    CMD streamlit run app.py --server.port 8080 --server.address 0.0.0.0\n    ```\n    â€» `app.py` ã®éƒ¨åˆ†ã¯å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«åã«åˆã‚ã›ã¦ãã ã•ã„ã€‚\n\n2.  **ãƒ‡ãƒ—ãƒ­ã‚¤ã‚³ãƒãƒ³ãƒ‰ã®å®Ÿè¡Œ**:\n    Google Cloud SDK (gcloud CLI) ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãŸã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚\n    ```bash\n    gcloud run deploy gemini-app --source . --region us-central1 --allow-unauthenticated\n    ```\n\n3.  **URLã®å–å¾—**:\n    æˆåŠŸã™ã‚‹ã¨ `https://gemini-app-xyz.a.run.app` ã®ã‚ˆã†ãªURLãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚ã“ã‚Œã‚’ã‚¹ãƒãƒ›ã«é€ã‚Šã€ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã€Œ198501ã€ã‚’å…¥åŠ›ã—ã¦åˆ©ç”¨ã—ã¾ã™ã€‚\n\n---\n\n### 4. å¿…é ˆã®å®‰å…¨å¯¾ç­–ï¼ˆã‚³ã‚¹ãƒˆç®¡ç†ï¼‰\n\nå‰è¿°ã®é€šã‚Šã€ã‚¢ãƒ—ãƒªå†…ã®è‡ªå‹•åœæ­¢æ©Ÿèƒ½ã¯ã‚¯ãƒ©ã‚¦ãƒ‰ä¸Šã§ã¯ä¿¡é ¼ã§ãã¾ã›ã‚“ã€‚ä»¥ä¸‹ã®è¨­å®šã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚\n\n1.  **Google Cloudäºˆç®—ã‚¢ãƒ©ãƒ¼ãƒˆã®è¨­å®š**:\n    *   Google Cloud Consoleã®ã€ŒãŠæ”¯æ‰•ã„ã€ > ã€Œäºˆç®—ã¨ã‚¢ãƒ©ãƒ¼ãƒˆã€ã‹ã‚‰è¨­å®šã—ã¾ã™ã€‚\n    *   ä¾‹ï¼šã€Œæœˆé¡500å††ã‚’è¶…ãˆãŸã‚‰ãƒ¡ãƒ¼ãƒ«é€šçŸ¥ã€ã‚’è¨­å®šã€‚\n2.  **APIã‚¯ã‚©ãƒ¼ã‚¿ï¼ˆä¸Šé™ï¼‰ã®è¨­å®š**:\n    *   ã€ŒIAM ã¨ç®¡ç†ã€ > ã€Œã‚¯ã‚©ãƒ¼ã‚¿ã€ã‹ã‚‰ã€Vertex AI API (Generative AI API) ã®1æ—¥ã‚ãŸã‚Šã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã«ä¸Šé™ã‚’è¨­å®šã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç‰©ç†çš„ã«ä½¿ã„ã™ãã‚’é˜²ã’ã¾ã™ã€‚\n\n**UIã®ãƒ’ãƒ³ãƒˆ**:\nã‚¹ãƒãƒ›ã§ã¯ç”»é¢ãŒç‹­ã„ãŸã‚ã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆå·¦å´ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ï¼‰ãŒéš ã‚Œã¦ã—ã¾ã„ã¾ã™ã€‚é »ç¹ã«åˆ‡ã‚Šæ›¿ãˆã‚‹è¨­å®šé …ç›®ãŒã‚ã‚‹å ´åˆã¯ã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã¯ãªããƒ¡ã‚¤ãƒ³ç”»é¢ã®ä¸Šéƒ¨ã« `st.expander`ï¼ˆæŠ˜ã‚ŠãŸãŸã¿ãƒ¡ãƒ‹ãƒ¥ãƒ¼ï¼‰ã‚’ä½¿ã£ã¦é…ç½®ã™ã‚‹ã¨ä½¿ã„ã‚„ã™ããªã‚Šã¾ã™ã€‚"
                }
            ]
        },
        {
            "id": "9f7b90cd-0ad8-4ece-a4c2-8d752a9df8e5",
            "title": "ç¾çŠ¶ã®ã‚³ãƒ¼ãƒ‰ã§ã€å›ç­”ãƒ¢ãƒ¼ãƒ‰ãŒè¤‡æ•°ã‚ã‚‹ãŒã€...",
            "timestamp": "2025-11-30T14:06:56.644990",
            "messages": [
                {
                    "role": "user",
                    "content": "ç¾çŠ¶ã®ã‚³ãƒ¼ãƒ‰ã§ã€å›ç­”ãƒ¢ãƒ¼ãƒ‰ãŒè¤‡æ•°ã‚ã‚‹ãŒã€æœ€ã‚‚å„ªç§€ãªãƒ¢ãƒ‡ãƒ«ã¯ç†Ÿè€ƒ(æœ¬æ°—MAX)ã‹ã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã®ã»ã†ãŒå„ªç§€ã‹?\nimport os\nimport uuid\nimport datetime\nimport streamlit as st\nfrom dotenv import load_dotenv\nfrom google import genai\nfrom google.genai import types\nfrom PIL import Image\nimport io\nfrom logic import (\n    USAGE_FILE, SESSIONS_FILE, MAX_BUDGET_USD, PRICING,\n    VERTEX_PROJECT, VERTEX_LOCATION,\n    load_usage, save_usage, calculate_cost, get_mime_type,\n    extract_youtube_id, get_youtube_transcript, get_relevant_context,\n    extract_text_from_response, load_sessions, save_sessions, get_client\n)\n\ntry:\n    from st_img_pastebutton import paste\n    import_error_msg = None\nexcept ImportError as e:\n    paste = None\n    import_error_msg = str(e)\n\n# =========================\n# ç’°å¢ƒå¤‰æ•° & å®šæ•°\n# =========================\n\nload_dotenv()\n\n\n\nst.set_page_config(page_title=\"Gemini 3 Web Studio\", layout=\"wide\")\n\n# =========================\n# Helper Functions\n# =========================\n\n# =========================\n# Helper Functions\n# =========================\n# Moved to logic.py\n\n# =========================\n# Session Management\n# =========================\n\n\n\ndef create_new_session():\n    current_sessions = load_sessions()\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": [],\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.rerun()\n\ndef switch_session(session_id):\n    st.session_state.current_session_id = session_id\n    st.rerun()\n\ndef update_current_session_messages(messages):\n    if st.session_state.current_session_id:\n        current_sessions = load_sessions()\n        for session in current_sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                session[\"messages\"] = messages\n                if session[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(messages) > 0:\n                    first_msg = messages[0][\"content\"]\n                    session[\"title\"] = (first_msg[:20] + \"...\") if len(first_msg) > 20 else first_msg\n                session[\"timestamp\"] = datetime.datetime.now().isoformat()\n                break\n        save_sessions(current_sessions)\n        st.session_state.sessions = current_sessions\n\ndef get_current_messages():\n    if st.session_state.current_session_id:\n        for session in st.session_state.sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                return session[\"messages\"]\n    return []\n\ndef delete_session(session_id):\n    current_sessions = load_sessions()\n    current_sessions = [s for s in current_sessions if s[\"id\"] != session_id]\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    if st.session_state.current_session_id == session_id:\n        st.session_state.current_session_id = None\n        if st.session_state.sessions:\n            st.session_state.current_session_id = st.session_state.sessions[0][\"id\"]\n    st.rerun()\n\ndef branch_session():\n    \"\"\"ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚’åˆ†å²\"\"\"\n    current_messages = get_current_messages()\n    current_sessions = load_sessions()\n    \n    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—\n    current_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n    for session in current_sessions:\n        if session[\"id\"] == st.session_state.current_session_id:\n            current_title = session[\"title\"]\n            break\n    \n    # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": f\"{current_title} (åˆ†å²)\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": current_messages.copy(),  # ç¾åœ¨ã®å±¥æ­´ã‚’ã‚³ãƒ”ãƒ¼\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    \n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.session_state.session_cost = 0.0  # ã‚³ã‚¹ãƒˆãƒªã‚»ãƒƒãƒˆ\n    st.rerun()\n\n# =========================\n# Initialization\n# =========================\n\nif \"sessions\" not in st.session_state:\n    st.session_state.sessions = load_sessions()\n\nif \"current_session_id\" not in st.session_state:\n    # Always create a new session when the app starts\n    create_new_session()\n\nif \"session_cost\" not in st.session_state:\n    st.session_state.session_cost = 0.0\n\nusage_stats = load_usage()\n\n# =========================\n# Sidebar\n# =========================\n\nwith st.sidebar:\n    st.markdown(\"\"\"\n    <div style=\"text-align: center; padding: 0; margin: 0; margin-top: -1rem;\">\n        <h1 style=\"font-size: 18px; font-weight: 700; margin: 0; padding: 0; letter-spacing: 1px;\">\n            Gemini 3<br/>Studio\n        </h1>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n    col1, col2 = st.columns(2)\n    with col1:\n        if st.button(\"â• æ–°è¦\", use_container_width=True):\n            create_new_session()\n    with col2:\n        if st.button(\"ğŸŒ± åˆ†å²\", use_container_width=True):\n            branch_session()\n\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    current_messages = get_current_messages()\n    if current_messages:\n        with st.expander(\"ğŸ”— å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ\", expanded=False):\n            export_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n            for s in st.session_state.sessions:\n                if s[\"id\"] == st.session_state.current_session_id:\n                    export_title = s[\"title\"]\n                    break\n\n            export_md = f\"# {export_title}\\n\\n\"\n            export_md += f\"**ä½œæˆæ—¥æ™‚**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n---\\n\\n\"\n            for msg in current_messages:\n                role_label = \"ğŸ§‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼\" if msg[\"role\"] == \"user\" else \"ğŸ¤– AI\"\n                export_md += f\"## {role_label}\\n\\n{msg['content']}\\n\\n---\\n\\n\"\n\n            if st.button(\"ãƒªãƒ³ã‚¯ç”Ÿæˆ\", use_container_width=True):\n                with st.spinner(\"ç”Ÿæˆä¸­...\"):\n                    try:\n                        import urllib.request\n                        import urllib.parse\n\n                        data = urllib.parse.urlencode(\n                            {\"content\": export_md, \"expiry_days\": 7, \"syntax\": \"md\"}\n                        ).encode()\n\n                        req = urllib.request.Request(\"https://dpaste.org/api/\", data=data)\n                        req.add_header(\"User-Agent\", \"Mozilla/5.0 (Gemini3Studio)\")\n\n                        with urllib.request.urlopen(req) as response:\n                            share_url = response.read().decode(\"utf-8\").strip()\n                            st.success(\"ä½œæˆå®Œäº†ï¼\")\n                            st.code(share_url)\n                            st.caption(\"â€»7æ—¥é–“æœ‰åŠ¹\")\n                    except Exception as e:\n                        st.error(f\"ã‚¨ãƒ©ãƒ¼: {e}\")\n\n    st.markdown(\"---\")\n\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    with st.expander(\"ğŸ“ æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«\", expanded=False):\n        uploaded_files = st.file_uploader(\n            \"ãƒ•ã‚¡ã‚¤ãƒ«\",\n            accept_multiple_files=True,\n            type=[\"png\", \"jpg\", \"jpeg\", \"mp4\", \"mov\", \"txt\", \"pdf\", \"csv\"],\n            label_visibility=\"collapsed\"\n        )\n\n    # ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ï¼ˆExpanderã®å¤–ã«å‡ºã™ï¼‰\n    if paste:\n        if \"paste_key\" not in st.session_state:\n            st.session_state.paste_key = 0\n        try:\n            pasted_image_bytes = paste(\n                label=\"ğŸ“‹ è²¼ä»˜\",\n                key=f\"paste_btn_{st.session_state.paste_key}\",\n            )\n        except Exception as e:\n            st.error(f\"Error: {e}\")\n        \n        if pasted_image_bytes:\n            st.success(\"è²¼ä»˜å®Œäº†\")\n            st.image(pasted_image_bytes, caption=\"ç”»åƒ\", use_container_width=True)\n            if st.button(\"ğŸ—‘ï¸ ã‚¯ãƒªã‚¢\", key=\"clear_paste\"):\n                st.session_state.paste_key += 1\n                st.rerun()\n    else:\n        st.warning(\"Clipboard lib missing\")\n\n    # ---- YouTube URL ----\n    with st.expander(\"ğŸ“º YouTubeåˆ†æ\", expanded=False):\n        youtube_url = st.text_input(\"URL\", placeholder=\"https://youtu.be/...\", label_visibility=\"collapsed\")\n\n    st.markdown(\"---\")\n    \n    st.markdown(\"---\")\n    \n    # ---- å›ç­”ãƒ¢ãƒ¼ãƒ‰ ----\n    with st.expander(\"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰\", expanded=True):\n        mode_type = st.radio(\n            \"ã‚¿ã‚¤ãƒ—\",\n            [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n            index=0,\n            horizontal=True,\n            label_visibility=\"collapsed\"\n        )\n        \n        if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n            response_mode = st.radio(\n                \"ãƒ¢ãƒ¼ãƒ‰\",\n                [\n                    \"2. ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                    \"3. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                    \"Î²2. ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                ],\n                index=0\n            )\n        elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n            response_mode = st.radio(\n                \"ãƒ¢ãƒ¼ãƒ‰\",\n                [\n                    \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                ],\n                index=0\n            )\n        else:\n            response_mode = st.radio(\n                \"ãƒ¢ãƒ¼ãƒ‰\",\n                [\n                    \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                ],\n                index=0\n            )\n    \n    strict_mode = False\n    \n    # ---- è¨­å®š (ãƒ¢ãƒ‡ãƒ«ãªã©) ----\n    with st.expander(\"âš™ï¸ è¨­å®š\", expanded=False):\n        model_options = [\n            \"gemini-3-pro-preview\",\n            \"gemini-2.5-pro\",\n            \"gemini-2.5-flash\",\n            \"gemini-2.5-flash-lite\",\n            \"gemini-2.0-flash\",\n        ]\n        model_id = st.selectbox(\"ãƒ¢ãƒ‡ãƒ«ID\", options=model_options, index=0)\n\n        use_search = st.toggle(\"Googleæ¤œç´¢\", value=True)\n        candidate_count = st.slider(\"å€™è£œæ•°\", min_value=1, max_value=3, value=3)\n\n    st.markdown(\"---\")\n\n    # ---- å±¥æ­´æ¤œç´¢ ----\n    search_query = st.text_input(\"ğŸ” å±¥æ­´æ¤œç´¢\", placeholder=\"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰...\")\n    if search_query:\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if search_query.lower() in s[\"title\"].lower():\n                filtered_sessions.append(s)\n                continue\n            found = False\n            for m in s[\"messages\"]:\n                if search_query.lower() in m[\"content\"].lower():\n                    filtered_sessions.append(s)\n                    found = True\n                    break\n            if not found:\n                pass\n    else:\n        # æ¤œç´¢ã—ã¦ã„ãªã„å ´åˆ: ç©ºã®ã€Œæ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã€ã‚’é™¤å¤–ï¼ˆç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯é™¤ãï¼‰\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if s[\"id\"] == st.session_state.current_session_id:\n                filtered_sessions.append(s)\n                continue\n            if s[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(s[\"messages\"]) == 0:\n                continue\n            filtered_sessions.append(s)\n\n    # CSSã§è¦‹ã‚„ã™ãä½¿ã„ã‚„ã™ãæœ€é©åŒ–\n    st.markdown(\"\"\"\n    <style>\n    /* å…¨ä½“ã®ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºç¸®å° */\n    .stApp, .stMarkdown, .stButton, .stSelectbox, .stTextInput, .stTextArea {\n        font-size: 12px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ä½™ç™½ã‚’æ¥µé™ã¾ã§è©°ã‚ã‚‹ */\n    section[data-testid=\"stSidebar\"] .block-container {\n        padding-top: 0rem !important;\n        padding-bottom: 0.3rem !important;\n        padding-left: 0.5rem !important;\n        padding-right: 0.5rem !important;\n    }\n    /* å„è¦ç´ é–“ã®éš™é–“ã‚’è©°ã‚ã‚‹ */\n    div[data-testid=\"stVerticalBlock\"] > div {\n        gap: 0.1rem !important;\n    }\n    /* Expanderã®ä½™ç™½å‰Šæ¸› */\n    .streamlit-expanderHeader {\n        font-size: 11px !important;\n        padding-top: 0px !important;\n        padding-bottom: 0px !important;\n        min-height: 1.3rem !important;\n    }\n    .streamlit-expanderContent {\n        padding-top: 0px !important;\n        padding-bottom: 0px !important;\n    }\n    /* éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã®ã‚¿ã‚¤ãƒˆãƒ« */\n    div[data-testid=\"stExpander\"] summary p {\n        font-size: 10px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ */\n    section[data-testid=\"stSidebar\"] button p {\n        font-size: 10px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã« */\n    section[data-testid=\"stSidebar\"] button {\n        padding: 0rem 0.2rem !important;\n        min-height: 1.4rem !important;\n        font-size: 10px !important;\n        margin-bottom: 0px !important;\n    }\n    /* ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®ãƒ©ãƒ™ãƒ«ã‚’å°ã•ã */\n    section[data-testid=\"stSidebar\"] .stRadio label {\n        font-size: 10px !important;\n    }\n    section[data-testid=\"stSidebar\"] .stRadio > label > div {\n        font-size: 10px !important;\n    }\n    /* ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ‡ã‚Šè©°ã‚ã‚‹ï¼ˆæ”¹è¡Œã•ã›ãªã„ï¼‰ */\n    section[data-testid=\"stSidebar\"] label, \n    section[data-testid=\"stSidebar\"] p,\n    section[data-testid=\"stSidebar\"] span {\n        white-space: nowrap !important;\n        overflow: hidden !important;\n        text-overflow: ellipsis !important;\n    }\n    /* åŒºåˆ‡ã‚Šç·š */\n    hr {\n        margin-top: 0.1rem !important;\n        margin-bottom: 0.1rem !important;\n    }\n    /* ãƒ˜ãƒƒãƒ€ãƒ¼ç¸®å° */\n    h1, h2, h3 {\n        padding-top: 0rem !important;\n        padding-bottom: 0rem !important;\n        margin-top: 0rem !important;\n        margin-bottom: 0rem !important;\n    }\n    </style>\n    \"\"\", unsafe_allow_html=True)\n    \n    # ç›´è¿‘5ä»¶ã¨éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«åˆ†å‰²\n    recent_sessions = filtered_sessions[:5] if len(filtered_sessions) > 5 else filtered_sessions\n    archive_sessions = filtered_sessions[5:] if len(filtered_sessions) > 5 else []\n    \n    # ç›´è¿‘5ä»¶ï¼ˆå¸¸ã«å±•é–‹ï¼‰\n    if recent_sessions:\n        st.markdown(\"**ğŸ“Œ ç›´è¿‘ã®ãƒãƒ£ãƒƒãƒˆ**\")\n        for session in recent_sessions:\n            col1, col2 = st.columns([0.8, 0.2])\n            with col1:\n                if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                    switch_session(session[\"id\"])\n            with col2:\n                if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                    delete_session(session[\"id\"])\n    \n    # éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆæŠ˜ã‚ŠãŸãŸã¿ï¼‰\n    if archive_sessions:\n        with st.expander(f\"ğŸ“œ éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ– ({len(archive_sessions)}ä»¶)\", expanded=False):\n            for session in archive_sessions:\n                col1, col2 = st.columns([0.8, 0.2])\n                with col1:\n                    if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                        switch_session(session[\"id\"])\n                with col2:\n                    if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                        delete_session(session[\"id\"])\n\n    st.markdown(\"---\")\n\n    # ---- ç”»åƒç”Ÿæˆ ----\n    with st.expander(\"ğŸ¨ ç”»åƒç”Ÿæˆ\", expanded=False):\n        img_prompt = st.text_area(\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\", placeholder=\"æœªæ¥çš„ãªéƒ½å¸‚...\")\n        aspect_ratio = st.selectbox(\"æ¯”ç‡\", [\"16:9\", \"1:1\", \"4:3\", \"3:4\", \"9:16\"])\n\n        generate_img_btn = st.button(\"ç”Ÿæˆ\", type=\"primary\", disabled=not img_prompt)\n        if generate_img_btn and img_prompt:\n            st.session_state.generate_image_trigger = {\n                \"prompt\": img_prompt,\n                \"aspect_ratio\": aspect_ratio,\n            }\n\n    st.markdown(\"---\")\n\n    # ---- è©•ä¾¡åˆ†æ ----\n    with st.expander(\"ğŸ“Š å“è³ªåˆ†æ\", expanded=False):\n        total_ratings = 0\n        positive_ratings = 0\n        model_ratings = {}\n\n        for s in st.session_state.sessions:\n            for m in s[\"messages\"]:\n                if \"rating\" in m and m[\"rating\"] is not None:\n                    total_ratings += 1\n                    if m[\"rating\"] == 1:\n                        positive_ratings += 1\n                    if \"metadata\" in m and \"model\" in m[\"metadata\"]:\n                        mod = m[\"metadata\"][\"model\"]\n                        if mod not in model_ratings:\n                            model_ratings[mod] = {\"total\": 0, \"positive\": 0}\n                        model_ratings[mod][\"total\"] += 1\n                        if m[\"rating\"] == 1:\n                            model_ratings[mod][\"positive\"] += 1\n\n        if total_ratings > 0:\n            approval_rate = (positive_ratings / total_ratings) * 100\n            st.metric(\"Positive Ratings\", f\"{positive_ratings}/{total_ratings}\", f\"{approval_rate:.1f}%\")\n            best_model = \"N/A\"\n            best_rate = -1\n            for mod, stats in model_ratings.items():\n                rate = stats[\"positive\"] / stats[\"total\"]\n                if rate > best_rate:\n                    best_rate = rate\n                    best_model = mod\n            if best_model != \"N/A\":\n                st.caption(f\"ğŸ† Best: **{best_model}** ({best_rate*100:.0f}%)\")\n        else:\n            st.caption(\"ãƒ‡ãƒ¼ã‚¿ãªã—\")\n\n    st.markdown(\"---\")\n\n    # ---- ã‚³ã‚¹ãƒˆè¡¨ç¤º ----\n    st.metric(\"Cost\", f\"${usage_stats['total_cost_usd']:.4f}\")\n    if st.session_state.session_cost > 0:\n        st.caption(f\"Session: ${st.session_state.session_cost:.4f}\")\n\n    if usage_stats[\"total_cost_usd\"] >= MAX_BUDGET_USD:\n        st.error(f\"âš ï¸ ä¸Šé™ (${MAX_BUDGET_USD}) åˆ°é”\")\n        stop_generation = True\n    else:\n        stop_generation = False\n\n    st.markdown(\"---\")\n    st.code(f\"PROJECT: {VERTEX_PROJECT}\\nLOCATION: {VERTEX_LOCATION} (Vertex AI)\")\n\n# =========================\n# Main UI\n# =========================\n\ncurrent_session_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\nfor s in st.session_state.sessions:\n    if s[\"id\"] == st.session_state.current_session_id:\n        current_session_title = s[\"title\"]\n        break\n\nst.header(current_session_title)\nst.markdown(\n    \"ä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\"\n)\n\n# ---- Vertex AI Client ----\n\n\n\nclient = get_client()\n\n# ---- å±¥æ­´è¡¨ç¤º ----\n\nmessages = get_current_messages()\nfor idx, msg in enumerate(messages):\n    with st.chat_message(msg[\"role\"]):\n        st.markdown(msg[\"content\"])\n        if msg[\"role\"] == \"model\":\n            col1, col2, col3 = st.columns([0.1, 0.1, 0.8])\n            current_rating = msg.get(\"rating\")\n            with col1:\n                if st.button(\"ğŸ‘\", key=f\"up_{idx}\"):\n                    messages[idx][\"rating\"] = 1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col2:\n                if st.button(\"ğŸ‘\", key=f\"down_{idx}\"):\n                    messages[idx][\"rating\"] = -1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col3:\n                if current_rating == 1:\n                    st.caption(\"âœ… é«˜è©•ä¾¡\")\n                elif current_rating == -1:\n                    st.caption(\"âŒ ä½è©•ä¾¡\")\n\n# =========================\n# ç”»åƒç”Ÿæˆãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°\n# =========================\n\nif hasattr(st.session_state, \"generate_image_trigger\") and st.session_state.generate_image_trigger:\n    img_data = st.session_state.generate_image_trigger\n    del st.session_state.generate_image_trigger\n\n    with st.chat_message(\"user\"):\n        st.markdown(f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\")\n        st.caption(f\"ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”: {img_data['aspect_ratio']}\")\n\n    messages.append({\"role\": \"user\", \"content\": f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\"})\n    update_current_session_messages(messages)\n\n    with st.chat_message(\"assistant\"):\n        with st.status(\"ç”»åƒã‚’ç”Ÿæˆä¸­...\", expanded=True) as status:\n            try:\n                config = types.GenerateContentConfig(\n                    response_modalities=[\"IMAGE\"],\n                    image_config=types.ImageConfig(\n                        aspect_ratio=img_data[\"aspect_ratio\"]\n                    ),\n                )\n                status.write(\"Gemini 3 Pro Imageã§ç”Ÿæˆä¸­...\")\n                response = client.models.generate_content(\n                    model=\"gemini-3-pro-image-preview\",\n                    contents=img_data[\"prompt\"],\n                    config=config,\n                )\n\n                generated_image = None\n\n                # ç”»åƒã‚’å–ã‚Šå‡ºã™\n                if getattr(response, \"candidates\", None):\n                    for candidate in response.candidates:\n                        if getattr(candidate, \"content\", None) and candidate.content.parts:\n                            for part in candidate.content.parts:\n                                if getattr(part, \"inline_data\", None):\n                                    try:\n                                        generated_image = part.as_image()\n                                    except AttributeError:\n                                        image_bytes_raw = part.inline_data.data\n                                        generated_image = Image.open(io.BytesIO(image_bytes_raw))\n                                    break\n                        if generated_image is not None:\n                            break\n\n                if generated_image is not None:\n                    st.image(generated_image, caption=img_data[\"prompt\"])\n                    buf = io.BytesIO()\n                    generated_image.save(buf, format=\"PNG\")\n                    image_bytes = buf.getvalue()\n                    st.download_button(\n                        label=\"ğŸ’¾ ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\",\n                        data=image_bytes,\n                        file_name=f\"generated_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png\",\n                        mime=\"image/png\",\n                    )\n                    messages.append(\n                        {\"role\": \"model\", \"content\": f\"âœ… ç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {img_data['prompt']}\"}\n                    )\n                    update_current_session_messages(messages)\n                    status.update(label=\"âœ… ç”»åƒç”Ÿæˆå®Œäº†\", state=\"complete\")\n                else:\n                    st.error(\"ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")\n                    status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n\n            except Exception as e:\n                status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n                st.error(f\"ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}\")\n\n# =========================\n# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›\n# =========================\n\nprompt = st.chat_input(\"ä½•ã‹èã„ã¦ãã ã•ã„...\", disabled=stop_generation)\n\nif prompt:\n    if stop_generation:\n        st.error(\"äºˆç®—ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚\")\n    else:\n        # ---- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€è¡¨ç¤º ----\n        with st.chat_message(\"user\"):\n            st.markdown(prompt)\n            if uploaded_files:\n                for uf in uploaded_files:\n                    st.caption(f\"ğŸ“ æ·»ä»˜: {uf.name}\")\n            if youtube_url:\n                st.caption(f\"ğŸ“º YouTube: {youtube_url}\")\n            if pasted_image_bytes:\n                st.caption(\"ğŸ“‹ ç”»åƒãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚Œã¾ã—ãŸ\")\n\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        update_current_session_messages(messages)\n\n        # ---- ãƒ¢ãƒ‡ãƒ«å¿œç­” ----\n        with st.chat_message(\"assistant\"):\n            status_container = st.status(\"æ€è€ƒä¸­...\", expanded=True)\n            try:\n                # ä¼šè©±å±¥æ­´\n                model_history = []\n                for msg in messages[:-1]:\n                    model_history.append(\n                        types.Content(\n                            role=msg[\"role\"],\n                            parts=[types.Part.from_text(text=msg[\"content\"])],\n                        )\n                    )\n\n                # ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³\n                current_parts = [types.Part.from_text(text=prompt)]\n\n                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«\n                for uploaded_file in uploaded_files or []:\n                    try:\n                        mime_type = get_mime_type(uploaded_file.name)\n                        bytes_data = uploaded_file.getvalue()\n                        part = types.Part.from_bytes(data=bytes_data, mime_type=mime_type)\n                        current_parts.append(part)\n                        status_container.write(f\"ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™å®Œäº†: {uploaded_file.name}\")\n                    except Exception as e:\n                        status_container.error(\n                            f\"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {uploaded_file.name} - {e}\"\n                        )\n\n                # è²¼ã‚Šä»˜ã‘ç”»åƒ\n                if pasted_image_bytes:\n                    import base64\n\n                    status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã‚’å‡¦ç†ä¸­...\")\n                    try:\n                        if isinstance(pasted_image_bytes, str):\n                            if pasted_image_bytes.startswith(\"data:\"):\n                                base64_str = pasted_image_bytes.split(\",\", 1)[1]\n                                image_bytes_decoded = base64.b64decode(base64_str)\n                            else:\n                                image_bytes_decoded = base64.b64decode(pasted_image_bytes)\n                        else:\n                            image_bytes_decoded = pasted_image_bytes\n                        part = types.Part.from_bytes(\n                            data=image_bytes_decoded, mime_type=\"image/png\"\n                        )\n                        current_parts.append(part)\n                        status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®æº–å‚™å®Œäº†\")\n                    except Exception as e:\n                        status_container.error(f\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n\n                # YouTube å­—å¹•\n                if youtube_url:\n                    vid_id = extract_youtube_id(youtube_url)\n                    if vid_id:\n                        status_container.write(\"YouTubeã®å­—å¹•ã‚’å–å¾—ä¸­...\")\n                        transcript_text = get_youtube_transcript(vid_id)\n                        current_parts.append(\n                            types.Part.from_text(text=f\"YouTube Transcript:\\n{transcript_text}\")\n                        )\n                    else:\n                        status_container.write(\"ç„¡åŠ¹ãªYouTube URLã§ã™ã€‚\")\n\n                contents_for_model = model_history + [\n                    types.Content(role=\"user\", parts=current_parts)\n                ]\n\n                # ---- Tool / Config ----\n                tools = []\n                final_candidate_count = candidate_count\n                if use_search:\n                    tools.append(types.Tool(google_search=types.GoogleSearch()))\n                    final_candidate_count = 1\n\n                # â˜… System Instruction ã®æ”¹å–„: ãƒ¡ã‚¿ç™ºè¨€ç¦æ­¢ã¨ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªæŒ¯ã‚‹èˆã„ã‚’æŒ‡ç¤º\n                base_system_instruction = (\n                    \"ã‚ãªãŸã¯é«˜åº¦ãªçŸ¥æ€§ã‚’æŒã¤å°‚é–€çš„ãªãƒªã‚µãƒ¼ãƒãƒ»ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\\n\"\n                    \"ä»¥ä¸‹ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’å³å®ˆã—ã¦ãã ã•ã„ï¼š\\n\"\n                    \"1. **ãƒ¡ã‚¿ç™ºè¨€ã®ç¦æ­¢**: ã€Œç§ã¯AIã§ã™ã€ã€Œä¸–ç•Œæœ€é«˜å³°ã®ï½ã¨ã—ã¦ã€ãªã©ã®è‡ªå·±è¨€åŠã‚„å‰ç½®ãã¯ä¸€åˆ‡è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚\\n\"\n                    \"2. **æ„å›³ã®æ±²ã¿å–ã‚Š**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã®èƒŒå¾Œã«ã‚ã‚‹æ„å›³ï¼ˆæ–‡è„ˆã€æš—é»™ã®å‰æï¼‰ã‚’æ¨æ¸¬ã—ã€è¨€è‘‰é€šã‚Šã§ã¯ãªãã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ¬å½“ã«çŸ¥ã‚ŠãŸã„ã“ã¨ã€ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n\"\n                    \"3. **æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”**: çµè«–ã‚’å…ˆã«è¿°ã¹ã€ãã®å¾Œã«è©³ç´°ãªæ ¹æ‹ ã€ã‚·ãƒŠãƒªã‚ªåˆ†æã€ãƒªã‚¹ã‚¯è¦å› ã‚’è«–ç†çš„ã«å±•é–‹ã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"4. **å®¢è¦³æ€§**: äºˆæ¸¬ã‚’è¡Œã†å ´åˆã¯ã€æ–­å®šã‚’é¿ã‘ã€è¤‡æ•°ã®ã‚·ãƒŠãƒªã‚ªï¼ˆæ¥½è¦³ã€æ‚²è¦³ã€ä¸­ç«‹ï¼‰ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"5. **å¼•ç”¨**: æ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸå ´åˆã¯ã€å¿…ãšæƒ…å ±æºã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚\"\n                )\n\n                final_answer = \"\"\n                grounding_metadata = None\n                \n                # =========================\n                # ãƒ¢ãƒ¼ãƒ‰è¨­å®šã®è§£æ\n                # =========================\n                enable_research = True  # å…¨ãƒ¢ãƒ¼ãƒ‰ã§ãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œ\n                enable_meta = \"ãƒ¡ã‚¿\" in response_mode or \"MAX\" in response_mode\n                enable_strict = \"é¬¼è»æ›¹\" in response_mode or \"MAX\" in response_mode\n\n                # =========================\n                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (é«˜é€Ÿ / é¬¼è»æ›¹)\n                # =========================\n                if not enable_research:\n                    config = types.GenerateContentConfig(\n                        temperature=0.7,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=base_system_instruction,\n                    )\n                    \n                    status_container.write(\"å›ç­”ç”Ÿæˆä¸­...\")\n                    response = client.models.generate_content(\n                        model=model_id,\n                        contents=contents_for_model,\n                        config=config,\n                    )\n                    \n                    final_answer = extract_text_from_response(response)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®—\n                    if response.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            response.usage_metadata.prompt_token_count,\n                            response.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += response.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += response.usage_metadata.candidates_token_count\n\n                    # é¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ (é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ç‰ˆ)\n                    if enable_strict:\n                        status_container.write(\"ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        reviewer_instruction = base_system_instruction + \"\"\"\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n                        review_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\nåˆç‰ˆå›ç­”:\\n{final_answer}\\n\\nãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\")])]\n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=types.GenerateContentConfig(temperature=0.1, candidate_count=1, system_instruction=reviewer_instruction)\n                        )\n                        final_answer = extract_text_from_response(review_resp)\n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        \n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(model_id, review_resp.usage_metadata.prompt_token_count, review_resp.usage_metadata.candidates_token_count)\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n\n                # =========================\n                # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰\n                # =========================\n                else:\n                    # =========================\n                    # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰: å¤šæ®µéšã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ \n                    # =========================\n                    \n                    # --- Phase 1: ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 1: ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    research_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒªã‚µãƒ¼ãƒå°‚ä»»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚æœ€çµ‚å›ç­”ã¯æ›¸ã‹ãšã€äº‹å®Ÿåé›†ã«é›†ä¸­ã™ã‚‹ã“ã¨ã€‚\n\n**èª¿æŸ»è¦³ç‚¹**:\n- è³ªå•ã«é–¢é€£ã™ã‚‹**æœ€æ–°ã®äº‹å®Ÿãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ»çµ±è¨ˆ**ï¼ˆ**2025å¹´ã®æƒ…å ±ã‚’æœ€å„ªå…ˆ**ï¼‰\n- **ç¾æ™‚ç‚¹ã§å­˜åœ¨ã™ã‚‹å…¨ã¦ã®é¸æŠè‚¢ãƒ»ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¶²ç¾…çš„ã«èª¿æŸ»**ï¼ˆä¾‹: è£½å“æ¯”è¼ƒãªã‚‰ã€æœ€æ–°ç‰ˆã ã‘ã§ãªãç›´è¿‘ã®å…¨ä¸–ä»£ã‚’èª¿æŸ»ï¼‰\n- å…¬å¼æƒ…å ±ã‚„ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã‹ã‚‰ã®å¼•ç”¨\n- é–¢é€£ã™ã‚‹èƒŒæ™¯æƒ…å ±ã‚„æ–‡è„ˆ\n- ç«¶åˆãƒ»ä»£æ›¿æ¡ˆãƒ»æ¯”è¼ƒå¯¾è±¡ã®**å®Œå…¨ãªãƒªã‚¹ãƒˆ**\n- ãƒªã‚¹ã‚¯ãƒ»åˆ¶ç´„ãƒ»æ³¨æ„ç‚¹ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n- å‚è€ƒã«ã—ãŸä¸»è¦ãªæƒ…å ±æºã®URL\n\n**é‡è¦**: \n- çµè«–ã‚„æ¨å¥¨ã¯æ›¸ã‹ãšã€å¾Œå·¥ç¨‹ãŒåˆ¤æ–­ã§ãã‚‹èª¿æŸ»ãƒ¡ãƒ¢ã«é›†ä¸­ã™ã‚‹ã“ã¨\n- **å¿…ãšæ¤œç´¢æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã€æœ€æ–°ã®æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã“ã¨**\n- **æ¤œç´¢çµæœã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æ—¥ä»˜ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒ»ãƒ¢ãƒ‡ãƒ«åã‚’å„ªå…ˆçš„ã«è¨˜è¼‰ã™ã‚‹ã“ã¨**\n- **æ¯”è¼ƒå¯¾è±¡ã¨ãªã‚‹é¸æŠè‚¢ã‚’è¦‹è½ã¨ã•ãªã„ã‚ˆã†ã€è¤‡æ•°ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è©¦ã™ã“ã¨**ï¼ˆä¾‹: ã€ŒiPhone æœ€æ–°ãƒ¢ãƒ‡ãƒ« 2025ã€ã€ŒiPhone 17ã€ã€ŒiPhone 2025å¹´ç™ºå£²ã€ãªã©ï¼‰\n- **ã€Œã“ã‚Œã‚ˆã‚Šæ–°ã—ã„ãƒ¢ãƒ‡ãƒ«/ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯å­˜åœ¨ã—ãªã„ã‹ï¼Ÿã€ã‚’å¸¸ã«ç¢ºèªã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ï¼ˆ2024å¹´ä»¥å‰ãªã©ï¼‰ã—ã‹è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãã®æ—¨ã‚’æ˜è¨˜ã™ã‚‹ã“ã¨\n\"\"\"\n\n                    # éå»ã®é–¢é€£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—\n                    past_context = get_relevant_context(prompt, st.session_state.sessions, st.session_state.current_session_id)\n                    \n                    # ãƒªã‚µãƒ¼ãƒç”¨ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ§‹ç¯‰\n                    research_parts = [types.Part(text=f\"ã“ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š\\n{prompt}\")]\n                    \n                    if past_context:\n                        research_parts.insert(0, types.Part(text=\"ä»¥ä¸‹ã¯éå»ã®é–¢é€£ãƒãƒ£ãƒƒãƒˆã‹ã‚‰æŠ½å‡ºã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã™ï¼š\\n\\n\" + past_context))\n                    \n                    research_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=research_parts)\n                    ]\n                    \n                    research_config = types.GenerateContentConfig(\n                        temperature=0.2,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=research_instruction,\n                    )\n                    \n                    research_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=research_contents,\n                        config=research_config,\n                    )\n                    \n                    research_text = extract_text_from_response(research_resp)\n                    \n                    # ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºã®ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ±ã‚’ä¿å­˜\n                    if research_resp.candidates and research_resp.candidates[0].grounding_metadata:\n                        grounding_metadata = research_resp.candidates[0].grounding_metadata\n                    \n                    status_container.write(\"âœ“ ãƒªã‚µãƒ¼ãƒå®Œäº†\")\n                    with status_container.expander(\"åé›†ã—ãŸèª¿æŸ»ãƒ¡ãƒ¢\", expanded=False):\n                        st.markdown(research_text)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1)\n                    if research_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            research_resp.usage_metadata.prompt_token_count,\n                            research_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += research_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += research_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 1.5: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    questions_text = \"\"\n                    if enable_meta:\n                        status_container.write(\"Phase 1.5: ãƒ¡ã‚¿è³ªå•ç”Ÿæˆä¸­...\")\n                        \n                        question_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ç›®çš„**: \nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•ã¨èª¿æŸ»ãƒ¡ãƒ¢ã‚’è¸ã¾ãˆã¦ã€ã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±ãç†è§£ã™ã‚‹ãŸã‚ã®ã€Œé‹­ã„ã‚µãƒ–è³ªå•ã€ã‚’ä½œæˆã™ã‚‹ã“ã¨ã€‚\n\n**ãƒ«ãƒ¼ãƒ«**:\n- æœ€å¤§5å€‹ã¾ã§\n- å„è³ªå•ã¯1-2è¡Œã§å…·ä½“çš„ã‹ã¤é‹­ã\n- ä»¥ä¸‹ã®è¦³ç‚¹ã‚’æ„è­˜:\n  1. å‰æãŒå´©ã‚Œã‚‹å¯èƒ½æ€§ã¯ã©ã“ã‹ï¼Ÿ\n  2. å¼·æ°—/å¼±æ°—ã‚·ãƒŠãƒªã‚ªã®åˆ†å²ç‚¹ã¯ä½•ã‹ï¼Ÿ\n  3. ç«¶åˆãƒ»æŠ€è¡“ãƒ»è¦åˆ¶ã®ä¸ç¢ºå®Ÿæ€§ã¯ï¼Ÿ\n  4. ã€Œäºˆæ¸¬ãŒå¤–ã‚Œã‚‹ã¨ã—ãŸã‚‰ã©ã‚“ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ï¼Ÿã€\n\n**å‡ºåŠ›**: ç®‡æ¡æ›¸ãï¼ˆQ1, Q2...ï¼‰ã®ã¿\n\"\"\"\n\n                        question_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•:\\n{prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\nã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±æ˜ã‚Šã™ã‚‹ãŸã‚ã®é‡è¦ãªã‚µãƒ–è³ªå•ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\")])]\n                        \n                        question_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=question_contents,\n                            config=types.GenerateContentConfig(\n                                temperature=0.4,\n                                candidate_count=1,\n                                system_instruction=question_instruction,\n                            )\n                        )\n                        \n                        questions_text = extract_text_from_response(question_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¡ã‚¿è³ªå•ç”Ÿæˆå®Œäº†\")\n                        with status_container.expander(\"ç”Ÿæˆã•ã‚ŒãŸãƒ¡ã‚¿è³ªå•\", expanded=False):\n                            st.markdown(questions_text)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1.5)\n                        if question_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                question_resp.usage_metadata.prompt_token_count,\n                                question_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += question_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += question_resp.usage_metadata.candidates_token_count\n\n                    # --- Phase 2: çµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 2: çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    if enable_meta:\n                        deep_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã¨ãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ã‚’æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**æ§‹æˆ**:\n1. **æ·±æ˜ã‚Šè€ƒå¯Ÿ**ï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n2. **çµè«–**ï¼ˆ2-3è¡Œï¼‰\n3. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n4. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨\n\"\"\"\n                    else:\n                        deep_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã‚’å”¯ä¸€ã®æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**æ§‹æˆ**:\n1. **çµè«–**ï¼ˆ2-3è¡Œã§æ˜ç¢ºã«ï¼‰\n2. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n3. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«åã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ã¨æ–°ã—ã„æƒ…å ±ãŒæ··åœ¨ã™ã‚‹å ´åˆã¯ã€æ–°ã—ã„æƒ…å ±ã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n\"\"\"\n                    \n                    synthesis_prompt_text = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if enable_meta and questions_text:\n                        synthesis_prompt_text += f\"==== ãƒ¡ã‚¿è³ªå•ä¸€è¦§ ====\\n{questions_text}\\n==== ãƒ¡ã‚¿è³ªå•ã“ã“ã¾ã§ ====\\n\\næŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n2. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»åˆ†æãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    else:\n                        synthesis_prompt_text += \"ä¸Šè¨˜ãƒ¡ãƒ¢ã‚’æ ¹æ‹ ã«ã€æœ€çµ‚å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å¿…ãšä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚**\"\n\n                    synthesis_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=[\n                            types.Part(text=synthesis_prompt_text)\n                        ])\n                    ]\n                    \n                    synthesis_config = types.GenerateContentConfig(\n                        temperature=0.3,\n                        candidate_count=1,\n                        tools=[],  # çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºã§ã¯æ¤œç´¢OFF\n                        system_instruction=deep_instruction,\n                    )\n                    \n                    synthesis_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=synthesis_contents,\n                        config=synthesis_config,\n                    )\n                    \n                    draft_answer = extract_text_from_response(synthesis_resp)\n                    \n                    status_container.write(\"âœ“ çµ±åˆå®Œäº†\")\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 2)\n                    if synthesis_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            synthesis_resp.usage_metadata.prompt_token_count,\n                            synthesis_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += synthesis_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += synthesis_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    if enable_strict:\n                        status_container.write(\"Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        \n\n                        reviewer_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™ã€‚ãŸã ã—ã€**èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’å„ªå…ˆã—ã€æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã™ã‚‹ã“ã¨**ã€‚\n\n**ãƒ¬ãƒ“ãƒ¥ãƒ¼è¦³ç‚¹**:\n- äº‹å®Ÿã¨æ¨æ¸¬ã‚’æ˜ç¢ºã«åˆ†ã‘ã‚‹\n- éåº¦ã«è‡ªä¿¡ã®ã‚ã‚‹æ–­å®šã‚’å¼±ã‚ã‚‹\n- æ•°å­—ã‚„å›ºæœ‰åè©ãŒèª¿æŸ»ãƒ¡ãƒ¢ã¨çŸ›ç›¾ã—ã¦ã„ãªã„ã‹ç¢ºèª\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ãƒ¢ãƒ‡ãƒ«ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ãŒæ­£ã—ãä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª**\n- **å¤ã„æƒ…å ±ã§ä¸Šæ›¸ãã—ã¦ã„ãªã„ã‹ç¢ºèª**\n- è¦‹è½ã¨ã—ã¦ã„ã‚‹é‡è¦ãªãƒªã‚¹ã‚¯ãƒ»ã‚·ãƒŠãƒªã‚ªãŒã‚ã‚Œã°è¿½åŠ \n\n**é‡è¦**: \n- èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ãŒæœ€æ–°ã§ã‚ã‚‹å ´åˆã€ãã‚Œã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n- ã‚ãªãŸã®çŸ¥è­˜ãŒå¤ã„å ´åˆã¯ã€èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’ä¿¡é ¼ã™ã‚‹ã“ã¨\n\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n\n                        review_contents = [\n                            types.Content(role=\"user\", parts=[\n                                types.Part.from_text(\n                                    text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\n\"\n                                    f\"==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                                    f\"åˆç‰ˆå›ç­”:\\n{draft_answer}\\n\\n\"\n                                    \"ä¸Šè¨˜ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚**\"\n                                )\n                            ])\n                        ]\n                        \n                        review_config = types.GenerateContentConfig(\n                            temperature=0.1,\n                            candidate_count=1,\n                            system_instruction=reviewer_instruction,\n                        )\n                        \n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=review_config,\n                        )\n                        \n                        final_answer = extract_text_from_response(review_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        with status_container.expander(\"åˆç‰ˆã¨ã®æ¯”è¼ƒ\", expanded=False):\n                            st.markdown(\"**åˆç‰ˆ:**\")\n                            st.markdown(draft_answer[:500] + \"...\" if len(draft_answer) > 500 else draft_answer)\n                            st.markdown(\"**ä¿®æ­£ç‰ˆ:**\")\n                            st.markdown(final_answer[:500] + \"...\" if len(final_answer) > 500 else final_answer)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 3)\n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                review_resp.usage_metadata.prompt_token_count,\n                                review_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n                    else:\n                        final_answer = draft_answer\n\n                save_usage(usage_stats)\n                status_container.update(label=\"å®Œäº†ï¼\", state=\"complete\", expanded=False)\n\n                # ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤º\n                st.caption(f\"ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_id}\")\n                st.markdown(final_answer)\n\n                # ---- ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ± ----\n                if grounding_metadata:\n                    st.markdown(\"---\")\n                    st.subheader(\"ğŸ“š æƒ…å ±æºã¨å¼•ç”¨\")\n                    if grounding_metadata.grounding_chunks:\n                        st.markdown(\"**æ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:**\")\n                        unique_sources = {}\n                        import urllib.parse\n\n                        for chunk in grounding_metadata.grounding_chunks:\n                            if getattr(chunk, \"web\", None):\n                                uri = getattr(chunk.web, \"uri\", None)\n                                title = getattr(chunk.web, \"title\", \"æƒ…å ±æº\")\n                                if uri and uri not in unique_sources:\n                                    parsed = urllib.parse.urlparse(uri)\n                                    domain = parsed.netloc.replace(\"www.\", \"\")\n                                    unique_sources[uri] = {\n                                        \"title\": title,\n                                        \"domain\": domain,\n                                    }\n                        for i, (uri, info) in enumerate(unique_sources.items(), 1):\n                            st.markdown(f\"{i}. **[{info['title']}]({uri})**\")\n                            st.caption(f\"   å‡ºå…¸: {info['domain']}\")\n\n                messages.append({\"role\": \"model\", \"content\": final_answer})\n                update_current_session_messages(messages)\n\n            except Exception as e:\n                status_container.update(label=\"Error\", state=\"error\")\n                err_text = str(e)\n                if \"RESOURCE_EXHAUSTED\" in err_text or \"429\" in err_text:\n                    st.error(\n                        \"âš ï¸ Vertex AI / Gemini ã®ã‚¯ã‚©ãƒ¼ã‚¿ã«é”ã—ã¾ã—ãŸã€‚\\n\\n\"\n                        \"ãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ / æ—¥æ¬¡åˆ¶é™ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\\n\"\n                        \"ãƒ»ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                        \"ãƒ»Google Cloud Console ã®ã€ŒVertex AI â†’ ä½¿ç”¨çŠ¶æ³ã€ã‹ã‚‰ã‚¯ã‚©ãƒ¼ã‚¿çŠ¶æ³ã‚’ç¢ºèªã§ãã¾ã™ã€‚\"\n                    )\n                elif \"NOT_FOUND\" in err_text and \"Publisher Model\" in err_text:\n                    st.error(\n                        \"âš ï¸ æŒ‡å®šã—ãŸãƒ¢ãƒ‡ãƒ«ãŒã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ / ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\\n\"\n                        \"ãƒ»ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ¢ãƒ‡ãƒ«IDã‚’ã€2.5ç³» ã¾ãŸã¯ 3 Pro ã«å¤‰æ›´ã—ã¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                    )\n                else:\n                    st.error(f\"An error occurred: {e}\")\n"
                },
                {
                    "role": "model",
                    "content": "### 1. æ·±æ˜ã‚Šè€ƒå¯Ÿï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n\nã‚³ãƒ¼ãƒ‰ã®ãƒ­ã‚¸ãƒƒã‚¯ã¨ç”ŸæˆAIã®ç‰¹æ€§ã«åŸºã¥ãã€æèµ·ã•ã‚ŒãŸæ‡¸å¿µç‚¹ï¼ˆãƒ¡ã‚¿è³ªå•ï¼‰ã«ã¤ã„ã¦åˆ†æã—ã¾ã™ã€‚\n\n*   **Q1. ã€Œç™ºæ•£ã€ã¨ã€ŒåæŸã€ã®ç›¸æ®ºãƒªã‚¹ã‚¯ï¼ˆå¹³å‡¡åŒ–ã®ãƒ‘ãƒ©ãƒ‰ãƒƒã‚¯ã‚¹ï¼‰**\n    *   **å›ç­”:** **é«˜ã„ç¢ºç‡ã§ç™ºç”Ÿã—ã¾ã™ã€‚** ã€Œãƒ¡ã‚¿æ€è€ƒã€ãƒ•ã‚§ãƒ¼ã‚ºã¯å¯èƒ½æ€§ã‚’åºƒã’ã‚‹ï¼ˆç™ºæ•£ï¼‰å½¹å‰²ã§ã™ãŒã€ã€Œé¬¼è»æ›¹ã€ãƒ•ã‚§ãƒ¼ã‚ºã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã¯ã€Œéåº¦ã«è‡ªä¿¡ã®ã‚ã‚‹æ–­å®šã‚’å¼±ã‚ã‚‹ã€ã€Œèª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’å„ªå…ˆã€ã¨ã„ã†æŒ‡ç¤ºãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¡ã‚¿æ€è€ƒã§å°ãå‡ºã•ã‚ŒãŸé‹­ã„ä»®èª¬ãŒã€è£ä»˜ã‘ã¨ãªã‚‹æ˜ç¢ºãªã‚½ãƒ¼ã‚¹ãŒãªã„å ´åˆã€ã€Œæ ¹æ‹ ä¸è¶³ã€ã¨ã—ã¦å‰Šé™¤ã¾ãŸã¯ãƒˆãƒ¼ãƒ³ãƒ€ã‚¦ãƒ³ã•ã‚Œã€çµæœã¨ã—ã¦ã€Œç„¡é›£ã§æ­£ç¢ºãªå›ç­”ã€ã«åæŸã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n*   **Q2. ãƒˆãƒ¼ã‚¯ãƒ³æ¶ˆè²»ã¨è¨˜æ†¶å¯¿å‘½**\n    *   **å›ç­”:** **é‡å¤§ãªãƒªã‚¹ã‚¯ã§ã™ã€‚** ã€Œæœ¬æ°—MAXã€ã¯1å›ã®å›ç­”ç”Ÿæˆã§4å›ï¼ˆãƒªã‚µãƒ¼ãƒã€ãƒ¡ã‚¿è³ªå•ã€çµ±åˆã€ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰ã®LLMå‘¼ã³å‡ºã—ã‚’è¡Œã„ã¾ã™ã€‚å…¥å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³é‡ãŒå˜ç´”è¨ˆç®—ã§é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã®3ã€œ4å€ã«ãªã‚‹ãŸã‚ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼ˆè¨˜æ†¶å®¹é‡ï¼‰ã‚’æ€¥é€Ÿã«æ¶ˆè²»ã—ã€é•·ã„ä¼šè©±ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã¯éå»ã®æ–‡è„ˆã‚’å¿˜ã‚Œã‚‹ã®ãŒæ—©ããªã‚Šã¾ã™ã€‚\n*   **Q3. ç›®çš„ã¨ã®ä¸ä¸€è‡´ï¼ˆå‰µé€ æ€§ vs æ­£ç¢ºæ€§ï¼‰**\n    *   **å›ç­”:** **ã‚·ãƒŠãƒªã‚ªã¨ã—ã¦å­˜åœ¨ã—ã¾ã™ã€‚** ãƒ–ãƒ¬ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒŸãƒ³ã‚°ã‚„SFçš„è€ƒå¯Ÿãªã©ã€Œé£›èºã€ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ã‚¿ã‚¹ã‚¯ã§ã¯ã€å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡Œã†ã€Œæœ¬æ°—MAXã€ã‚ˆã‚Šã‚‚ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡Œã‚ãªã„**ã€Œ3. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)ã€ã®æ–¹ãŒå„ªç§€**ãªçµæœï¼ˆé¢ç™½ã„å›ç­”ï¼‰ã‚’å‡ºåŠ›ã™ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã§ã™ã€‚\n*   **Q4. ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®é™ç•Œï¼ˆFlashç³»ã§ã®ä¸å…·åˆï¼‰**\n    *   **å›ç­”:** **æ‡¸å¿µã•ã‚Œã¾ã™ã€‚** è¤‡é›‘ãªå¤šæ®µéšæ¨è«–ï¼ˆSystem 2çš„å‡¦ç†ï¼‰ã¯ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®å°‘ãªã„ãƒ¢ãƒ‡ãƒ«ï¼ˆFlashç³»ï¼‰ã§ã¯æŒ‡ç¤ºã®è¿½å¾“æ€§ãŒä½ä¸‹ã™ã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚ã€Œæœ¬æ°—MAXã€ã®è¤‡é›‘ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒã‚§ãƒ¼ãƒ³ã‚’å®Œå…¨ã«æ©Ÿèƒ½ã•ã›ã‚‹ã«ã¯ã€**Gemini 1.5 Pro / 3 Pro ä»¥ä¸Šã®ãƒ¢ãƒ‡ãƒ«**ãŒæ¨å¥¨ã•ã‚Œã¾ã™ã€‚\n*   **Q5. ãƒã‚°ä¿®æ­£å¾Œã®å‹¢åŠ›å›³**\n    *   **å›ç­”:** ç¾çŠ¶ã®ã‚³ãƒ¼ãƒ‰ã¯å…¨ãƒ¢ãƒ¼ãƒ‰ã§ãƒªã‚µãƒ¼ãƒãŒå¼·åˆ¶ã•ã‚Œã¦ã„ã¾ã™ãŒã€ã“ã‚ŒãŒä¿®æ­£ã•ã‚Œã‚Œã°ã€Œé€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã€ã¯åœ§å€’çš„ãªé€Ÿåº¦ã¨ã„ã†ä¾¡å€¤ã‚’æŒã¡ã¾ã™ã€‚ãã®å ´åˆã€ã€Œæœ¬æ°—MAXã€ã¯ã€Œæ™‚é–“ã¨ã‚³ã‚¹ãƒˆã‚’åº¦å¤–è¦–ã—ãŸå“è³ªç‰¹åŒ–ã€ã¨ã„ã†ä½ç½®ä»˜ã‘ãŒã‚ˆã‚Šé®®æ˜ã«ãªã‚Šã€æ—¥å¸¸ä½¿ã„ã«ã¯é©ã•ãªããªã‚Šã¾ã™ã€‚\n\n---\n\n### 2. çµè«–\n\nç¾çŠ¶ã®ã‚³ãƒ¼ãƒ‰ã«ãŠã„ã¦ã€**è«–ç†çš„æ•´åˆæ€§ãƒ»æƒ…å ±ã®ç¶²ç¾…æ€§ãƒ»æ­£ç¢ºã•**ã‚’åŸºæº–ã¨ã™ã‚‹ãªã‚‰ã°ã€**ã€ŒÎ²2. ç†Ÿè€ƒ (æœ¬æ°—MAX)ã€ãŒæœ€ã‚‚å„ªç§€ãªãƒ¢ãƒ‡ãƒ«**ã§ã‚ã‚‹ã“ã¨ã¯é–“é•ã„ã‚ã‚Šã¾ã›ã‚“ã€‚\n\nãŸã ã—ã€**ã€Œå‰µé€ çš„ãªã‚¢ã‚¤ãƒ‡ã‚¢å‡ºã—ã€**ã«ãŠã„ã¦ã¯ãƒ¬ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½ãŒè¶³ã‹ã›ã¨ãªã‚‹ãŸã‚**ã€Œ3. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)ã€**ãŒå„ªã‚Œã¦ãŠã‚Šã€**ã€Œã‚³ã‚¹ãƒˆå¯¾åŠ¹æœï¼ˆã‚³ã‚¹ãƒ‘ï¼‰ã€**ã®è¦³ç‚¹ã§ã¯**ã€Œ2. ç†Ÿè€ƒ + é¬¼è»æ›¹ã€**ãŒæœ€é©è§£ã¨ãªã‚‹ã‚±ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã™ã€‚ã€Œä¸‡èƒ½ã®æœ€å¼·ã€ã§ã¯ãªãã€Œå“è³ªç‰¹åŒ–ã®æœ€å¼·ã€ã¨ç†è§£ã™ã¹ãã§ã™ã€‚\n\n---\n\n### 3. è©³ç´°ãªåˆ†æï¼ˆã‚³ãƒ¼ãƒ‰ãƒ­ã‚¸ãƒƒã‚¯ã«åŸºã¥ãï¼‰\n\næä¾›ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã®å†…éƒ¨ãƒ­ã‚¸ãƒƒã‚¯ã‚’è§£æã™ã‚‹ã¨ã€å„ãƒ¢ãƒ¼ãƒ‰ã¯ä»¥ä¸‹ã®æ©Ÿèƒ½ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®çµ„ã¿åˆã‚ã›ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚ã€Œæœ¬æ°—MAXã€ã®ã¿ãŒå…¨ã¦ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æ´»æ€§åŒ–ã•ã›ã¦ã„ã¾ã™ã€‚\n\n| æ©Ÿèƒ½ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« | å½¹å‰² | æœ¬æ°—MAX | ãƒ¡ã‚¿æ€è€ƒ | é¬¼è»æ›¹ | ãƒªã‚µãƒ¼ãƒ/é€šå¸¸ |\n| :--- | :--- | :---: | :---: | :---: | :---: |\n| **Research** | æ¤œç´¢ã«ã‚ˆã‚‹äº‹å®Ÿåé›† | âœ… | âœ… | âœ… | âœ… |\n| **Meta-Thinking** | å•ã„ã®å†è¨­å®šãƒ»å¤šè§’çš„è¦–ç‚¹ã®ç”Ÿæˆ | **âœ…** | **âœ…** | â– | â– |\n| **Synthesis** | æƒ…å ±ã®çµ±åˆãƒ»å›ç­”ä½œæˆ | âœ… | âœ… | âœ… | âœ… |\n| **Strict Review** | æ‰¹åˆ¤çš„ãƒã‚§ãƒƒã‚¯ãƒ»ä¿®æ­£ | **âœ…** | â– | **âœ…** | â– |\n\n#### ãªãœã€Œæœ¬æ°—MAXã€ãŒå“è³ªé¢ã§æœ€å¼·ãªã®ã‹\n1.  **è¦–ç‚¹ã®æ·±ã•**: `enable_meta = True` ã«ã‚ˆã‚Šã€å˜ãªã‚‹æ¤œç´¢çµæœã®ã¾ã¨ã‚ã«ç•™ã¾ã‚‰ãšã€ã€Œå‰æã‚’ç–‘ã†ã€ã€Œãƒªã‚¹ã‚¯ã‚’è€ƒãˆã‚‹ã€ã¨ã„ã£ãŸæ·±ã„æ´å¯ŸãŒå›ç­”ã«çµ„ã¿è¾¼ã¾ã‚Œã¾ã™ã€‚\n2.  **æ­£ç¢ºæ€§ã®æ‹…ä¿**: `enable_strict = True` ã«ã‚ˆã‚Šã€ç”Ÿæˆã•ã‚ŒãŸå›ç­”ã‚’ã€Œé¬¼è»æ›¹ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§å†è©•ä¾¡ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå˜˜ï¼‰ã‚„è«–ç†çš„é£›èºãŒä¿®æ­£ã•ã‚Œã¾ã™ã€‚\n3.  **ç›¸äº’è£œå®Œ**: ã€Œãƒ¡ã‚¿æ€è€ƒã€ã§åºƒã’ãŸé¢¨å‘‚æ•·ã‚’ã€ã€Œé¬¼è»æ›¹ã€ãŒç•³ã‚€ã¨ã„ã†ãƒ—ãƒ­ã‚»ã‚¹ãŒã€äººé–“ãŒæ¨æ•²ã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã«æœ€ã‚‚è¿‘ã„ãŸã‚ã§ã™ã€‚\n\n#### ä»–ã®ãƒ¢ãƒ‡ãƒ«ãŒå„ªã‚Œã‚‹ã‚·ãƒŠãƒªã‚ª\n*   **ã€Œ3. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)ã€ãŒå‹ã‚‹å ´åˆ**:\n    *   æ–°è¦äº‹æ¥­ã®ã‚¢ã‚¤ãƒ‡ã‚¢å‡ºã—ã‚„ã€æœªæ¥äºˆæ¸¬ãªã©ã€æ­£è§£ãŒãªã„å•ã„ã«å¯¾ã—ã¦ã€Œå®ˆã‚Šã€ã«å…¥ã‚‰ãšå¤§èƒ†ãªç™ºæƒ³ãŒæ¬²ã—ã„å ´åˆã€‚é¬¼è»æ›¹ã«ã‚ˆã‚‹ã€Œæ ¹æ‹ ã¯ï¼Ÿã€ã¨ã„ã†ãƒ„ãƒƒã‚³ãƒŸã‚’å›é¿ã§ãã¾ã™ã€‚\n*   **ã€Œ2. ç†Ÿè€ƒ + é¬¼è»æ›¹ã€ãŒå‹ã‚‹å ´åˆ**:\n    *   äº‹å®Ÿç¢ºèªï¼ˆãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ï¼‰ã®ã¿ãŒç›®çš„ã®å ´åˆã€‚ãƒ¡ã‚¿æ€è€ƒã«ã‚ˆã‚‹æ·±æ˜ã‚Šã¯ä¸è¦ã§ã€æ­£ç¢ºã•ã ã‘ãŒæ¬²ã—ã„æ™‚ã¯ã€ã“ã¡ã‚‰ã®æ–¹ãŒãƒˆãƒ¼ã‚¯ãƒ³æ¶ˆè²»ãŒå°‘ãªãçµŒæ¸ˆçš„ã§ã™ã€‚\n\n---\n\n### 4. è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯\n\nã‚³ãƒ¼ãƒ‰ã®å®Ÿè£…çŠ¶æ³ã‹ã‚‰ã€ä»¥ä¸‹ã®ç‚¹ã«æ³¨æ„ã—ã¦é‹ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n\n1.  **ã€Œé€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã€ã®ãƒã‚°ã«ã‚ˆã‚‹æŒ™å‹•**:\n    *   ã‚³ãƒ¼ãƒ‰å†…ã§ `enable_research = True` ãŒå›ºå®šã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€æœ¬æ¥é«˜é€Ÿã§ã‚ã‚‹ã¯ãšã®ã€Œé€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã€ã‚‚æ¤œç´¢ã‚’å®Ÿè¡Œã—ã¦ã—ã¾ã„ã¾ã™ã€‚ç¾çŠ¶ã§ã¯ã€Œé€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã€ã‚’ä½¿ã†ãƒ¡ãƒªãƒƒãƒˆã¯ã»ã¼ãªãã€ã€Œ1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)ã€ã¨å®Ÿè³ªçš„ã«åŒã˜æŒ™å‹•ã«ãªã‚Šã¾ã™ã€‚\n2.  **ã‚³ã‚¹ãƒˆï¼ˆæ–™é‡‘ï¼‰ã®å¢—å¤§**:\n    *   ã€Œæœ¬æ°—MAXã€ã¯1å›ã®å›ç­”ã§å†…éƒ¨çš„ã«è¤‡æ•°å›ã®APIã‚³ãƒ¼ãƒ«ã‚’è¡Œã„ã¾ã™ã€‚ç‰¹ã«ç”»åƒã‚„é•·æ–‡ãƒ†ã‚­ã‚¹ãƒˆã‚’æ‰±ã†å ´åˆã€å¾“é‡èª²é‡‘ï¼ˆVertex AIï¼‰ã®ã‚³ã‚¹ãƒˆãŒæ•°å€ã«è†¨ã‚Œä¸ŠãŒã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚\n3.  **ã‚¿ã‚¤ãƒ ãƒ©ã‚°**:\n    *   Streamlitã® `st.status` ã§é€²æ—ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ãŒã€ã€Œæœ¬æ°—MAXã€ã¯å®Œäº†ã¾ã§ã«æ•°åç§’ã€œ1åˆ†ç¨‹åº¦ã‹ã‹ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ãƒãƒ£ãƒƒãƒˆä½“é¨“ã¨ã—ã¦ã¯ã‚¹ãƒˆãƒ¬ã‚¹ã«ãªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚"
                }
            ]
        },
        {
            "id": "4f92bea2-53a5-4960-b8b2-98621a894174",
            "title": "ç¾çŠ¶ã®ã‚³ãƒ¼ãƒ‰ã§ã€å›ç­”ãƒ¢ãƒ¼ãƒ‰ãŒè¤‡æ•°ã‚ã‚‹ãŒã€...",
            "timestamp": "2025-11-30T14:06:32.113113",
            "messages": [
                {
                    "role": "user",
                    "content": "ç¾çŠ¶ã®ã‚³ãƒ¼ãƒ‰ã§ã€å›ç­”ãƒ¢ãƒ¼ãƒ‰ãŒè¤‡æ•°ã‚ã‚‹ãŒã€æœ€ã‚‚å„ªç§€ãªãƒ¢ãƒ‡ãƒ«ã¯ç†Ÿè€ƒ(æœ¬æ°—MAX)ã‹ã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã®ã»ã†ãŒå„ªç§€ã‹?\nimport os\nimport uuid\nimport datetime\nimport streamlit as st\nfrom dotenv import load_dotenv\nfrom google import genai\nfrom google.genai import types\nfrom PIL import Image\nimport io\nfrom logic import (\n    USAGE_FILE, SESSIONS_FILE, MAX_BUDGET_USD, PRICING,\n    VERTEX_PROJECT, VERTEX_LOCATION,\n    load_usage, save_usage, calculate_cost, get_mime_type,\n    extract_youtube_id, get_youtube_transcript, get_relevant_context,\n    extract_text_from_response, load_sessions, save_sessions, get_client\n)\n\ntry:\n    from st_img_pastebutton import paste\n    import_error_msg = None\nexcept ImportError as e:\n    paste = None\n    import_error_msg = str(e)\n\n# =========================\n# ç’°å¢ƒå¤‰æ•° & å®šæ•°\n# =========================\n\nload_dotenv()\n\n\n\nst.set_page_config(page_title=\"Gemini 3 Web Studio\", layout=\"wide\")\n\n# =========================\n# Helper Functions\n# =========================\n\n# =========================\n# Helper Functions\n# =========================\n# Moved to logic.py\n\n# =========================\n# Session Management\n# =========================\n\n\n\ndef create_new_session():\n    current_sessions = load_sessions()\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": [],\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.rerun()\n\ndef switch_session(session_id):\n    st.session_state.current_session_id = session_id\n    st.rerun()\n\ndef update_current_session_messages(messages):\n    if st.session_state.current_session_id:\n        current_sessions = load_sessions()\n        for session in current_sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                session[\"messages\"] = messages\n                if session[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(messages) > 0:\n                    first_msg = messages[0][\"content\"]\n                    session[\"title\"] = (first_msg[:20] + \"...\") if len(first_msg) > 20 else first_msg\n                session[\"timestamp\"] = datetime.datetime.now().isoformat()\n                break\n        save_sessions(current_sessions)\n        st.session_state.sessions = current_sessions\n\ndef get_current_messages():\n    if st.session_state.current_session_id:\n        for session in st.session_state.sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                return session[\"messages\"]\n    return []\n\ndef delete_session(session_id):\n    current_sessions = load_sessions()\n    current_sessions = [s for s in current_sessions if s[\"id\"] != session_id]\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    if st.session_state.current_session_id == session_id:\n        st.session_state.current_session_id = None\n        if st.session_state.sessions:\n            st.session_state.current_session_id = st.session_state.sessions[0][\"id\"]\n    st.rerun()\n\ndef branch_session():\n    \"\"\"ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚’åˆ†å²\"\"\"\n    current_messages = get_current_messages()\n    current_sessions = load_sessions()\n    \n    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—\n    current_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n    for session in current_sessions:\n        if session[\"id\"] == st.session_state.current_session_id:\n            current_title = session[\"title\"]\n            break\n    \n    # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": f\"{current_title} (åˆ†å²)\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": current_messages.copy(),  # ç¾åœ¨ã®å±¥æ­´ã‚’ã‚³ãƒ”ãƒ¼\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    \n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.session_state.session_cost = 0.0  # ã‚³ã‚¹ãƒˆãƒªã‚»ãƒƒãƒˆ\n    st.rerun()\n\n# =========================\n# Initialization\n# =========================\n\nif \"sessions\" not in st.session_state:\n    st.session_state.sessions = load_sessions()\n\nif \"current_session_id\" not in st.session_state:\n    # Always create a new session when the app starts\n    create_new_session()\n\nif \"session_cost\" not in st.session_state:\n    st.session_state.session_cost = 0.0\n\nusage_stats = load_usage()\n\n# =========================\n# Sidebar\n# =========================\n\nwith st.sidebar:\n    st.markdown(\"\"\"\n    <div style=\"text-align: center; padding: 0; margin: 0; margin-top: -1rem;\">\n        <h1 style=\"font-size: 18px; font-weight: 700; margin: 0; padding: 0; letter-spacing: 1px;\">\n            Gemini 3<br/>Studio\n        </h1>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n    col1, col2 = st.columns(2)\n    with col1:\n        if st.button(\"â• æ–°è¦\", use_container_width=True):\n            create_new_session()\n    with col2:\n        if st.button(\"ğŸŒ± åˆ†å²\", use_container_width=True):\n            branch_session()\n\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    current_messages = get_current_messages()\n    if current_messages:\n        with st.expander(\"ğŸ”— å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ\", expanded=False):\n            export_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n            for s in st.session_state.sessions:\n                if s[\"id\"] == st.session_state.current_session_id:\n                    export_title = s[\"title\"]\n                    break\n\n            export_md = f\"# {export_title}\\n\\n\"\n            export_md += f\"**ä½œæˆæ—¥æ™‚**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n---\\n\\n\"\n            for msg in current_messages:\n                role_label = \"ğŸ§‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼\" if msg[\"role\"] == \"user\" else \"ğŸ¤– AI\"\n                export_md += f\"## {role_label}\\n\\n{msg['content']}\\n\\n---\\n\\n\"\n\n            if st.button(\"ãƒªãƒ³ã‚¯ç”Ÿæˆ\", use_container_width=True):\n                with st.spinner(\"ç”Ÿæˆä¸­...\"):\n                    try:\n                        import urllib.request\n                        import urllib.parse\n\n                        data = urllib.parse.urlencode(\n                            {\"content\": export_md, \"expiry_days\": 7, \"syntax\": \"md\"}\n                        ).encode()\n\n                        req = urllib.request.Request(\"https://dpaste.org/api/\", data=data)\n                        req.add_header(\"User-Agent\", \"Mozilla/5.0 (Gemini3Studio)\")\n\n                        with urllib.request.urlopen(req) as response:\n                            share_url = response.read().decode(\"utf-8\").strip()\n                            st.success(\"ä½œæˆå®Œäº†ï¼\")\n                            st.code(share_url)\n                            st.caption(\"â€»7æ—¥é–“æœ‰åŠ¹\")\n                    except Exception as e:\n                        st.error(f\"ã‚¨ãƒ©ãƒ¼: {e}\")\n\n    st.markdown(\"---\")\n\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    with st.expander(\"ğŸ“ æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«\", expanded=False):\n        uploaded_files = st.file_uploader(\n            \"ãƒ•ã‚¡ã‚¤ãƒ«\",\n            accept_multiple_files=True,\n            type=[\"png\", \"jpg\", \"jpeg\", \"mp4\", \"mov\", \"txt\", \"pdf\", \"csv\"],\n            label_visibility=\"collapsed\"\n        )\n\n    # ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ï¼ˆExpanderã®å¤–ã«å‡ºã™ï¼‰\n    if paste:\n        if \"paste_key\" not in st.session_state:\n            st.session_state.paste_key = 0\n        try:\n            pasted_image_bytes = paste(\n                label=\"ğŸ“‹ è²¼ä»˜\",\n                key=f\"paste_btn_{st.session_state.paste_key}\",\n            )\n        except Exception as e:\n            st.error(f\"Error: {e}\")\n        \n        if pasted_image_bytes:\n            st.success(\"è²¼ä»˜å®Œäº†\")\n            st.image(pasted_image_bytes, caption=\"ç”»åƒ\", use_container_width=True)\n            if st.button(\"ğŸ—‘ï¸ ã‚¯ãƒªã‚¢\", key=\"clear_paste\"):\n                st.session_state.paste_key += 1\n                st.rerun()\n    else:\n        st.warning(\"Clipboard lib missing\")\n\n    # ---- YouTube URL ----\n    with st.expander(\"ğŸ“º YouTubeåˆ†æ\", expanded=False):\n        youtube_url = st.text_input(\"URL\", placeholder=\"https://youtu.be/...\", label_visibility=\"collapsed\")\n\n    st.markdown(\"---\")\n    \n    st.markdown(\"---\")\n    \n    # ---- å›ç­”ãƒ¢ãƒ¼ãƒ‰ ----\n    with st.expander(\"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰\", expanded=True):\n        mode_type = st.radio(\n            \"ã‚¿ã‚¤ãƒ—\",\n            [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n            index=0,\n            horizontal=True,\n            label_visibility=\"collapsed\"\n        )\n        \n        if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n            response_mode = st.radio(\n                \"ãƒ¢ãƒ¼ãƒ‰\",\n                [\n                    \"2. ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                    \"3. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                    \"Î²2. ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                ],\n                index=0\n            )\n        elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n            response_mode = st.radio(\n                \"ãƒ¢ãƒ¼ãƒ‰\",\n                [\n                    \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                ],\n                index=0\n            )\n        else:\n            response_mode = st.radio(\n                \"ãƒ¢ãƒ¼ãƒ‰\",\n                [\n                    \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                ],\n                index=0\n            )\n    \n    strict_mode = False\n    \n    # ---- è¨­å®š (ãƒ¢ãƒ‡ãƒ«ãªã©) ----\n    with st.expander(\"âš™ï¸ è¨­å®š\", expanded=False):\n        model_options = [\n            \"gemini-3-pro-preview\",\n            \"gemini-2.5-pro\",\n            \"gemini-2.5-flash\",\n            \"gemini-2.5-flash-lite\",\n            \"gemini-2.0-flash\",\n        ]\n        model_id = st.selectbox(\"ãƒ¢ãƒ‡ãƒ«ID\", options=model_options, index=0)\n\n        use_search = st.toggle(\"Googleæ¤œç´¢\", value=True)\n        candidate_count = st.slider(\"å€™è£œæ•°\", min_value=1, max_value=3, value=3)\n\n    st.markdown(\"---\")\n\n    # ---- å±¥æ­´æ¤œç´¢ ----\n    search_query = st.text_input(\"ğŸ” å±¥æ­´æ¤œç´¢\", placeholder=\"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰...\")\n    if search_query:\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if search_query.lower() in s[\"title\"].lower():\n                filtered_sessions.append(s)\n                continue\n            found = False\n            for m in s[\"messages\"]:\n                if search_query.lower() in m[\"content\"].lower():\n                    filtered_sessions.append(s)\n                    found = True\n                    break\n            if not found:\n                pass\n    else:\n        # æ¤œç´¢ã—ã¦ã„ãªã„å ´åˆ: ç©ºã®ã€Œæ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã€ã‚’é™¤å¤–ï¼ˆç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯é™¤ãï¼‰\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if s[\"id\"] == st.session_state.current_session_id:\n                filtered_sessions.append(s)\n                continue\n            if s[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(s[\"messages\"]) == 0:\n                continue\n            filtered_sessions.append(s)\n\n    # CSSã§è¦‹ã‚„ã™ãä½¿ã„ã‚„ã™ãæœ€é©åŒ–\n    st.markdown(\"\"\"\n    <style>\n    /* å…¨ä½“ã®ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºç¸®å° */\n    .stApp, .stMarkdown, .stButton, .stSelectbox, .stTextInput, .stTextArea {\n        font-size: 12px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ä½™ç™½ã‚’æ¥µé™ã¾ã§è©°ã‚ã‚‹ */\n    section[data-testid=\"stSidebar\"] .block-container {\n        padding-top: 0rem !important;\n        padding-bottom: 0.3rem !important;\n        padding-left: 0.5rem !important;\n        padding-right: 0.5rem !important;\n    }\n    /* å„è¦ç´ é–“ã®éš™é–“ã‚’è©°ã‚ã‚‹ */\n    div[data-testid=\"stVerticalBlock\"] > div {\n        gap: 0.1rem !important;\n    }\n    /* Expanderã®ä½™ç™½å‰Šæ¸› */\n    .streamlit-expanderHeader {\n        font-size: 11px !important;\n        padding-top: 0px !important;\n        padding-bottom: 0px !important;\n        min-height: 1.3rem !important;\n    }\n    .streamlit-expanderContent {\n        padding-top: 0px !important;\n        padding-bottom: 0px !important;\n    }\n    /* éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã®ã‚¿ã‚¤ãƒˆãƒ« */\n    div[data-testid=\"stExpander\"] summary p {\n        font-size: 10px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ */\n    section[data-testid=\"stSidebar\"] button p {\n        font-size: 10px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã« */\n    section[data-testid=\"stSidebar\"] button {\n        padding: 0rem 0.2rem !important;\n        min-height: 1.4rem !important;\n        font-size: 10px !important;\n        margin-bottom: 0px !important;\n    }\n    /* ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®ãƒ©ãƒ™ãƒ«ã‚’å°ã•ã */\n    section[data-testid=\"stSidebar\"] .stRadio label {\n        font-size: 10px !important;\n    }\n    section[data-testid=\"stSidebar\"] .stRadio > label > div {\n        font-size: 10px !important;\n    }\n    /* ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ‡ã‚Šè©°ã‚ã‚‹ï¼ˆæ”¹è¡Œã•ã›ãªã„ï¼‰ */\n    section[data-testid=\"stSidebar\"] label, \n    section[data-testid=\"stSidebar\"] p,\n    section[data-testid=\"stSidebar\"] span {\n        white-space: nowrap !important;\n        overflow: hidden !important;\n        text-overflow: ellipsis !important;\n    }\n    /* åŒºåˆ‡ã‚Šç·š */\n    hr {\n        margin-top: 0.1rem !important;\n        margin-bottom: 0.1rem !important;\n    }\n    /* ãƒ˜ãƒƒãƒ€ãƒ¼ç¸®å° */\n    h1, h2, h3 {\n        padding-top: 0rem !important;\n        padding-bottom: 0rem !important;\n        margin-top: 0rem !important;\n        margin-bottom: 0rem !important;\n    }\n    </style>\n    \"\"\", unsafe_allow_html=True)\n    \n    # ç›´è¿‘5ä»¶ã¨éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«åˆ†å‰²\n    recent_sessions = filtered_sessions[:5] if len(filtered_sessions) > 5 else filtered_sessions\n    archive_sessions = filtered_sessions[5:] if len(filtered_sessions) > 5 else []\n    \n    # ç›´è¿‘5ä»¶ï¼ˆå¸¸ã«å±•é–‹ï¼‰\n    if recent_sessions:\n        st.markdown(\"**ğŸ“Œ ç›´è¿‘ã®ãƒãƒ£ãƒƒãƒˆ**\")\n        for session in recent_sessions:\n            col1, col2 = st.columns([0.8, 0.2])\n            with col1:\n                if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                    switch_session(session[\"id\"])\n            with col2:\n                if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                    delete_session(session[\"id\"])\n    \n    # éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆæŠ˜ã‚ŠãŸãŸã¿ï¼‰\n    if archive_sessions:\n        with st.expander(f\"ğŸ“œ éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ– ({len(archive_sessions)}ä»¶)\", expanded=False):\n            for session in archive_sessions:\n                col1, col2 = st.columns([0.8, 0.2])\n                with col1:\n                    if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                        switch_session(session[\"id\"])\n                with col2:\n                    if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                        delete_session(session[\"id\"])\n\n    st.markdown(\"---\")\n\n    # ---- ç”»åƒç”Ÿæˆ ----\n    with st.expander(\"ğŸ¨ ç”»åƒç”Ÿæˆ\", expanded=False):\n        img_prompt = st.text_area(\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\", placeholder=\"æœªæ¥çš„ãªéƒ½å¸‚...\")\n        aspect_ratio = st.selectbox(\"æ¯”ç‡\", [\"16:9\", \"1:1\", \"4:3\", \"3:4\", \"9:16\"])\n\n        generate_img_btn = st.button(\"ç”Ÿæˆ\", type=\"primary\", disabled=not img_prompt)\n        if generate_img_btn and img_prompt:\n            st.session_state.generate_image_trigger = {\n                \"prompt\": img_prompt,\n                \"aspect_ratio\": aspect_ratio,\n            }\n\n    st.markdown(\"---\")\n\n    # ---- è©•ä¾¡åˆ†æ ----\n    with st.expander(\"ğŸ“Š å“è³ªåˆ†æ\", expanded=False):\n        total_ratings = 0\n        positive_ratings = 0\n        model_ratings = {}\n\n        for s in st.session_state.sessions:\n            for m in s[\"messages\"]:\n                if \"rating\" in m and m[\"rating\"] is not None:\n                    total_ratings += 1\n                    if m[\"rating\"] == 1:\n                        positive_ratings += 1\n                    if \"metadata\" in m and \"model\" in m[\"metadata\"]:\n                        mod = m[\"metadata\"][\"model\"]\n                        if mod not in model_ratings:\n                            model_ratings[mod] = {\"total\": 0, \"positive\": 0}\n                        model_ratings[mod][\"total\"] += 1\n                        if m[\"rating\"] == 1:\n                            model_ratings[mod][\"positive\"] += 1\n\n        if total_ratings > 0:\n            approval_rate = (positive_ratings / total_ratings) * 100\n            st.metric(\"Positive Ratings\", f\"{positive_ratings}/{total_ratings}\", f\"{approval_rate:.1f}%\")\n            best_model = \"N/A\"\n            best_rate = -1\n            for mod, stats in model_ratings.items():\n                rate = stats[\"positive\"] / stats[\"total\"]\n                if rate > best_rate:\n                    best_rate = rate\n                    best_model = mod\n            if best_model != \"N/A\":\n                st.caption(f\"ğŸ† Best: **{best_model}** ({best_rate*100:.0f}%)\")\n        else:\n            st.caption(\"ãƒ‡ãƒ¼ã‚¿ãªã—\")\n\n    st.markdown(\"---\")\n\n    # ---- ã‚³ã‚¹ãƒˆè¡¨ç¤º ----\n    st.metric(\"Cost\", f\"${usage_stats['total_cost_usd']:.4f}\")\n    if st.session_state.session_cost > 0:\n        st.caption(f\"Session: ${st.session_state.session_cost:.4f}\")\n\n    if usage_stats[\"total_cost_usd\"] >= MAX_BUDGET_USD:\n        st.error(f\"âš ï¸ ä¸Šé™ (${MAX_BUDGET_USD}) åˆ°é”\")\n        stop_generation = True\n    else:\n        stop_generation = False\n\n    st.markdown(\"---\")\n    st.code(f\"PROJECT: {VERTEX_PROJECT}\\nLOCATION: {VERTEX_LOCATION} (Vertex AI)\")\n\n# =========================\n# Main UI\n# =========================\n\ncurrent_session_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\nfor s in st.session_state.sessions:\n    if s[\"id\"] == st.session_state.current_session_id:\n        current_session_title = s[\"title\"]\n        break\n\nst.header(current_session_title)\nst.markdown(\n    \"ä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\"\n)\n\n# ---- Vertex AI Client ----\n\n\n\nclient = get_client()\n\n# ---- å±¥æ­´è¡¨ç¤º ----\n\nmessages = get_current_messages()\nfor idx, msg in enumerate(messages):\n    with st.chat_message(msg[\"role\"]):\n        st.markdown(msg[\"content\"])\n        if msg[\"role\"] == \"model\":\n            col1, col2, col3 = st.columns([0.1, 0.1, 0.8])\n            current_rating = msg.get(\"rating\")\n            with col1:\n                if st.button(\"ğŸ‘\", key=f\"up_{idx}\"):\n                    messages[idx][\"rating\"] = 1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col2:\n                if st.button(\"ğŸ‘\", key=f\"down_{idx}\"):\n                    messages[idx][\"rating\"] = -1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col3:\n                if current_rating == 1:\n                    st.caption(\"âœ… é«˜è©•ä¾¡\")\n                elif current_rating == -1:\n                    st.caption(\"âŒ ä½è©•ä¾¡\")\n\n# =========================\n# ç”»åƒç”Ÿæˆãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°\n# =========================\n\nif hasattr(st.session_state, \"generate_image_trigger\") and st.session_state.generate_image_trigger:\n    img_data = st.session_state.generate_image_trigger\n    del st.session_state.generate_image_trigger\n\n    with st.chat_message(\"user\"):\n        st.markdown(f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\")\n        st.caption(f\"ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”: {img_data['aspect_ratio']}\")\n\n    messages.append({\"role\": \"user\", \"content\": f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\"})\n    update_current_session_messages(messages)\n\n    with st.chat_message(\"assistant\"):\n        with st.status(\"ç”»åƒã‚’ç”Ÿæˆä¸­...\", expanded=True) as status:\n            try:\n                config = types.GenerateContentConfig(\n                    response_modalities=[\"IMAGE\"],\n                    image_config=types.ImageConfig(\n                        aspect_ratio=img_data[\"aspect_ratio\"]\n                    ),\n                )\n                status.write(\"Gemini 3 Pro Imageã§ç”Ÿæˆä¸­...\")\n                response = client.models.generate_content(\n                    model=\"gemini-3-pro-image-preview\",\n                    contents=img_data[\"prompt\"],\n                    config=config,\n                )\n\n                generated_image = None\n\n                # ç”»åƒã‚’å–ã‚Šå‡ºã™\n                if getattr(response, \"candidates\", None):\n                    for candidate in response.candidates:\n                        if getattr(candidate, \"content\", None) and candidate.content.parts:\n                            for part in candidate.content.parts:\n                                if getattr(part, \"inline_data\", None):\n                                    try:\n                                        generated_image = part.as_image()\n                                    except AttributeError:\n                                        image_bytes_raw = part.inline_data.data\n                                        generated_image = Image.open(io.BytesIO(image_bytes_raw))\n                                    break\n                        if generated_image is not None:\n                            break\n\n                if generated_image is not None:\n                    st.image(generated_image, caption=img_data[\"prompt\"])\n                    buf = io.BytesIO()\n                    generated_image.save(buf, format=\"PNG\")\n                    image_bytes = buf.getvalue()\n                    st.download_button(\n                        label=\"ğŸ’¾ ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\",\n                        data=image_bytes,\n                        file_name=f\"generated_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png\",\n                        mime=\"image/png\",\n                    )\n                    messages.append(\n                        {\"role\": \"model\", \"content\": f\"âœ… ç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {img_data['prompt']}\"}\n                    )\n                    update_current_session_messages(messages)\n                    status.update(label=\"âœ… ç”»åƒç”Ÿæˆå®Œäº†\", state=\"complete\")\n                else:\n                    st.error(\"ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")\n                    status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n\n            except Exception as e:\n                status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n                st.error(f\"ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}\")\n\n# =========================\n# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›\n# =========================\n\nprompt = st.chat_input(\"ä½•ã‹èã„ã¦ãã ã•ã„...\", disabled=stop_generation)\n\nif prompt:\n    if stop_generation:\n        st.error(\"äºˆç®—ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚\")\n    else:\n        # ---- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€è¡¨ç¤º ----\n        with st.chat_message(\"user\"):\n            st.markdown(prompt)\n            if uploaded_files:\n                for uf in uploaded_files:\n                    st.caption(f\"ğŸ“ æ·»ä»˜: {uf.name}\")\n            if youtube_url:\n                st.caption(f\"ğŸ“º YouTube: {youtube_url}\")\n            if pasted_image_bytes:\n                st.caption(\"ğŸ“‹ ç”»åƒãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚Œã¾ã—ãŸ\")\n\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        update_current_session_messages(messages)\n\n        # ---- ãƒ¢ãƒ‡ãƒ«å¿œç­” ----\n        with st.chat_message(\"assistant\"):\n            status_container = st.status(\"æ€è€ƒä¸­...\", expanded=True)\n            try:\n                # ä¼šè©±å±¥æ­´\n                model_history = []\n                for msg in messages[:-1]:\n                    model_history.append(\n                        types.Content(\n                            role=msg[\"role\"],\n                            parts=[types.Part.from_text(text=msg[\"content\"])],\n                        )\n                    )\n\n                # ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³\n                current_parts = [types.Part.from_text(text=prompt)]\n\n                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«\n                for uploaded_file in uploaded_files or []:\n                    try:\n                        mime_type = get_mime_type(uploaded_file.name)\n                        bytes_data = uploaded_file.getvalue()\n                        part = types.Part.from_bytes(data=bytes_data, mime_type=mime_type)\n                        current_parts.append(part)\n                        status_container.write(f\"ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™å®Œäº†: {uploaded_file.name}\")\n                    except Exception as e:\n                        status_container.error(\n                            f\"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {uploaded_file.name} - {e}\"\n                        )\n\n                # è²¼ã‚Šä»˜ã‘ç”»åƒ\n                if pasted_image_bytes:\n                    import base64\n\n                    status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã‚’å‡¦ç†ä¸­...\")\n                    try:\n                        if isinstance(pasted_image_bytes, str):\n                            if pasted_image_bytes.startswith(\"data:\"):\n                                base64_str = pasted_image_bytes.split(\",\", 1)[1]\n                                image_bytes_decoded = base64.b64decode(base64_str)\n                            else:\n                                image_bytes_decoded = base64.b64decode(pasted_image_bytes)\n                        else:\n                            image_bytes_decoded = pasted_image_bytes\n                        part = types.Part.from_bytes(\n                            data=image_bytes_decoded, mime_type=\"image/png\"\n                        )\n                        current_parts.append(part)\n                        status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®æº–å‚™å®Œäº†\")\n                    except Exception as e:\n                        status_container.error(f\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n\n                # YouTube å­—å¹•\n                if youtube_url:\n                    vid_id = extract_youtube_id(youtube_url)\n                    if vid_id:\n                        status_container.write(\"YouTubeã®å­—å¹•ã‚’å–å¾—ä¸­...\")\n                        transcript_text = get_youtube_transcript(vid_id)\n                        current_parts.append(\n                            types.Part.from_text(text=f\"YouTube Transcript:\\n{transcript_text}\")\n                        )\n                    else:\n                        status_container.write(\"ç„¡åŠ¹ãªYouTube URLã§ã™ã€‚\")\n\n                contents_for_model = model_history + [\n                    types.Content(role=\"user\", parts=current_parts)\n                ]\n\n                # ---- Tool / Config ----\n                tools = []\n                final_candidate_count = candidate_count\n                if use_search:\n                    tools.append(types.Tool(google_search=types.GoogleSearch()))\n                    final_candidate_count = 1\n\n                # â˜… System Instruction ã®æ”¹å–„: ãƒ¡ã‚¿ç™ºè¨€ç¦æ­¢ã¨ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªæŒ¯ã‚‹èˆã„ã‚’æŒ‡ç¤º\n                base_system_instruction = (\n                    \"ã‚ãªãŸã¯é«˜åº¦ãªçŸ¥æ€§ã‚’æŒã¤å°‚é–€çš„ãªãƒªã‚µãƒ¼ãƒãƒ»ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\\n\"\n                    \"ä»¥ä¸‹ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’å³å®ˆã—ã¦ãã ã•ã„ï¼š\\n\"\n                    \"1. **ãƒ¡ã‚¿ç™ºè¨€ã®ç¦æ­¢**: ã€Œç§ã¯AIã§ã™ã€ã€Œä¸–ç•Œæœ€é«˜å³°ã®ï½ã¨ã—ã¦ã€ãªã©ã®è‡ªå·±è¨€åŠã‚„å‰ç½®ãã¯ä¸€åˆ‡è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚\\n\"\n                    \"2. **æ„å›³ã®æ±²ã¿å–ã‚Š**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã®èƒŒå¾Œã«ã‚ã‚‹æ„å›³ï¼ˆæ–‡è„ˆã€æš—é»™ã®å‰æï¼‰ã‚’æ¨æ¸¬ã—ã€è¨€è‘‰é€šã‚Šã§ã¯ãªãã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ¬å½“ã«çŸ¥ã‚ŠãŸã„ã“ã¨ã€ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n\"\n                    \"3. **æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”**: çµè«–ã‚’å…ˆã«è¿°ã¹ã€ãã®å¾Œã«è©³ç´°ãªæ ¹æ‹ ã€ã‚·ãƒŠãƒªã‚ªåˆ†æã€ãƒªã‚¹ã‚¯è¦å› ã‚’è«–ç†çš„ã«å±•é–‹ã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"4. **å®¢è¦³æ€§**: äºˆæ¸¬ã‚’è¡Œã†å ´åˆã¯ã€æ–­å®šã‚’é¿ã‘ã€è¤‡æ•°ã®ã‚·ãƒŠãƒªã‚ªï¼ˆæ¥½è¦³ã€æ‚²è¦³ã€ä¸­ç«‹ï¼‰ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"5. **å¼•ç”¨**: æ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸå ´åˆã¯ã€å¿…ãšæƒ…å ±æºã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚\"\n                )\n\n                final_answer = \"\"\n                grounding_metadata = None\n                \n                # =========================\n                # ãƒ¢ãƒ¼ãƒ‰è¨­å®šã®è§£æ\n                # =========================\n                enable_research = True  # å…¨ãƒ¢ãƒ¼ãƒ‰ã§ãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œ\n                enable_meta = \"ãƒ¡ã‚¿\" in response_mode or \"MAX\" in response_mode\n                enable_strict = \"é¬¼è»æ›¹\" in response_mode or \"MAX\" in response_mode\n\n                # =========================\n                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (é«˜é€Ÿ / é¬¼è»æ›¹)\n                # =========================\n                if not enable_research:\n                    config = types.GenerateContentConfig(\n                        temperature=0.7,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=base_system_instruction,\n                    )\n                    \n                    status_container.write(\"å›ç­”ç”Ÿæˆä¸­...\")\n                    response = client.models.generate_content(\n                        model=model_id,\n                        contents=contents_for_model,\n                        config=config,\n                    )\n                    \n                    final_answer = extract_text_from_response(response)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®—\n                    if response.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            response.usage_metadata.prompt_token_count,\n                            response.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += response.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += response.usage_metadata.candidates_token_count\n\n                    # é¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ (é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ç‰ˆ)\n                    if enable_strict:\n                        status_container.write(\"ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        reviewer_instruction = base_system_instruction + \"\"\"\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n                        review_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\nåˆç‰ˆå›ç­”:\\n{final_answer}\\n\\nãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\")])]\n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=types.GenerateContentConfig(temperature=0.1, candidate_count=1, system_instruction=reviewer_instruction)\n                        )\n                        final_answer = extract_text_from_response(review_resp)\n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        \n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(model_id, review_resp.usage_metadata.prompt_token_count, review_resp.usage_metadata.candidates_token_count)\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n\n                # =========================\n                # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰\n                # =========================\n                else:\n                    # =========================\n                    # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰: å¤šæ®µéšã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ \n                    # =========================\n                    \n                    # --- Phase 1: ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 1: ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    research_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒªã‚µãƒ¼ãƒå°‚ä»»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚æœ€çµ‚å›ç­”ã¯æ›¸ã‹ãšã€äº‹å®Ÿåé›†ã«é›†ä¸­ã™ã‚‹ã“ã¨ã€‚\n\n**èª¿æŸ»è¦³ç‚¹**:\n- è³ªå•ã«é–¢é€£ã™ã‚‹**æœ€æ–°ã®äº‹å®Ÿãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ»çµ±è¨ˆ**ï¼ˆ**2025å¹´ã®æƒ…å ±ã‚’æœ€å„ªå…ˆ**ï¼‰\n- **ç¾æ™‚ç‚¹ã§å­˜åœ¨ã™ã‚‹å…¨ã¦ã®é¸æŠè‚¢ãƒ»ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¶²ç¾…çš„ã«èª¿æŸ»**ï¼ˆä¾‹: è£½å“æ¯”è¼ƒãªã‚‰ã€æœ€æ–°ç‰ˆã ã‘ã§ãªãç›´è¿‘ã®å…¨ä¸–ä»£ã‚’èª¿æŸ»ï¼‰\n- å…¬å¼æƒ…å ±ã‚„ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã‹ã‚‰ã®å¼•ç”¨\n- é–¢é€£ã™ã‚‹èƒŒæ™¯æƒ…å ±ã‚„æ–‡è„ˆ\n- ç«¶åˆãƒ»ä»£æ›¿æ¡ˆãƒ»æ¯”è¼ƒå¯¾è±¡ã®**å®Œå…¨ãªãƒªã‚¹ãƒˆ**\n- ãƒªã‚¹ã‚¯ãƒ»åˆ¶ç´„ãƒ»æ³¨æ„ç‚¹ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n- å‚è€ƒã«ã—ãŸä¸»è¦ãªæƒ…å ±æºã®URL\n\n**é‡è¦**: \n- çµè«–ã‚„æ¨å¥¨ã¯æ›¸ã‹ãšã€å¾Œå·¥ç¨‹ãŒåˆ¤æ–­ã§ãã‚‹èª¿æŸ»ãƒ¡ãƒ¢ã«é›†ä¸­ã™ã‚‹ã“ã¨\n- **å¿…ãšæ¤œç´¢æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã€æœ€æ–°ã®æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã“ã¨**\n- **æ¤œç´¢çµæœã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æ—¥ä»˜ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒ»ãƒ¢ãƒ‡ãƒ«åã‚’å„ªå…ˆçš„ã«è¨˜è¼‰ã™ã‚‹ã“ã¨**\n- **æ¯”è¼ƒå¯¾è±¡ã¨ãªã‚‹é¸æŠè‚¢ã‚’è¦‹è½ã¨ã•ãªã„ã‚ˆã†ã€è¤‡æ•°ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è©¦ã™ã“ã¨**ï¼ˆä¾‹: ã€ŒiPhone æœ€æ–°ãƒ¢ãƒ‡ãƒ« 2025ã€ã€ŒiPhone 17ã€ã€ŒiPhone 2025å¹´ç™ºå£²ã€ãªã©ï¼‰\n- **ã€Œã“ã‚Œã‚ˆã‚Šæ–°ã—ã„ãƒ¢ãƒ‡ãƒ«/ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯å­˜åœ¨ã—ãªã„ã‹ï¼Ÿã€ã‚’å¸¸ã«ç¢ºèªã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ï¼ˆ2024å¹´ä»¥å‰ãªã©ï¼‰ã—ã‹è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãã®æ—¨ã‚’æ˜è¨˜ã™ã‚‹ã“ã¨\n\"\"\"\n\n                    # éå»ã®é–¢é€£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—\n                    past_context = get_relevant_context(prompt, st.session_state.sessions, st.session_state.current_session_id)\n                    \n                    # ãƒªã‚µãƒ¼ãƒç”¨ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ§‹ç¯‰\n                    research_parts = [types.Part(text=f\"ã“ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š\\n{prompt}\")]\n                    \n                    if past_context:\n                        research_parts.insert(0, types.Part(text=\"ä»¥ä¸‹ã¯éå»ã®é–¢é€£ãƒãƒ£ãƒƒãƒˆã‹ã‚‰æŠ½å‡ºã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã™ï¼š\\n\\n\" + past_context))\n                    \n                    research_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=research_parts)\n                    ]\n                    \n                    research_config = types.GenerateContentConfig(\n                        temperature=0.2,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=research_instruction,\n                    )\n                    \n                    research_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=research_contents,\n                        config=research_config,\n                    )\n                    \n                    research_text = extract_text_from_response(research_resp)\n                    \n                    # ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºã®ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ±ã‚’ä¿å­˜\n                    if research_resp.candidates and research_resp.candidates[0].grounding_metadata:\n                        grounding_metadata = research_resp.candidates[0].grounding_metadata\n                    \n                    status_container.write(\"âœ“ ãƒªã‚µãƒ¼ãƒå®Œäº†\")\n                    with status_container.expander(\"åé›†ã—ãŸèª¿æŸ»ãƒ¡ãƒ¢\", expanded=False):\n                        st.markdown(research_text)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1)\n                    if research_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            research_resp.usage_metadata.prompt_token_count,\n                            research_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += research_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += research_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 1.5: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    questions_text = \"\"\n                    if enable_meta:\n                        status_container.write(\"Phase 1.5: ãƒ¡ã‚¿è³ªå•ç”Ÿæˆä¸­...\")\n                        \n                        question_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ç›®çš„**: \nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•ã¨èª¿æŸ»ãƒ¡ãƒ¢ã‚’è¸ã¾ãˆã¦ã€ã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±ãç†è§£ã™ã‚‹ãŸã‚ã®ã€Œé‹­ã„ã‚µãƒ–è³ªå•ã€ã‚’ä½œæˆã™ã‚‹ã“ã¨ã€‚\n\n**ãƒ«ãƒ¼ãƒ«**:\n- æœ€å¤§5å€‹ã¾ã§\n- å„è³ªå•ã¯1-2è¡Œã§å…·ä½“çš„ã‹ã¤é‹­ã\n- ä»¥ä¸‹ã®è¦³ç‚¹ã‚’æ„è­˜:\n  1. å‰æãŒå´©ã‚Œã‚‹å¯èƒ½æ€§ã¯ã©ã“ã‹ï¼Ÿ\n  2. å¼·æ°—/å¼±æ°—ã‚·ãƒŠãƒªã‚ªã®åˆ†å²ç‚¹ã¯ä½•ã‹ï¼Ÿ\n  3. ç«¶åˆãƒ»æŠ€è¡“ãƒ»è¦åˆ¶ã®ä¸ç¢ºå®Ÿæ€§ã¯ï¼Ÿ\n  4. ã€Œäºˆæ¸¬ãŒå¤–ã‚Œã‚‹ã¨ã—ãŸã‚‰ã©ã‚“ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ï¼Ÿã€\n\n**å‡ºåŠ›**: ç®‡æ¡æ›¸ãï¼ˆQ1, Q2...ï¼‰ã®ã¿\n\"\"\"\n\n                        question_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•:\\n{prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\nã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±æ˜ã‚Šã™ã‚‹ãŸã‚ã®é‡è¦ãªã‚µãƒ–è³ªå•ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\")])]\n                        \n                        question_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=question_contents,\n                            config=types.GenerateContentConfig(\n                                temperature=0.4,\n                                candidate_count=1,\n                                system_instruction=question_instruction,\n                            )\n                        )\n                        \n                        questions_text = extract_text_from_response(question_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¡ã‚¿è³ªå•ç”Ÿæˆå®Œäº†\")\n                        with status_container.expander(\"ç”Ÿæˆã•ã‚ŒãŸãƒ¡ã‚¿è³ªå•\", expanded=False):\n                            st.markdown(questions_text)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1.5)\n                        if question_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                question_resp.usage_metadata.prompt_token_count,\n                                question_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += question_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += question_resp.usage_metadata.candidates_token_count\n\n                    # --- Phase 2: çµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 2: çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    if enable_meta:\n                        deep_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã¨ãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ã‚’æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**æ§‹æˆ**:\n1. **æ·±æ˜ã‚Šè€ƒå¯Ÿ**ï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n2. **çµè«–**ï¼ˆ2-3è¡Œï¼‰\n3. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n4. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨\n\"\"\"\n                    else:\n                        deep_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã‚’å”¯ä¸€ã®æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**æ§‹æˆ**:\n1. **çµè«–**ï¼ˆ2-3è¡Œã§æ˜ç¢ºã«ï¼‰\n2. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n3. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«åã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ã¨æ–°ã—ã„æƒ…å ±ãŒæ··åœ¨ã™ã‚‹å ´åˆã¯ã€æ–°ã—ã„æƒ…å ±ã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n\"\"\"\n                    \n                    synthesis_prompt_text = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if enable_meta and questions_text:\n                        synthesis_prompt_text += f\"==== ãƒ¡ã‚¿è³ªå•ä¸€è¦§ ====\\n{questions_text}\\n==== ãƒ¡ã‚¿è³ªå•ã“ã“ã¾ã§ ====\\n\\næŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n2. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»åˆ†æãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    else:\n                        synthesis_prompt_text += \"ä¸Šè¨˜ãƒ¡ãƒ¢ã‚’æ ¹æ‹ ã«ã€æœ€çµ‚å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å¿…ãšä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚**\"\n\n                    synthesis_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=[\n                            types.Part(text=synthesis_prompt_text)\n                        ])\n                    ]\n                    \n                    synthesis_config = types.GenerateContentConfig(\n                        temperature=0.3,\n                        candidate_count=1,\n                        tools=[],  # çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºã§ã¯æ¤œç´¢OFF\n                        system_instruction=deep_instruction,\n                    )\n                    \n                    synthesis_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=synthesis_contents,\n                        config=synthesis_config,\n                    )\n                    \n                    draft_answer = extract_text_from_response(synthesis_resp)\n                    \n                    status_container.write(\"âœ“ çµ±åˆå®Œäº†\")\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 2)\n                    if synthesis_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            synthesis_resp.usage_metadata.prompt_token_count,\n                            synthesis_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += synthesis_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += synthesis_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    if enable_strict:\n                        status_container.write(\"Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        \n\n                        reviewer_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™ã€‚ãŸã ã—ã€**èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’å„ªå…ˆã—ã€æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã™ã‚‹ã“ã¨**ã€‚\n\n**ãƒ¬ãƒ“ãƒ¥ãƒ¼è¦³ç‚¹**:\n- äº‹å®Ÿã¨æ¨æ¸¬ã‚’æ˜ç¢ºã«åˆ†ã‘ã‚‹\n- éåº¦ã«è‡ªä¿¡ã®ã‚ã‚‹æ–­å®šã‚’å¼±ã‚ã‚‹\n- æ•°å­—ã‚„å›ºæœ‰åè©ãŒèª¿æŸ»ãƒ¡ãƒ¢ã¨çŸ›ç›¾ã—ã¦ã„ãªã„ã‹ç¢ºèª\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ãƒ¢ãƒ‡ãƒ«ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ãŒæ­£ã—ãä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª**\n- **å¤ã„æƒ…å ±ã§ä¸Šæ›¸ãã—ã¦ã„ãªã„ã‹ç¢ºèª**\n- è¦‹è½ã¨ã—ã¦ã„ã‚‹é‡è¦ãªãƒªã‚¹ã‚¯ãƒ»ã‚·ãƒŠãƒªã‚ªãŒã‚ã‚Œã°è¿½åŠ \n\n**é‡è¦**: \n- èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ãŒæœ€æ–°ã§ã‚ã‚‹å ´åˆã€ãã‚Œã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n- ã‚ãªãŸã®çŸ¥è­˜ãŒå¤ã„å ´åˆã¯ã€èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’ä¿¡é ¼ã™ã‚‹ã“ã¨\n\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n\n                        review_contents = [\n                            types.Content(role=\"user\", parts=[\n                                types.Part.from_text(\n                                    text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\n\"\n                                    f\"==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                                    f\"åˆç‰ˆå›ç­”:\\n{draft_answer}\\n\\n\"\n                                    \"ä¸Šè¨˜ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚**\"\n                                )\n                            ])\n                        ]\n                        \n                        review_config = types.GenerateContentConfig(\n                            temperature=0.1,\n                            candidate_count=1,\n                            system_instruction=reviewer_instruction,\n                        )\n                        \n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=review_config,\n                        )\n                        \n                        final_answer = extract_text_from_response(review_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        with status_container.expander(\"åˆç‰ˆã¨ã®æ¯”è¼ƒ\", expanded=False):\n                            st.markdown(\"**åˆç‰ˆ:**\")\n                            st.markdown(draft_answer[:500] + \"...\" if len(draft_answer) > 500 else draft_answer)\n                            st.markdown(\"**ä¿®æ­£ç‰ˆ:**\")\n                            st.markdown(final_answer[:500] + \"...\" if len(final_answer) > 500 else final_answer)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 3)\n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                review_resp.usage_metadata.prompt_token_count,\n                                review_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n                    else:\n                        final_answer = draft_answer\n\n                save_usage(usage_stats)\n                status_container.update(label=\"å®Œäº†ï¼\", state=\"complete\", expanded=False)\n\n                # ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤º\n                st.caption(f\"ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_id}\")\n                st.markdown(final_answer)\n\n                # ---- ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ± ----\n                if grounding_metadata:\n                    st.markdown(\"---\")\n                    st.subheader(\"ğŸ“š æƒ…å ±æºã¨å¼•ç”¨\")\n                    if grounding_metadata.grounding_chunks:\n                        st.markdown(\"**æ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:**\")\n                        unique_sources = {}\n                        import urllib.parse\n\n                        for chunk in grounding_metadata.grounding_chunks:\n                            if getattr(chunk, \"web\", None):\n                                uri = getattr(chunk.web, \"uri\", None)\n                                title = getattr(chunk.web, \"title\", \"æƒ…å ±æº\")\n                                if uri and uri not in unique_sources:\n                                    parsed = urllib.parse.urlparse(uri)\n                                    domain = parsed.netloc.replace(\"www.\", \"\")\n                                    unique_sources[uri] = {\n                                        \"title\": title,\n                                        \"domain\": domain,\n                                    }\n                        for i, (uri, info) in enumerate(unique_sources.items(), 1):\n                            st.markdown(f\"{i}. **[{info['title']}]({uri})**\")\n                            st.caption(f\"   å‡ºå…¸: {info['domain']}\")\n\n                messages.append({\"role\": \"model\", \"content\": final_answer})\n                update_current_session_messages(messages)\n\n            except Exception as e:\n                status_container.update(label=\"Error\", state=\"error\")\n                err_text = str(e)\n                if \"RESOURCE_EXHAUSTED\" in err_text or \"429\" in err_text:\n                    st.error(\n                        \"âš ï¸ Vertex AI / Gemini ã®ã‚¯ã‚©ãƒ¼ã‚¿ã«é”ã—ã¾ã—ãŸã€‚\\n\\n\"\n                        \"ãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ / æ—¥æ¬¡åˆ¶é™ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\\n\"\n                        \"ãƒ»ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                        \"ãƒ»Google Cloud Console ã®ã€ŒVertex AI â†’ ä½¿ç”¨çŠ¶æ³ã€ã‹ã‚‰ã‚¯ã‚©ãƒ¼ã‚¿çŠ¶æ³ã‚’ç¢ºèªã§ãã¾ã™ã€‚\"\n                    )\n                elif \"NOT_FOUND\" in err_text and \"Publisher Model\" in err_text:\n                    st.error(\n                        \"âš ï¸ æŒ‡å®šã—ãŸãƒ¢ãƒ‡ãƒ«ãŒã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ / ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\\n\"\n                        \"ãƒ»ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ¢ãƒ‡ãƒ«IDã‚’ã€2.5ç³» ã¾ãŸã¯ 3 Pro ã«å¤‰æ›´ã—ã¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                    )\n                else:\n                    st.error(f\"An error occurred: {e}\")\n"
                },
                {
                    "role": "model",
                    "content": "### çµè«–\nç¾çŠ¶ã®ã‚³ãƒ¼ãƒ‰ãƒ­ã‚¸ãƒƒã‚¯ã«ãŠã„ã¦ã€**ã€ŒÎ²2. ç†Ÿè€ƒ (æœ¬æ°—MAX)ã€ãŒæœ€ã‚‚å„ªç§€ï¼ˆé«˜å“è³ªï¼‰ãªå›ç­”ã‚’ç”Ÿæˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«**ã§ã™ã€‚\n\nã“ã®ãƒ¢ãƒ¼ãƒ‰ã¯ã€ã‚³ãƒ¼ãƒ‰ã«å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ã€Œãƒªã‚µãƒ¼ãƒï¼ˆæƒ…å ±åé›†ï¼‰ã€ã€Œãƒ¡ã‚¿æ€è€ƒï¼ˆå¤šè§’çš„ãªæ·±æ˜ã‚Šï¼‰ã€ã€Œé¬¼è»æ›¹ï¼ˆå³æ ¼ãªå“è³ªãƒã‚§ãƒƒã‚¯ï¼‰ã€ã®å…¨æ©Ÿèƒ½ã‚’å”¯ä¸€å®Ÿè¡Œã™ã‚‹ã€Œå…¨éƒ¨å…¥ã‚Šã€ã®æ§‹æˆã¨ãªã£ã¦ãŠã‚Šã€æœ€ã‚‚æ·±ã„æ´å¯Ÿã¨é«˜ã„æ­£ç¢ºæ€§ãŒæœŸå¾…ã§ãã¾ã™ã€‚\n\n---\n\n### è©³ç´°åˆ†æï¼šãƒ¢ãƒ¼ãƒ‰åˆ¥å†…éƒ¨ãƒ­ã‚¸ãƒƒã‚¯ã®æ¯”è¼ƒ\n\næä¾›ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã®ãƒ•ãƒ©ã‚°åˆ¤å®šï¼ˆ`enable_meta`, `enable_strict`ï¼‰ãŠã‚ˆã³ `enable_research = True`ï¼ˆå›ºå®šï¼‰ã®å®Ÿè£…ã«åŸºã¥ãã€å„ãƒ¢ãƒ¼ãƒ‰ã®å‡¦ç†ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ•´ç†ã—ã¾ã—ãŸã€‚\n\n| ãƒ¢ãƒ¼ãƒ‰å | Phase 1<br>ãƒªã‚µãƒ¼ãƒ | Phase 1.5<br>ãƒ¡ã‚¿æ€è€ƒ | Phase 2<br>çµ±åˆå›ç­” | Phase 3<br>é¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ | å®Ÿè£…ä¸Šã®æŒ™å‹• |\n| :--- | :---: | :---: | :---: | :---: | :--- |\n| **Î²1. é€šå¸¸ (é«˜é€Ÿ)** | âœ… | âŒ | âœ… | âŒ | å®Ÿè³ªçš„ã«ã€Œç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)ã€ã¨åŒä¸€æ©Ÿèƒ½ã€‚ |\n| **1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)** | âœ… | âŒ | âœ… | âŒ | æ¤œç´¢ã‚’è¡Œã„ã€ãã®çµæœã‚’ã¾ã¨ã‚ã‚‹æ¨™æº–çš„ãªRAGã€‚ |\n| **2. ç†Ÿè€ƒ + é¬¼è»æ›¹** | âœ… | âŒ | âœ… | âœ… | å›ç­”å¾Œã«è‡ªå·±æ‰¹åˆ¤ãƒ»ä¿®æ­£ã‚’è¡Œã„ã€ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’æŠ‘åˆ¶ã€‚ |\n| **3. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)** | âœ… | âœ… | âœ… | âŒ | å›ç­”å‰ã«ã€Œé‹­ã„ã‚µãƒ–è³ªå•ã€ã‚’è‡ªå•è‡ªç­”ã—ã€è€ƒå¯Ÿã‚’æ·±ã‚ã‚‹ã€‚ |\n| **Î²2. ç†Ÿè€ƒ (æœ¬æ°—MAX)** | **âœ…** | **âœ…** | **âœ…** | **âœ…** | **å…¨ãƒ•ã‚§ãƒ¼ã‚ºã‚’å®Ÿè¡Œã™ã‚‹æœ€ä¸Šä½ãƒ¢ãƒ¼ãƒ‰ã€‚** |\n\n#### ã€Œæœ¬æ°—MAXã€ãŒæœ€ã‚‚å„ªç§€ã§ã‚ã‚‹æŠ€è¡“çš„æ ¹æ‹ \n1.  **å…¥åŠ›å“è³ªã®å‘ä¸Šï¼ˆãƒ¡ã‚¿æ€è€ƒï¼‰**:\n    *   Phase 1.5ã§ã€Œå‰æã‚’ç–‘ã†ã€ã€Œåˆ¥ã‚·ãƒŠãƒªã‚ªã‚’è€ƒãˆã‚‹ã€ã¨ã„ã£ãŸãƒ¡ã‚¿èªçŸ¥çš„ãªå•ã„ã‚’ç”Ÿæˆãƒ»å›ç­”ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å˜ãªã‚‹æ¤œç´¢çµæœã®è¦ç´„ã§ã¯ãªã„ã€å¤šè§’çš„ãªè¦–ç‚¹ã‚’å«ã‚“ã å›ç­”ç”ŸæˆãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚\n2.  **å‡ºåŠ›å“è³ªã®æ‹…ä¿ï¼ˆé¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰**:\n    *   Phase 3ã§ã€ç”Ÿæˆã•ã‚ŒãŸå›ç­”ãƒ‰ãƒ©ãƒ•ãƒˆã«å¯¾ã—ã€Œäº‹å®Ÿã¨æ¨æ¸¬ã®åŒºåˆ¥ã€ã€Œæœ€æ–°æƒ…å ±ã®ç¶­æŒã€ãªã©ã‚’å³æ ¼ã«ãƒã‚§ãƒƒã‚¯ã—ã€ä¿®æ­£ç‰ˆã‚’ä½œæˆã—ã¾ã™ã€‚\n\n---\n\n### ã‚³ãƒ¼ãƒ‰å®Ÿè£…ã«é–¢ã™ã‚‹é‡è¦ãªæ³¨æ„ç‚¹\n\nã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®è¦³ç‚¹ã‹ã‚‰ã€ä»¥ä¸‹ã®å®Ÿè£…ä»•æ§˜ã«ç•™æ„ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n\n1.  **ã€Œé€šå¸¸ (é«˜é€Ÿ)ã€ãƒ¢ãƒ¼ãƒ‰ã¯é«˜é€ŸåŒ–ã•ã‚Œãªã„**:\n    *   ã‚³ãƒ¼ãƒ‰å†…ã§ `enable_research = True` ãŒå›ºå®šã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€`if not enable_research:` ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆæ¤œç´¢ãªã—ã®é«˜é€Ÿãƒ‘ã‚¹ï¼‰ã¯å®Ÿè¡Œã•ã‚Œã¾ã›ã‚“ã€‚\n    *   çµæœã¨ã—ã¦ã€ã€ŒÎ²1. é€šå¸¸ (é«˜é€Ÿ)ã€ã‚’é¸æŠã—ã¦ã‚‚æ¤œç´¢å‡¦ç†ï¼ˆPhase 1ï¼‰ãŒå¿…ãšå®Ÿè¡Œã•ã‚Œã€ã€Œ1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)ã€ã¨å…¨ãåŒã˜å‡¦ç†ãƒ•ãƒ­ãƒ¼ã¨ãªã‚Šã¾ã™ã€‚\n2.  **ã‚³ã‚¹ãƒˆã¨ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•**:\n    *   ã€Œæœ¬æ°—MAXã€ã¯APIã‚’è¨ˆ4å›ï¼ˆãƒªã‚µãƒ¼ãƒâ†’ãƒ¡ã‚¿è³ªå•â†’çµ±åˆâ†’ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰å‘¼ã³å‡ºã™ãŸã‚ã€**ã‚³ã‚¹ãƒˆã¨å¾…ã¡æ™‚é–“ãŒä»–ã®ãƒ¢ãƒ¼ãƒ‰ã®ç´„2ã€œ3å€**ã«ãªã‚Šã¾ã™ã€‚ã€Œå„ªç§€ã•ã€ã‚’ã€Œå¿œç­”é€Ÿåº¦ã€ã‚„ã€Œå®‰ã•ã€ã§å®šç¾©ã™ã‚‹å ´åˆã¯ã€ã“ã®ãƒ¢ãƒ¼ãƒ‰ã¯æœ€é©ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"
                }
            ]
        },
        {
            "id": "f3a86dbe-77a8-4221-a319-391cabea8369",
            "title": "ç¾çŠ¶ã®ã‚³ãƒ¼ãƒ‰ã§ã€å›ç­”ãƒ¢ãƒ¼ãƒ‰ãŒè¤‡æ•°ã‚ã‚‹ãŒã€...",
            "timestamp": "2025-11-30T14:03:35.681639",
            "messages": [
                {
                    "role": "user",
                    "content": "ç¾çŠ¶ã®ã‚³ãƒ¼ãƒ‰ã§ã€å›ç­”ãƒ¢ãƒ¼ãƒ‰ãŒè¤‡æ•°ã‚ã‚‹ãŒã€æœ€ã‚‚å„ªç§€ãªãƒ¢ãƒ‡ãƒ«ã¯ç†Ÿè€ƒ(æœ¬æ°—MAX)ã‹ã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã®ã»ã†ãŒå„ªç§€ã‹?\nimport os\nimport uuid\nimport datetime\nimport streamlit as st\nfrom dotenv import load_dotenv\nfrom google import genai\nfrom google.genai import types\nfrom PIL import Image\nimport io\nfrom logic import (\n    USAGE_FILE, SESSIONS_FILE, MAX_BUDGET_USD, PRICING,\n    VERTEX_PROJECT, VERTEX_LOCATION,\n    load_usage, save_usage, calculate_cost, get_mime_type,\n    extract_youtube_id, get_youtube_transcript, get_relevant_context,\n    extract_text_from_response, load_sessions, save_sessions, get_client\n)\n\ntry:\n    from st_img_pastebutton import paste\n    import_error_msg = None\nexcept ImportError as e:\n    paste = None\n    import_error_msg = str(e)\n\n# =========================\n# ç’°å¢ƒå¤‰æ•° & å®šæ•°\n# =========================\n\nload_dotenv()\n\n\n\nst.set_page_config(page_title=\"Gemini 3 Web Studio\", layout=\"wide\")\n\n# =========================\n# Helper Functions\n# =========================\n\n# =========================\n# Helper Functions\n# =========================\n# Moved to logic.py\n\n# =========================\n# Session Management\n# =========================\n\n\n\ndef create_new_session():\n    current_sessions = load_sessions()\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": [],\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.rerun()\n\ndef switch_session(session_id):\n    st.session_state.current_session_id = session_id\n    st.rerun()\n\ndef update_current_session_messages(messages):\n    if st.session_state.current_session_id:\n        current_sessions = load_sessions()\n        for session in current_sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                session[\"messages\"] = messages\n                if session[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(messages) > 0:\n                    first_msg = messages[0][\"content\"]\n                    session[\"title\"] = (first_msg[:20] + \"...\") if len(first_msg) > 20 else first_msg\n                session[\"timestamp\"] = datetime.datetime.now().isoformat()\n                break\n        save_sessions(current_sessions)\n        st.session_state.sessions = current_sessions\n\ndef get_current_messages():\n    if st.session_state.current_session_id:\n        for session in st.session_state.sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                return session[\"messages\"]\n    return []\n\ndef delete_session(session_id):\n    current_sessions = load_sessions()\n    current_sessions = [s for s in current_sessions if s[\"id\"] != session_id]\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    if st.session_state.current_session_id == session_id:\n        st.session_state.current_session_id = None\n        if st.session_state.sessions:\n            st.session_state.current_session_id = st.session_state.sessions[0][\"id\"]\n    st.rerun()\n\ndef branch_session():\n    \"\"\"ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚’åˆ†å²\"\"\"\n    current_messages = get_current_messages()\n    current_sessions = load_sessions()\n    \n    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—\n    current_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n    for session in current_sessions:\n        if session[\"id\"] == st.session_state.current_session_id:\n            current_title = session[\"title\"]\n            break\n    \n    # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": f\"{current_title} (åˆ†å²)\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": current_messages.copy(),  # ç¾åœ¨ã®å±¥æ­´ã‚’ã‚³ãƒ”ãƒ¼\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    \n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.session_state.session_cost = 0.0  # ã‚³ã‚¹ãƒˆãƒªã‚»ãƒƒãƒˆ\n    st.rerun()\n\n# =========================\n# Initialization\n# =========================\n\nif \"sessions\" not in st.session_state:\n    st.session_state.sessions = load_sessions()\n\nif \"current_session_id\" not in st.session_state:\n    # Always create a new session when the app starts\n    create_new_session()\n\nif \"session_cost\" not in st.session_state:\n    st.session_state.session_cost = 0.0\n\nusage_stats = load_usage()\n\n# =========================\n# Sidebar\n# =========================\n\nwith st.sidebar:\n    st.markdown(\"\"\"\n    <div style=\"text-align: center; padding: 0; margin: 0; margin-top: -1rem;\">\n        <h1 style=\"font-size: 18px; font-weight: 700; margin: 0; padding: 0; letter-spacing: 1px;\">\n            Gemini 3<br/>Studio\n        </h1>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n\n    col1, col2 = st.columns(2)\n    with col1:\n        if st.button(\"â• æ–°è¦\", use_container_width=True):\n            create_new_session()\n    with col2:\n        if st.button(\"ğŸŒ± åˆ†å²\", use_container_width=True):\n            branch_session()\n\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    current_messages = get_current_messages()\n    if current_messages:\n        with st.expander(\"ğŸ”— å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ\", expanded=False):\n            export_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n            for s in st.session_state.sessions:\n                if s[\"id\"] == st.session_state.current_session_id:\n                    export_title = s[\"title\"]\n                    break\n\n            export_md = f\"# {export_title}\\n\\n\"\n            export_md += f\"**ä½œæˆæ—¥æ™‚**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n---\\n\\n\"\n            for msg in current_messages:\n                role_label = \"ğŸ§‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼\" if msg[\"role\"] == \"user\" else \"ğŸ¤– AI\"\n                export_md += f\"## {role_label}\\n\\n{msg['content']}\\n\\n---\\n\\n\"\n\n            if st.button(\"ãƒªãƒ³ã‚¯ç”Ÿæˆ\", use_container_width=True):\n                with st.spinner(\"ç”Ÿæˆä¸­...\"):\n                    try:\n                        import urllib.request\n                        import urllib.parse\n\n                        data = urllib.parse.urlencode(\n                            {\"content\": export_md, \"expiry_days\": 7, \"syntax\": \"md\"}\n                        ).encode()\n\n                        req = urllib.request.Request(\"https://dpaste.org/api/\", data=data)\n                        req.add_header(\"User-Agent\", \"Mozilla/5.0 (Gemini3Studio)\")\n\n                        with urllib.request.urlopen(req) as response:\n                            share_url = response.read().decode(\"utf-8\").strip()\n                            st.success(\"ä½œæˆå®Œäº†ï¼\")\n                            st.code(share_url)\n                            st.caption(\"â€»7æ—¥é–“æœ‰åŠ¹\")\n                    except Exception as e:\n                        st.error(f\"ã‚¨ãƒ©ãƒ¼: {e}\")\n\n    st.markdown(\"---\")\n\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    with st.expander(\"ğŸ“ æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«\", expanded=False):\n        uploaded_files = st.file_uploader(\n            \"ãƒ•ã‚¡ã‚¤ãƒ«\",\n            accept_multiple_files=True,\n            type=[\"png\", \"jpg\", \"jpeg\", \"mp4\", \"mov\", \"txt\", \"pdf\", \"csv\"],\n            label_visibility=\"collapsed\"\n        )\n\n    # ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ï¼ˆExpanderã®å¤–ã«å‡ºã™ï¼‰\n    if paste:\n        if \"paste_key\" not in st.session_state:\n            st.session_state.paste_key = 0\n        try:\n            pasted_image_bytes = paste(\n                label=\"ğŸ“‹ è²¼ä»˜\",\n                key=f\"paste_btn_{st.session_state.paste_key}\",\n            )\n        except Exception as e:\n            st.error(f\"Error: {e}\")\n        \n        if pasted_image_bytes:\n            st.success(\"è²¼ä»˜å®Œäº†\")\n            st.image(pasted_image_bytes, caption=\"ç”»åƒ\", use_container_width=True)\n            if st.button(\"ğŸ—‘ï¸ ã‚¯ãƒªã‚¢\", key=\"clear_paste\"):\n                st.session_state.paste_key += 1\n                st.rerun()\n    else:\n        st.warning(\"Clipboard lib missing\")\n\n    # ---- YouTube URL ----\n    with st.expander(\"ğŸ“º YouTubeåˆ†æ\", expanded=False):\n        youtube_url = st.text_input(\"URL\", placeholder=\"https://youtu.be/...\", label_visibility=\"collapsed\")\n\n    st.markdown(\"---\")\n    \n    st.markdown(\"---\")\n    \n    # ---- å›ç­”ãƒ¢ãƒ¼ãƒ‰ ----\n    with st.expander(\"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰\", expanded=True):\n        mode_type = st.radio(\n            \"ã‚¿ã‚¤ãƒ—\",\n            [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n            index=0,\n            horizontal=True,\n            label_visibility=\"collapsed\"\n        )\n        \n        if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n            response_mode = st.radio(\n                \"ãƒ¢ãƒ¼ãƒ‰\",\n                [\n                    \"2. ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                    \"3. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                    \"Î²2. ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n                ],\n                index=0\n            )\n        elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n            response_mode = st.radio(\n                \"ãƒ¢ãƒ¼ãƒ‰\",\n                [\n                    \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n                ],\n                index=0\n            )\n        else:\n            response_mode = st.radio(\n                \"ãƒ¢ãƒ¼ãƒ‰\",\n                [\n                    \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n                ],\n                index=0\n            )\n    \n    strict_mode = False\n    \n    # ---- è¨­å®š (ãƒ¢ãƒ‡ãƒ«ãªã©) ----\n    with st.expander(\"âš™ï¸ è¨­å®š\", expanded=False):\n        model_options = [\n            \"gemini-3-pro-preview\",\n            \"gemini-2.5-pro\",\n            \"gemini-2.5-flash\",\n            \"gemini-2.5-flash-lite\",\n            \"gemini-2.0-flash\",\n        ]\n        model_id = st.selectbox(\"ãƒ¢ãƒ‡ãƒ«ID\", options=model_options, index=0)\n\n        use_search = st.toggle(\"Googleæ¤œç´¢\", value=True)\n        candidate_count = st.slider(\"å€™è£œæ•°\", min_value=1, max_value=3, value=3)\n\n    st.markdown(\"---\")\n\n    # ---- å±¥æ­´æ¤œç´¢ ----\n    search_query = st.text_input(\"ğŸ” å±¥æ­´æ¤œç´¢\", placeholder=\"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰...\")\n    if search_query:\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if search_query.lower() in s[\"title\"].lower():\n                filtered_sessions.append(s)\n                continue\n            found = False\n            for m in s[\"messages\"]:\n                if search_query.lower() in m[\"content\"].lower():\n                    filtered_sessions.append(s)\n                    found = True\n                    break\n            if not found:\n                pass\n    else:\n        # æ¤œç´¢ã—ã¦ã„ãªã„å ´åˆ: ç©ºã®ã€Œæ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã€ã‚’é™¤å¤–ï¼ˆç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯é™¤ãï¼‰\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if s[\"id\"] == st.session_state.current_session_id:\n                filtered_sessions.append(s)\n                continue\n            if s[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(s[\"messages\"]) == 0:\n                continue\n            filtered_sessions.append(s)\n\n    # CSSã§è¦‹ã‚„ã™ãä½¿ã„ã‚„ã™ãæœ€é©åŒ–\n    st.markdown(\"\"\"\n    <style>\n    /* å…¨ä½“ã®ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºç¸®å° */\n    .stApp, .stMarkdown, .stButton, .stSelectbox, .stTextInput, .stTextArea {\n        font-size: 12px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ä½™ç™½ã‚’æ¥µé™ã¾ã§è©°ã‚ã‚‹ */\n    section[data-testid=\"stSidebar\"] .block-container {\n        padding-top: 0rem !important;\n        padding-bottom: 0.3rem !important;\n        padding-left: 0.5rem !important;\n        padding-right: 0.5rem !important;\n    }\n    /* å„è¦ç´ é–“ã®éš™é–“ã‚’è©°ã‚ã‚‹ */\n    div[data-testid=\"stVerticalBlock\"] > div {\n        gap: 0.1rem !important;\n    }\n    /* Expanderã®ä½™ç™½å‰Šæ¸› */\n    .streamlit-expanderHeader {\n        font-size: 11px !important;\n        padding-top: 0px !important;\n        padding-bottom: 0px !important;\n        min-height: 1.3rem !important;\n    }\n    .streamlit-expanderContent {\n        padding-top: 0px !important;\n        padding-bottom: 0px !important;\n    }\n    /* éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã®ã‚¿ã‚¤ãƒˆãƒ« */\n    div[data-testid=\"stExpander\"] summary p {\n        font-size: 10px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ */\n    section[data-testid=\"stSidebar\"] button p {\n        font-size: 10px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã« */\n    section[data-testid=\"stSidebar\"] button {\n        padding: 0rem 0.2rem !important;\n        min-height: 1.4rem !important;\n        font-size: 10px !important;\n        margin-bottom: 0px !important;\n    }\n    /* ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®ãƒ©ãƒ™ãƒ«ã‚’å°ã•ã */\n    section[data-testid=\"stSidebar\"] .stRadio label {\n        font-size: 10px !important;\n    }\n    section[data-testid=\"stSidebar\"] .stRadio > label > div {\n        font-size: 10px !important;\n    }\n    /* ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ‡ã‚Šè©°ã‚ã‚‹ï¼ˆæ”¹è¡Œã•ã›ãªã„ï¼‰ */\n    section[data-testid=\"stSidebar\"] label, \n    section[data-testid=\"stSidebar\"] p,\n    section[data-testid=\"stSidebar\"] span {\n        white-space: nowrap !important;\n        overflow: hidden !important;\n        text-overflow: ellipsis !important;\n    }\n    /* åŒºåˆ‡ã‚Šç·š */\n    hr {\n        margin-top: 0.1rem !important;\n        margin-bottom: 0.1rem !important;\n    }\n    /* ãƒ˜ãƒƒãƒ€ãƒ¼ç¸®å° */\n    h1, h2, h3 {\n        padding-top: 0rem !important;\n        padding-bottom: 0rem !important;\n        margin-top: 0rem !important;\n        margin-bottom: 0rem !important;\n    }\n    </style>\n    \"\"\", unsafe_allow_html=True)\n    \n    # ç›´è¿‘5ä»¶ã¨éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«åˆ†å‰²\n    recent_sessions = filtered_sessions[:5] if len(filtered_sessions) > 5 else filtered_sessions\n    archive_sessions = filtered_sessions[5:] if len(filtered_sessions) > 5 else []\n    \n    # ç›´è¿‘5ä»¶ï¼ˆå¸¸ã«å±•é–‹ï¼‰\n    if recent_sessions:\n        st.markdown(\"**ğŸ“Œ ç›´è¿‘ã®ãƒãƒ£ãƒƒãƒˆ**\")\n        for session in recent_sessions:\n            col1, col2 = st.columns([0.8, 0.2])\n            with col1:\n                if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                    switch_session(session[\"id\"])\n            with col2:\n                if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                    delete_session(session[\"id\"])\n    \n    # éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆæŠ˜ã‚ŠãŸãŸã¿ï¼‰\n    if archive_sessions:\n        with st.expander(f\"ğŸ“œ éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ– ({len(archive_sessions)}ä»¶)\", expanded=False):\n            for session in archive_sessions:\n                col1, col2 = st.columns([0.8, 0.2])\n                with col1:\n                    if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                        switch_session(session[\"id\"])\n                with col2:\n                    if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                        delete_session(session[\"id\"])\n\n    st.markdown(\"---\")\n\n    # ---- ç”»åƒç”Ÿæˆ ----\n    with st.expander(\"ğŸ¨ ç”»åƒç”Ÿæˆ\", expanded=False):\n        img_prompt = st.text_area(\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\", placeholder=\"æœªæ¥çš„ãªéƒ½å¸‚...\")\n        aspect_ratio = st.selectbox(\"æ¯”ç‡\", [\"16:9\", \"1:1\", \"4:3\", \"3:4\", \"9:16\"])\n\n        generate_img_btn = st.button(\"ç”Ÿæˆ\", type=\"primary\", disabled=not img_prompt)\n        if generate_img_btn and img_prompt:\n            st.session_state.generate_image_trigger = {\n                \"prompt\": img_prompt,\n                \"aspect_ratio\": aspect_ratio,\n            }\n\n    st.markdown(\"---\")\n\n    # ---- è©•ä¾¡åˆ†æ ----\n    with st.expander(\"ğŸ“Š å“è³ªåˆ†æ\", expanded=False):\n        total_ratings = 0\n        positive_ratings = 0\n        model_ratings = {}\n\n        for s in st.session_state.sessions:\n            for m in s[\"messages\"]:\n                if \"rating\" in m and m[\"rating\"] is not None:\n                    total_ratings += 1\n                    if m[\"rating\"] == 1:\n                        positive_ratings += 1\n                    if \"metadata\" in m and \"model\" in m[\"metadata\"]:\n                        mod = m[\"metadata\"][\"model\"]\n                        if mod not in model_ratings:\n                            model_ratings[mod] = {\"total\": 0, \"positive\": 0}\n                        model_ratings[mod][\"total\"] += 1\n                        if m[\"rating\"] == 1:\n                            model_ratings[mod][\"positive\"] += 1\n\n        if total_ratings > 0:\n            approval_rate = (positive_ratings / total_ratings) * 100\n            st.metric(\"Positive Ratings\", f\"{positive_ratings}/{total_ratings}\", f\"{approval_rate:.1f}%\")\n            best_model = \"N/A\"\n            best_rate = -1\n            for mod, stats in model_ratings.items():\n                rate = stats[\"positive\"] / stats[\"total\"]\n                if rate > best_rate:\n                    best_rate = rate\n                    best_model = mod\n            if best_model != \"N/A\":\n                st.caption(f\"ğŸ† Best: **{best_model}** ({best_rate*100:.0f}%)\")\n        else:\n            st.caption(\"ãƒ‡ãƒ¼ã‚¿ãªã—\")\n\n    st.markdown(\"---\")\n\n    # ---- ã‚³ã‚¹ãƒˆè¡¨ç¤º ----\n    st.metric(\"Cost\", f\"${usage_stats['total_cost_usd']:.4f}\")\n    if st.session_state.session_cost > 0:\n        st.caption(f\"Session: ${st.session_state.session_cost:.4f}\")\n\n    if usage_stats[\"total_cost_usd\"] >= MAX_BUDGET_USD:\n        st.error(f\"âš ï¸ ä¸Šé™ (${MAX_BUDGET_USD}) åˆ°é”\")\n        stop_generation = True\n    else:\n        stop_generation = False\n\n    st.markdown(\"---\")\n    st.code(f\"PROJECT: {VERTEX_PROJECT}\\nLOCATION: {VERTEX_LOCATION} (Vertex AI)\")\n\n# =========================\n# Main UI\n# =========================\n\ncurrent_session_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\nfor s in st.session_state.sessions:\n    if s[\"id\"] == st.session_state.current_session_id:\n        current_session_title = s[\"title\"]\n        break\n\nst.header(current_session_title)\nst.markdown(\n    \"ä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\"\n)\n\n# ---- Vertex AI Client ----\n\n\n\nclient = get_client()\n\n# ---- å±¥æ­´è¡¨ç¤º ----\n\nmessages = get_current_messages()\nfor idx, msg in enumerate(messages):\n    with st.chat_message(msg[\"role\"]):\n        st.markdown(msg[\"content\"])\n        if msg[\"role\"] == \"model\":\n            col1, col2, col3 = st.columns([0.1, 0.1, 0.8])\n            current_rating = msg.get(\"rating\")\n            with col1:\n                if st.button(\"ğŸ‘\", key=f\"up_{idx}\"):\n                    messages[idx][\"rating\"] = 1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col2:\n                if st.button(\"ğŸ‘\", key=f\"down_{idx}\"):\n                    messages[idx][\"rating\"] = -1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col3:\n                if current_rating == 1:\n                    st.caption(\"âœ… é«˜è©•ä¾¡\")\n                elif current_rating == -1:\n                    st.caption(\"âŒ ä½è©•ä¾¡\")\n\n# =========================\n# ç”»åƒç”Ÿæˆãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°\n# =========================\n\nif hasattr(st.session_state, \"generate_image_trigger\") and st.session_state.generate_image_trigger:\n    img_data = st.session_state.generate_image_trigger\n    del st.session_state.generate_image_trigger\n\n    with st.chat_message(\"user\"):\n        st.markdown(f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\")\n        st.caption(f\"ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”: {img_data['aspect_ratio']}\")\n\n    messages.append({\"role\": \"user\", \"content\": f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\"})\n    update_current_session_messages(messages)\n\n    with st.chat_message(\"assistant\"):\n        with st.status(\"ç”»åƒã‚’ç”Ÿæˆä¸­...\", expanded=True) as status:\n            try:\n                config = types.GenerateContentConfig(\n                    response_modalities=[\"IMAGE\"],\n                    image_config=types.ImageConfig(\n                        aspect_ratio=img_data[\"aspect_ratio\"]\n                    ),\n                )\n                status.write(\"Gemini 3 Pro Imageã§ç”Ÿæˆä¸­...\")\n                response = client.models.generate_content(\n                    model=\"gemini-3-pro-image-preview\",\n                    contents=img_data[\"prompt\"],\n                    config=config,\n                )\n\n                generated_image = None\n\n                # ç”»åƒã‚’å–ã‚Šå‡ºã™\n                if getattr(response, \"candidates\", None):\n                    for candidate in response.candidates:\n                        if getattr(candidate, \"content\", None) and candidate.content.parts:\n                            for part in candidate.content.parts:\n                                if getattr(part, \"inline_data\", None):\n                                    try:\n                                        generated_image = part.as_image()\n                                    except AttributeError:\n                                        image_bytes_raw = part.inline_data.data\n                                        generated_image = Image.open(io.BytesIO(image_bytes_raw))\n                                    break\n                        if generated_image is not None:\n                            break\n\n                if generated_image is not None:\n                    st.image(generated_image, caption=img_data[\"prompt\"])\n                    buf = io.BytesIO()\n                    generated_image.save(buf, format=\"PNG\")\n                    image_bytes = buf.getvalue()\n                    st.download_button(\n                        label=\"ğŸ’¾ ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\",\n                        data=image_bytes,\n                        file_name=f\"generated_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png\",\n                        mime=\"image/png\",\n                    )\n                    messages.append(\n                        {\"role\": \"model\", \"content\": f\"âœ… ç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {img_data['prompt']}\"}\n                    )\n                    update_current_session_messages(messages)\n                    status.update(label=\"âœ… ç”»åƒç”Ÿæˆå®Œäº†\", state=\"complete\")\n                else:\n                    st.error(\"ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")\n                    status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n\n            except Exception as e:\n                status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n                st.error(f\"ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}\")\n\n# =========================\n# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›\n# =========================\n\nprompt = st.chat_input(\"ä½•ã‹èã„ã¦ãã ã•ã„...\", disabled=stop_generation)\n\nif prompt:\n    if stop_generation:\n        st.error(\"äºˆç®—ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚\")\n    else:\n        # ---- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€è¡¨ç¤º ----\n        with st.chat_message(\"user\"):\n            st.markdown(prompt)\n            if uploaded_files:\n                for uf in uploaded_files:\n                    st.caption(f\"ğŸ“ æ·»ä»˜: {uf.name}\")\n            if youtube_url:\n                st.caption(f\"ğŸ“º YouTube: {youtube_url}\")\n            if pasted_image_bytes:\n                st.caption(\"ğŸ“‹ ç”»åƒãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚Œã¾ã—ãŸ\")\n\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        update_current_session_messages(messages)\n\n        # ---- ãƒ¢ãƒ‡ãƒ«å¿œç­” ----\n        with st.chat_message(\"assistant\"):\n            status_container = st.status(\"æ€è€ƒä¸­...\", expanded=True)\n            try:\n                # ä¼šè©±å±¥æ­´\n                model_history = []\n                for msg in messages[:-1]:\n                    model_history.append(\n                        types.Content(\n                            role=msg[\"role\"],\n                            parts=[types.Part.from_text(text=msg[\"content\"])],\n                        )\n                    )\n\n                # ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³\n                current_parts = [types.Part.from_text(text=prompt)]\n\n                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«\n                for uploaded_file in uploaded_files or []:\n                    try:\n                        mime_type = get_mime_type(uploaded_file.name)\n                        bytes_data = uploaded_file.getvalue()\n                        part = types.Part.from_bytes(data=bytes_data, mime_type=mime_type)\n                        current_parts.append(part)\n                        status_container.write(f\"ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™å®Œäº†: {uploaded_file.name}\")\n                    except Exception as e:\n                        status_container.error(\n                            f\"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {uploaded_file.name} - {e}\"\n                        )\n\n                # è²¼ã‚Šä»˜ã‘ç”»åƒ\n                if pasted_image_bytes:\n                    import base64\n\n                    status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã‚’å‡¦ç†ä¸­...\")\n                    try:\n                        if isinstance(pasted_image_bytes, str):\n                            if pasted_image_bytes.startswith(\"data:\"):\n                                base64_str = pasted_image_bytes.split(\",\", 1)[1]\n                                image_bytes_decoded = base64.b64decode(base64_str)\n                            else:\n                                image_bytes_decoded = base64.b64decode(pasted_image_bytes)\n                        else:\n                            image_bytes_decoded = pasted_image_bytes\n                        part = types.Part.from_bytes(\n                            data=image_bytes_decoded, mime_type=\"image/png\"\n                        )\n                        current_parts.append(part)\n                        status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®æº–å‚™å®Œäº†\")\n                    except Exception as e:\n                        status_container.error(f\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n\n                # YouTube å­—å¹•\n                if youtube_url:\n                    vid_id = extract_youtube_id(youtube_url)\n                    if vid_id:\n                        status_container.write(\"YouTubeã®å­—å¹•ã‚’å–å¾—ä¸­...\")\n                        transcript_text = get_youtube_transcript(vid_id)\n                        current_parts.append(\n                            types.Part.from_text(text=f\"YouTube Transcript:\\n{transcript_text}\")\n                        )\n                    else:\n                        status_container.write(\"ç„¡åŠ¹ãªYouTube URLã§ã™ã€‚\")\n\n                contents_for_model = model_history + [\n                    types.Content(role=\"user\", parts=current_parts)\n                ]\n\n                # ---- Tool / Config ----\n                tools = []\n                final_candidate_count = candidate_count\n                if use_search:\n                    tools.append(types.Tool(google_search=types.GoogleSearch()))\n                    final_candidate_count = 1\n\n                # â˜… System Instruction ã®æ”¹å–„: ãƒ¡ã‚¿ç™ºè¨€ç¦æ­¢ã¨ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªæŒ¯ã‚‹èˆã„ã‚’æŒ‡ç¤º\n                base_system_instruction = (\n                    \"ã‚ãªãŸã¯é«˜åº¦ãªçŸ¥æ€§ã‚’æŒã¤å°‚é–€çš„ãªãƒªã‚µãƒ¼ãƒãƒ»ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\\n\"\n                    \"ä»¥ä¸‹ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’å³å®ˆã—ã¦ãã ã•ã„ï¼š\\n\"\n                    \"1. **ãƒ¡ã‚¿ç™ºè¨€ã®ç¦æ­¢**: ã€Œç§ã¯AIã§ã™ã€ã€Œä¸–ç•Œæœ€é«˜å³°ã®ï½ã¨ã—ã¦ã€ãªã©ã®è‡ªå·±è¨€åŠã‚„å‰ç½®ãã¯ä¸€åˆ‡è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚\\n\"\n                    \"2. **æ„å›³ã®æ±²ã¿å–ã‚Š**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã®èƒŒå¾Œã«ã‚ã‚‹æ„å›³ï¼ˆæ–‡è„ˆã€æš—é»™ã®å‰æï¼‰ã‚’æ¨æ¸¬ã—ã€è¨€è‘‰é€šã‚Šã§ã¯ãªãã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ¬å½“ã«çŸ¥ã‚ŠãŸã„ã“ã¨ã€ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n\"\n                    \"3. **æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”**: çµè«–ã‚’å…ˆã«è¿°ã¹ã€ãã®å¾Œã«è©³ç´°ãªæ ¹æ‹ ã€ã‚·ãƒŠãƒªã‚ªåˆ†æã€ãƒªã‚¹ã‚¯è¦å› ã‚’è«–ç†çš„ã«å±•é–‹ã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"4. **å®¢è¦³æ€§**: äºˆæ¸¬ã‚’è¡Œã†å ´åˆã¯ã€æ–­å®šã‚’é¿ã‘ã€è¤‡æ•°ã®ã‚·ãƒŠãƒªã‚ªï¼ˆæ¥½è¦³ã€æ‚²è¦³ã€ä¸­ç«‹ï¼‰ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"5. **å¼•ç”¨**: æ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸå ´åˆã¯ã€å¿…ãšæƒ…å ±æºã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚\"\n                )\n\n                final_answer = \"\"\n                grounding_metadata = None\n                \n                # =========================\n                # ãƒ¢ãƒ¼ãƒ‰è¨­å®šã®è§£æ\n                # =========================\n                enable_research = True  # å…¨ãƒ¢ãƒ¼ãƒ‰ã§ãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œ\n                enable_meta = \"ãƒ¡ã‚¿\" in response_mode or \"MAX\" in response_mode\n                enable_strict = \"é¬¼è»æ›¹\" in response_mode or \"MAX\" in response_mode\n\n                # =========================\n                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (é«˜é€Ÿ / é¬¼è»æ›¹)\n                # =========================\n                if not enable_research:\n                    config = types.GenerateContentConfig(\n                        temperature=0.7,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=base_system_instruction,\n                    )\n                    \n                    status_container.write(\"å›ç­”ç”Ÿæˆä¸­...\")\n                    response = client.models.generate_content(\n                        model=model_id,\n                        contents=contents_for_model,\n                        config=config,\n                    )\n                    \n                    final_answer = extract_text_from_response(response)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®—\n                    if response.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            response.usage_metadata.prompt_token_count,\n                            response.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += response.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += response.usage_metadata.candidates_token_count\n\n                    # é¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ (é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ç‰ˆ)\n                    if enable_strict:\n                        status_container.write(\"ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        reviewer_instruction = base_system_instruction + \"\"\"\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n                        review_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\nåˆç‰ˆå›ç­”:\\n{final_answer}\\n\\nãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\")])]\n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=types.GenerateContentConfig(temperature=0.1, candidate_count=1, system_instruction=reviewer_instruction)\n                        )\n                        final_answer = extract_text_from_response(review_resp)\n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        \n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(model_id, review_resp.usage_metadata.prompt_token_count, review_resp.usage_metadata.candidates_token_count)\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n\n                # =========================\n                # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰\n                # =========================\n                else:\n                    # =========================\n                    # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰: å¤šæ®µéšã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ \n                    # =========================\n                    \n                    # --- Phase 1: ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 1: ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    research_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒªã‚µãƒ¼ãƒå°‚ä»»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚æœ€çµ‚å›ç­”ã¯æ›¸ã‹ãšã€äº‹å®Ÿåé›†ã«é›†ä¸­ã™ã‚‹ã“ã¨ã€‚\n\n**èª¿æŸ»è¦³ç‚¹**:\n- è³ªå•ã«é–¢é€£ã™ã‚‹**æœ€æ–°ã®äº‹å®Ÿãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ»çµ±è¨ˆ**ï¼ˆ**2025å¹´ã®æƒ…å ±ã‚’æœ€å„ªå…ˆ**ï¼‰\n- **ç¾æ™‚ç‚¹ã§å­˜åœ¨ã™ã‚‹å…¨ã¦ã®é¸æŠè‚¢ãƒ»ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¶²ç¾…çš„ã«èª¿æŸ»**ï¼ˆä¾‹: è£½å“æ¯”è¼ƒãªã‚‰ã€æœ€æ–°ç‰ˆã ã‘ã§ãªãç›´è¿‘ã®å…¨ä¸–ä»£ã‚’èª¿æŸ»ï¼‰\n- å…¬å¼æƒ…å ±ã‚„ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã‹ã‚‰ã®å¼•ç”¨\n- é–¢é€£ã™ã‚‹èƒŒæ™¯æƒ…å ±ã‚„æ–‡è„ˆ\n- ç«¶åˆãƒ»ä»£æ›¿æ¡ˆãƒ»æ¯”è¼ƒå¯¾è±¡ã®**å®Œå…¨ãªãƒªã‚¹ãƒˆ**\n- ãƒªã‚¹ã‚¯ãƒ»åˆ¶ç´„ãƒ»æ³¨æ„ç‚¹ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n- å‚è€ƒã«ã—ãŸä¸»è¦ãªæƒ…å ±æºã®URL\n\n**é‡è¦**: \n- çµè«–ã‚„æ¨å¥¨ã¯æ›¸ã‹ãšã€å¾Œå·¥ç¨‹ãŒåˆ¤æ–­ã§ãã‚‹èª¿æŸ»ãƒ¡ãƒ¢ã«é›†ä¸­ã™ã‚‹ã“ã¨\n- **å¿…ãšæ¤œç´¢æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã€æœ€æ–°ã®æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã“ã¨**\n- **æ¤œç´¢çµæœã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æ—¥ä»˜ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒ»ãƒ¢ãƒ‡ãƒ«åã‚’å„ªå…ˆçš„ã«è¨˜è¼‰ã™ã‚‹ã“ã¨**\n- **æ¯”è¼ƒå¯¾è±¡ã¨ãªã‚‹é¸æŠè‚¢ã‚’è¦‹è½ã¨ã•ãªã„ã‚ˆã†ã€è¤‡æ•°ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è©¦ã™ã“ã¨**ï¼ˆä¾‹: ã€ŒiPhone æœ€æ–°ãƒ¢ãƒ‡ãƒ« 2025ã€ã€ŒiPhone 17ã€ã€ŒiPhone 2025å¹´ç™ºå£²ã€ãªã©ï¼‰\n- **ã€Œã“ã‚Œã‚ˆã‚Šæ–°ã—ã„ãƒ¢ãƒ‡ãƒ«/ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯å­˜åœ¨ã—ãªã„ã‹ï¼Ÿã€ã‚’å¸¸ã«ç¢ºèªã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ï¼ˆ2024å¹´ä»¥å‰ãªã©ï¼‰ã—ã‹è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãã®æ—¨ã‚’æ˜è¨˜ã™ã‚‹ã“ã¨\n\"\"\"\n\n                    # éå»ã®é–¢é€£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—\n                    past_context = get_relevant_context(prompt, st.session_state.sessions, st.session_state.current_session_id)\n                    \n                    # ãƒªã‚µãƒ¼ãƒç”¨ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ§‹ç¯‰\n                    research_parts = [types.Part(text=f\"ã“ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š\\n{prompt}\")]\n                    \n                    if past_context:\n                        research_parts.insert(0, types.Part(text=\"ä»¥ä¸‹ã¯éå»ã®é–¢é€£ãƒãƒ£ãƒƒãƒˆã‹ã‚‰æŠ½å‡ºã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã™ï¼š\\n\\n\" + past_context))\n                    \n                    research_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=research_parts)\n                    ]\n                    \n                    research_config = types.GenerateContentConfig(\n                        temperature=0.2,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=research_instruction,\n                    )\n                    \n                    research_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=research_contents,\n                        config=research_config,\n                    )\n                    \n                    research_text = extract_text_from_response(research_resp)\n                    \n                    # ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºã®ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ±ã‚’ä¿å­˜\n                    if research_resp.candidates and research_resp.candidates[0].grounding_metadata:\n                        grounding_metadata = research_resp.candidates[0].grounding_metadata\n                    \n                    status_container.write(\"âœ“ ãƒªã‚µãƒ¼ãƒå®Œäº†\")\n                    with status_container.expander(\"åé›†ã—ãŸèª¿æŸ»ãƒ¡ãƒ¢\", expanded=False):\n                        st.markdown(research_text)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1)\n                    if research_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            research_resp.usage_metadata.prompt_token_count,\n                            research_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += research_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += research_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 1.5: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    questions_text = \"\"\n                    if enable_meta:\n                        status_container.write(\"Phase 1.5: ãƒ¡ã‚¿è³ªå•ç”Ÿæˆä¸­...\")\n                        \n                        question_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ç›®çš„**: \nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•ã¨èª¿æŸ»ãƒ¡ãƒ¢ã‚’è¸ã¾ãˆã¦ã€ã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±ãç†è§£ã™ã‚‹ãŸã‚ã®ã€Œé‹­ã„ã‚µãƒ–è³ªå•ã€ã‚’ä½œæˆã™ã‚‹ã“ã¨ã€‚\n\n**ãƒ«ãƒ¼ãƒ«**:\n- æœ€å¤§5å€‹ã¾ã§\n- å„è³ªå•ã¯1-2è¡Œã§å…·ä½“çš„ã‹ã¤é‹­ã\n- ä»¥ä¸‹ã®è¦³ç‚¹ã‚’æ„è­˜:\n  1. å‰æãŒå´©ã‚Œã‚‹å¯èƒ½æ€§ã¯ã©ã“ã‹ï¼Ÿ\n  2. å¼·æ°—/å¼±æ°—ã‚·ãƒŠãƒªã‚ªã®åˆ†å²ç‚¹ã¯ä½•ã‹ï¼Ÿ\n  3. ç«¶åˆãƒ»æŠ€è¡“ãƒ»è¦åˆ¶ã®ä¸ç¢ºå®Ÿæ€§ã¯ï¼Ÿ\n  4. ã€Œäºˆæ¸¬ãŒå¤–ã‚Œã‚‹ã¨ã—ãŸã‚‰ã©ã‚“ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ï¼Ÿã€\n\n**å‡ºåŠ›**: ç®‡æ¡æ›¸ãï¼ˆQ1, Q2...ï¼‰ã®ã¿\n\"\"\"\n\n                        question_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•:\\n{prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\nã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±æ˜ã‚Šã™ã‚‹ãŸã‚ã®é‡è¦ãªã‚µãƒ–è³ªå•ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\")])]\n                        \n                        question_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=question_contents,\n                            config=types.GenerateContentConfig(\n                                temperature=0.4,\n                                candidate_count=1,\n                                system_instruction=question_instruction,\n                            )\n                        )\n                        \n                        questions_text = extract_text_from_response(question_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¡ã‚¿è³ªå•ç”Ÿæˆå®Œäº†\")\n                        with status_container.expander(\"ç”Ÿæˆã•ã‚ŒãŸãƒ¡ã‚¿è³ªå•\", expanded=False):\n                            st.markdown(questions_text)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1.5)\n                        if question_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                question_resp.usage_metadata.prompt_token_count,\n                                question_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += question_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += question_resp.usage_metadata.candidates_token_count\n\n                    # --- Phase 2: çµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 2: çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    if enable_meta:\n                        deep_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã¨ãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ã‚’æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**æ§‹æˆ**:\n1. **æ·±æ˜ã‚Šè€ƒå¯Ÿ**ï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n2. **çµè«–**ï¼ˆ2-3è¡Œï¼‰\n3. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n4. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨\n\"\"\"\n                    else:\n                        deep_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã‚’å”¯ä¸€ã®æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**æ§‹æˆ**:\n1. **çµè«–**ï¼ˆ2-3è¡Œã§æ˜ç¢ºã«ï¼‰\n2. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n3. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«åã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ã¨æ–°ã—ã„æƒ…å ±ãŒæ··åœ¨ã™ã‚‹å ´åˆã¯ã€æ–°ã—ã„æƒ…å ±ã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n\"\"\"\n                    \n                    synthesis_prompt_text = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if enable_meta and questions_text:\n                        synthesis_prompt_text += f\"==== ãƒ¡ã‚¿è³ªå•ä¸€è¦§ ====\\n{questions_text}\\n==== ãƒ¡ã‚¿è³ªå•ã“ã“ã¾ã§ ====\\n\\næŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n2. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»åˆ†æãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    else:\n                        synthesis_prompt_text += \"ä¸Šè¨˜ãƒ¡ãƒ¢ã‚’æ ¹æ‹ ã«ã€æœ€çµ‚å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å¿…ãšä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚**\"\n\n                    synthesis_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=[\n                            types.Part(text=synthesis_prompt_text)\n                        ])\n                    ]\n                    \n                    synthesis_config = types.GenerateContentConfig(\n                        temperature=0.3,\n                        candidate_count=1,\n                        tools=[],  # çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºã§ã¯æ¤œç´¢OFF\n                        system_instruction=deep_instruction,\n                    )\n                    \n                    synthesis_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=synthesis_contents,\n                        config=synthesis_config,\n                    )\n                    \n                    draft_answer = extract_text_from_response(synthesis_resp)\n                    \n                    status_container.write(\"âœ“ çµ±åˆå®Œäº†\")\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 2)\n                    if synthesis_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            synthesis_resp.usage_metadata.prompt_token_count,\n                            synthesis_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += synthesis_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += synthesis_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    if enable_strict:\n                        status_container.write(\"Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        \n\n                        reviewer_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™ã€‚ãŸã ã—ã€**èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’å„ªå…ˆã—ã€æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã™ã‚‹ã“ã¨**ã€‚\n\n**ãƒ¬ãƒ“ãƒ¥ãƒ¼è¦³ç‚¹**:\n- äº‹å®Ÿã¨æ¨æ¸¬ã‚’æ˜ç¢ºã«åˆ†ã‘ã‚‹\n- éåº¦ã«è‡ªä¿¡ã®ã‚ã‚‹æ–­å®šã‚’å¼±ã‚ã‚‹\n- æ•°å­—ã‚„å›ºæœ‰åè©ãŒèª¿æŸ»ãƒ¡ãƒ¢ã¨çŸ›ç›¾ã—ã¦ã„ãªã„ã‹ç¢ºèª\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ãƒ¢ãƒ‡ãƒ«ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ãŒæ­£ã—ãä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª**\n- **å¤ã„æƒ…å ±ã§ä¸Šæ›¸ãã—ã¦ã„ãªã„ã‹ç¢ºèª**\n- è¦‹è½ã¨ã—ã¦ã„ã‚‹é‡è¦ãªãƒªã‚¹ã‚¯ãƒ»ã‚·ãƒŠãƒªã‚ªãŒã‚ã‚Œã°è¿½åŠ \n\n**é‡è¦**: \n- èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ãŒæœ€æ–°ã§ã‚ã‚‹å ´åˆã€ãã‚Œã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n- ã‚ãªãŸã®çŸ¥è­˜ãŒå¤ã„å ´åˆã¯ã€èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’ä¿¡é ¼ã™ã‚‹ã“ã¨\n\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n\n                        review_contents = [\n                            types.Content(role=\"user\", parts=[\n                                types.Part.from_text(\n                                    text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\n\"\n                                    f\"==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                                    f\"åˆç‰ˆå›ç­”:\\n{draft_answer}\\n\\n\"\n                                    \"ä¸Šè¨˜ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚**\"\n                                )\n                            ])\n                        ]\n                        \n                        review_config = types.GenerateContentConfig(\n                            temperature=0.1,\n                            candidate_count=1,\n                            system_instruction=reviewer_instruction,\n                        )\n                        \n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=review_config,\n                        )\n                        \n                        final_answer = extract_text_from_response(review_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        with status_container.expander(\"åˆç‰ˆã¨ã®æ¯”è¼ƒ\", expanded=False):\n                            st.markdown(\"**åˆç‰ˆ:**\")\n                            st.markdown(draft_answer[:500] + \"...\" if len(draft_answer) > 500 else draft_answer)\n                            st.markdown(\"**ä¿®æ­£ç‰ˆ:**\")\n                            st.markdown(final_answer[:500] + \"...\" if len(final_answer) > 500 else final_answer)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 3)\n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                review_resp.usage_metadata.prompt_token_count,\n                                review_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n                    else:\n                        final_answer = draft_answer\n\n                save_usage(usage_stats)\n                status_container.update(label=\"å®Œäº†ï¼\", state=\"complete\", expanded=False)\n\n                # ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤º\n                st.caption(f\"ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_id}\")\n                st.markdown(final_answer)\n\n                # ---- ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ± ----\n                if grounding_metadata:\n                    st.markdown(\"---\")\n                    st.subheader(\"ğŸ“š æƒ…å ±æºã¨å¼•ç”¨\")\n                    if grounding_metadata.grounding_chunks:\n                        st.markdown(\"**æ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:**\")\n                        unique_sources = {}\n                        import urllib.parse\n\n                        for chunk in grounding_metadata.grounding_chunks:\n                            if getattr(chunk, \"web\", None):\n                                uri = getattr(chunk.web, \"uri\", None)\n                                title = getattr(chunk.web, \"title\", \"æƒ…å ±æº\")\n                                if uri and uri not in unique_sources:\n                                    parsed = urllib.parse.urlparse(uri)\n                                    domain = parsed.netloc.replace(\"www.\", \"\")\n                                    unique_sources[uri] = {\n                                        \"title\": title,\n                                        \"domain\": domain,\n                                    }\n                        for i, (uri, info) in enumerate(unique_sources.items(), 1):\n                            st.markdown(f\"{i}. **[{info['title']}]({uri})**\")\n                            st.caption(f\"   å‡ºå…¸: {info['domain']}\")\n\n                messages.append({\"role\": \"model\", \"content\": final_answer})\n                update_current_session_messages(messages)\n\n            except Exception as e:\n                status_container.update(label=\"Error\", state=\"error\")\n                err_text = str(e)\n                if \"RESOURCE_EXHAUSTED\" in err_text or \"429\" in err_text:\n                    st.error(\n                        \"âš ï¸ Vertex AI / Gemini ã®ã‚¯ã‚©ãƒ¼ã‚¿ã«é”ã—ã¾ã—ãŸã€‚\\n\\n\"\n                        \"ãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ / æ—¥æ¬¡åˆ¶é™ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\\n\"\n                        \"ãƒ»ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                        \"ãƒ»Google Cloud Console ã®ã€ŒVertex AI â†’ ä½¿ç”¨çŠ¶æ³ã€ã‹ã‚‰ã‚¯ã‚©ãƒ¼ã‚¿çŠ¶æ³ã‚’ç¢ºèªã§ãã¾ã™ã€‚\"\n                    )\n                elif \"NOT_FOUND\" in err_text and \"Publisher Model\" in err_text:\n                    st.error(\n                        \"âš ï¸ æŒ‡å®šã—ãŸãƒ¢ãƒ‡ãƒ«ãŒã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ / ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\\n\"\n                        \"ãƒ»ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ¢ãƒ‡ãƒ«IDã‚’ã€2.5ç³» ã¾ãŸã¯ 3 Pro ã«å¤‰æ›´ã—ã¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                    )\n                else:\n                    st.error(f\"An error occurred: {e}\")\n"
                }
            ]
        },
        {
            "id": "92ccd26a-7d1c-483c-9ab6-69c045df756d",
            "title": "GPTã§éå»æ¨è«–ã—ãŸå†…å®¹ã‚’ã€ãŠã™ã™ã‚ã¨ã—...",
            "timestamp": "2025-11-30T13:01:40.818229",
            "messages": [
                {
                    "role": "user",
                    "content": "GPTã§éå»æ¨è«–ã—ãŸå†…å®¹ã‚’ã€ãŠã™ã™ã‚ã¨ã—ã¦ã€è‡ªå‹•æ²è¼‰ã™ã‚‹ä»•çµ„ã¿ã‚’ã€ä»¥ä¸‹ã‚³ãƒ¼ãƒ‰ã§è¿½åŠ ã™ã‚‹ã“ã¨ã¯ã€å¯èƒ½ã‹ï¼Ÿ\n\nç¾çŠ¶gpt5.1proãŒæ¨è«–ã®ãƒ™ã‚¹ãƒˆã ã¨è€ƒãˆã¦ã„ã‚‹ãŒã€ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°èƒ½åŠ›ãŒè‡ªä½œgeminiã«ã¯ã‚ã‚‹ã€‚\ngpt5.1proã‚’100ã¨ã—ã¦ã€ä»¥ä¸‹ã§ä»£ç”¨ã§ãã‚‹ã‹ï¼Ÿ(antigravityã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹å¯èƒ½æ€§ã‚‚ã‚ã‚‹)\n\nimport os\nimport json\nimport re\nimport uuid\nimport datetime\nimport streamlit as st\nfrom dotenv import load_dotenv\nfrom google import genai\nfrom google.genai import types\nfrom youtube_transcript_api import YouTubeTranscriptApi\nfrom PIL import Image\nimport io\n\ntry:\n    from st_img_pastebutton import paste\n    import_error_msg = None\nexcept ImportError as e:\n    paste = None\n    import_error_msg = str(e)\n\n# =========================\n# ç’°å¢ƒå¤‰æ•° & å®šæ•°\n# =========================\n\nload_dotenv()\n\nUSAGE_FILE = \"usage_stats.json\"\nSESSIONS_FILE = \"chat_sessions.json\"\nMAX_BUDGET_USD = float(os.getenv(\"MAX_BUDGET_USD\", \"5.0\"))\n\n# â€»é‡‘é¡ã¯ã ã„ãŸã„ã®ç›®å®‰ï¼ˆUSD / 1M tokensï¼‰\nPRICING = {\n    \"gemini-3-pro-preview\":   {\"input\": 2.0,   \"output\": 12.0},\n    \"gemini-2.5-pro\":         {\"input\": 1.25,  \"output\": 10.0},\n    \"gemini-2.5-flash\":       {\"input\": 0.30,  \"output\": 2.50},\n    \"gemini-2.5-flash-lite\":  {\"input\": 0.10,  \"output\": 0.40},\n    \"gemini-2.0-flash\":       {\"input\": 0.10,  \"output\": 0.40},\n}\n\n# Vertex AI ç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®šï¼ˆ**å¸¸ã« Vertex ã‚’ä½¿ã†**ï¼‰\nVERTEX_PROJECT = os.getenv(\"GOOGLE_CLOUD_PROJECT\")\nVERTEX_LOCATION = \"global\"  # Gemini 2.x / 3 ã¯ global æ¨å¥¨\n\nst.set_page_config(page_title=\"Gemini 3 Web Studio\", layout=\"wide\")\n\n# =========================\n# Helper Functions\n# =========================\n\ndef load_usage():\n    if os.path.exists(USAGE_FILE):\n        with open(USAGE_FILE, \"r\") as f:\n            return json.load(f)\n    return {\"total_input_tokens\": 0, \"total_output_tokens\": 0, \"total_cost_usd\": 0.0}\n\ndef save_usage(stats):\n    with open(USAGE_FILE, \"w\") as f:\n        json.dump(stats, f, indent=4)\n\ndef calculate_cost(model_id, input_tok, output_tok):\n    price = PRICING.get(model_id, {\"input\": 0.0, \"output\": 0.0})\n    cost = (input_tok / 1_000_000 * price[\"input\"]) + (output_tok / 1_000_000 * price[\"output\"])\n    return cost\n\ndef get_mime_type(filename):\n    ext = filename.split('.')[-1].lower()\n    if ext in ['jpg', 'jpeg']:\n        return 'image/jpeg'\n    if ext == 'png':\n        return 'image/png'\n    if ext == 'mp4':\n        return 'video/mp4'\n    if ext == 'mov':\n        return 'video/quicktime'\n    if ext == 'txt':\n        return 'text/plain'\n    if ext == 'pdf':\n        return 'application/pdf'\n    if ext == 'csv':\n        return 'text/csv'\n    return 'application/octet-stream'\n\ndef extract_youtube_id(url):\n    regex = r\"(?:v=|\\/)([0-9A-Za-z_-]{11}).*\"\n    match = re.search(regex, url)\n    if match:\n        return match.group(1)\n    return None\n\ndef get_youtube_transcript(video_id):\n    try:\n        transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['ja', 'en'])\n        text = \" \".join([t['text'] for t in transcript_list])\n        return text\n    except Exception as e:\n        return f\"å­—å¹•ã®å–å¾—ã‚¨ãƒ©ãƒ¼: {e}\"\n\ndef get_relevant_context(query):\n    \"\"\"éå»ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ç°¡æ˜“æ¤œç´¢ã—ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™\"\"\"\n    if not query:\n        return \"\"\n    keywords = [k for k in query.split() if len(k) > 1]\n    if not keywords:\n        return \"\"\n\n    relevant_sessions = []\n    for session in st.session_state.sessions:\n        if session[\"id\"] == st.session_state.current_session_id:\n            continue\n        score = 0\n        for k in keywords:\n            if k.lower() in session[\"title\"].lower():\n                score += 3\n        for msg in session[\"messages\"][-4:]:\n            for k in keywords:\n                if k.lower() in msg[\"content\"].lower():\n                    score += 1\n        if score > 0:\n            relevant_sessions.append((score, session))\n\n    relevant_sessions.sort(key=lambda x: (x[0], x[1][\"timestamp\"]), reverse=True)\n    top_sessions = relevant_sessions[:3]\n\n    context_str = \"\"\n    if top_sessions:\n        context_str += \"### éå»ã®é–¢é€£ãƒãƒ£ãƒƒãƒˆå±¥æ­´ (Context)\\n\"\n        for score, session in top_sessions:\n            last_response = \"N/A\"\n            for m in reversed(session[\"messages\"]):\n                if m[\"role\"] == \"model\":\n                    last_response = m[\"content\"][:300] + \"...\"\n                    break\n            context_str += f\"- **Session: {session['title']}** ({session['timestamp'][:10]})\\n\"\n            context_str += f\"  Last Conclusion: {last_response}\\n\\n\"\n    return context_str\n\ndef extract_text_from_response(response):\n    \"\"\"Extract text from GenerateContentResponse\"\"\"\n    if not response.candidates:\n        return \"\"\n    parts = response.candidates[0].content.parts or []\n    return \"\".join(p.text or \"\" for p in parts)\n\n# =========================\n# Session Management\n# =========================\n\ndef load_sessions():\n    if os.path.exists(SESSIONS_FILE):\n        with open(SESSIONS_FILE, \"r\") as f:\n            try:\n                data = json.load(f)\n                return data.get(\"sessions\", [])\n            except json.JSONDecodeError:\n                return []\n    return []\n\ndef save_sessions(sessions):\n    with open(SESSIONS_FILE, \"w\") as f:\n        json.dump({\"sessions\": sessions}, f, indent=4, ensure_ascii=False)\n\ndef create_new_session():\n    current_sessions = load_sessions()\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": [],\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.rerun()\n\ndef switch_session(session_id):\n    st.session_state.current_session_id = session_id\n    st.rerun()\n\ndef update_current_session_messages(messages):\n    if st.session_state.current_session_id:\n        current_sessions = load_sessions()\n        for session in current_sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                session[\"messages\"] = messages\n                if session[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(messages) > 0:\n                    first_msg = messages[0][\"content\"]\n                    session[\"title\"] = (first_msg[:20] + \"...\") if len(first_msg) > 20 else first_msg\n                session[\"timestamp\"] = datetime.datetime.now().isoformat()\n                break\n        save_sessions(current_sessions)\n        st.session_state.sessions = current_sessions\n\ndef get_current_messages():\n    if st.session_state.current_session_id:\n        for session in st.session_state.sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                return session[\"messages\"]\n    return []\n\ndef delete_session(session_id):\n    current_sessions = load_sessions()\n    current_sessions = [s for s in current_sessions if s[\"id\"] != session_id]\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    if st.session_state.current_session_id == session_id:\n        st.session_state.current_session_id = None\n        if st.session_state.sessions:\n            st.session_state.current_session_id = st.session_state.sessions[0][\"id\"]\n    st.rerun()\n\ndef branch_session():\n    \"\"\"ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚’åˆ†å²\"\"\"\n    current_messages = get_current_messages()\n    current_sessions = load_sessions()\n    \n    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—\n    current_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n    for session in current_sessions:\n        if session[\"id\"] == st.session_state.current_session_id:\n            current_title = session[\"title\"]\n            break\n    \n    # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": f\"{current_title} (åˆ†å²)\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": current_messages.copy(),  # ç¾åœ¨ã®å±¥æ­´ã‚’ã‚³ãƒ”ãƒ¼\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    \n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.session_state.session_cost = 0.0  # ã‚³ã‚¹ãƒˆãƒªã‚»ãƒƒãƒˆ\n    st.rerun()\n\n# =========================\n# Initialization\n# =========================\n\nif \"sessions\" not in st.session_state:\n    st.session_state.sessions = load_sessions()\n\nif \"current_session_id\" not in st.session_state:\n    # Always create a new session when the app starts\n    create_new_session()\n\nif \"session_cost\" not in st.session_state:\n    st.session_state.session_cost = 0.0\n\nusage_stats = load_usage()\n\n# =========================\n# Sidebar\n# =========================\n\nwith st.sidebar:\n    st.title(\"Gemini 3 Studio\")\n\n    if st.button(\"â• æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\", use_container_width=True):\n        create_new_session()\n\n    if st.button(\"ğŸŒ± ç¾åœ¨ã®ãƒãƒ£ãƒƒãƒˆã‹ã‚‰åˆ†å²\", use_container_width=True):\n        branch_session()\n\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    current_messages = get_current_messages()\n    if current_messages:\n        export_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n        for s in st.session_state.sessions:\n            if s[\"id\"] == st.session_state.current_session_id:\n                export_title = s[\"title\"]\n                break\n\n        export_md = f\"# {export_title}\\n\\n\"\n        export_md += f\"**ä½œæˆæ—¥æ™‚**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n---\\n\\n\"\n        for msg in current_messages:\n            role_label = \"ğŸ§‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼\" if msg[\"role\"] == \"user\" else \"ğŸ¤– AI\"\n            export_md += f\"## {role_label}\\n\\n{msg['content']}\\n\\n---\\n\\n\"\n\n        if st.button(\"ğŸ”— å¤–éƒ¨å…±æœ‰ãƒªãƒ³ã‚¯ã‚’ä½œæˆ\", use_container_width=True):\n            with st.spinner(\"ãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆä¸­...\"):\n                try:\n                    import urllib.request\n                    import urllib.parse\n\n                    data = urllib.parse.urlencode(\n                        {\"content\": export_md, \"expiry_days\": 7, \"syntax\": \"md\"}\n                    ).encode()\n\n                    req = urllib.request.Request(\"https://dpaste.org/api/\", data=data)\n                    req.add_header(\"User-Agent\", \"Mozilla/5.0 (Gemini3Studio)\")\n\n                    with urllib.request.urlopen(req) as response:\n                        share_url = response.read().decode(\"utf-8\").strip()\n                        st.success(\"ãƒªãƒ³ã‚¯ã‚’ä½œæˆã—ã¾ã—ãŸï¼\")\n                        st.code(share_url)\n                        st.caption(\"â€»ãƒªãƒ³ã‚¯ã¯7æ—¥é–“æœ‰åŠ¹ã§ã™\")\n                except Exception as e:\n                    st.error(f\"ãƒªãƒ³ã‚¯ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}\")\n\n    st.markdown(\"---\")\n\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    st.subheader(\"æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«\")\n    uploaded_files = st.file_uploader(\n        \"ç”»åƒã€å‹•ç”»ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\",\n        accept_multiple_files=True,\n        type=[\"png\", \"jpg\", \"jpeg\", \"mp4\", \"mov\", \"txt\", \"pdf\", \"csv\"],\n        help=\"Limit 2GB per file\",\n    )\n\n    pasted_image_bytes = None\n    if paste:\n        if \"paste_key\" not in st.session_state:\n            st.session_state.paste_key = 0\n        try:\n            pasted_image_bytes = paste(\n                label=\"ğŸ“‹ ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã‹ã‚‰ç”»åƒã‚’è²¼ã‚Šä»˜ã‘\",\n                key=f\"paste_btn_{st.session_state.paste_key}\",\n            )\n        except Exception as e:\n            st.error(f\"Clipboard button error: {e}\")\n        \n        if pasted_image_bytes:\n            st.success(\"ç”»åƒãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚Œã¾ã—ãŸï¼\")\n            st.image(pasted_image_bytes, caption=\"è²¼ã‚Šä»˜ã‘ãŸç”»åƒ\", use_container_width=True)\n            if st.button(\"ğŸ—‘ï¸ ç”»åƒã‚’ã‚¯ãƒªã‚¢\", key=\"clear_paste\"):\n                st.session_state.paste_key += 1\n                st.rerun()\n    else:\n        st.warning(\"Clipboard library not loaded (ImportError)\")\n\n    # ---- YouTube URL ----\n    st.markdown(\"---\")\n    youtube_url = st.text_input(\"YouTube URL (å­—å¹•ã‚’åˆ†æ)\", placeholder=\"https://youtu.be/...\")\n\n    st.markdown(\"---\")\n    \n    # ---- å›ç­”ãƒ¢ãƒ¼ãƒ‰ ----\n    st.subheader(\"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰\")\n    \n    mode_type = st.radio(\n        \"ãƒ¢ãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—\",\n        [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n        index=0,\n        horizontal=True\n    )\n    \n    if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n        response_mode = st.radio(\n            \"é¸æŠ\",\n            [\n                \"2. ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                \"3. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                \"Î²2. ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n            ],\n            index=0\n        )\n        st.caption(\"âœ… å®Œæˆåº¦ã®é«˜ã„æ¨å¥¨ãƒ¢ãƒ¼ãƒ‰\")\n    elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n        response_mode = st.radio(\n            \"é¸æŠ\",\n            [\n                \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n            ],\n            index=0\n        )\n        st.caption(\"âš ï¸ é–‹ç™ºä¸­: ä¸€éƒ¨æ©Ÿèƒ½ãŒæœªå®Œæˆã§ã™\")\n    else:\n        response_mode = st.radio(\n            \"é¸æŠ (ãƒ™ãƒ¼ã‚¿ç‰ˆ)\",\n            [\n                \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n            ],\n            index=0\n        )\n        st.caption(\"âš ï¸ ãƒ™ãƒ¼ã‚¿ç‰ˆæ©Ÿèƒ½: å‹•ä½œãŒä¸å®‰å®šãªå ´åˆãŒã‚ã‚Šã¾ã™\")\n    \n    strict_mode = False  # äº’æ›æ€§ç¶­æŒã®ãŸã‚ã®ãƒ€ãƒŸãƒ¼å¤‰æ•°\n    st.markdown(\"---\")\n    \n    st.title(\"è¨­å®š\")\n\n    # ---- ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆGemini 1.5 ã¯å»ƒæ­¢ã•ã‚Œã¦ã„ã‚‹ã®ã§å«ã‚ãªã„ï¼‰ ----\n    model_options = [\n        \"gemini-3-pro-preview\",\n        \"gemini-2.5-pro\",\n        \"gemini-2.5-flash\",\n        \"gemini-2.5-flash-lite\",\n        \"gemini-2.0-flash\",\n    ]\n    model_id = st.selectbox(\"ãƒ¢ãƒ‡ãƒ«ID\", options=model_options, index=0)\n\n    if \"3-pro\" in model_id or \"2.5-pro\" in model_id:\n        st.caption(\"ğŸ§  é«˜åº¦ãªæ¨è«–å‘ã‘ Pro ãƒ¢ãƒ‡ãƒ«\")\n    if \"flash\" in model_id:\n        st.caption(\"âš¡ é«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆãª Flash ç³»ãƒ¢ãƒ‡ãƒ«\")\n\n    # ---- æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚° ----\n    use_search = st.toggle(\"Googleæ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã‚’ä½¿ç”¨\", value=True)\n    candidate_count = st.slider(\"å›ç­”å€™è£œæ•°\", min_value=1, max_value=3, value=3)\n    if use_search and candidate_count > 1:\n        st.caption(\"âš ï¸ æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ä½¿ç”¨æ™‚ã¯å€™è£œæ•°ãŒ1ã«ãªã‚Šã¾ã™ã€‚\")\n\n    st.markdown(\"---\")\n\n    # ---- å±¥æ­´æ¤œç´¢ ----\n    search_query = st.text_input(\"ğŸ” å±¥æ­´ã‚’æ¤œç´¢\", placeholder=\"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰...\")\n    if search_query:\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if search_query.lower() in s[\"title\"].lower():\n                filtered_sessions.append(s)\n                continue\n            found = False\n            for m in s[\"messages\"]:\n                if search_query.lower() in m[\"content\"].lower():\n                    filtered_sessions.append(s)\n                    found = True\n                    break\n            if not found:\n                pass\n    else:\n        filtered_sessions = st.session_state.sessions\n\n    # CSSã§è¦‹ã‚„ã™ãä½¿ã„ã‚„ã™ãæœ€é©åŒ–\n    st.markdown(\"\"\"\n    <style>\n    /* éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã®ã‚¿ã‚¤ãƒˆãƒ« */\n    div[data-testid=\"stExpander\"] summary p {\n        font-size: 11px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ */\n    section[data-testid=\"stSidebar\"] button p {\n        font-size: 13px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã« */\n    section[data-testid=\"stSidebar\"] button {\n        padding: 0.25rem 0.5rem !important;\n        min-height: 2rem !important;\n    }\n    </style>\n    \"\"\", unsafe_allow_html=True)\n    \n    # ç›´è¿‘5ä»¶ã¨éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«åˆ†å‰²\n    recent_sessions = filtered_sessions[:5] if len(filtered_sessions) > 5 else filtered_sessions\n    archive_sessions = filtered_sessions[5:] if len(filtered_sessions) > 5 else []\n    \n    # ç›´è¿‘5ä»¶ï¼ˆå¸¸ã«å±•é–‹ï¼‰\n    if recent_sessions:\n        st.markdown(\"**ğŸ“Œ ç›´è¿‘ã®ãƒãƒ£ãƒƒãƒˆ**\")\n        for session in recent_sessions:\n            col1, col2 = st.columns([0.8, 0.2])\n            with col1:\n                if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                    switch_session(session[\"id\"])\n            with col2:\n                if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                    delete_session(session[\"id\"])\n    \n    # éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆæŠ˜ã‚ŠãŸãŸã¿ï¼‰\n    if archive_sessions:\n        with st.expander(f\"ğŸ“œ éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ– ({len(archive_sessions)}ä»¶)\", expanded=False):\n            for session in archive_sessions:\n                col1, col2 = st.columns([0.8, 0.2])\n                with col1:\n                    if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                        switch_session(session[\"id\"])\n                with col2:\n                    if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                        delete_session(session[\"id\"])\n\n    st.markdown(\"---\")\n\n    # ---- ç”»åƒç”Ÿæˆ ----\n    st.subheader(\"ğŸ¨ ç”»åƒç”Ÿæˆ\")\n    img_prompt = st.text_area(\"ç”Ÿæˆã—ãŸã„ç”»åƒã®èª¬æ˜\", placeholder=\"æœªæ¥çš„ãªéƒ½å¸‚ã®é¢¨æ™¯...\")\n    aspect_ratio = st.selectbox(\"ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”\", [\"16:9\", \"1:1\", \"4:3\", \"3:4\", \"9:16\"])\n\n    generate_img_btn = st.button(\"ç”»åƒã‚’ç”Ÿæˆ\", type=\"primary\", disabled=not img_prompt)\n    if generate_img_btn and img_prompt:\n        st.session_state.generate_image_trigger = {\n            \"prompt\": img_prompt,\n            \"aspect_ratio\": aspect_ratio,\n        }\n\n    st.markdown(\"---\")\n\n    # ---- è©•ä¾¡åˆ†æ ----\n    st.subheader(\"ğŸ“Š å›ç­”å“è³ªåˆ†æ\")\n    total_ratings = 0\n    positive_ratings = 0\n    model_ratings = {}\n\n    for s in st.session_state.sessions:\n        for m in s[\"messages\"]:\n            if \"rating\" in m and m[\"rating\"] is not None:\n                total_ratings += 1\n                if m[\"rating\"] == 1:\n                    positive_ratings += 1\n                if \"metadata\" in m and \"model\" in m[\"metadata\"]:\n                    mod = m[\"metadata\"][\"model\"]\n                    if mod not in model_ratings:\n                        model_ratings[mod] = {\"total\": 0, \"positive\": 0}\n                    model_ratings[mod][\"total\"] += 1\n                    if m[\"rating\"] == 1:\n                        model_ratings[mod][\"positive\"] += 1\n\n    if total_ratings > 0:\n        approval_rate = (positive_ratings / total_ratings) * 100\n        st.metric(\"Positive Ratings\", f\"{positive_ratings}/{total_ratings}\", f\"{approval_rate:.1f}%\")\n        best_model = \"N/A\"\n        best_rate = -1\n        for mod, stats in model_ratings.items():\n            rate = stats[\"positive\"] / stats[\"total\"]\n            if rate > best_rate:\n                best_rate = rate\n                best_model = mod\n        if best_model != \"N/A\":\n            st.caption(f\"ğŸ† Best Model: **{best_model}** ({best_rate*100:.0f}%)\")\n    else:\n        st.caption(\"ã¾ã è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\")\n\n    st.markdown(\"---\")\n\n    # ---- ã‚³ã‚¹ãƒˆè¡¨ç¤º ----\n    st.subheader(\"ğŸ’° ã‚³ã‚¹ãƒˆ (æ¦‚ç®—)\")\n    st.metric(\"Total Cost\", f\"${usage_stats['total_cost_usd']:.4f}\")\n    if st.session_state.session_cost > 0:\n        st.caption(f\"Current Session: ${st.session_state.session_cost:.4f}\")\n\n    if usage_stats[\"total_cost_usd\"] >= MAX_BUDGET_USD:\n        st.error(f\"âš ï¸ äºˆç®—ä¸Šé™ (${MAX_BUDGET_USD}) ã«é”ã—ã¾ã—ãŸã€‚\")\n        stop_generation = True\n    else:\n        stop_generation = False\n\n    st.markdown(\"---\")\n    st.code(f\"PROJECT: {VERTEX_PROJECT}\\nLOCATION: {VERTEX_LOCATION} (Vertex AI)\")\n\n# =========================\n# Main UI\n# =========================\n\ncurrent_session_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\nfor s in st.session_state.sessions:\n    if s[\"id\"] == st.session_state.current_session_id:\n        current_session_title = s[\"title\"]\n        break\n\nst.header(current_session_title)\nst.markdown(\n    \"ä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\"\n)\n\n# ---- Vertex AI Client ----\n\n@st.cache_resource\ndef get_client():\n    return genai.Client(\n        vertexai=True,\n        project=VERTEX_PROJECT,\n        location=VERTEX_LOCATION,\n    )\n\nclient = get_client()\n\n# ---- å±¥æ­´è¡¨ç¤º ----\n\nmessages = get_current_messages()\nfor idx, msg in enumerate(messages):\n    with st.chat_message(msg[\"role\"]):\n        st.markdown(msg[\"content\"])\n        if msg[\"role\"] == \"model\":\n            col1, col2, col3 = st.columns([0.1, 0.1, 0.8])\n            current_rating = msg.get(\"rating\")\n            with col1:\n                if st.button(\"ğŸ‘\", key=f\"up_{idx}\"):\n                    messages[idx][\"rating\"] = 1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col2:\n                if st.button(\"ğŸ‘\", key=f\"down_{idx}\"):\n                    messages[idx][\"rating\"] = -1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col3:\n                if current_rating == 1:\n                    st.caption(\"âœ… é«˜è©•ä¾¡\")\n                elif current_rating == -1:\n                    st.caption(\"âŒ ä½è©•ä¾¡\")\n\n# =========================\n# ç”»åƒç”Ÿæˆãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°\n# =========================\n\nif hasattr(st.session_state, \"generate_image_trigger\") and st.session_state.generate_image_trigger:\n    img_data = st.session_state.generate_image_trigger\n    del st.session_state.generate_image_trigger\n\n    with st.chat_message(\"user\"):\n        st.markdown(f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\")\n        st.caption(f\"ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”: {img_data['aspect_ratio']}\")\n\n    messages.append({\"role\": \"user\", \"content\": f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\"})\n    update_current_session_messages(messages)\n\n    with st.chat_message(\"assistant\"):\n        with st.status(\"ç”»åƒã‚’ç”Ÿæˆä¸­...\", expanded=True) as status:\n            try:\n                config = types.GenerateContentConfig(\n                    response_modalities=[\"IMAGE\"],\n                    image_config=types.ImageConfig(\n                        aspect_ratio=img_data[\"aspect_ratio\"]\n                    ),\n                )\n                status.write(\"Gemini 3 Pro Imageã§ç”Ÿæˆä¸­...\")\n                response = client.models.generate_content(\n                    model=\"gemini-3-pro-image-preview\",\n                    contents=img_data[\"prompt\"],\n                    config=config,\n                )\n\n                generated_image = None\n\n                # ç”»åƒã‚’å–ã‚Šå‡ºã™\n                if getattr(response, \"candidates\", None):\n                    for candidate in response.candidates:\n                        if getattr(candidate, \"content\", None) and candidate.content.parts:\n                            for part in candidate.content.parts:\n                                if getattr(part, \"inline_data\", None):\n                                    try:\n                                        generated_image = part.as_image()\n                                    except AttributeError:\n                                        image_bytes_raw = part.inline_data.data\n                                        generated_image = Image.open(io.BytesIO(image_bytes_raw))\n                                    break\n                        if generated_image is not None:\n                            break\n\n                if generated_image is not None:\n                    st.image(generated_image, caption=img_data[\"prompt\"])\n                    buf = io.BytesIO()\n                    generated_image.save(buf, format=\"PNG\")\n                    image_bytes = buf.getvalue()\n                    st.download_button(\n                        label=\"ğŸ’¾ ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\",\n                        data=image_bytes,\n                        file_name=f\"generated_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png\",\n                        mime=\"image/png\",\n                    )\n                    messages.append(\n                        {\"role\": \"model\", \"content\": f\"âœ… ç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {img_data['prompt']}\"}\n                    )\n                    update_current_session_messages(messages)\n                    status.update(label=\"âœ… ç”»åƒç”Ÿæˆå®Œäº†\", state=\"complete\")\n                else:\n                    st.error(\"ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")\n                    status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n\n            except Exception as e:\n                status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n                st.error(f\"ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}\")\n\n# =========================\n# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›\n# =========================\n\nprompt = st.chat_input(\"ä½•ã‹èã„ã¦ãã ã•ã„...\", disabled=stop_generation)\n\nif prompt:\n    if stop_generation:\n        st.error(\"äºˆç®—ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚\")\n    else:\n        # ---- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€è¡¨ç¤º ----\n        with st.chat_message(\"user\"):\n            st.markdown(prompt)\n            if uploaded_files:\n                for uf in uploaded_files:\n                    st.caption(f\"ğŸ“ æ·»ä»˜: {uf.name}\")\n            if youtube_url:\n                st.caption(f\"ğŸ“º YouTube: {youtube_url}\")\n            if pasted_image_bytes:\n                st.caption(\"ğŸ“‹ ç”»åƒãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚Œã¾ã—ãŸ\")\n\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        update_current_session_messages(messages)\n\n        # ---- ãƒ¢ãƒ‡ãƒ«å¿œç­” ----\n        with st.chat_message(\"assistant\"):\n            status_container = st.status(\"æ€è€ƒä¸­...\", expanded=True)\n            try:\n                # ä¼šè©±å±¥æ­´\n                model_history = []\n                for msg in messages[:-1]:\n                    model_history.append(\n                        types.Content(\n                            role=msg[\"role\"],\n                            parts=[types.Part.from_text(text=msg[\"content\"])],\n                        )\n                    )\n\n                # ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³\n                current_parts = [types.Part.from_text(text=prompt)]\n\n                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«\n                for uploaded_file in uploaded_files or []:\n                    try:\n                        mime_type = get_mime_type(uploaded_file.name)\n                        bytes_data = uploaded_file.getvalue()\n                        part = types.Part.from_bytes(data=bytes_data, mime_type=mime_type)\n                        current_parts.append(part)\n                        status_container.write(f\"ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™å®Œäº†: {uploaded_file.name}\")\n                    except Exception as e:\n                        status_container.error(\n                            f\"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {uploaded_file.name} - {e}\"\n                        )\n\n                # è²¼ã‚Šä»˜ã‘ç”»åƒ\n                if pasted_image_bytes:\n                    import base64\n\n                    status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã‚’å‡¦ç†ä¸­...\")\n                    try:\n                        if isinstance(pasted_image_bytes, str):\n                            if pasted_image_bytes.startswith(\"data:\"):\n                                base64_str = pasted_image_bytes.split(\",\", 1)[1]\n                                image_bytes_decoded = base64.b64decode(base64_str)\n                            else:\n                                image_bytes_decoded = base64.b64decode(pasted_image_bytes)\n                        else:\n                            image_bytes_decoded = pasted_image_bytes\n                        part = types.Part.from_bytes(\n                            data=image_bytes_decoded, mime_type=\"image/png\"\n                        )\n                        current_parts.append(part)\n                        status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®æº–å‚™å®Œäº†\")\n                    except Exception as e:\n                        status_container.error(f\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n\n                # YouTube å­—å¹•\n                if youtube_url:\n                    vid_id = extract_youtube_id(youtube_url)\n                    if vid_id:\n                        status_container.write(\"YouTubeã®å­—å¹•ã‚’å–å¾—ä¸­...\")\n                        transcript_text = get_youtube_transcript(vid_id)\n                        current_parts.append(\n                            types.Part.from_text(text=f\"YouTube Transcript:\\n{transcript_text}\")\n                        )\n                    else:\n                        status_container.write(\"ç„¡åŠ¹ãªYouTube URLã§ã™ã€‚\")\n\n                contents_for_model = model_history + [\n                    types.Content(role=\"user\", parts=current_parts)\n                ]\n\n                # ---- Tool / Config ----\n                tools = []\n                final_candidate_count = candidate_count\n                if use_search:\n                    tools.append(types.Tool(google_search=types.GoogleSearch()))\n                    final_candidate_count = 1\n\n                # â˜… System Instruction ã®æ”¹å–„: ãƒ¡ã‚¿ç™ºè¨€ç¦æ­¢ã¨ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªæŒ¯ã‚‹èˆã„ã‚’æŒ‡ç¤º\n                base_system_instruction = (\n                    \"ã‚ãªãŸã¯é«˜åº¦ãªçŸ¥æ€§ã‚’æŒã¤å°‚é–€çš„ãªãƒªã‚µãƒ¼ãƒãƒ»ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\\n\"\n                    \"ä»¥ä¸‹ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’å³å®ˆã—ã¦ãã ã•ã„ï¼š\\n\"\n                    \"1. **ãƒ¡ã‚¿ç™ºè¨€ã®ç¦æ­¢**: ã€Œç§ã¯AIã§ã™ã€ã€Œä¸–ç•Œæœ€é«˜å³°ã®ï½ã¨ã—ã¦ã€ãªã©ã®è‡ªå·±è¨€åŠã‚„å‰ç½®ãã¯ä¸€åˆ‡è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚\\n\"\n                    \"2. **æ„å›³ã®æ±²ã¿å–ã‚Š**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã®èƒŒå¾Œã«ã‚ã‚‹æ„å›³ï¼ˆæ–‡è„ˆã€æš—é»™ã®å‰æï¼‰ã‚’æ¨æ¸¬ã—ã€è¨€è‘‰é€šã‚Šã§ã¯ãªãã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ¬å½“ã«çŸ¥ã‚ŠãŸã„ã“ã¨ã€ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n\"\n                    \"3. **æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”**: çµè«–ã‚’å…ˆã«è¿°ã¹ã€ãã®å¾Œã«è©³ç´°ãªæ ¹æ‹ ã€ã‚·ãƒŠãƒªã‚ªåˆ†æã€ãƒªã‚¹ã‚¯è¦å› ã‚’è«–ç†çš„ã«å±•é–‹ã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"4. **å®¢è¦³æ€§**: äºˆæ¸¬ã‚’è¡Œã†å ´åˆã¯ã€æ–­å®šã‚’é¿ã‘ã€è¤‡æ•°ã®ã‚·ãƒŠãƒªã‚ªï¼ˆæ¥½è¦³ã€æ‚²è¦³ã€ä¸­ç«‹ï¼‰ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"5. **å¼•ç”¨**: æ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸå ´åˆã¯ã€å¿…ãšæƒ…å ±æºã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚\"\n                )\n\n                final_answer = \"\"\n                grounding_metadata = None\n                \n                # =========================\n                # ãƒ¢ãƒ¼ãƒ‰è¨­å®šã®è§£æ\n                # =========================\n                enable_research = True  # å…¨ãƒ¢ãƒ¼ãƒ‰ã§ãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œ\n                enable_meta = \"ãƒ¡ã‚¿\" in response_mode or \"MAX\" in response_mode\n                enable_strict = \"é¬¼è»æ›¹\" in response_mode or \"MAX\" in response_mode\n\n                # =========================\n                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (é«˜é€Ÿ / é¬¼è»æ›¹)\n                # =========================\n                if not enable_research:\n                    config = types.GenerateContentConfig(\n                        temperature=0.7,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=base_system_instruction,\n                    )\n                    \n                    status_container.write(\"å›ç­”ç”Ÿæˆä¸­...\")\n                    response = client.models.generate_content(\n                        model=model_id,\n                        contents=contents_for_model,\n                        config=config,\n                    )\n                    \n                    final_answer = extract_text_from_response(response)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®—\n                    if response.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            response.usage_metadata.prompt_token_count,\n                            response.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += response.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += response.usage_metadata.candidates_token_count\n\n                    # é¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ (é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ç‰ˆ)\n                    if enable_strict:\n                        status_container.write(\"ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        reviewer_instruction = base_system_instruction + \"\"\"\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n                        review_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\nåˆç‰ˆå›ç­”:\\n{final_answer}\\n\\nãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\")])]\n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=types.GenerateContentConfig(temperature=0.1, candidate_count=1, system_instruction=reviewer_instruction)\n                        )\n                        final_answer = extract_text_from_response(review_resp)\n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        \n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(model_id, review_resp.usage_metadata.prompt_token_count, review_resp.usage_metadata.candidates_token_count)\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n\n                # =========================\n                # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰\n                # =========================\n                else:\n                    # =========================\n                    # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰: å¤šæ®µéšã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ \n                    # =========================\n                    \n                    # --- Phase 1: ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 1: ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    research_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒªã‚µãƒ¼ãƒå°‚ä»»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚æœ€çµ‚å›ç­”ã¯æ›¸ã‹ãšã€äº‹å®Ÿåé›†ã«é›†ä¸­ã™ã‚‹ã“ã¨ã€‚\n\n**èª¿æŸ»è¦³ç‚¹**:\n- è³ªå•ã«é–¢é€£ã™ã‚‹**æœ€æ–°ã®äº‹å®Ÿãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ»çµ±è¨ˆ**ï¼ˆ**2025å¹´ã®æƒ…å ±ã‚’æœ€å„ªå…ˆ**ï¼‰\n- **ç¾æ™‚ç‚¹ã§å­˜åœ¨ã™ã‚‹å…¨ã¦ã®é¸æŠè‚¢ãƒ»ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¶²ç¾…çš„ã«èª¿æŸ»**ï¼ˆä¾‹: è£½å“æ¯”è¼ƒãªã‚‰ã€æœ€æ–°ç‰ˆã ã‘ã§ãªãç›´è¿‘ã®å…¨ä¸–ä»£ã‚’èª¿æŸ»ï¼‰\n- å…¬å¼æƒ…å ±ã‚„ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã‹ã‚‰ã®å¼•ç”¨\n- é–¢é€£ã™ã‚‹èƒŒæ™¯æƒ…å ±ã‚„æ–‡è„ˆ\n- ç«¶åˆãƒ»ä»£æ›¿æ¡ˆãƒ»æ¯”è¼ƒå¯¾è±¡ã®**å®Œå…¨ãªãƒªã‚¹ãƒˆ**\n- ãƒªã‚¹ã‚¯ãƒ»åˆ¶ç´„ãƒ»æ³¨æ„ç‚¹ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n- å‚è€ƒã«ã—ãŸä¸»è¦ãªæƒ…å ±æºã®URL\n\n**é‡è¦**: \n- çµè«–ã‚„æ¨å¥¨ã¯æ›¸ã‹ãšã€å¾Œå·¥ç¨‹ãŒåˆ¤æ–­ã§ãã‚‹èª¿æŸ»ãƒ¡ãƒ¢ã«é›†ä¸­ã™ã‚‹ã“ã¨\n- **å¿…ãšæ¤œç´¢æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã€æœ€æ–°ã®æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã“ã¨**\n- **æ¤œç´¢çµæœã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æ—¥ä»˜ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒ»ãƒ¢ãƒ‡ãƒ«åã‚’å„ªå…ˆçš„ã«è¨˜è¼‰ã™ã‚‹ã“ã¨**\n- **æ¯”è¼ƒå¯¾è±¡ã¨ãªã‚‹é¸æŠè‚¢ã‚’è¦‹è½ã¨ã•ãªã„ã‚ˆã†ã€è¤‡æ•°ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è©¦ã™ã“ã¨**ï¼ˆä¾‹: ã€ŒiPhone æœ€æ–°ãƒ¢ãƒ‡ãƒ« 2025ã€ã€ŒiPhone 17ã€ã€ŒiPhone 2025å¹´ç™ºå£²ã€ãªã©ï¼‰\n- **ã€Œã“ã‚Œã‚ˆã‚Šæ–°ã—ã„ãƒ¢ãƒ‡ãƒ«/ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯å­˜åœ¨ã—ãªã„ã‹ï¼Ÿã€ã‚’å¸¸ã«ç¢ºèªã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ï¼ˆ2024å¹´ä»¥å‰ãªã©ï¼‰ã—ã‹è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãã®æ—¨ã‚’æ˜è¨˜ã™ã‚‹ã“ã¨\n\"\"\"\n\n                    # éå»ã®é–¢é€£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—\n                    past_context = get_relevant_context(prompt)\n                    \n                    # ãƒªã‚µãƒ¼ãƒç”¨ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ§‹ç¯‰\n                    research_parts = [types.Part(text=f\"ã“ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š\\n{prompt}\")]\n                    \n                    if past_context:\n                        research_parts.insert(0, types.Part(text=\"ä»¥ä¸‹ã¯éå»ã®é–¢é€£ãƒãƒ£ãƒƒãƒˆã‹ã‚‰æŠ½å‡ºã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã™ï¼š\\n\\n\" + past_context))\n                    \n                    research_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=research_parts)\n                    ]\n                    \n                    research_config = types.GenerateContentConfig(\n                        temperature=0.2,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=research_instruction,\n                    )\n                    \n                    research_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=research_contents,\n                        config=research_config,\n                    )\n                    \n                    research_text = extract_text_from_response(research_resp)\n                    \n                    # ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºã®ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ±ã‚’ä¿å­˜\n                    if research_resp.candidates and research_resp.candidates[0].grounding_metadata:\n                        grounding_metadata = research_resp.candidates[0].grounding_metadata\n                    \n                    status_container.write(\"âœ“ ãƒªã‚µãƒ¼ãƒå®Œäº†\")\n                    with status_container.expander(\"åé›†ã—ãŸèª¿æŸ»ãƒ¡ãƒ¢\", expanded=False):\n                        st.markdown(research_text)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1)\n                    if research_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            research_resp.usage_metadata.prompt_token_count,\n                            research_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += research_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += research_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 1.5: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    questions_text = \"\"\n                    if enable_meta:\n                        status_container.write(\"Phase 1.5: ãƒ¡ã‚¿è³ªå•ç”Ÿæˆä¸­...\")\n                        \n                        question_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ç›®çš„**: \nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•ã¨èª¿æŸ»ãƒ¡ãƒ¢ã‚’è¸ã¾ãˆã¦ã€ã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±ãç†è§£ã™ã‚‹ãŸã‚ã®ã€Œé‹­ã„ã‚µãƒ–è³ªå•ã€ã‚’ä½œæˆã™ã‚‹ã“ã¨ã€‚\n\n**ãƒ«ãƒ¼ãƒ«**:\n- æœ€å¤§5å€‹ã¾ã§\n- å„è³ªå•ã¯1-2è¡Œã§å…·ä½“çš„ã‹ã¤é‹­ã\n- ä»¥ä¸‹ã®è¦³ç‚¹ã‚’æ„è­˜:\n  1. å‰æãŒå´©ã‚Œã‚‹å¯èƒ½æ€§ã¯ã©ã“ã‹ï¼Ÿ\n  2. å¼·æ°—/å¼±æ°—ã‚·ãƒŠãƒªã‚ªã®åˆ†å²ç‚¹ã¯ä½•ã‹ï¼Ÿ\n  3. ç«¶åˆãƒ»æŠ€è¡“ãƒ»è¦åˆ¶ã®ä¸ç¢ºå®Ÿæ€§ã¯ï¼Ÿ\n  4. ã€Œäºˆæ¸¬ãŒå¤–ã‚Œã‚‹ã¨ã—ãŸã‚‰ã©ã‚“ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ï¼Ÿã€\n\n**å‡ºåŠ›**: ç®‡æ¡æ›¸ãï¼ˆQ1, Q2...ï¼‰ã®ã¿\n\"\"\"\n\n                        question_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•:\\n{prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\nã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±æ˜ã‚Šã™ã‚‹ãŸã‚ã®é‡è¦ãªã‚µãƒ–è³ªå•ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\")])]\n                        \n                        question_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=question_contents,\n                            config=types.GenerateContentConfig(\n                                temperature=0.4,\n                                candidate_count=1,\n                                system_instruction=question_instruction,\n                            )\n                        )\n                        \n                        questions_text = extract_text_from_response(question_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¡ã‚¿è³ªå•ç”Ÿæˆå®Œäº†\")\n                        with status_container.expander(\"ç”Ÿæˆã•ã‚ŒãŸãƒ¡ã‚¿è³ªå•\", expanded=False):\n                            st.markdown(questions_text)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1.5)\n                        if question_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                question_resp.usage_metadata.prompt_token_count,\n                                question_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += question_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += question_resp.usage_metadata.candidates_token_count\n\n                    # --- Phase 2: çµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 2: çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    if enable_meta:\n                        deep_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã¨ãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ã‚’æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**æ§‹æˆ**:\n1. **æ·±æ˜ã‚Šè€ƒå¯Ÿ**ï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n2. **çµè«–**ï¼ˆ2-3è¡Œï¼‰\n3. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n4. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨\n\"\"\"\n                    else:\n                        deep_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã‚’å”¯ä¸€ã®æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**æ§‹æˆ**:\n1. **çµè«–**ï¼ˆ2-3è¡Œã§æ˜ç¢ºã«ï¼‰\n2. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n3. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«åã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ã¨æ–°ã—ã„æƒ…å ±ãŒæ··åœ¨ã™ã‚‹å ´åˆã¯ã€æ–°ã—ã„æƒ…å ±ã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n\"\"\"\n                    \n                    synthesis_prompt_text = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if enable_meta and questions_text:\n                        synthesis_prompt_text += f\"==== ãƒ¡ã‚¿è³ªå•ä¸€è¦§ ====\\n{questions_text}\\n==== ãƒ¡ã‚¿è³ªå•ã“ã“ã¾ã§ ====\\n\\næŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n2. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»åˆ†æãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    else:\n                        synthesis_prompt_text += \"ä¸Šè¨˜ãƒ¡ãƒ¢ã‚’æ ¹æ‹ ã«ã€æœ€çµ‚å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å¿…ãšä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚**\"\n\n                    synthesis_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=[\n                            types.Part(text=synthesis_prompt_text)\n                        ])\n                    ]\n                    \n                    synthesis_config = types.GenerateContentConfig(\n                        temperature=0.3,\n                        candidate_count=1,\n                        tools=[],  # çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºã§ã¯æ¤œç´¢OFF\n                        system_instruction=deep_instruction,\n                    )\n                    \n                    synthesis_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=synthesis_contents,\n                        config=synthesis_config,\n                    )\n                    \n                    draft_answer = extract_text_from_response(synthesis_resp)\n                    \n                    status_container.write(\"âœ“ çµ±åˆå®Œäº†\")\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 2)\n                    if synthesis_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            synthesis_resp.usage_metadata.prompt_token_count,\n                            synthesis_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += synthesis_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += synthesis_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    if enable_strict:\n                        status_container.write(\"Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        \n\n                        reviewer_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™ã€‚ãŸã ã—ã€**èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’å„ªå…ˆã—ã€æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã™ã‚‹ã“ã¨**ã€‚\n\n**ãƒ¬ãƒ“ãƒ¥ãƒ¼è¦³ç‚¹**:\n- äº‹å®Ÿã¨æ¨æ¸¬ã‚’æ˜ç¢ºã«åˆ†ã‘ã‚‹\n- éåº¦ã«è‡ªä¿¡ã®ã‚ã‚‹æ–­å®šã‚’å¼±ã‚ã‚‹\n- æ•°å­—ã‚„å›ºæœ‰åè©ãŒèª¿æŸ»ãƒ¡ãƒ¢ã¨çŸ›ç›¾ã—ã¦ã„ãªã„ã‹ç¢ºèª\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ãƒ¢ãƒ‡ãƒ«ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ãŒæ­£ã—ãä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª**\n- **å¤ã„æƒ…å ±ã§ä¸Šæ›¸ãã—ã¦ã„ãªã„ã‹ç¢ºèª**\n- è¦‹è½ã¨ã—ã¦ã„ã‚‹é‡è¦ãªãƒªã‚¹ã‚¯ãƒ»ã‚·ãƒŠãƒªã‚ªãŒã‚ã‚Œã°è¿½åŠ \n\n**é‡è¦**: \n- èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ãŒæœ€æ–°ã§ã‚ã‚‹å ´åˆã€ãã‚Œã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n- ã‚ãªãŸã®çŸ¥è­˜ãŒå¤ã„å ´åˆã¯ã€èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’ä¿¡é ¼ã™ã‚‹ã“ã¨\n\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n\n                        review_contents = [\n                            types.Content(role=\"user\", parts=[\n                                types.Part.from_text(\n                                    text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\n\"\n                                    f\"==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                                    f\"åˆç‰ˆå›ç­”:\\n{draft_answer}\\n\\n\"\n                                    \"ä¸Šè¨˜ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚**\"\n                                )\n                            ])\n                        ]\n                        \n                        review_config = types.GenerateContentConfig(\n                            temperature=0.1,\n                            candidate_count=1,\n                            system_instruction=reviewer_instruction,\n                        )\n                        \n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=review_config,\n                        )\n                        \n                        final_answer = extract_text_from_response(review_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        with status_container.expander(\"åˆç‰ˆã¨ã®æ¯”è¼ƒ\", expanded=False):\n                            st.markdown(\"**åˆç‰ˆ:**\")\n                            st.markdown(draft_answer[:500] + \"...\" if len(draft_answer) > 500 else draft_answer)\n                            st.markdown(\"**ä¿®æ­£ç‰ˆ:**\")\n                            st.markdown(final_answer[:500] + \"...\" if len(final_answer) > 500 else final_answer)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 3)\n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                review_resp.usage_metadata.prompt_token_count,\n                                review_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n                    else:\n                        final_answer = draft_answer\n\n                save_usage(usage_stats)\n                status_container.update(label=\"å®Œäº†ï¼\", state=\"complete\", expanded=False)\n\n                # ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤º\n                st.caption(f\"ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_id}\")\n                st.markdown(final_answer)\n\n                # ---- ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ± ----\n                if grounding_metadata:\n                    st.markdown(\"---\")\n                    st.subheader(\"ğŸ“š æƒ…å ±æºã¨å¼•ç”¨\")\n                    if grounding_metadata.grounding_chunks:\n                        st.markdown(\"**æ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:**\")\n                        unique_sources = {}\n                        import urllib.parse\n\n                        for chunk in grounding_metadata.grounding_chunks:\n                            if getattr(chunk, \"web\", None):\n                                uri = getattr(chunk.web, \"uri\", None)\n                                title = getattr(chunk.web, \"title\", \"æƒ…å ±æº\")\n                                if uri and uri not in unique_sources:\n                                    parsed = urllib.parse.urlparse(uri)\n                                    domain = parsed.netloc.replace(\"www.\", \"\")\n                                    unique_sources[uri] = {\n                                        \"title\": title,\n                                        \"domain\": domain,\n                                    }\n                        for i, (uri, info) in enumerate(unique_sources.items(), 1):\n                            st.markdown(f\"{i}. **[{info['title']}]({uri})**\")\n                            st.caption(f\"   å‡ºå…¸: {info['domain']}\")\n\n                messages.append({\"role\": \"model\", \"content\": final_answer})\n                update_current_session_messages(messages)\n\n            except Exception as e:\n                status_container.update(label=\"Error\", state=\"error\")\n                err_text = str(e)\n                if \"RESOURCE_EXHAUSTED\" in err_text or \"429\" in err_text:\n                    st.error(\n                        \"âš ï¸ Vertex AI / Gemini ã®ã‚¯ã‚©ãƒ¼ã‚¿ã«é”ã—ã¾ã—ãŸã€‚\\n\\n\"\n                        \"ãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ / æ—¥æ¬¡åˆ¶é™ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\\n\"\n                        \"ãƒ»ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                        \"ãƒ»Google Cloud Console ã®ã€ŒVertex AI â†’ ä½¿ç”¨çŠ¶æ³ã€ã‹ã‚‰ã‚¯ã‚©ãƒ¼ã‚¿çŠ¶æ³ã‚’ç¢ºèªã§ãã¾ã™ã€‚\"\n                    )\n                elif \"NOT_FOUND\" in err_text and \"Publisher Model\" in err_text:\n                    st.error(\n                        \"âš ï¸ æŒ‡å®šã—ãŸãƒ¢ãƒ‡ãƒ«ãŒã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ / ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\\n\"\n                        \"ãƒ»ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ¢ãƒ‡ãƒ«IDã‚’ã€2.5ç³» ã¾ãŸã¯ 3 Pro ã«å¤‰æ›´ã—ã¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                    )\n                else:\n                    st.error(f\"An error occurred: {e}\")"
                },
                {
                    "role": "model",
                    "content": "çµè«–ã‹ã‚‰ç”³ã—ä¸Šã’ã¾ã™ã€‚\n\n1.  **æ©Ÿèƒ½è¿½åŠ **: **å®Œå…¨ã«å¯èƒ½**ã§ã™ã€‚ãŸã ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„å›³ã™ã‚‹ã€ŒGPTã®éå»ãƒ­ã‚°ã€ã‚’è¡¨ç¤ºã™ã‚‹ã«ã¯ã€æ—¢å­˜ã® `chat_sessions.json` ã«ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã™ã‚‹ã‹ã€å°‚ç”¨ã®èª­ã¿è¾¼ã¿ãƒ­ã‚¸ãƒƒã‚¯ã‚’è¿½åŠ ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n2.  **ãƒ¢ãƒ‡ãƒ«ä»£æ›¿æ€§**: **ååˆ†ã«ä»£ç”¨å¯èƒ½ï¼ˆã‚¹ã‚³ã‚¢ 98ã€œ102ï¼‰**ã§ã™ã€‚2025å¹´11æœˆæ™‚ç‚¹ã®æœ€æ–°ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«ãŠã„ã¦ã€Gemini 3 Pro Previewã¯GPT-5.1 Proã¨æ‹®æŠ—ã—ã¦ãŠã‚Šã€ç‰¹ã«é•·æ–‡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚„Antigravityï¼ˆGoogleã®AI IDEï¼‰ã‚’æ´»ç”¨ã—ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåŒ–ã«ãŠã„ã¦ã¯ã€GPTå˜ä½“åˆ©ç”¨ã‚’ä¸Šå›ã‚‹ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ãŒã‚ã‚Šã¾ã™ã€‚\n\nä»¥ä¸‹ã«è©³ç´°ãªå®Ÿè£…æ¡ˆã¨åˆ†æã‚’æç¤ºã—ã¾ã™ã€‚\n\n---\n\n### 1. æ©Ÿèƒ½è¿½åŠ ã®å®Ÿè£…æ¡ˆï¼ˆã‚³ãƒ¼ãƒ‰ä¿®æ­£ï¼‰\n\nã”æç¤ºã®ã‚³ãƒ¼ãƒ‰ã«ã¯ `rating`ï¼ˆè©•ä¾¡ï¼‰ã‚’ä¿å­˜ã™ã‚‹ä»•çµ„ã¿ãŒã‚ã‚‹ãŸã‚ã€ã“ã‚Œã‚’æ´»ç”¨ã—ã¾ã™ã€‚ã€ŒGPTã®éå»æ¨è«–ã€ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã«ã¯ã€**GPTã®ãƒ­ã‚°ã‚’ã“ã®ã‚¢ãƒ—ãƒªã®JSONå½¢å¼ã«åˆã‚ã›ã¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹**ã®ãŒæœ€ã‚‚è¿‘é“ã§ã™ã€‚\n\nä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’ `Helper Functions` ã¨ `Sidebar` ã«è¿½åŠ ã—ã¦ãã ã•ã„ã€‚\n\n#### A. ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã®è¿½åŠ \né«˜è©•ä¾¡ï¼ˆrating=1ï¼‰ã®å›ç­”ã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°ã§ã™ã€‚\n\n```python\ndef get_best_practices():\n    \"\"\"éå»ã®é«˜è©•ä¾¡(rating=1)å›ç­”ã‚’æŠ½å‡ºã—ã¦ãƒªã‚¹ãƒˆåŒ–\"\"\"\n    sessions = load_sessions()\n    best_items = []\n    \n    for s in sessions:\n        for i, m in enumerate(s[\"messages\"]):\n            # ãƒ¢ãƒ‡ãƒ«ã®å›ç­”ã‹ã¤é«˜è©•ä¾¡ãŒã¤ã„ã¦ã„ã‚‹å ´åˆ\n            if m[\"role\"] == \"model\" and m.get(\"rating\") == 1:\n                # ç›´å‰ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’å–å¾—ï¼ˆæ–‡è„ˆã¨ã—ã¦è¡¨ç¤ºã™ã‚‹ãŸã‚ï¼‰\n                question = \"ï¼ˆè³ªå•ä¸æ˜ï¼‰\"\n                if i > 0 and s[\"messages\"][i-1][\"role\"] == \"user\":\n                    question = s[\"messages\"][i-1][\"content\"]\n                \n                best_items.append({\n                    \"id\": s[\"id\"],\n                    \"date\": s[\"timestamp\"][:10],\n                    \"question\": question,\n                    \"answer\": m[\"content\"]\n                })\n    \n    # æ–°ã—ã„é †ã«ã‚½ãƒ¼ãƒˆ\n    best_items.sort(key=lambda x: x[\"date\"], reverse=True)\n    return best_items\n```\n\n#### B. ã‚µã‚¤ãƒ‰ãƒãƒ¼ã¸ã®è¡¨ç¤ºãƒ­ã‚¸ãƒƒã‚¯\nã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€Œå±¥æ­´æ¤œç´¢ã€ã®ä¸‹ã‚ãŸã‚Šã«ä»¥ä¸‹ã‚’è¿½åŠ ã—ã¾ã™ã€‚\n\n```python\n    st.markdown(\"---\")\n    st.subheader(\"ğŸ† ãŠã™ã™ã‚ã®æ¨è«– (Best Practices)\")\n    \n    best_practices = get_best_practices()\n    \n    if not best_practices:\n        st.caption(\"ã¾ã é«˜è©•ä¾¡ï¼ˆğŸ‘ï¼‰ã®å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\")\n        st.caption(\"â€»GPTã®ãƒ­ã‚°ã‚’è¡¨ç¤ºã™ã‚‹ã«ã¯ chat_sessions.json ã«ãƒ‡ãƒ¼ã‚¿ã‚’è¿½è¨˜ã—ã¦ãã ã•ã„ã€‚\")\n    else:\n        for item in best_practices[:5]:  # æœ€æ–°5ä»¶ã‚’è¡¨ç¤º\n            with st.expander(f\"â˜… {item['date']}: {item['question'][:20]}...\"):\n                st.markdown(item['answer'])\n                if st.button(\"ã“ã®å†…å®¹ã‚’å¼•ç”¨\", key=f\"quote_{item['id']}_{item['question'][:5]}\"):\n                    st.code(item['answer'], language=\"markdown\")\n                    st.caption(\"â†‘ ã‚³ãƒ”ãƒ¼ã—ã¦ä½¿ç”¨ã—ã¦ãã ã•ã„\")\n```\n\n#### C. GPTãƒ­ã‚°ã®å–ã‚Šè¾¼ã¿æ–¹æ³•ï¼ˆé‡è¦ï¼‰\nGPTã®ãƒ­ã‚°ã‚’è¡¨ç¤ºã•ã›ã‚‹ã«ã¯ã€æ‰‹å‹•ã¾ãŸã¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ `chat_sessions.json` ã«ä»¥ä¸‹ã®å½¢å¼ã§ãƒ‡ãƒ¼ã‚¿ã‚’è¿½è¨˜ã—ã¦ãã ã•ã„ã€‚\n```json\n{\n    \"id\": \"gpt-import-001\",\n    \"title\": \"GPT-5.1 Pro ãƒ™ã‚¹ãƒˆæ¨è«–: ã€‡ã€‡ã«ã¤ã„ã¦\",\n    \"timestamp\": \"2025-11-01T12:00:00\",\n    \"messages\": [\n        {\"role\": \"user\", \"content\": \"è³ªå•å†…å®¹...\"},\n        {\"role\": \"model\", \"content\": \"GPTã®å›ç­”å†…å®¹...\", \"rating\": 1} \n    ]\n}\n```\nâ€» `\"rating\": 1` ã‚’ä»˜ä¸ã™ã‚‹ã“ã¨ã§ã€ä¸Šè¨˜ã‚³ãƒ¼ãƒ‰ãŒè‡ªå‹•çš„ã«ã€ŒãŠã™ã™ã‚ã€ã¨ã—ã¦èªè­˜ã—ã¾ã™ã€‚\n\n---\n\n### 2. GPT-5.1 Pro ã¨ã®æ¯”è¼ƒãƒ»ä»£æ›¿æ€§åˆ†æ\n\nGPT-5.1 Proã‚’ **100** ã¨ã—ãŸå ´åˆã® Gemini 3 Pro Preview (2025å¹´11æœˆç‰ˆ) ã®è©•ä¾¡ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚\n\n| è©•ä¾¡é …ç›® | ã‚¹ã‚³ã‚¢ | åˆ†æãƒ»æ ¹æ‹  (2025å¹´11æœˆæ™‚ç‚¹) |\n| :--- | :--- | :--- |\n| **ç´”ç²‹ãªæ¨è«–èƒ½åŠ›** | **98** | **ã»ã¼äº’è§’**ã€‚SWE-bench Verifiedã«ãŠã„ã¦ã€GPT-5.1-Codex-Maxã¯ç´„77.9%ã€Gemini 3 Pro Previewã¯ç´„76.2%ã‚’è¨˜éŒ²ã—ã¦ãŠã‚Šã€å®Ÿç”¨ä¸Šã®å·®ã¯èª¤å·®ç¯„å›²ã§ã™ã€‚Geminiã‚‚Thinking Modeã‚’æ­è¼‰ã—ã€ç²˜ã‚Šå¼·ã„æ¨è«–ãŒå¯èƒ½ã«ãªã‚Šã¾ã—ãŸã€‚ |\n| **ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†** | **102** | **Geminiå„ªä½**ã€‚1Mãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ã«ã‚ˆã‚Šã€å¤§é‡ã®éå»ãƒ­ã‚°ã‚„è³‡æ–™ã‚’èª­ã¿è¾¼ã¾ã›ãŸçŠ¶æ…‹ã§ã®å›ç­”ç²¾åº¦ã¯GeminiãŒä¸Šå›ã‚Šã¾ã™ã€‚ |\n| **ã‚³ã‚¹ãƒˆåŠ¹ç‡** | **110** | **Geminiå„ªä½**ã€‚åŒç­‰ã®æ¨è«–ã‚’è¡Œã‚ã›ãŸå ´åˆã€Geminiã®æ–¹ãŒå®‰ä¾¡ã«é‹ç”¨ã§ãã‚‹å‚¾å‘ã«ã‚ã‚Šã¾ã™ã€‚ |\n\n#### çµè«–ï¼šä»£ç”¨ã§ãã‚‹ã‹ï¼Ÿ\n**YESã€ä»£ç”¨å¯èƒ½ã§ã™ã€‚**\nç‰¹ã«è‡ªä½œã‚¢ãƒ—ãƒªï¼ˆ`st.sidebar` ã§ã®å±¥æ­´ç®¡ç†ã‚„æ¤œç´¢æ©Ÿèƒ½ä»˜ãï¼‰ã¨ã„ã†ç’°å¢ƒä¸‹ã§ã¯ã€Geminiã®é•·æ–‡å‡¦ç†èƒ½åŠ›ãŒæ´»ãã‚‹ãŸã‚ã€ç·åˆçš„ãªä½“é¨“ã¯GPT-5.1 Proå˜ä½“åˆ©ç”¨ã‚’ä¸Šå›ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n\n---\n\n### 3. Antigravityã«ã‚ˆã‚‹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã¤ã„ã¦\n\nè³ªå•ã«ã‚ã‚‹ã€ŒAntigravityã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹å¯èƒ½æ€§ã€ã«ã¤ã„ã¦ã€æ­£ç¢ºãªèªè­˜åˆã‚ã›ãŒå¿…è¦ã§ã™ã€‚\n\n*   **Antigravityã®æ­£ä½“**: ã“ã‚Œã¯Pythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã¯ãªãã€GoogleãŒ2025å¹´11æœˆã«å…¬é–‹ã—ãŸ**AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–‹ç™ºãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ï¼ˆIDEï¼‰**ã§ã™ã€‚\n*   **ã€Œãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€ã®å®Ÿæ…‹**: ã“ã“ã§ã®ä½œæ¥­ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’å¤‰æ›´ã™ã‚‹Fine-tuningã§ã¯ãªãã€**ã€Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å½¹å‰²å®šç¾©ï¼ˆRoleï¼‰ã€ã€Œæ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã®æ˜ç¤ºï¼ˆSystem Instructionsï¼‰ã€ã€Œãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨æ¨©é™ã€ã‚’æœ€é©åŒ–ã™ã‚‹ã“ã¨**ï¼ˆAgentic Workflowã®æ§‹ç¯‰ï¼‰ã‚’æŒ‡ã—ã¾ã™ã€‚\n*   **å„ªä½æ€§**: è‡ªä½œGeminiã‚¢ãƒ—ãƒªã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã¨ã—ã¦Antigravityã§æ§‹ç¯‰ã—ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å‘¼ã³å‡ºã™æ§‹æˆã«ã™ã‚Œã°ã€å˜ãªã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’è¶…ãˆãŸã€éå¸¸ã«é«˜åº¦ãªã€Œè‡ªåˆ†å°‚ç”¨ã®æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ã€ã‚’æ§‹ç¯‰å¯èƒ½ã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ±ç”¨çš„ãªGPT-5.1 Proã«å¯¾ã™ã‚‹æ˜ç¢ºãªå·®åˆ¥åŒ–è¦å› ã¨ãªã‚Šã¾ã™ã€‚\n\n### æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³\nã¾ãšã¯æç¤ºã—ãŸã‚³ãƒ¼ãƒ‰ã‚’è¿½åŠ ã—ã¦ã€Œè‰¯è³ªãªå›ç­”ã‚’ã‚¹ãƒˆãƒƒã‚¯ãƒ»å†åˆ©ç”¨ã™ã‚‹ã‚µã‚¤ã‚¯ãƒ«ã€ã‚’ä½œã‚Šã€ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’ `gemini-3-pro-preview` ã«å›ºå®šã—ã¦é‹ç”¨ã‚’é–‹å§‹ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚GPTã®ãƒ­ã‚°ã¯JSONå½¢å¼ã«å¤‰æ›ã—ã¦å–ã‚Šè¾¼ã‚€ã“ã¨ã§ã€è³‡ç”£ã¨ã—ã¦æ´»ç”¨ã§ãã¾ã™ã€‚"
                }
            ]
        },
        {
            "id": "5dc8df70-3e30-44cb-8fb0-7b70f1bdd9e4",
            "title": "ç¾çŠ¶gpt5.1proãŒæ¨è«–ã®ãƒ™ã‚¹ãƒˆã ã¨...",
            "timestamp": "2025-11-30T12:59:04.998247",
            "messages": [
                {
                    "role": "user",
                    "content": "ç¾çŠ¶gpt5.1proãŒæ¨è«–ã®ãƒ™ã‚¹ãƒˆã ã¨è€ƒãˆã¦ã„ã‚‹ãŒã€ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°èƒ½åŠ›ãŒè‡ªä½œgeminiã«ã¯ã‚ã‚‹ã€‚\ngpt5.1proã‚’100ã¨ã—ã¦ã€ä»¥ä¸‹ã§ä»£ç”¨ã§ãã‚‹ã‹ï¼Ÿ(antigravityã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹å¯èƒ½æ€§ã‚‚ã‚ã‚‹)\n\nimport os\nimport json\nimport re\nimport uuid\nimport datetime\nimport streamlit as st\nfrom dotenv import load_dotenv\nfrom google import genai\nfrom google.genai import types\nfrom youtube_transcript_api import YouTubeTranscriptApi\nfrom PIL import Image\nimport io\n\ntry:\n    from st_img_pastebutton import paste\n    import_error_msg = None\nexcept ImportError as e:\n    paste = None\n    import_error_msg = str(e)\n\n# =========================\n# ç’°å¢ƒå¤‰æ•° & å®šæ•°\n# =========================\n\nload_dotenv()\n\nUSAGE_FILE = \"usage_stats.json\"\nSESSIONS_FILE = \"chat_sessions.json\"\nMAX_BUDGET_USD = float(os.getenv(\"MAX_BUDGET_USD\", \"5.0\"))\n\n# â€»é‡‘é¡ã¯ã ã„ãŸã„ã®ç›®å®‰ï¼ˆUSD / 1M tokensï¼‰\nPRICING = {\n    \"gemini-3-pro-preview\":   {\"input\": 2.0,   \"output\": 12.0},\n    \"gemini-2.5-pro\":         {\"input\": 1.25,  \"output\": 10.0},\n    \"gemini-2.5-flash\":       {\"input\": 0.30,  \"output\": 2.50},\n    \"gemini-2.5-flash-lite\":  {\"input\": 0.10,  \"output\": 0.40},\n    \"gemini-2.0-flash\":       {\"input\": 0.10,  \"output\": 0.40},\n}\n\n# Vertex AI ç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®šï¼ˆ**å¸¸ã« Vertex ã‚’ä½¿ã†**ï¼‰\nVERTEX_PROJECT = os.getenv(\"GOOGLE_CLOUD_PROJECT\")\nVERTEX_LOCATION = \"global\"  # Gemini 2.x / 3 ã¯ global æ¨å¥¨\n\nst.set_page_config(page_title=\"Gemini 3 Web Studio\", layout=\"wide\")\n\n# =========================\n# Helper Functions\n# =========================\n\ndef load_usage():\n    if os.path.exists(USAGE_FILE):\n        with open(USAGE_FILE, \"r\") as f:\n            return json.load(f)\n    return {\"total_input_tokens\": 0, \"total_output_tokens\": 0, \"total_cost_usd\": 0.0}\n\ndef save_usage(stats):\n    with open(USAGE_FILE, \"w\") as f:\n        json.dump(stats, f, indent=4)\n\ndef calculate_cost(model_id, input_tok, output_tok):\n    price = PRICING.get(model_id, {\"input\": 0.0, \"output\": 0.0})\n    cost = (input_tok / 1_000_000 * price[\"input\"]) + (output_tok / 1_000_000 * price[\"output\"])\n    return cost\n\ndef get_mime_type(filename):\n    ext = filename.split('.')[-1].lower()\n    if ext in ['jpg', 'jpeg']:\n        return 'image/jpeg'\n    if ext == 'png':\n        return 'image/png'\n    if ext == 'mp4':\n        return 'video/mp4'\n    if ext == 'mov':\n        return 'video/quicktime'\n    if ext == 'txt':\n        return 'text/plain'\n    if ext == 'pdf':\n        return 'application/pdf'\n    if ext == 'csv':\n        return 'text/csv'\n    return 'application/octet-stream'\n\ndef extract_youtube_id(url):\n    regex = r\"(?:v=|\\/)([0-9A-Za-z_-]{11}).*\"\n    match = re.search(regex, url)\n    if match:\n        return match.group(1)\n    return None\n\ndef get_youtube_transcript(video_id):\n    try:\n        transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['ja', 'en'])\n        text = \" \".join([t['text'] for t in transcript_list])\n        return text\n    except Exception as e:\n        return f\"å­—å¹•ã®å–å¾—ã‚¨ãƒ©ãƒ¼: {e}\"\n\ndef get_relevant_context(query):\n    \"\"\"éå»ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ç°¡æ˜“æ¤œç´¢ã—ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™\"\"\"\n    if not query:\n        return \"\"\n    keywords = [k for k in query.split() if len(k) > 1]\n    if not keywords:\n        return \"\"\n\n    relevant_sessions = []\n    for session in st.session_state.sessions:\n        if session[\"id\"] == st.session_state.current_session_id:\n            continue\n        score = 0\n        for k in keywords:\n            if k.lower() in session[\"title\"].lower():\n                score += 3\n        for msg in session[\"messages\"][-4:]:\n            for k in keywords:\n                if k.lower() in msg[\"content\"].lower():\n                    score += 1\n        if score > 0:\n            relevant_sessions.append((score, session))\n\n    relevant_sessions.sort(key=lambda x: (x[0], x[1][\"timestamp\"]), reverse=True)\n    top_sessions = relevant_sessions[:3]\n\n    context_str = \"\"\n    if top_sessions:\n        context_str += \"### éå»ã®é–¢é€£ãƒãƒ£ãƒƒãƒˆå±¥æ­´ (Context)\\n\"\n        for score, session in top_sessions:\n            last_response = \"N/A\"\n            for m in reversed(session[\"messages\"]):\n                if m[\"role\"] == \"model\":\n                    last_response = m[\"content\"][:300] + \"...\"\n                    break\n            context_str += f\"- **Session: {session['title']}** ({session['timestamp'][:10]})\\n\"\n            context_str += f\"  Last Conclusion: {last_response}\\n\\n\"\n    return context_str\n\ndef extract_text_from_response(response):\n    \"\"\"Extract text from GenerateContentResponse\"\"\"\n    if not response.candidates:\n        return \"\"\n    parts = response.candidates[0].content.parts or []\n    return \"\".join(p.text or \"\" for p in parts)\n\n# =========================\n# Session Management\n# =========================\n\ndef load_sessions():\n    if os.path.exists(SESSIONS_FILE):\n        with open(SESSIONS_FILE, \"r\") as f:\n            try:\n                data = json.load(f)\n                return data.get(\"sessions\", [])\n            except json.JSONDecodeError:\n                return []\n    return []\n\ndef save_sessions(sessions):\n    with open(SESSIONS_FILE, \"w\") as f:\n        json.dump({\"sessions\": sessions}, f, indent=4, ensure_ascii=False)\n\ndef create_new_session():\n    current_sessions = load_sessions()\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": [],\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.rerun()\n\ndef switch_session(session_id):\n    st.session_state.current_session_id = session_id\n    st.rerun()\n\ndef update_current_session_messages(messages):\n    if st.session_state.current_session_id:\n        current_sessions = load_sessions()\n        for session in current_sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                session[\"messages\"] = messages\n                if session[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(messages) > 0:\n                    first_msg = messages[0][\"content\"]\n                    session[\"title\"] = (first_msg[:20] + \"...\") if len(first_msg) > 20 else first_msg\n                session[\"timestamp\"] = datetime.datetime.now().isoformat()\n                break\n        save_sessions(current_sessions)\n        st.session_state.sessions = current_sessions\n\ndef get_current_messages():\n    if st.session_state.current_session_id:\n        for session in st.session_state.sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                return session[\"messages\"]\n    return []\n\ndef delete_session(session_id):\n    current_sessions = load_sessions()\n    current_sessions = [s for s in current_sessions if s[\"id\"] != session_id]\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    if st.session_state.current_session_id == session_id:\n        st.session_state.current_session_id = None\n        if st.session_state.sessions:\n            st.session_state.current_session_id = st.session_state.sessions[0][\"id\"]\n    st.rerun()\n\ndef branch_session():\n    \"\"\"ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚’åˆ†å²\"\"\"\n    current_messages = get_current_messages()\n    current_sessions = load_sessions()\n    \n    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—\n    current_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n    for session in current_sessions:\n        if session[\"id\"] == st.session_state.current_session_id:\n            current_title = session[\"title\"]\n            break\n    \n    # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": f\"{current_title} (åˆ†å²)\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": current_messages.copy(),  # ç¾åœ¨ã®å±¥æ­´ã‚’ã‚³ãƒ”ãƒ¼\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    \n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.session_state.session_cost = 0.0  # ã‚³ã‚¹ãƒˆãƒªã‚»ãƒƒãƒˆ\n    st.rerun()\n\n# =========================\n# Initialization\n# =========================\n\nif \"sessions\" not in st.session_state:\n    st.session_state.sessions = load_sessions()\n\nif \"current_session_id\" not in st.session_state:\n    # Always create a new session when the app starts\n    create_new_session()\n\nif \"session_cost\" not in st.session_state:\n    st.session_state.session_cost = 0.0\n\nusage_stats = load_usage()\n\n# =========================\n# Sidebar\n# =========================\n\nwith st.sidebar:\n    st.title(\"Gemini 3 Studio\")\n\n    if st.button(\"â• æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\", use_container_width=True):\n        create_new_session()\n\n    if st.button(\"ğŸŒ± ç¾åœ¨ã®ãƒãƒ£ãƒƒãƒˆã‹ã‚‰åˆ†å²\", use_container_width=True):\n        branch_session()\n\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    current_messages = get_current_messages()\n    if current_messages:\n        export_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n        for s in st.session_state.sessions:\n            if s[\"id\"] == st.session_state.current_session_id:\n                export_title = s[\"title\"]\n                break\n\n        export_md = f\"# {export_title}\\n\\n\"\n        export_md += f\"**ä½œæˆæ—¥æ™‚**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n---\\n\\n\"\n        for msg in current_messages:\n            role_label = \"ğŸ§‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼\" if msg[\"role\"] == \"user\" else \"ğŸ¤– AI\"\n            export_md += f\"## {role_label}\\n\\n{msg['content']}\\n\\n---\\n\\n\"\n\n        if st.button(\"ğŸ”— å¤–éƒ¨å…±æœ‰ãƒªãƒ³ã‚¯ã‚’ä½œæˆ\", use_container_width=True):\n            with st.spinner(\"ãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆä¸­...\"):\n                try:\n                    import urllib.request\n                    import urllib.parse\n\n                    data = urllib.parse.urlencode(\n                        {\"content\": export_md, \"expiry_days\": 7, \"syntax\": \"md\"}\n                    ).encode()\n\n                    req = urllib.request.Request(\"https://dpaste.org/api/\", data=data)\n                    req.add_header(\"User-Agent\", \"Mozilla/5.0 (Gemini3Studio)\")\n\n                    with urllib.request.urlopen(req) as response:\n                        share_url = response.read().decode(\"utf-8\").strip()\n                        st.success(\"ãƒªãƒ³ã‚¯ã‚’ä½œæˆã—ã¾ã—ãŸï¼\")\n                        st.code(share_url)\n                        st.caption(\"â€»ãƒªãƒ³ã‚¯ã¯7æ—¥é–“æœ‰åŠ¹ã§ã™\")\n                except Exception as e:\n                    st.error(f\"ãƒªãƒ³ã‚¯ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}\")\n\n    st.markdown(\"---\")\n\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    st.subheader(\"æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«\")\n    uploaded_files = st.file_uploader(\n        \"ç”»åƒã€å‹•ç”»ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\",\n        accept_multiple_files=True,\n        type=[\"png\", \"jpg\", \"jpeg\", \"mp4\", \"mov\", \"txt\", \"pdf\", \"csv\"],\n        help=\"Limit 2GB per file\",\n    )\n\n    pasted_image_bytes = None\n    if paste:\n        if \"paste_key\" not in st.session_state:\n            st.session_state.paste_key = 0\n        try:\n            pasted_image_bytes = paste(\n                label=\"ğŸ“‹ ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã‹ã‚‰ç”»åƒã‚’è²¼ã‚Šä»˜ã‘\",\n                key=f\"paste_btn_{st.session_state.paste_key}\",\n            )\n        except Exception as e:\n            st.error(f\"Clipboard button error: {e}\")\n        \n        if pasted_image_bytes:\n            st.success(\"ç”»åƒãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚Œã¾ã—ãŸï¼\")\n            st.image(pasted_image_bytes, caption=\"è²¼ã‚Šä»˜ã‘ãŸç”»åƒ\", use_container_width=True)\n            if st.button(\"ğŸ—‘ï¸ ç”»åƒã‚’ã‚¯ãƒªã‚¢\", key=\"clear_paste\"):\n                st.session_state.paste_key += 1\n                st.rerun()\n    else:\n        st.warning(\"Clipboard library not loaded (ImportError)\")\n\n    # ---- YouTube URL ----\n    st.markdown(\"---\")\n    youtube_url = st.text_input(\"YouTube URL (å­—å¹•ã‚’åˆ†æ)\", placeholder=\"https://youtu.be/...\")\n\n    st.markdown(\"---\")\n    \n    # ---- å›ç­”ãƒ¢ãƒ¼ãƒ‰ ----\n    st.subheader(\"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰\")\n    \n    mode_type = st.radio(\n        \"ãƒ¢ãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—\",\n        [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n        index=0,\n        horizontal=True\n    )\n    \n    if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n        response_mode = st.radio(\n            \"é¸æŠ\",\n            [\n                \"2. ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                \"3. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                \"Î²2. ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n            ],\n            index=0\n        )\n        st.caption(\"âœ… å®Œæˆåº¦ã®é«˜ã„æ¨å¥¨ãƒ¢ãƒ¼ãƒ‰\")\n    elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n        response_mode = st.radio(\n            \"é¸æŠ\",\n            [\n                \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n            ],\n            index=0\n        )\n        st.caption(\"âš ï¸ é–‹ç™ºä¸­: ä¸€éƒ¨æ©Ÿèƒ½ãŒæœªå®Œæˆã§ã™\")\n    else:\n        response_mode = st.radio(\n            \"é¸æŠ (ãƒ™ãƒ¼ã‚¿ç‰ˆ)\",\n            [\n                \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n            ],\n            index=0\n        )\n        st.caption(\"âš ï¸ ãƒ™ãƒ¼ã‚¿ç‰ˆæ©Ÿèƒ½: å‹•ä½œãŒä¸å®‰å®šãªå ´åˆãŒã‚ã‚Šã¾ã™\")\n    \n    strict_mode = False  # äº’æ›æ€§ç¶­æŒã®ãŸã‚ã®ãƒ€ãƒŸãƒ¼å¤‰æ•°\n    st.markdown(\"---\")\n    \n    st.title(\"è¨­å®š\")\n\n    # ---- ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆGemini 1.5 ã¯å»ƒæ­¢ã•ã‚Œã¦ã„ã‚‹ã®ã§å«ã‚ãªã„ï¼‰ ----\n    model_options = [\n        \"gemini-3-pro-preview\",\n        \"gemini-2.5-pro\",\n        \"gemini-2.5-flash\",\n        \"gemini-2.5-flash-lite\",\n        \"gemini-2.0-flash\",\n    ]\n    model_id = st.selectbox(\"ãƒ¢ãƒ‡ãƒ«ID\", options=model_options, index=0)\n\n    if \"3-pro\" in model_id or \"2.5-pro\" in model_id:\n        st.caption(\"ğŸ§  é«˜åº¦ãªæ¨è«–å‘ã‘ Pro ãƒ¢ãƒ‡ãƒ«\")\n    if \"flash\" in model_id:\n        st.caption(\"âš¡ é«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆãª Flash ç³»ãƒ¢ãƒ‡ãƒ«\")\n\n    # ---- æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚° ----\n    use_search = st.toggle(\"Googleæ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã‚’ä½¿ç”¨\", value=True)\n    candidate_count = st.slider(\"å›ç­”å€™è£œæ•°\", min_value=1, max_value=3, value=3)\n    if use_search and candidate_count > 1:\n        st.caption(\"âš ï¸ æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ä½¿ç”¨æ™‚ã¯å€™è£œæ•°ãŒ1ã«ãªã‚Šã¾ã™ã€‚\")\n\n    st.markdown(\"---\")\n\n    # ---- å±¥æ­´æ¤œç´¢ ----\n    search_query = st.text_input(\"ğŸ” å±¥æ­´ã‚’æ¤œç´¢\", placeholder=\"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰...\")\n    if search_query:\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if search_query.lower() in s[\"title\"].lower():\n                filtered_sessions.append(s)\n                continue\n            found = False\n            for m in s[\"messages\"]:\n                if search_query.lower() in m[\"content\"].lower():\n                    filtered_sessions.append(s)\n                    found = True\n                    break\n            if not found:\n                pass\n    else:\n        filtered_sessions = st.session_state.sessions\n\n    # CSSã§è¦‹ã‚„ã™ãä½¿ã„ã‚„ã™ãæœ€é©åŒ–\n    st.markdown(\"\"\"\n    <style>\n    /* éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã®ã‚¿ã‚¤ãƒˆãƒ« */\n    div[data-testid=\"stExpander\"] summary p {\n        font-size: 11px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ */\n    section[data-testid=\"stSidebar\"] button p {\n        font-size: 13px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã« */\n    section[data-testid=\"stSidebar\"] button {\n        padding: 0.25rem 0.5rem !important;\n        min-height: 2rem !important;\n    }\n    </style>\n    \"\"\", unsafe_allow_html=True)\n    \n    # ç›´è¿‘5ä»¶ã¨éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«åˆ†å‰²\n    recent_sessions = filtered_sessions[:5] if len(filtered_sessions) > 5 else filtered_sessions\n    archive_sessions = filtered_sessions[5:] if len(filtered_sessions) > 5 else []\n    \n    # ç›´è¿‘5ä»¶ï¼ˆå¸¸ã«å±•é–‹ï¼‰\n    if recent_sessions:\n        st.markdown(\"**ğŸ“Œ ç›´è¿‘ã®ãƒãƒ£ãƒƒãƒˆ**\")\n        for session in recent_sessions:\n            col1, col2 = st.columns([0.8, 0.2])\n            with col1:\n                if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                    switch_session(session[\"id\"])\n            with col2:\n                if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                    delete_session(session[\"id\"])\n    \n    # éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆæŠ˜ã‚ŠãŸãŸã¿ï¼‰\n    if archive_sessions:\n        with st.expander(f\"ğŸ“œ éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ– ({len(archive_sessions)}ä»¶)\", expanded=False):\n            for session in archive_sessions:\n                col1, col2 = st.columns([0.8, 0.2])\n                with col1:\n                    if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                        switch_session(session[\"id\"])\n                with col2:\n                    if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                        delete_session(session[\"id\"])\n\n    st.markdown(\"---\")\n\n    # ---- ç”»åƒç”Ÿæˆ ----\n    st.subheader(\"ğŸ¨ ç”»åƒç”Ÿæˆ\")\n    img_prompt = st.text_area(\"ç”Ÿæˆã—ãŸã„ç”»åƒã®èª¬æ˜\", placeholder=\"æœªæ¥çš„ãªéƒ½å¸‚ã®é¢¨æ™¯...\")\n    aspect_ratio = st.selectbox(\"ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”\", [\"16:9\", \"1:1\", \"4:3\", \"3:4\", \"9:16\"])\n\n    generate_img_btn = st.button(\"ç”»åƒã‚’ç”Ÿæˆ\", type=\"primary\", disabled=not img_prompt)\n    if generate_img_btn and img_prompt:\n        st.session_state.generate_image_trigger = {\n            \"prompt\": img_prompt,\n            \"aspect_ratio\": aspect_ratio,\n        }\n\n    st.markdown(\"---\")\n\n    # ---- è©•ä¾¡åˆ†æ ----\n    st.subheader(\"ğŸ“Š å›ç­”å“è³ªåˆ†æ\")\n    total_ratings = 0\n    positive_ratings = 0\n    model_ratings = {}\n\n    for s in st.session_state.sessions:\n        for m in s[\"messages\"]:\n            if \"rating\" in m and m[\"rating\"] is not None:\n                total_ratings += 1\n                if m[\"rating\"] == 1:\n                    positive_ratings += 1\n                if \"metadata\" in m and \"model\" in m[\"metadata\"]:\n                    mod = m[\"metadata\"][\"model\"]\n                    if mod not in model_ratings:\n                        model_ratings[mod] = {\"total\": 0, \"positive\": 0}\n                    model_ratings[mod][\"total\"] += 1\n                    if m[\"rating\"] == 1:\n                        model_ratings[mod][\"positive\"] += 1\n\n    if total_ratings > 0:\n        approval_rate = (positive_ratings / total_ratings) * 100\n        st.metric(\"Positive Ratings\", f\"{positive_ratings}/{total_ratings}\", f\"{approval_rate:.1f}%\")\n        best_model = \"N/A\"\n        best_rate = -1\n        for mod, stats in model_ratings.items():\n            rate = stats[\"positive\"] / stats[\"total\"]\n            if rate > best_rate:\n                best_rate = rate\n                best_model = mod\n        if best_model != \"N/A\":\n            st.caption(f\"ğŸ† Best Model: **{best_model}** ({best_rate*100:.0f}%)\")\n    else:\n        st.caption(\"ã¾ã è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\")\n\n    st.markdown(\"---\")\n\n    # ---- ã‚³ã‚¹ãƒˆè¡¨ç¤º ----\n    st.subheader(\"ğŸ’° ã‚³ã‚¹ãƒˆ (æ¦‚ç®—)\")\n    st.metric(\"Total Cost\", f\"${usage_stats['total_cost_usd']:.4f}\")\n    if st.session_state.session_cost > 0:\n        st.caption(f\"Current Session: ${st.session_state.session_cost:.4f}\")\n\n    if usage_stats[\"total_cost_usd\"] >= MAX_BUDGET_USD:\n        st.error(f\"âš ï¸ äºˆç®—ä¸Šé™ (${MAX_BUDGET_USD}) ã«é”ã—ã¾ã—ãŸã€‚\")\n        stop_generation = True\n    else:\n        stop_generation = False\n\n    st.markdown(\"---\")\n    st.code(f\"PROJECT: {VERTEX_PROJECT}\\nLOCATION: {VERTEX_LOCATION} (Vertex AI)\")\n\n# =========================\n# Main UI\n# =========================\n\ncurrent_session_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\nfor s in st.session_state.sessions:\n    if s[\"id\"] == st.session_state.current_session_id:\n        current_session_title = s[\"title\"]\n        break\n\nst.header(current_session_title)\nst.markdown(\n    \"ä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\"\n)\n\n# ---- Vertex AI Client ----\n\n@st.cache_resource\ndef get_client():\n    return genai.Client(\n        vertexai=True,\n        project=VERTEX_PROJECT,\n        location=VERTEX_LOCATION,\n    )\n\nclient = get_client()\n\n# ---- å±¥æ­´è¡¨ç¤º ----\n\nmessages = get_current_messages()\nfor idx, msg in enumerate(messages):\n    with st.chat_message(msg[\"role\"]):\n        st.markdown(msg[\"content\"])\n        if msg[\"role\"] == \"model\":\n            col1, col2, col3 = st.columns([0.1, 0.1, 0.8])\n            current_rating = msg.get(\"rating\")\n            with col1:\n                if st.button(\"ğŸ‘\", key=f\"up_{idx}\"):\n                    messages[idx][\"rating\"] = 1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col2:\n                if st.button(\"ğŸ‘\", key=f\"down_{idx}\"):\n                    messages[idx][\"rating\"] = -1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col3:\n                if current_rating == 1:\n                    st.caption(\"âœ… é«˜è©•ä¾¡\")\n                elif current_rating == -1:\n                    st.caption(\"âŒ ä½è©•ä¾¡\")\n\n# =========================\n# ç”»åƒç”Ÿæˆãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°\n# =========================\n\nif hasattr(st.session_state, \"generate_image_trigger\") and st.session_state.generate_image_trigger:\n    img_data = st.session_state.generate_image_trigger\n    del st.session_state.generate_image_trigger\n\n    with st.chat_message(\"user\"):\n        st.markdown(f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\")\n        st.caption(f\"ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”: {img_data['aspect_ratio']}\")\n\n    messages.append({\"role\": \"user\", \"content\": f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\"})\n    update_current_session_messages(messages)\n\n    with st.chat_message(\"assistant\"):\n        with st.status(\"ç”»åƒã‚’ç”Ÿæˆä¸­...\", expanded=True) as status:\n            try:\n                config = types.GenerateContentConfig(\n                    response_modalities=[\"IMAGE\"],\n                    image_config=types.ImageConfig(\n                        aspect_ratio=img_data[\"aspect_ratio\"]\n                    ),\n                )\n                status.write(\"Gemini 3 Pro Imageã§ç”Ÿæˆä¸­...\")\n                response = client.models.generate_content(\n                    model=\"gemini-3-pro-image-preview\",\n                    contents=img_data[\"prompt\"],\n                    config=config,\n                )\n\n                generated_image = None\n\n                # ç”»åƒã‚’å–ã‚Šå‡ºã™\n                if getattr(response, \"candidates\", None):\n                    for candidate in response.candidates:\n                        if getattr(candidate, \"content\", None) and candidate.content.parts:\n                            for part in candidate.content.parts:\n                                if getattr(part, \"inline_data\", None):\n                                    try:\n                                        generated_image = part.as_image()\n                                    except AttributeError:\n                                        image_bytes_raw = part.inline_data.data\n                                        generated_image = Image.open(io.BytesIO(image_bytes_raw))\n                                    break\n                        if generated_image is not None:\n                            break\n\n                if generated_image is not None:\n                    st.image(generated_image, caption=img_data[\"prompt\"])\n                    buf = io.BytesIO()\n                    generated_image.save(buf, format=\"PNG\")\n                    image_bytes = buf.getvalue()\n                    st.download_button(\n                        label=\"ğŸ’¾ ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\",\n                        data=image_bytes,\n                        file_name=f\"generated_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png\",\n                        mime=\"image/png\",\n                    )\n                    messages.append(\n                        {\"role\": \"model\", \"content\": f\"âœ… ç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {img_data['prompt']}\"}\n                    )\n                    update_current_session_messages(messages)\n                    status.update(label=\"âœ… ç”»åƒç”Ÿæˆå®Œäº†\", state=\"complete\")\n                else:\n                    st.error(\"ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")\n                    status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n\n            except Exception as e:\n                status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n                st.error(f\"ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}\")\n\n# =========================\n# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›\n# =========================\n\nprompt = st.chat_input(\"ä½•ã‹èã„ã¦ãã ã•ã„...\", disabled=stop_generation)\n\nif prompt:\n    if stop_generation:\n        st.error(\"äºˆç®—ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚\")\n    else:\n        # ---- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€è¡¨ç¤º ----\n        with st.chat_message(\"user\"):\n            st.markdown(prompt)\n            if uploaded_files:\n                for uf in uploaded_files:\n                    st.caption(f\"ğŸ“ æ·»ä»˜: {uf.name}\")\n            if youtube_url:\n                st.caption(f\"ğŸ“º YouTube: {youtube_url}\")\n            if pasted_image_bytes:\n                st.caption(\"ğŸ“‹ ç”»åƒãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚Œã¾ã—ãŸ\")\n\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        update_current_session_messages(messages)\n\n        # ---- ãƒ¢ãƒ‡ãƒ«å¿œç­” ----\n        with st.chat_message(\"assistant\"):\n            status_container = st.status(\"æ€è€ƒä¸­...\", expanded=True)\n            try:\n                # ä¼šè©±å±¥æ­´\n                model_history = []\n                for msg in messages[:-1]:\n                    model_history.append(\n                        types.Content(\n                            role=msg[\"role\"],\n                            parts=[types.Part.from_text(text=msg[\"content\"])],\n                        )\n                    )\n\n                # ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³\n                current_parts = [types.Part.from_text(text=prompt)]\n\n                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«\n                for uploaded_file in uploaded_files or []:\n                    try:\n                        mime_type = get_mime_type(uploaded_file.name)\n                        bytes_data = uploaded_file.getvalue()\n                        part = types.Part.from_bytes(data=bytes_data, mime_type=mime_type)\n                        current_parts.append(part)\n                        status_container.write(f\"ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™å®Œäº†: {uploaded_file.name}\")\n                    except Exception as e:\n                        status_container.error(\n                            f\"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {uploaded_file.name} - {e}\"\n                        )\n\n                # è²¼ã‚Šä»˜ã‘ç”»åƒ\n                if pasted_image_bytes:\n                    import base64\n\n                    status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã‚’å‡¦ç†ä¸­...\")\n                    try:\n                        if isinstance(pasted_image_bytes, str):\n                            if pasted_image_bytes.startswith(\"data:\"):\n                                base64_str = pasted_image_bytes.split(\",\", 1)[1]\n                                image_bytes_decoded = base64.b64decode(base64_str)\n                            else:\n                                image_bytes_decoded = base64.b64decode(pasted_image_bytes)\n                        else:\n                            image_bytes_decoded = pasted_image_bytes\n                        part = types.Part.from_bytes(\n                            data=image_bytes_decoded, mime_type=\"image/png\"\n                        )\n                        current_parts.append(part)\n                        status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®æº–å‚™å®Œäº†\")\n                    except Exception as e:\n                        status_container.error(f\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n\n                # YouTube å­—å¹•\n                if youtube_url:\n                    vid_id = extract_youtube_id(youtube_url)\n                    if vid_id:\n                        status_container.write(\"YouTubeã®å­—å¹•ã‚’å–å¾—ä¸­...\")\n                        transcript_text = get_youtube_transcript(vid_id)\n                        current_parts.append(\n                            types.Part.from_text(text=f\"YouTube Transcript:\\n{transcript_text}\")\n                        )\n                    else:\n                        status_container.write(\"ç„¡åŠ¹ãªYouTube URLã§ã™ã€‚\")\n\n                contents_for_model = model_history + [\n                    types.Content(role=\"user\", parts=current_parts)\n                ]\n\n                # ---- Tool / Config ----\n                tools = []\n                final_candidate_count = candidate_count\n                if use_search:\n                    tools.append(types.Tool(google_search=types.GoogleSearch()))\n                    final_candidate_count = 1\n\n                # â˜… System Instruction ã®æ”¹å–„: ãƒ¡ã‚¿ç™ºè¨€ç¦æ­¢ã¨ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªæŒ¯ã‚‹èˆã„ã‚’æŒ‡ç¤º\n                base_system_instruction = (\n                    \"ã‚ãªãŸã¯é«˜åº¦ãªçŸ¥æ€§ã‚’æŒã¤å°‚é–€çš„ãªãƒªã‚µãƒ¼ãƒãƒ»ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\\n\"\n                    \"ä»¥ä¸‹ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’å³å®ˆã—ã¦ãã ã•ã„ï¼š\\n\"\n                    \"1. **ãƒ¡ã‚¿ç™ºè¨€ã®ç¦æ­¢**: ã€Œç§ã¯AIã§ã™ã€ã€Œä¸–ç•Œæœ€é«˜å³°ã®ï½ã¨ã—ã¦ã€ãªã©ã®è‡ªå·±è¨€åŠã‚„å‰ç½®ãã¯ä¸€åˆ‡è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚\\n\"\n                    \"2. **æ„å›³ã®æ±²ã¿å–ã‚Š**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã®èƒŒå¾Œã«ã‚ã‚‹æ„å›³ï¼ˆæ–‡è„ˆã€æš—é»™ã®å‰æï¼‰ã‚’æ¨æ¸¬ã—ã€è¨€è‘‰é€šã‚Šã§ã¯ãªãã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ¬å½“ã«çŸ¥ã‚ŠãŸã„ã“ã¨ã€ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n\"\n                    \"3. **æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”**: çµè«–ã‚’å…ˆã«è¿°ã¹ã€ãã®å¾Œã«è©³ç´°ãªæ ¹æ‹ ã€ã‚·ãƒŠãƒªã‚ªåˆ†æã€ãƒªã‚¹ã‚¯è¦å› ã‚’è«–ç†çš„ã«å±•é–‹ã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"4. **å®¢è¦³æ€§**: äºˆæ¸¬ã‚’è¡Œã†å ´åˆã¯ã€æ–­å®šã‚’é¿ã‘ã€è¤‡æ•°ã®ã‚·ãƒŠãƒªã‚ªï¼ˆæ¥½è¦³ã€æ‚²è¦³ã€ä¸­ç«‹ï¼‰ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"5. **å¼•ç”¨**: æ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸå ´åˆã¯ã€å¿…ãšæƒ…å ±æºã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚\"\n                )\n\n                final_answer = \"\"\n                grounding_metadata = None\n                \n                # =========================\n                # ãƒ¢ãƒ¼ãƒ‰è¨­å®šã®è§£æ\n                # =========================\n                enable_research = True  # å…¨ãƒ¢ãƒ¼ãƒ‰ã§ãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œ\n                enable_meta = \"ãƒ¡ã‚¿\" in response_mode or \"MAX\" in response_mode\n                enable_strict = \"é¬¼è»æ›¹\" in response_mode or \"MAX\" in response_mode\n\n                # =========================\n                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (é«˜é€Ÿ / é¬¼è»æ›¹)\n                # =========================\n                if not enable_research:\n                    config = types.GenerateContentConfig(\n                        temperature=0.7,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=base_system_instruction,\n                    )\n                    \n                    status_container.write(\"å›ç­”ç”Ÿæˆä¸­...\")\n                    response = client.models.generate_content(\n                        model=model_id,\n                        contents=contents_for_model,\n                        config=config,\n                    )\n                    \n                    final_answer = extract_text_from_response(response)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®—\n                    if response.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            response.usage_metadata.prompt_token_count,\n                            response.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += response.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += response.usage_metadata.candidates_token_count\n\n                    # é¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ (é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ç‰ˆ)\n                    if enable_strict:\n                        status_container.write(\"ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        reviewer_instruction = base_system_instruction + \"\"\"\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n                        review_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\nåˆç‰ˆå›ç­”:\\n{final_answer}\\n\\nãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\")])]\n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=types.GenerateContentConfig(temperature=0.1, candidate_count=1, system_instruction=reviewer_instruction)\n                        )\n                        final_answer = extract_text_from_response(review_resp)\n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        \n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(model_id, review_resp.usage_metadata.prompt_token_count, review_resp.usage_metadata.candidates_token_count)\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n\n                # =========================\n                # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰\n                # =========================\n                else:\n                    # =========================\n                    # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰: å¤šæ®µéšã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ \n                    # =========================\n                    \n                    # --- Phase 1: ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 1: ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    research_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒªã‚µãƒ¼ãƒå°‚ä»»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚æœ€çµ‚å›ç­”ã¯æ›¸ã‹ãšã€äº‹å®Ÿåé›†ã«é›†ä¸­ã™ã‚‹ã“ã¨ã€‚\n\n**èª¿æŸ»è¦³ç‚¹**:\n- è³ªå•ã«é–¢é€£ã™ã‚‹**æœ€æ–°ã®äº‹å®Ÿãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ»çµ±è¨ˆ**ï¼ˆ**2025å¹´ã®æƒ…å ±ã‚’æœ€å„ªå…ˆ**ï¼‰\n- **ç¾æ™‚ç‚¹ã§å­˜åœ¨ã™ã‚‹å…¨ã¦ã®é¸æŠè‚¢ãƒ»ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¶²ç¾…çš„ã«èª¿æŸ»**ï¼ˆä¾‹: è£½å“æ¯”è¼ƒãªã‚‰ã€æœ€æ–°ç‰ˆã ã‘ã§ãªãç›´è¿‘ã®å…¨ä¸–ä»£ã‚’èª¿æŸ»ï¼‰\n- å…¬å¼æƒ…å ±ã‚„ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã‹ã‚‰ã®å¼•ç”¨\n- é–¢é€£ã™ã‚‹èƒŒæ™¯æƒ…å ±ã‚„æ–‡è„ˆ\n- ç«¶åˆãƒ»ä»£æ›¿æ¡ˆãƒ»æ¯”è¼ƒå¯¾è±¡ã®**å®Œå…¨ãªãƒªã‚¹ãƒˆ**\n- ãƒªã‚¹ã‚¯ãƒ»åˆ¶ç´„ãƒ»æ³¨æ„ç‚¹ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n- å‚è€ƒã«ã—ãŸä¸»è¦ãªæƒ…å ±æºã®URL\n\n**é‡è¦**: \n- çµè«–ã‚„æ¨å¥¨ã¯æ›¸ã‹ãšã€å¾Œå·¥ç¨‹ãŒåˆ¤æ–­ã§ãã‚‹èª¿æŸ»ãƒ¡ãƒ¢ã«é›†ä¸­ã™ã‚‹ã“ã¨\n- **å¿…ãšæ¤œç´¢æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã€æœ€æ–°ã®æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã“ã¨**\n- **æ¤œç´¢çµæœã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æ—¥ä»˜ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒ»ãƒ¢ãƒ‡ãƒ«åã‚’å„ªå…ˆçš„ã«è¨˜è¼‰ã™ã‚‹ã“ã¨**\n- **æ¯”è¼ƒå¯¾è±¡ã¨ãªã‚‹é¸æŠè‚¢ã‚’è¦‹è½ã¨ã•ãªã„ã‚ˆã†ã€è¤‡æ•°ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è©¦ã™ã“ã¨**ï¼ˆä¾‹: ã€ŒiPhone æœ€æ–°ãƒ¢ãƒ‡ãƒ« 2025ã€ã€ŒiPhone 17ã€ã€ŒiPhone 2025å¹´ç™ºå£²ã€ãªã©ï¼‰\n- **ã€Œã“ã‚Œã‚ˆã‚Šæ–°ã—ã„ãƒ¢ãƒ‡ãƒ«/ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯å­˜åœ¨ã—ãªã„ã‹ï¼Ÿã€ã‚’å¸¸ã«ç¢ºèªã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ï¼ˆ2024å¹´ä»¥å‰ãªã©ï¼‰ã—ã‹è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãã®æ—¨ã‚’æ˜è¨˜ã™ã‚‹ã“ã¨\n\"\"\"\n\n                    # éå»ã®é–¢é€£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—\n                    past_context = get_relevant_context(prompt)\n                    \n                    # ãƒªã‚µãƒ¼ãƒç”¨ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ§‹ç¯‰\n                    research_parts = [types.Part(text=f\"ã“ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š\\n{prompt}\")]\n                    \n                    if past_context:\n                        research_parts.insert(0, types.Part(text=\"ä»¥ä¸‹ã¯éå»ã®é–¢é€£ãƒãƒ£ãƒƒãƒˆã‹ã‚‰æŠ½å‡ºã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã™ï¼š\\n\\n\" + past_context))\n                    \n                    research_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=research_parts)\n                    ]\n                    \n                    research_config = types.GenerateContentConfig(\n                        temperature=0.2,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=research_instruction,\n                    )\n                    \n                    research_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=research_contents,\n                        config=research_config,\n                    )\n                    \n                    research_text = extract_text_from_response(research_resp)\n                    \n                    # ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºã®ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ±ã‚’ä¿å­˜\n                    if research_resp.candidates and research_resp.candidates[0].grounding_metadata:\n                        grounding_metadata = research_resp.candidates[0].grounding_metadata\n                    \n                    status_container.write(\"âœ“ ãƒªã‚µãƒ¼ãƒå®Œäº†\")\n                    with status_container.expander(\"åé›†ã—ãŸèª¿æŸ»ãƒ¡ãƒ¢\", expanded=False):\n                        st.markdown(research_text)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1)\n                    if research_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            research_resp.usage_metadata.prompt_token_count,\n                            research_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += research_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += research_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 1.5: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    questions_text = \"\"\n                    if enable_meta:\n                        status_container.write(\"Phase 1.5: ãƒ¡ã‚¿è³ªå•ç”Ÿæˆä¸­...\")\n                        \n                        question_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ç›®çš„**: \nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•ã¨èª¿æŸ»ãƒ¡ãƒ¢ã‚’è¸ã¾ãˆã¦ã€ã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±ãç†è§£ã™ã‚‹ãŸã‚ã®ã€Œé‹­ã„ã‚µãƒ–è³ªå•ã€ã‚’ä½œæˆã™ã‚‹ã“ã¨ã€‚\n\n**ãƒ«ãƒ¼ãƒ«**:\n- æœ€å¤§5å€‹ã¾ã§\n- å„è³ªå•ã¯1-2è¡Œã§å…·ä½“çš„ã‹ã¤é‹­ã\n- ä»¥ä¸‹ã®è¦³ç‚¹ã‚’æ„è­˜:\n  1. å‰æãŒå´©ã‚Œã‚‹å¯èƒ½æ€§ã¯ã©ã“ã‹ï¼Ÿ\n  2. å¼·æ°—/å¼±æ°—ã‚·ãƒŠãƒªã‚ªã®åˆ†å²ç‚¹ã¯ä½•ã‹ï¼Ÿ\n  3. ç«¶åˆãƒ»æŠ€è¡“ãƒ»è¦åˆ¶ã®ä¸ç¢ºå®Ÿæ€§ã¯ï¼Ÿ\n  4. ã€Œäºˆæ¸¬ãŒå¤–ã‚Œã‚‹ã¨ã—ãŸã‚‰ã©ã‚“ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ï¼Ÿã€\n\n**å‡ºåŠ›**: ç®‡æ¡æ›¸ãï¼ˆQ1, Q2...ï¼‰ã®ã¿\n\"\"\"\n\n                        question_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•:\\n{prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\nã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±æ˜ã‚Šã™ã‚‹ãŸã‚ã®é‡è¦ãªã‚µãƒ–è³ªå•ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\")])]\n                        \n                        question_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=question_contents,\n                            config=types.GenerateContentConfig(\n                                temperature=0.4,\n                                candidate_count=1,\n                                system_instruction=question_instruction,\n                            )\n                        )\n                        \n                        questions_text = extract_text_from_response(question_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¡ã‚¿è³ªå•ç”Ÿæˆå®Œäº†\")\n                        with status_container.expander(\"ç”Ÿæˆã•ã‚ŒãŸãƒ¡ã‚¿è³ªå•\", expanded=False):\n                            st.markdown(questions_text)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1.5)\n                        if question_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                question_resp.usage_metadata.prompt_token_count,\n                                question_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += question_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += question_resp.usage_metadata.candidates_token_count\n\n                    # --- Phase 2: çµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 2: çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    if enable_meta:\n                        deep_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã¨ãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ã‚’æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**æ§‹æˆ**:\n1. **æ·±æ˜ã‚Šè€ƒå¯Ÿ**ï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n2. **çµè«–**ï¼ˆ2-3è¡Œï¼‰\n3. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n4. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨\n\"\"\"\n                    else:\n                        deep_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã‚’å”¯ä¸€ã®æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**æ§‹æˆ**:\n1. **çµè«–**ï¼ˆ2-3è¡Œã§æ˜ç¢ºã«ï¼‰\n2. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n3. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«åã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ã¨æ–°ã—ã„æƒ…å ±ãŒæ··åœ¨ã™ã‚‹å ´åˆã¯ã€æ–°ã—ã„æƒ…å ±ã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n\"\"\"\n                    \n                    synthesis_prompt_text = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if enable_meta and questions_text:\n                        synthesis_prompt_text += f\"==== ãƒ¡ã‚¿è³ªå•ä¸€è¦§ ====\\n{questions_text}\\n==== ãƒ¡ã‚¿è³ªå•ã“ã“ã¾ã§ ====\\n\\næŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n2. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»åˆ†æãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    else:\n                        synthesis_prompt_text += \"ä¸Šè¨˜ãƒ¡ãƒ¢ã‚’æ ¹æ‹ ã«ã€æœ€çµ‚å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å¿…ãšä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚**\"\n\n                    synthesis_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=[\n                            types.Part(text=synthesis_prompt_text)\n                        ])\n                    ]\n                    \n                    synthesis_config = types.GenerateContentConfig(\n                        temperature=0.3,\n                        candidate_count=1,\n                        tools=[],  # çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºã§ã¯æ¤œç´¢OFF\n                        system_instruction=deep_instruction,\n                    )\n                    \n                    synthesis_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=synthesis_contents,\n                        config=synthesis_config,\n                    )\n                    \n                    draft_answer = extract_text_from_response(synthesis_resp)\n                    \n                    status_container.write(\"âœ“ çµ±åˆå®Œäº†\")\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 2)\n                    if synthesis_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            synthesis_resp.usage_metadata.prompt_token_count,\n                            synthesis_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += synthesis_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += synthesis_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    if enable_strict:\n                        status_container.write(\"Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        \n\n                        reviewer_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™ã€‚ãŸã ã—ã€**èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’å„ªå…ˆã—ã€æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã™ã‚‹ã“ã¨**ã€‚\n\n**ãƒ¬ãƒ“ãƒ¥ãƒ¼è¦³ç‚¹**:\n- äº‹å®Ÿã¨æ¨æ¸¬ã‚’æ˜ç¢ºã«åˆ†ã‘ã‚‹\n- éåº¦ã«è‡ªä¿¡ã®ã‚ã‚‹æ–­å®šã‚’å¼±ã‚ã‚‹\n- æ•°å­—ã‚„å›ºæœ‰åè©ãŒèª¿æŸ»ãƒ¡ãƒ¢ã¨çŸ›ç›¾ã—ã¦ã„ãªã„ã‹ç¢ºèª\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ãƒ¢ãƒ‡ãƒ«ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ãŒæ­£ã—ãä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª**\n- **å¤ã„æƒ…å ±ã§ä¸Šæ›¸ãã—ã¦ã„ãªã„ã‹ç¢ºèª**\n- è¦‹è½ã¨ã—ã¦ã„ã‚‹é‡è¦ãªãƒªã‚¹ã‚¯ãƒ»ã‚·ãƒŠãƒªã‚ªãŒã‚ã‚Œã°è¿½åŠ \n\n**é‡è¦**: \n- èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ãŒæœ€æ–°ã§ã‚ã‚‹å ´åˆã€ãã‚Œã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n- ã‚ãªãŸã®çŸ¥è­˜ãŒå¤ã„å ´åˆã¯ã€èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’ä¿¡é ¼ã™ã‚‹ã“ã¨\n\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n\n                        review_contents = [\n                            types.Content(role=\"user\", parts=[\n                                types.Part.from_text(\n                                    text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\n\"\n                                    f\"==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                                    f\"åˆç‰ˆå›ç­”:\\n{draft_answer}\\n\\n\"\n                                    \"ä¸Šè¨˜ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚**\"\n                                )\n                            ])\n                        ]\n                        \n                        review_config = types.GenerateContentConfig(\n                            temperature=0.1,\n                            candidate_count=1,\n                            system_instruction=reviewer_instruction,\n                        )\n                        \n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=review_config,\n                        )\n                        \n                        final_answer = extract_text_from_response(review_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        with status_container.expander(\"åˆç‰ˆã¨ã®æ¯”è¼ƒ\", expanded=False):\n                            st.markdown(\"**åˆç‰ˆ:**\")\n                            st.markdown(draft_answer[:500] + \"...\" if len(draft_answer) > 500 else draft_answer)\n                            st.markdown(\"**ä¿®æ­£ç‰ˆ:**\")\n                            st.markdown(final_answer[:500] + \"...\" if len(final_answer) > 500 else final_answer)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 3)\n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                review_resp.usage_metadata.prompt_token_count,\n                                review_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n                    else:\n                        final_answer = draft_answer\n\n                save_usage(usage_stats)\n                status_container.update(label=\"å®Œäº†ï¼\", state=\"complete\", expanded=False)\n\n                # ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤º\n                st.caption(f\"ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_id}\")\n                st.markdown(final_answer)\n\n                # ---- ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ± ----\n                if grounding_metadata:\n                    st.markdown(\"---\")\n                    st.subheader(\"ğŸ“š æƒ…å ±æºã¨å¼•ç”¨\")\n                    if grounding_metadata.grounding_chunks:\n                        st.markdown(\"**æ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:**\")\n                        unique_sources = {}\n                        import urllib.parse\n\n                        for chunk in grounding_metadata.grounding_chunks:\n                            if getattr(chunk, \"web\", None):\n                                uri = getattr(chunk.web, \"uri\", None)\n                                title = getattr(chunk.web, \"title\", \"æƒ…å ±æº\")\n                                if uri and uri not in unique_sources:\n                                    parsed = urllib.parse.urlparse(uri)\n                                    domain = parsed.netloc.replace(\"www.\", \"\")\n                                    unique_sources[uri] = {\n                                        \"title\": title,\n                                        \"domain\": domain,\n                                    }\n                        for i, (uri, info) in enumerate(unique_sources.items(), 1):\n                            st.markdown(f\"{i}. **[{info['title']}]({uri})**\")\n                            st.caption(f\"   å‡ºå…¸: {info['domain']}\")\n\n                messages.append({\"role\": \"model\", \"content\": final_answer})\n                update_current_session_messages(messages)\n\n            except Exception as e:\n                status_container.update(label=\"Error\", state=\"error\")\n                err_text = str(e)\n                if \"RESOURCE_EXHAUSTED\" in err_text or \"429\" in err_text:\n                    st.error(\n                        \"âš ï¸ Vertex AI / Gemini ã®ã‚¯ã‚©ãƒ¼ã‚¿ã«é”ã—ã¾ã—ãŸã€‚\\n\\n\"\n                        \"ãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ / æ—¥æ¬¡åˆ¶é™ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\\n\"\n                        \"ãƒ»ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                        \"ãƒ»Google Cloud Console ã®ã€ŒVertex AI â†’ ä½¿ç”¨çŠ¶æ³ã€ã‹ã‚‰ã‚¯ã‚©ãƒ¼ã‚¿çŠ¶æ³ã‚’ç¢ºèªã§ãã¾ã™ã€‚\"\n                    )\n                elif \"NOT_FOUND\" in err_text and \"Publisher Model\" in err_text:\n                    st.error(\n                        \"âš ï¸ æŒ‡å®šã—ãŸãƒ¢ãƒ‡ãƒ«ãŒã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ / ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\\n\"\n                        \"ãƒ»ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ¢ãƒ‡ãƒ«IDã‚’ã€2.5ç³» ã¾ãŸã¯ 3 Pro ã«å¤‰æ›´ã—ã¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                    )\n                else:\n                    st.error(f\"An error occurred: {e}\")"
                },
                {
                    "role": "model",
                    "content": "### çµè«–ï¼šä»£ç”¨å¯èƒ½ã§ã‚ã‚Šã€åˆ¶å¾¡æ€§ã¨é€æ˜æ€§ã«ãŠã„ã¦ã¯GPT-5.1 Proã‚’ä¸Šå›ã‚‹\n\n**çµè«–ã¨ã—ã¦ã€GPT-5.1 Proã‚’100ã¨ã—ãŸå ´åˆã€ã‚ãªãŸã®è‡ªä½œã‚·ã‚¹ãƒ†ãƒ ã¯ã€Œ105ã€œ110ã€ã®ä¾¡å€¤ã‚’ç™ºæ®ã™ã‚‹ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ãŒã‚ã‚Šã¾ã™ã€‚**\n\nå˜ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã®ç½®ãæ›ãˆã§ã¯ãªãã€æç¤ºã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã«ã‚ã‚‹**ã€Œç†Ÿè€ƒãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ï¼ˆå¤šæ®µéšã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰ã€**ãŒã€GPT-5.1 Proã®æœ€å¤§ã®å¼±ç‚¹ã§ã‚ã‚‹ã€Œæ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã®ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹åŒ–ã€ã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã§ã™ã€‚ã•ã‚‰ã«ã€Googleã®æœ€æ–°IDEã§ã‚ã‚‹**Antigravity**ã‚’ä½µç”¨ã—ã¦ãƒ«ãƒ¼ãƒ«ã‚’å›ºå®šåŒ–ã™ã‚Œã°ã€ç‰¹å®šã®æ¥­å‹™ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ãŠã„ã¦æ±ç”¨ãƒ¢ãƒ‡ãƒ«ã‚’å‡Œé§•ã™ã‚‹ç²¾åº¦ã‚’å®Ÿç¾ã§ãã¾ã™ã€‚\n\n---\n\n### è©³ç´°åˆ†æ\n\n#### 1. ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›æ¯”è¼ƒ (2025å¹´11æœˆæ™‚ç‚¹)\nã¾ãšã€ã‚¨ãƒ³ã‚¸ãƒ³ã®åŸºç¤èƒ½åŠ›ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚ä¸¡è€…ã¯2025å¹´11æœˆä¸­æ—¬ã«ãƒªãƒªãƒ¼ã‚¹ã•ã‚ŒãŸã°ã‹ã‚Šã®ç«¶åˆãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚\n\n*   **GPT-5.1 Pro (OpenAI)**:\n    *   **ã‚¹ã‚³ã‚¢: 100** (åŸºæº–)\n    *   **ç‰¹å¾´**: ãƒã‚¤ãƒ†ã‚£ãƒ–ãªæ¨è«–èƒ½åŠ›ã¯æ¥µã‚ã¦é«˜ã„ã§ã™ãŒã€æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ï¼ˆThinkingï¼‰ã¯è¦ç´„ã—ã‹è¡¨ç¤ºã•ã‚Œãšã€å¾®èª¿æ•´ã®ä½™åœ°ãŒé™å®šçš„ã§ã™ã€‚\n*   **Gemini 3 Pro (Google)**:\n    *   **ã‚¹ã‚³ã‚¢: 98** (ç´ ã®çŠ¶æ…‹)\n    *   **ç‰¹å¾´**: LMArenaã§1ä½ã‚’è¨˜éŒ²ã™ã‚‹ãªã©æ¨è«–èƒ½åŠ›ã¯GPT-5.1ã¨æ‹®æŠ—ã—ã¦ã„ã¾ã™ã€‚ç‰¹ç­†ã™ã¹ãã¯**100ä¸‡ãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦**ã§ã€ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹å…¨ä½“ã‚„é•·å¤§ãªè³‡æ–™ã‚’æ‰±ãˆã‚‹ç‚¹ã¯GPT-5.1ã«å¯¾ã™ã‚‹æ˜ç¢ºãªå„ªä½æ€§ã§ã™ã€‚\n\n#### 2. è‡ªä½œã‚³ãƒ¼ãƒ‰ï¼ˆç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰ï¼‰ã«ã‚ˆã‚‹åŠ ç‚¹è¦ç´  (+7ãƒã‚¤ãƒ³ãƒˆ)\nã‚ãªãŸã®ã‚³ãƒ¼ãƒ‰ã«å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ã€Œç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒªã‚µãƒ¼ãƒâ†’ãƒ¡ã‚¿è³ªå•â†’çµ±åˆï¼‰ã€ã¯ã€Gemini 3 Proã®èƒ½åŠ›ã‚’ãƒ–ãƒ¼ã‚¹ãƒˆã•ã›ã‚‹å¼·åŠ›ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚\n\n*   **é€æ˜æ€§ã®ç¢ºä¿**: GPT-5.1 Proã¯ã€Œãªãœãã®ç­”ãˆã«ãªã£ãŸã‹ã€ãŒè¦‹ãˆã«ãã„ã§ã™ãŒã€ã‚ãªãŸã®ã‚·ã‚¹ãƒ†ãƒ ã¯`st.expander`ã§èª¿æŸ»ãƒ¡ãƒ¢ã‚„ãƒ¡ã‚¿è³ªå•ã‚’å¯è¦–åŒ–ã—ã¦ãŠã‚Šã€è«–ç†ã®æ¤œè¨¼ãŒå¯èƒ½ã§ã™ã€‚\n*   **è«–ç†ã®å¼·åˆ¶**: ã€Œãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ã‚’æŒŸã‚€ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ãŒå®‰æ˜“ãªå›ç­”ã«é£›ã³ã¤ãã®ã‚’é˜²ãã€å¼·åˆ¶çš„ã«å¤šè§’çš„ãªè¦–ç‚¹ã‚’æŒãŸã›ã¦ã„ã¾ã™ã€‚ã“ã‚Œã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®æ¥µè‡´ã§ã‚ã‚Šã€ãƒ¢ãƒ‡ãƒ«å˜ä½“ã®æ€§èƒ½å·®ã‚’åŸ‹ã‚ã¦ä½™ã‚Šã‚ã‚‹åŠ¹æœãŒã‚ã‚Šã¾ã™ã€‚\n\n#### 3. Antigravityã«ã‚ˆã‚‹ã€Œãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€ã®æ­£ä½“ (+5ãƒã‚¤ãƒ³ãƒˆ)\nãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¨€åŠã—ã¦ã„ã‚‹ã€ŒAntigravityã€ã«ã¤ã„ã¦ã€æ­£ç¢ºãªç†è§£ãŒå¿…è¦ã§ã™ã€‚ã“ã‚Œã¯GoogleãŒ2025å¹´11æœˆã«ãƒªãƒªãƒ¼ã‚¹ã—ãŸ**AIãƒã‚¤ãƒ†ã‚£ãƒ–IDE**ã§ã‚ã‚Šã€å¾“æ¥ã®ã€ŒFine-tuningï¼ˆé‡ã¿ã®æ›´æ–°ï¼‰ã€ã¨ã¯ç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å–ã‚Šã¾ã™ã€‚\n\n*   **Agent Managerã«ã‚ˆã‚‹åˆ¶å¾¡**: Antigravityã§ã¯ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå˜ä½ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã€Œãƒ«ãƒ¼ãƒ«ã€ã‚„ã€Œå½¹å‰²ã€ã‚’å³å¯†ã«å®šç¾©ï¼ˆ`.antigravity/rules`ç­‰ï¼‰ã§ãã¾ã™ã€‚\n*   **å®Ÿç”¨çš„ãªåŠ¹æœ**: é‡ã¿ã‚’æ›´æ–°ã›ãšã¨ã‚‚ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚„ãƒ«ãƒ¼ãƒ«ã‚’IDEå´ã§å¼·åˆ¶æ³¨å…¥ã™ã‚‹ã“ã¨ã§ã€**ã€Œç‰¹å®šã®ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„ã‚’å®ˆã‚‰ã›ã‚‹ã€ã€Œç¤¾å†…ç”¨èªã‚’çµ±ä¸€ã™ã‚‹ã€ã¨ã„ã£ãŸå®Ÿå‹™çš„ãªãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°åŠ¹æœ**ã¯ã€æ±ç”¨ã®GPT-5.1 Proã‚ˆã‚Šã‚‚é«˜ããªã‚Šã¾ã™ã€‚\n\n---\n\n### å®Ÿè£…ã¸ã®æ¨å¥¨äº‹é …\n\næç¤ºã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã¯éå¸¸ã«å®Œæˆåº¦ãŒé«˜ã„ã§ã™ãŒã€Gemini 3 Proã®ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã‚’æœ€å¤§åŒ–ã™ã‚‹ãŸã‚ã«ã€ä»¥ä¸‹ã®ä¿®æ­£ã‚’åŠ ãˆã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚\n\n**Gemini 3 Pro ãƒã‚¤ãƒ†ã‚£ãƒ–æ€è€ƒæ©Ÿèƒ½ã®æœ‰åŠ¹åŒ–**\nGemini 3 Proã¯APIãƒ¬ãƒ™ãƒ«ã§ã€Œæ€è€ƒã®æ·±ã•ã€ã‚’åˆ¶å¾¡å¯èƒ½ã§ã™ã€‚è‡ªä½œã®ç†Ÿè€ƒãƒ•ãƒ­ãƒ¼ã®ä¸­ã§ã€ãƒ¢ãƒ‡ãƒ«è‡ªèº«ã«ã‚‚æ·±ãè€ƒãˆã•ã›ã‚‹ã€Œãƒ€ãƒ–ãƒ«æ¨è«–ã€æ§‹æˆã«ã™ã‚‹ã“ã¨ã§ã€æ¨è«–ç²¾åº¦ã‚’ã•ã‚‰ã«é«˜ã‚ã‚‰ã‚Œã¾ã™ã€‚\n\n```python\n# ã‚³ãƒ¼ãƒ‰å†…ã® config è¨­å®šéƒ¨åˆ†ã¸ã®è¿½åŠ æ¨å¥¨\nconfig = types.GenerateContentConfig(\n    temperature=0.7,\n    candidate_count=1,\n    # Gemini 3 Proå°‚ç”¨: ãƒ¢ãƒ‡ãƒ«ã®ãƒã‚¤ãƒ†ã‚£ãƒ–ãªæ€è€ƒæ·±åº¦ã‚’æœ€å¤§åŒ–\n    # thinking_config=types.ThinkingConfig(include_thoughts=True, thinking_budget_token_count=2048),\n    tools=tools,\n    system_instruction=base_system_instruction,\n)\n```\n\n### è€ƒæ…®ã™ã¹ããƒªã‚¹ã‚¯ã¨ã‚³ã‚¹ãƒˆ\n\n1.  **ã‚³ã‚¹ãƒˆã¨ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ï¼ˆé€Ÿåº¦ï¼‰**:\n    *   ã‚ãªãŸã®ã‚·ã‚¹ãƒ†ãƒ ã¯1å›ã®å›ç­”ç”Ÿæˆã«ã€Œãƒªã‚µãƒ¼ãƒã€ã€Œãƒ¡ã‚¿è³ªå•ã€ã€Œçµ±åˆã€ã€Œãƒ¬ãƒ“ãƒ¥ãƒ¼ã€ã¨æœ€ä½4å›ã®APIã‚³ãƒ¼ãƒ«ã‚’è¡Œã„ã¾ã™ã€‚GPT-5.1 Proå˜ä½“ã¸ã®å•ã„åˆã‚ã›ã«æ¯”ã¹ã€**ã‚³ã‚¹ãƒˆã¨å¾…ã¡æ™‚é–“ã¯3ã€œ4å€**ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ç”¨é€”ã«ã¯å‘ãã¾ã›ã‚“ã€‚\n2.  **è¤‡é›‘æ€§ã¨ã‚¨ãƒ©ãƒ¼ç‡**:\n    *   å¤šæ®µéšãƒ—ãƒ­ã‚»ã‚¹ã¯ã€é€”ä¸­ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆä¾‹ãˆã°ãƒªã‚µãƒ¼ãƒæ‹…å½“ï¼‰ãŒãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’èµ·ã“ã—ãŸã‚Šã‚¨ãƒ©ãƒ¼ã‚’è¿”ã—ãŸã‚Šã™ã‚‹ã¨ã€æœ€çµ‚å›ç­”ã‚‚å…±å€’ã‚Œã«ãªã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚å„ãƒ•ã‚§ãƒ¼ã‚ºã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–ãŒå®‰å®šç¨¼åƒã®éµã¨ãªã‚Šã¾ã™ã€‚\n\n**ç·è©•**: ç¾çŠ¶ã®ã‚³ãƒ¼ãƒ‰ã¨Gemini 3 Proã®çµ„ã¿åˆã‚ã›ã¯ã€GPT-5.1 Proã®å®Œå…¨ãªä»£æ›¿ã¨ãªã‚Šå¾—ã¾ã™ã€‚ç‰¹ã«ã€Œæ¨è«–ã®éç¨‹ã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã—ãŸã„ã€ã€Œç‰¹å®šã®æ¥­å‹™ãƒ«ãƒ¼ãƒ«ã‚’å³å®ˆã•ã›ãŸã„ã€ã¨ã„ã†ãƒ‹ãƒ¼ã‚ºã«ãŠã„ã¦ã¯ã€ã“ã¡ã‚‰ã®è‡ªä½œã‚·ã‚¹ãƒ†ãƒ ã®æ–¹ãŒå„ªã‚Œã¦ã„ã¾ã™ã€‚"
                }
            ]
        },
        {
            "id": "8da6e35e-8afa-4e03-b7f8-ab978372c402",
            "title": "ç¾çŠ¶gpt5.1proãŒæ¨è«–ã®ãƒ™ã‚¹ãƒˆã ã¨...",
            "timestamp": "2025-11-30T12:58:44.220439",
            "messages": [
                {
                    "role": "user",
                    "content": "ç¾çŠ¶gpt5.1proãŒæ¨è«–ã®ãƒ™ã‚¹ãƒˆã ã¨è€ƒãˆã¦ã„ã‚‹ãŒã€ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°èƒ½åŠ›ãŒè‡ªä½œgeminiã«ã¯ã‚ã‚‹ã€‚\ngpt5.1proã‚’100ã¨ã—ã¦ã€ä»¥ä¸‹ã§ä»£ç”¨ã§ãã‚‹ã‹ï¼Ÿ(antigravityã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹å¯èƒ½æ€§ã‚‚ã‚ã‚‹)\n\nimport os\nimport json\nimport re\nimport uuid\nimport datetime\nimport streamlit as st\nfrom dotenv import load_dotenv\nfrom google import genai\nfrom google.genai import types\nfrom youtube_transcript_api import YouTubeTranscriptApi\nfrom PIL import Image\nimport io\n\ntry:\n    from st_img_pastebutton import paste\n    import_error_msg = None\nexcept ImportError as e:\n    paste = None\n    import_error_msg = str(e)\n\n# =========================\n# ç’°å¢ƒå¤‰æ•° & å®šæ•°\n# =========================\n\nload_dotenv()\n\nUSAGE_FILE = \"usage_stats.json\"\nSESSIONS_FILE = \"chat_sessions.json\"\nMAX_BUDGET_USD = float(os.getenv(\"MAX_BUDGET_USD\", \"5.0\"))\n\n# â€»é‡‘é¡ã¯ã ã„ãŸã„ã®ç›®å®‰ï¼ˆUSD / 1M tokensï¼‰\nPRICING = {\n    \"gemini-3-pro-preview\":   {\"input\": 2.0,   \"output\": 12.0},\n    \"gemini-2.5-pro\":         {\"input\": 1.25,  \"output\": 10.0},\n    \"gemini-2.5-flash\":       {\"input\": 0.30,  \"output\": 2.50},\n    \"gemini-2.5-flash-lite\":  {\"input\": 0.10,  \"output\": 0.40},\n    \"gemini-2.0-flash\":       {\"input\": 0.10,  \"output\": 0.40},\n}\n\n# Vertex AI ç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®šï¼ˆ**å¸¸ã« Vertex ã‚’ä½¿ã†**ï¼‰\nVERTEX_PROJECT = os.getenv(\"GOOGLE_CLOUD_PROJECT\")\nVERTEX_LOCATION = \"global\"  # Gemini 2.x / 3 ã¯ global æ¨å¥¨\n\nst.set_page_config(page_title=\"Gemini 3 Web Studio\", layout=\"wide\")\n\n# =========================\n# Helper Functions\n# =========================\n\ndef load_usage():\n    if os.path.exists(USAGE_FILE):\n        with open(USAGE_FILE, \"r\") as f:\n            return json.load(f)\n    return {\"total_input_tokens\": 0, \"total_output_tokens\": 0, \"total_cost_usd\": 0.0}\n\ndef save_usage(stats):\n    with open(USAGE_FILE, \"w\") as f:\n        json.dump(stats, f, indent=4)\n\ndef calculate_cost(model_id, input_tok, output_tok):\n    price = PRICING.get(model_id, {\"input\": 0.0, \"output\": 0.0})\n    cost = (input_tok / 1_000_000 * price[\"input\"]) + (output_tok / 1_000_000 * price[\"output\"])\n    return cost\n\ndef get_mime_type(filename):\n    ext = filename.split('.')[-1].lower()\n    if ext in ['jpg', 'jpeg']:\n        return 'image/jpeg'\n    if ext == 'png':\n        return 'image/png'\n    if ext == 'mp4':\n        return 'video/mp4'\n    if ext == 'mov':\n        return 'video/quicktime'\n    if ext == 'txt':\n        return 'text/plain'\n    if ext == 'pdf':\n        return 'application/pdf'\n    if ext == 'csv':\n        return 'text/csv'\n    return 'application/octet-stream'\n\ndef extract_youtube_id(url):\n    regex = r\"(?:v=|\\/)([0-9A-Za-z_-]{11}).*\"\n    match = re.search(regex, url)\n    if match:\n        return match.group(1)\n    return None\n\ndef get_youtube_transcript(video_id):\n    try:\n        transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['ja', 'en'])\n        text = \" \".join([t['text'] for t in transcript_list])\n        return text\n    except Exception as e:\n        return f\"å­—å¹•ã®å–å¾—ã‚¨ãƒ©ãƒ¼: {e}\"\n\ndef get_relevant_context(query):\n    \"\"\"éå»ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ç°¡æ˜“æ¤œç´¢ã—ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™\"\"\"\n    if not query:\n        return \"\"\n    keywords = [k for k in query.split() if len(k) > 1]\n    if not keywords:\n        return \"\"\n\n    relevant_sessions = []\n    for session in st.session_state.sessions:\n        if session[\"id\"] == st.session_state.current_session_id:\n            continue\n        score = 0\n        for k in keywords:\n            if k.lower() in session[\"title\"].lower():\n                score += 3\n        for msg in session[\"messages\"][-4:]:\n            for k in keywords:\n                if k.lower() in msg[\"content\"].lower():\n                    score += 1\n        if score > 0:\n            relevant_sessions.append((score, session))\n\n    relevant_sessions.sort(key=lambda x: (x[0], x[1][\"timestamp\"]), reverse=True)\n    top_sessions = relevant_sessions[:3]\n\n    context_str = \"\"\n    if top_sessions:\n        context_str += \"### éå»ã®é–¢é€£ãƒãƒ£ãƒƒãƒˆå±¥æ­´ (Context)\\n\"\n        for score, session in top_sessions:\n            last_response = \"N/A\"\n            for m in reversed(session[\"messages\"]):\n                if m[\"role\"] == \"model\":\n                    last_response = m[\"content\"][:300] + \"...\"\n                    break\n            context_str += f\"- **Session: {session['title']}** ({session['timestamp'][:10]})\\n\"\n            context_str += f\"  Last Conclusion: {last_response}\\n\\n\"\n    return context_str\n\ndef extract_text_from_response(response):\n    \"\"\"Extract text from GenerateContentResponse\"\"\"\n    if not response.candidates:\n        return \"\"\n    parts = response.candidates[0].content.parts or []\n    return \"\".join(p.text or \"\" for p in parts)\n\n# =========================\n# Session Management\n# =========================\n\ndef load_sessions():\n    if os.path.exists(SESSIONS_FILE):\n        with open(SESSIONS_FILE, \"r\") as f:\n            try:\n                data = json.load(f)\n                return data.get(\"sessions\", [])\n            except json.JSONDecodeError:\n                return []\n    return []\n\ndef save_sessions(sessions):\n    with open(SESSIONS_FILE, \"w\") as f:\n        json.dump({\"sessions\": sessions}, f, indent=4, ensure_ascii=False)\n\ndef create_new_session():\n    current_sessions = load_sessions()\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": [],\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.rerun()\n\ndef switch_session(session_id):\n    st.session_state.current_session_id = session_id\n    st.rerun()\n\ndef update_current_session_messages(messages):\n    if st.session_state.current_session_id:\n        current_sessions = load_sessions()\n        for session in current_sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                session[\"messages\"] = messages\n                if session[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(messages) > 0:\n                    first_msg = messages[0][\"content\"]\n                    session[\"title\"] = (first_msg[:20] + \"...\") if len(first_msg) > 20 else first_msg\n                session[\"timestamp\"] = datetime.datetime.now().isoformat()\n                break\n        save_sessions(current_sessions)\n        st.session_state.sessions = current_sessions\n\ndef get_current_messages():\n    if st.session_state.current_session_id:\n        for session in st.session_state.sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                return session[\"messages\"]\n    return []\n\ndef delete_session(session_id):\n    current_sessions = load_sessions()\n    current_sessions = [s for s in current_sessions if s[\"id\"] != session_id]\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    if st.session_state.current_session_id == session_id:\n        st.session_state.current_session_id = None\n        if st.session_state.sessions:\n            st.session_state.current_session_id = st.session_state.sessions[0][\"id\"]\n    st.rerun()\n\ndef branch_session():\n    \"\"\"ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚’åˆ†å²\"\"\"\n    current_messages = get_current_messages()\n    current_sessions = load_sessions()\n    \n    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—\n    current_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n    for session in current_sessions:\n        if session[\"id\"] == st.session_state.current_session_id:\n            current_title = session[\"title\"]\n            break\n    \n    # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": f\"{current_title} (åˆ†å²)\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": current_messages.copy(),  # ç¾åœ¨ã®å±¥æ­´ã‚’ã‚³ãƒ”ãƒ¼\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    \n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.session_state.session_cost = 0.0  # ã‚³ã‚¹ãƒˆãƒªã‚»ãƒƒãƒˆ\n    st.rerun()\n\n# =========================\n# Initialization\n# =========================\n\nif \"sessions\" not in st.session_state:\n    st.session_state.sessions = load_sessions()\n\nif \"current_session_id\" not in st.session_state:\n    # Always create a new session when the app starts\n    create_new_session()\n\nif \"session_cost\" not in st.session_state:\n    st.session_state.session_cost = 0.0\n\nusage_stats = load_usage()\n\n# =========================\n# Sidebar\n# =========================\n\nwith st.sidebar:\n    st.title(\"Gemini 3 Studio\")\n\n    if st.button(\"â• æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\", use_container_width=True):\n        create_new_session()\n\n    if st.button(\"ğŸŒ± ç¾åœ¨ã®ãƒãƒ£ãƒƒãƒˆã‹ã‚‰åˆ†å²\", use_container_width=True):\n        branch_session()\n\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    current_messages = get_current_messages()\n    if current_messages:\n        export_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n        for s in st.session_state.sessions:\n            if s[\"id\"] == st.session_state.current_session_id:\n                export_title = s[\"title\"]\n                break\n\n        export_md = f\"# {export_title}\\n\\n\"\n        export_md += f\"**ä½œæˆæ—¥æ™‚**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n---\\n\\n\"\n        for msg in current_messages:\n            role_label = \"ğŸ§‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼\" if msg[\"role\"] == \"user\" else \"ğŸ¤– AI\"\n            export_md += f\"## {role_label}\\n\\n{msg['content']}\\n\\n---\\n\\n\"\n\n        if st.button(\"ğŸ”— å¤–éƒ¨å…±æœ‰ãƒªãƒ³ã‚¯ã‚’ä½œæˆ\", use_container_width=True):\n            with st.spinner(\"ãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆä¸­...\"):\n                try:\n                    import urllib.request\n                    import urllib.parse\n\n                    data = urllib.parse.urlencode(\n                        {\"content\": export_md, \"expiry_days\": 7, \"syntax\": \"md\"}\n                    ).encode()\n\n                    req = urllib.request.Request(\"https://dpaste.org/api/\", data=data)\n                    req.add_header(\"User-Agent\", \"Mozilla/5.0 (Gemini3Studio)\")\n\n                    with urllib.request.urlopen(req) as response:\n                        share_url = response.read().decode(\"utf-8\").strip()\n                        st.success(\"ãƒªãƒ³ã‚¯ã‚’ä½œæˆã—ã¾ã—ãŸï¼\")\n                        st.code(share_url)\n                        st.caption(\"â€»ãƒªãƒ³ã‚¯ã¯7æ—¥é–“æœ‰åŠ¹ã§ã™\")\n                except Exception as e:\n                    st.error(f\"ãƒªãƒ³ã‚¯ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}\")\n\n    st.markdown(\"---\")\n\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    st.subheader(\"æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«\")\n    uploaded_files = st.file_uploader(\n        \"ç”»åƒã€å‹•ç”»ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\",\n        accept_multiple_files=True,\n        type=[\"png\", \"jpg\", \"jpeg\", \"mp4\", \"mov\", \"txt\", \"pdf\", \"csv\"],\n        help=\"Limit 2GB per file\",\n    )\n\n    pasted_image_bytes = None\n    if paste:\n        if \"paste_key\" not in st.session_state:\n            st.session_state.paste_key = 0\n        try:\n            pasted_image_bytes = paste(\n                label=\"ğŸ“‹ ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã‹ã‚‰ç”»åƒã‚’è²¼ã‚Šä»˜ã‘\",\n                key=f\"paste_btn_{st.session_state.paste_key}\",\n            )\n        except Exception as e:\n            st.error(f\"Clipboard button error: {e}\")\n        \n        if pasted_image_bytes:\n            st.success(\"ç”»åƒãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚Œã¾ã—ãŸï¼\")\n            st.image(pasted_image_bytes, caption=\"è²¼ã‚Šä»˜ã‘ãŸç”»åƒ\", use_container_width=True)\n            if st.button(\"ğŸ—‘ï¸ ç”»åƒã‚’ã‚¯ãƒªã‚¢\", key=\"clear_paste\"):\n                st.session_state.paste_key += 1\n                st.rerun()\n    else:\n        st.warning(\"Clipboard library not loaded (ImportError)\")\n\n    # ---- YouTube URL ----\n    st.markdown(\"---\")\n    youtube_url = st.text_input(\"YouTube URL (å­—å¹•ã‚’åˆ†æ)\", placeholder=\"https://youtu.be/...\")\n\n    st.markdown(\"---\")\n    \n    # ---- å›ç­”ãƒ¢ãƒ¼ãƒ‰ ----\n    st.subheader(\"ğŸ¯ å›ç­”ãƒ¢ãƒ¼ãƒ‰\")\n    \n    mode_type = st.radio(\n        \"ãƒ¢ãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—\",\n        [\"é¸æŠ1 (å®Œå…¨ç‰ˆ)\", \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\", \"ãƒ™ãƒ¼ã‚¿ç‰ˆ\"],\n        index=0,\n        horizontal=True\n    )\n    \n    if mode_type == \"é¸æŠ1 (å®Œå…¨ç‰ˆ)\":\n        response_mode = st.radio(\n            \"é¸æŠ\",\n            [\n                \"2. ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n                \"3. ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n                \"Î²2. ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n            ],\n            index=0\n        )\n        st.caption(\"âœ… å®Œæˆåº¦ã®é«˜ã„æ¨å¥¨ãƒ¢ãƒ¼ãƒ‰\")\n    elif mode_type == \"é¸æŠ2 (ä¸å®Œå…¨ç‰ˆ)\":\n        response_mode = st.radio(\n            \"é¸æŠ\",\n            [\n                \"1. ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n            ],\n            index=0\n        )\n        st.caption(\"âš ï¸ é–‹ç™ºä¸­: ä¸€éƒ¨æ©Ÿèƒ½ãŒæœªå®Œæˆã§ã™\")\n    else:\n        response_mode = st.radio(\n            \"é¸æŠ (ãƒ™ãƒ¼ã‚¿ç‰ˆ)\",\n            [\n                \"Î²1. é€šå¸¸ (é«˜é€Ÿ)\",\n            ],\n            index=0\n        )\n        st.caption(\"âš ï¸ ãƒ™ãƒ¼ã‚¿ç‰ˆæ©Ÿèƒ½: å‹•ä½œãŒä¸å®‰å®šãªå ´åˆãŒã‚ã‚Šã¾ã™\")\n    \n    strict_mode = False  # äº’æ›æ€§ç¶­æŒã®ãŸã‚ã®ãƒ€ãƒŸãƒ¼å¤‰æ•°\n    st.markdown(\"---\")\n    \n    st.title(\"è¨­å®š\")\n\n    # ---- ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆGemini 1.5 ã¯å»ƒæ­¢ã•ã‚Œã¦ã„ã‚‹ã®ã§å«ã‚ãªã„ï¼‰ ----\n    model_options = [\n        \"gemini-3-pro-preview\",\n        \"gemini-2.5-pro\",\n        \"gemini-2.5-flash\",\n        \"gemini-2.5-flash-lite\",\n        \"gemini-2.0-flash\",\n    ]\n    model_id = st.selectbox(\"ãƒ¢ãƒ‡ãƒ«ID\", options=model_options, index=0)\n\n    if \"3-pro\" in model_id or \"2.5-pro\" in model_id:\n        st.caption(\"ğŸ§  é«˜åº¦ãªæ¨è«–å‘ã‘ Pro ãƒ¢ãƒ‡ãƒ«\")\n    if \"flash\" in model_id:\n        st.caption(\"âš¡ é«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆãª Flash ç³»ãƒ¢ãƒ‡ãƒ«\")\n\n    # ---- æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚° ----\n    use_search = st.toggle(\"Googleæ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã‚’ä½¿ç”¨\", value=True)\n    candidate_count = st.slider(\"å›ç­”å€™è£œæ•°\", min_value=1, max_value=3, value=3)\n    if use_search and candidate_count > 1:\n        st.caption(\"âš ï¸ æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ä½¿ç”¨æ™‚ã¯å€™è£œæ•°ãŒ1ã«ãªã‚Šã¾ã™ã€‚\")\n\n    st.markdown(\"---\")\n\n    # ---- å±¥æ­´æ¤œç´¢ ----\n    search_query = st.text_input(\"ğŸ” å±¥æ­´ã‚’æ¤œç´¢\", placeholder=\"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰...\")\n    if search_query:\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if search_query.lower() in s[\"title\"].lower():\n                filtered_sessions.append(s)\n                continue\n            found = False\n            for m in s[\"messages\"]:\n                if search_query.lower() in m[\"content\"].lower():\n                    filtered_sessions.append(s)\n                    found = True\n                    break\n            if not found:\n                pass\n    else:\n        filtered_sessions = st.session_state.sessions\n\n    # CSSã§è¦‹ã‚„ã™ãä½¿ã„ã‚„ã™ãæœ€é©åŒ–\n    st.markdown(\"\"\"\n    <style>\n    /* éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã®ã‚¿ã‚¤ãƒˆãƒ« */\n    div[data-testid=\"stExpander\"] summary p {\n        font-size: 11px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ */\n    section[data-testid=\"stSidebar\"] button p {\n        font-size: 13px !important;\n    }\n    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã« */\n    section[data-testid=\"stSidebar\"] button {\n        padding: 0.25rem 0.5rem !important;\n        min-height: 2rem !important;\n    }\n    </style>\n    \"\"\", unsafe_allow_html=True)\n    \n    # ç›´è¿‘5ä»¶ã¨éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«åˆ†å‰²\n    recent_sessions = filtered_sessions[:5] if len(filtered_sessions) > 5 else filtered_sessions\n    archive_sessions = filtered_sessions[5:] if len(filtered_sessions) > 5 else []\n    \n    # ç›´è¿‘5ä»¶ï¼ˆå¸¸ã«å±•é–‹ï¼‰\n    if recent_sessions:\n        st.markdown(\"**ğŸ“Œ ç›´è¿‘ã®ãƒãƒ£ãƒƒãƒˆ**\")\n        for session in recent_sessions:\n            col1, col2 = st.columns([0.8, 0.2])\n            with col1:\n                if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                    switch_session(session[\"id\"])\n            with col2:\n                if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                    delete_session(session[\"id\"])\n    \n    # éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆæŠ˜ã‚ŠãŸãŸã¿ï¼‰\n    if archive_sessions:\n        with st.expander(f\"ğŸ“œ éå»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ– ({len(archive_sessions)}ä»¶)\", expanded=False):\n            for session in archive_sessions:\n                col1, col2 = st.columns([0.8, 0.2])\n                with col1:\n                    if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                        switch_session(session[\"id\"])\n                with col2:\n                    if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                        delete_session(session[\"id\"])\n\n    st.markdown(\"---\")\n\n    # ---- ç”»åƒç”Ÿæˆ ----\n    st.subheader(\"ğŸ¨ ç”»åƒç”Ÿæˆ\")\n    img_prompt = st.text_area(\"ç”Ÿæˆã—ãŸã„ç”»åƒã®èª¬æ˜\", placeholder=\"æœªæ¥çš„ãªéƒ½å¸‚ã®é¢¨æ™¯...\")\n    aspect_ratio = st.selectbox(\"ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”\", [\"16:9\", \"1:1\", \"4:3\", \"3:4\", \"9:16\"])\n\n    generate_img_btn = st.button(\"ç”»åƒã‚’ç”Ÿæˆ\", type=\"primary\", disabled=not img_prompt)\n    if generate_img_btn and img_prompt:\n        st.session_state.generate_image_trigger = {\n            \"prompt\": img_prompt,\n            \"aspect_ratio\": aspect_ratio,\n        }\n\n    st.markdown(\"---\")\n\n    # ---- è©•ä¾¡åˆ†æ ----\n    st.subheader(\"ğŸ“Š å›ç­”å“è³ªåˆ†æ\")\n    total_ratings = 0\n    positive_ratings = 0\n    model_ratings = {}\n\n    for s in st.session_state.sessions:\n        for m in s[\"messages\"]:\n            if \"rating\" in m and m[\"rating\"] is not None:\n                total_ratings += 1\n                if m[\"rating\"] == 1:\n                    positive_ratings += 1\n                if \"metadata\" in m and \"model\" in m[\"metadata\"]:\n                    mod = m[\"metadata\"][\"model\"]\n                    if mod not in model_ratings:\n                        model_ratings[mod] = {\"total\": 0, \"positive\": 0}\n                    model_ratings[mod][\"total\"] += 1\n                    if m[\"rating\"] == 1:\n                        model_ratings[mod][\"positive\"] += 1\n\n    if total_ratings > 0:\n        approval_rate = (positive_ratings / total_ratings) * 100\n        st.metric(\"Positive Ratings\", f\"{positive_ratings}/{total_ratings}\", f\"{approval_rate:.1f}%\")\n        best_model = \"N/A\"\n        best_rate = -1\n        for mod, stats in model_ratings.items():\n            rate = stats[\"positive\"] / stats[\"total\"]\n            if rate > best_rate:\n                best_rate = rate\n                best_model = mod\n        if best_model != \"N/A\":\n            st.caption(f\"ğŸ† Best Model: **{best_model}** ({best_rate*100:.0f}%)\")\n    else:\n        st.caption(\"ã¾ã è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\")\n\n    st.markdown(\"---\")\n\n    # ---- ã‚³ã‚¹ãƒˆè¡¨ç¤º ----\n    st.subheader(\"ğŸ’° ã‚³ã‚¹ãƒˆ (æ¦‚ç®—)\")\n    st.metric(\"Total Cost\", f\"${usage_stats['total_cost_usd']:.4f}\")\n    if st.session_state.session_cost > 0:\n        st.caption(f\"Current Session: ${st.session_state.session_cost:.4f}\")\n\n    if usage_stats[\"total_cost_usd\"] >= MAX_BUDGET_USD:\n        st.error(f\"âš ï¸ äºˆç®—ä¸Šé™ (${MAX_BUDGET_USD}) ã«é”ã—ã¾ã—ãŸã€‚\")\n        stop_generation = True\n    else:\n        stop_generation = False\n\n    st.markdown(\"---\")\n    st.code(f\"PROJECT: {VERTEX_PROJECT}\\nLOCATION: {VERTEX_LOCATION} (Vertex AI)\")\n\n# =========================\n# Main UI\n# =========================\n\ncurrent_session_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\nfor s in st.session_state.sessions:\n    if s[\"id\"] == st.session_state.current_session_id:\n        current_session_title = s[\"title\"]\n        break\n\nst.header(current_session_title)\nst.markdown(\n    \"ä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\"\n)\n\n# ---- Vertex AI Client ----\n\n@st.cache_resource\ndef get_client():\n    return genai.Client(\n        vertexai=True,\n        project=VERTEX_PROJECT,\n        location=VERTEX_LOCATION,\n    )\n\nclient = get_client()\n\n# ---- å±¥æ­´è¡¨ç¤º ----\n\nmessages = get_current_messages()\nfor idx, msg in enumerate(messages):\n    with st.chat_message(msg[\"role\"]):\n        st.markdown(msg[\"content\"])\n        if msg[\"role\"] == \"model\":\n            col1, col2, col3 = st.columns([0.1, 0.1, 0.8])\n            current_rating = msg.get(\"rating\")\n            with col1:\n                if st.button(\"ğŸ‘\", key=f\"up_{idx}\"):\n                    messages[idx][\"rating\"] = 1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col2:\n                if st.button(\"ğŸ‘\", key=f\"down_{idx}\"):\n                    messages[idx][\"rating\"] = -1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col3:\n                if current_rating == 1:\n                    st.caption(\"âœ… é«˜è©•ä¾¡\")\n                elif current_rating == -1:\n                    st.caption(\"âŒ ä½è©•ä¾¡\")\n\n# =========================\n# ç”»åƒç”Ÿæˆãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°\n# =========================\n\nif hasattr(st.session_state, \"generate_image_trigger\") and st.session_state.generate_image_trigger:\n    img_data = st.session_state.generate_image_trigger\n    del st.session_state.generate_image_trigger\n\n    with st.chat_message(\"user\"):\n        st.markdown(f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\")\n        st.caption(f\"ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”: {img_data['aspect_ratio']}\")\n\n    messages.append({\"role\": \"user\", \"content\": f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\"})\n    update_current_session_messages(messages)\n\n    with st.chat_message(\"assistant\"):\n        with st.status(\"ç”»åƒã‚’ç”Ÿæˆä¸­...\", expanded=True) as status:\n            try:\n                config = types.GenerateContentConfig(\n                    response_modalities=[\"IMAGE\"],\n                    image_config=types.ImageConfig(\n                        aspect_ratio=img_data[\"aspect_ratio\"]\n                    ),\n                )\n                status.write(\"Gemini 3 Pro Imageã§ç”Ÿæˆä¸­...\")\n                response = client.models.generate_content(\n                    model=\"gemini-3-pro-image-preview\",\n                    contents=img_data[\"prompt\"],\n                    config=config,\n                )\n\n                generated_image = None\n\n                # ç”»åƒã‚’å–ã‚Šå‡ºã™\n                if getattr(response, \"candidates\", None):\n                    for candidate in response.candidates:\n                        if getattr(candidate, \"content\", None) and candidate.content.parts:\n                            for part in candidate.content.parts:\n                                if getattr(part, \"inline_data\", None):\n                                    try:\n                                        generated_image = part.as_image()\n                                    except AttributeError:\n                                        image_bytes_raw = part.inline_data.data\n                                        generated_image = Image.open(io.BytesIO(image_bytes_raw))\n                                    break\n                        if generated_image is not None:\n                            break\n\n                if generated_image is not None:\n                    st.image(generated_image, caption=img_data[\"prompt\"])\n                    buf = io.BytesIO()\n                    generated_image.save(buf, format=\"PNG\")\n                    image_bytes = buf.getvalue()\n                    st.download_button(\n                        label=\"ğŸ’¾ ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\",\n                        data=image_bytes,\n                        file_name=f\"generated_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png\",\n                        mime=\"image/png\",\n                    )\n                    messages.append(\n                        {\"role\": \"model\", \"content\": f\"âœ… ç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {img_data['prompt']}\"}\n                    )\n                    update_current_session_messages(messages)\n                    status.update(label=\"âœ… ç”»åƒç”Ÿæˆå®Œäº†\", state=\"complete\")\n                else:\n                    st.error(\"ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")\n                    status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n\n            except Exception as e:\n                status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n                st.error(f\"ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}\")\n\n# =========================\n# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›\n# =========================\n\nprompt = st.chat_input(\"ä½•ã‹èã„ã¦ãã ã•ã„...\", disabled=stop_generation)\n\nif prompt:\n    if stop_generation:\n        st.error(\"äºˆç®—ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚\")\n    else:\n        # ---- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€è¡¨ç¤º ----\n        with st.chat_message(\"user\"):\n            st.markdown(prompt)\n            if uploaded_files:\n                for uf in uploaded_files:\n                    st.caption(f\"ğŸ“ æ·»ä»˜: {uf.name}\")\n            if youtube_url:\n                st.caption(f\"ğŸ“º YouTube: {youtube_url}\")\n            if pasted_image_bytes:\n                st.caption(\"ğŸ“‹ ç”»åƒãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚Œã¾ã—ãŸ\")\n\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        update_current_session_messages(messages)\n\n        # ---- ãƒ¢ãƒ‡ãƒ«å¿œç­” ----\n        with st.chat_message(\"assistant\"):\n            status_container = st.status(\"æ€è€ƒä¸­...\", expanded=True)\n            try:\n                # ä¼šè©±å±¥æ­´\n                model_history = []\n                for msg in messages[:-1]:\n                    model_history.append(\n                        types.Content(\n                            role=msg[\"role\"],\n                            parts=[types.Part.from_text(text=msg[\"content\"])],\n                        )\n                    )\n\n                # ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³\n                current_parts = [types.Part.from_text(text=prompt)]\n\n                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«\n                for uploaded_file in uploaded_files or []:\n                    try:\n                        mime_type = get_mime_type(uploaded_file.name)\n                        bytes_data = uploaded_file.getvalue()\n                        part = types.Part.from_bytes(data=bytes_data, mime_type=mime_type)\n                        current_parts.append(part)\n                        status_container.write(f\"ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™å®Œäº†: {uploaded_file.name}\")\n                    except Exception as e:\n                        status_container.error(\n                            f\"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {uploaded_file.name} - {e}\"\n                        )\n\n                # è²¼ã‚Šä»˜ã‘ç”»åƒ\n                if pasted_image_bytes:\n                    import base64\n\n                    status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã‚’å‡¦ç†ä¸­...\")\n                    try:\n                        if isinstance(pasted_image_bytes, str):\n                            if pasted_image_bytes.startswith(\"data:\"):\n                                base64_str = pasted_image_bytes.split(\",\", 1)[1]\n                                image_bytes_decoded = base64.b64decode(base64_str)\n                            else:\n                                image_bytes_decoded = base64.b64decode(pasted_image_bytes)\n                        else:\n                            image_bytes_decoded = pasted_image_bytes\n                        part = types.Part.from_bytes(\n                            data=image_bytes_decoded, mime_type=\"image/png\"\n                        )\n                        current_parts.append(part)\n                        status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®æº–å‚™å®Œäº†\")\n                    except Exception as e:\n                        status_container.error(f\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n\n                # YouTube å­—å¹•\n                if youtube_url:\n                    vid_id = extract_youtube_id(youtube_url)\n                    if vid_id:\n                        status_container.write(\"YouTubeã®å­—å¹•ã‚’å–å¾—ä¸­...\")\n                        transcript_text = get_youtube_transcript(vid_id)\n                        current_parts.append(\n                            types.Part.from_text(text=f\"YouTube Transcript:\\n{transcript_text}\")\n                        )\n                    else:\n                        status_container.write(\"ç„¡åŠ¹ãªYouTube URLã§ã™ã€‚\")\n\n                contents_for_model = model_history + [\n                    types.Content(role=\"user\", parts=current_parts)\n                ]\n\n                # ---- Tool / Config ----\n                tools = []\n                final_candidate_count = candidate_count\n                if use_search:\n                    tools.append(types.Tool(google_search=types.GoogleSearch()))\n                    final_candidate_count = 1\n\n                # â˜… System Instruction ã®æ”¹å–„: ãƒ¡ã‚¿ç™ºè¨€ç¦æ­¢ã¨ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªæŒ¯ã‚‹èˆã„ã‚’æŒ‡ç¤º\n                base_system_instruction = (\n                    \"ã‚ãªãŸã¯é«˜åº¦ãªçŸ¥æ€§ã‚’æŒã¤å°‚é–€çš„ãªãƒªã‚µãƒ¼ãƒãƒ»ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\\n\"\n                    \"ä»¥ä¸‹ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’å³å®ˆã—ã¦ãã ã•ã„ï¼š\\n\"\n                    \"1. **ãƒ¡ã‚¿ç™ºè¨€ã®ç¦æ­¢**: ã€Œç§ã¯AIã§ã™ã€ã€Œä¸–ç•Œæœ€é«˜å³°ã®ï½ã¨ã—ã¦ã€ãªã©ã®è‡ªå·±è¨€åŠã‚„å‰ç½®ãã¯ä¸€åˆ‡è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚\\n\"\n                    \"2. **æ„å›³ã®æ±²ã¿å–ã‚Š**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã®èƒŒå¾Œã«ã‚ã‚‹æ„å›³ï¼ˆæ–‡è„ˆã€æš—é»™ã®å‰æï¼‰ã‚’æ¨æ¸¬ã—ã€è¨€è‘‰é€šã‚Šã§ã¯ãªãã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ¬å½“ã«çŸ¥ã‚ŠãŸã„ã“ã¨ã€ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n\"\n                    \"3. **æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”**: çµè«–ã‚’å…ˆã«è¿°ã¹ã€ãã®å¾Œã«è©³ç´°ãªæ ¹æ‹ ã€ã‚·ãƒŠãƒªã‚ªåˆ†æã€ãƒªã‚¹ã‚¯è¦å› ã‚’è«–ç†çš„ã«å±•é–‹ã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"4. **å®¢è¦³æ€§**: äºˆæ¸¬ã‚’è¡Œã†å ´åˆã¯ã€æ–­å®šã‚’é¿ã‘ã€è¤‡æ•°ã®ã‚·ãƒŠãƒªã‚ªï¼ˆæ¥½è¦³ã€æ‚²è¦³ã€ä¸­ç«‹ï¼‰ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"5. **å¼•ç”¨**: æ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸå ´åˆã¯ã€å¿…ãšæƒ…å ±æºã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚\"\n                )\n\n                final_answer = \"\"\n                grounding_metadata = None\n                \n                # =========================\n                # ãƒ¢ãƒ¼ãƒ‰è¨­å®šã®è§£æ\n                # =========================\n                enable_research = True  # å…¨ãƒ¢ãƒ¼ãƒ‰ã§ãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œ\n                enable_meta = \"ãƒ¡ã‚¿\" in response_mode or \"MAX\" in response_mode\n                enable_strict = \"é¬¼è»æ›¹\" in response_mode or \"MAX\" in response_mode\n\n                # =========================\n                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (é«˜é€Ÿ / é¬¼è»æ›¹)\n                # =========================\n                if not enable_research:\n                    config = types.GenerateContentConfig(\n                        temperature=0.7,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=base_system_instruction,\n                    )\n                    \n                    status_container.write(\"å›ç­”ç”Ÿæˆä¸­...\")\n                    response = client.models.generate_content(\n                        model=model_id,\n                        contents=contents_for_model,\n                        config=config,\n                    )\n                    \n                    final_answer = extract_text_from_response(response)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®—\n                    if response.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            response.usage_metadata.prompt_token_count,\n                            response.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += response.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += response.usage_metadata.candidates_token_count\n\n                    # é¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ (é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ç‰ˆ)\n                    if enable_strict:\n                        status_container.write(\"ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        reviewer_instruction = base_system_instruction + \"\"\"\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n                        review_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\nåˆç‰ˆå›ç­”:\\n{final_answer}\\n\\nãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\")])]\n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=types.GenerateContentConfig(temperature=0.1, candidate_count=1, system_instruction=reviewer_instruction)\n                        )\n                        final_answer = extract_text_from_response(review_resp)\n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        \n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(model_id, review_resp.usage_metadata.prompt_token_count, review_resp.usage_metadata.candidates_token_count)\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n\n                # =========================\n                # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰\n                # =========================\n                else:\n                    # =========================\n                    # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰: å¤šæ®µéšã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ \n                    # =========================\n                    \n                    # --- Phase 1: ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 1: ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    research_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒªã‚µãƒ¼ãƒå°‚ä»»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚æœ€çµ‚å›ç­”ã¯æ›¸ã‹ãšã€äº‹å®Ÿåé›†ã«é›†ä¸­ã™ã‚‹ã“ã¨ã€‚\n\n**èª¿æŸ»è¦³ç‚¹**:\n- è³ªå•ã«é–¢é€£ã™ã‚‹**æœ€æ–°ã®äº‹å®Ÿãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ»çµ±è¨ˆ**ï¼ˆ**2025å¹´ã®æƒ…å ±ã‚’æœ€å„ªå…ˆ**ï¼‰\n- **ç¾æ™‚ç‚¹ã§å­˜åœ¨ã™ã‚‹å…¨ã¦ã®é¸æŠè‚¢ãƒ»ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¶²ç¾…çš„ã«èª¿æŸ»**ï¼ˆä¾‹: è£½å“æ¯”è¼ƒãªã‚‰ã€æœ€æ–°ç‰ˆã ã‘ã§ãªãç›´è¿‘ã®å…¨ä¸–ä»£ã‚’èª¿æŸ»ï¼‰\n- å…¬å¼æƒ…å ±ã‚„ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã‹ã‚‰ã®å¼•ç”¨\n- é–¢é€£ã™ã‚‹èƒŒæ™¯æƒ…å ±ã‚„æ–‡è„ˆ\n- ç«¶åˆãƒ»ä»£æ›¿æ¡ˆãƒ»æ¯”è¼ƒå¯¾è±¡ã®**å®Œå…¨ãªãƒªã‚¹ãƒˆ**\n- ãƒªã‚¹ã‚¯ãƒ»åˆ¶ç´„ãƒ»æ³¨æ„ç‚¹ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n- å‚è€ƒã«ã—ãŸä¸»è¦ãªæƒ…å ±æºã®URL\n\n**é‡è¦**: \n- çµè«–ã‚„æ¨å¥¨ã¯æ›¸ã‹ãšã€å¾Œå·¥ç¨‹ãŒåˆ¤æ–­ã§ãã‚‹èª¿æŸ»ãƒ¡ãƒ¢ã«é›†ä¸­ã™ã‚‹ã“ã¨\n- **å¿…ãšæ¤œç´¢æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã€æœ€æ–°ã®æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã“ã¨**\n- **æ¤œç´¢çµæœã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æ—¥ä»˜ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒ»ãƒ¢ãƒ‡ãƒ«åã‚’å„ªå…ˆçš„ã«è¨˜è¼‰ã™ã‚‹ã“ã¨**\n- **æ¯”è¼ƒå¯¾è±¡ã¨ãªã‚‹é¸æŠè‚¢ã‚’è¦‹è½ã¨ã•ãªã„ã‚ˆã†ã€è¤‡æ•°ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è©¦ã™ã“ã¨**ï¼ˆä¾‹: ã€ŒiPhone æœ€æ–°ãƒ¢ãƒ‡ãƒ« 2025ã€ã€ŒiPhone 17ã€ã€ŒiPhone 2025å¹´ç™ºå£²ã€ãªã©ï¼‰\n- **ã€Œã“ã‚Œã‚ˆã‚Šæ–°ã—ã„ãƒ¢ãƒ‡ãƒ«/ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯å­˜åœ¨ã—ãªã„ã‹ï¼Ÿã€ã‚’å¸¸ã«ç¢ºèªã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ï¼ˆ2024å¹´ä»¥å‰ãªã©ï¼‰ã—ã‹è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãã®æ—¨ã‚’æ˜è¨˜ã™ã‚‹ã“ã¨\n\"\"\"\n\n                    # éå»ã®é–¢é€£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—\n                    past_context = get_relevant_context(prompt)\n                    \n                    # ãƒªã‚µãƒ¼ãƒç”¨ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ§‹ç¯‰\n                    research_parts = [types.Part(text=f\"ã“ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š\\n{prompt}\")]\n                    \n                    if past_context:\n                        research_parts.insert(0, types.Part(text=\"ä»¥ä¸‹ã¯éå»ã®é–¢é€£ãƒãƒ£ãƒƒãƒˆã‹ã‚‰æŠ½å‡ºã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã™ï¼š\\n\\n\" + past_context))\n                    \n                    research_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=research_parts)\n                    ]\n                    \n                    research_config = types.GenerateContentConfig(\n                        temperature=0.2,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=research_instruction,\n                    )\n                    \n                    research_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=research_contents,\n                        config=research_config,\n                    )\n                    \n                    research_text = extract_text_from_response(research_resp)\n                    \n                    # ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºã®ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ±ã‚’ä¿å­˜\n                    if research_resp.candidates and research_resp.candidates[0].grounding_metadata:\n                        grounding_metadata = research_resp.candidates[0].grounding_metadata\n                    \n                    status_container.write(\"âœ“ ãƒªã‚µãƒ¼ãƒå®Œäº†\")\n                    with status_container.expander(\"åé›†ã—ãŸèª¿æŸ»ãƒ¡ãƒ¢\", expanded=False):\n                        st.markdown(research_text)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1)\n                    if research_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            research_resp.usage_metadata.prompt_token_count,\n                            research_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += research_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += research_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 1.5: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    questions_text = \"\"\n                    if enable_meta:\n                        status_container.write(\"Phase 1.5: ãƒ¡ã‚¿è³ªå•ç”Ÿæˆä¸­...\")\n                        \n                        question_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ç›®çš„**: \nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•ã¨èª¿æŸ»ãƒ¡ãƒ¢ã‚’è¸ã¾ãˆã¦ã€ã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±ãç†è§£ã™ã‚‹ãŸã‚ã®ã€Œé‹­ã„ã‚µãƒ–è³ªå•ã€ã‚’ä½œæˆã™ã‚‹ã“ã¨ã€‚\n\n**ãƒ«ãƒ¼ãƒ«**:\n- æœ€å¤§5å€‹ã¾ã§\n- å„è³ªå•ã¯1-2è¡Œã§å…·ä½“çš„ã‹ã¤é‹­ã\n- ä»¥ä¸‹ã®è¦³ç‚¹ã‚’æ„è­˜:\n  1. å‰æãŒå´©ã‚Œã‚‹å¯èƒ½æ€§ã¯ã©ã“ã‹ï¼Ÿ\n  2. å¼·æ°—/å¼±æ°—ã‚·ãƒŠãƒªã‚ªã®åˆ†å²ç‚¹ã¯ä½•ã‹ï¼Ÿ\n  3. ç«¶åˆãƒ»æŠ€è¡“ãƒ»è¦åˆ¶ã®ä¸ç¢ºå®Ÿæ€§ã¯ï¼Ÿ\n  4. ã€Œäºˆæ¸¬ãŒå¤–ã‚Œã‚‹ã¨ã—ãŸã‚‰ã©ã‚“ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ï¼Ÿã€\n\n**å‡ºåŠ›**: ç®‡æ¡æ›¸ãï¼ˆQ1, Q2...ï¼‰ã®ã¿\n\"\"\"\n\n                        question_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•:\\n{prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\nã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±æ˜ã‚Šã™ã‚‹ãŸã‚ã®é‡è¦ãªã‚µãƒ–è³ªå•ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\")])]\n                        \n                        question_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=question_contents,\n                            config=types.GenerateContentConfig(\n                                temperature=0.4,\n                                candidate_count=1,\n                                system_instruction=question_instruction,\n                            )\n                        )\n                        \n                        questions_text = extract_text_from_response(question_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¡ã‚¿è³ªå•ç”Ÿæˆå®Œäº†\")\n                        with status_container.expander(\"ç”Ÿæˆã•ã‚ŒãŸãƒ¡ã‚¿è³ªå•\", expanded=False):\n                            st.markdown(questions_text)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1.5)\n                        if question_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                question_resp.usage_metadata.prompt_token_count,\n                                question_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += question_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += question_resp.usage_metadata.candidates_token_count\n\n                    # --- Phase 2: çµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 2: çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    if enable_meta:\n                        deep_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã¨ãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ã‚’æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**æ§‹æˆ**:\n1. **æ·±æ˜ã‚Šè€ƒå¯Ÿ**ï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n2. **çµè«–**ï¼ˆ2-3è¡Œï¼‰\n3. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n4. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨\n\"\"\"\n                    else:\n                        deep_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã‚’å”¯ä¸€ã®æ ¹æ‹ ã¨ã—ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n**æ§‹æˆ**:\n1. **çµè«–**ï¼ˆ2-3è¡Œã§æ˜ç¢ºã«ï¼‰\n2. **è©³ç´°ãªåˆ†æ**ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãï¼‰\n3. **è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯**ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n\n**é‡è¦**: \n- æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«åã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨**\n- å¤ã„æƒ…å ±ã¨æ–°ã—ã„æƒ…å ±ãŒæ··åœ¨ã™ã‚‹å ´åˆã¯ã€æ–°ã—ã„æƒ…å ±ã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n\"\"\"\n                    \n                    synthesis_prompt_text = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if enable_meta and questions_text:\n                        synthesis_prompt_text += f\"==== ãƒ¡ã‚¿è³ªå•ä¸€è¦§ ====\\n{questions_text}\\n==== ãƒ¡ã‚¿è³ªå•ã“ã“ã¾ã§ ====\\n\\næŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n2. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»åˆ†æãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    else:\n                        synthesis_prompt_text += \"ä¸Šè¨˜ãƒ¡ãƒ¢ã‚’æ ¹æ‹ ã«ã€æœ€çµ‚å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ã‚’å¿…ãšä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚**\"\n\n                    synthesis_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=[\n                            types.Part(text=synthesis_prompt_text)\n                        ])\n                    ]\n                    \n                    synthesis_config = types.GenerateContentConfig(\n                        temperature=0.3,\n                        candidate_count=1,\n                        tools=[],  # çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºã§ã¯æ¤œç´¢OFF\n                        system_instruction=deep_instruction,\n                    )\n                    \n                    synthesis_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=synthesis_contents,\n                        config=synthesis_config,\n                    )\n                    \n                    draft_answer = extract_text_from_response(synthesis_resp)\n                    \n                    status_container.write(\"âœ“ çµ±åˆå®Œäº†\")\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 2)\n                    if synthesis_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            synthesis_resp.usage_metadata.prompt_token_count,\n                            synthesis_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += synthesis_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += synthesis_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    if enable_strict:\n                        status_container.write(\"Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        \n\n                        reviewer_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™ã€‚ãŸã ã—ã€**èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’å„ªå…ˆã—ã€æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã™ã‚‹ã“ã¨**ã€‚\n\n**ãƒ¬ãƒ“ãƒ¥ãƒ¼è¦³ç‚¹**:\n- äº‹å®Ÿã¨æ¨æ¸¬ã‚’æ˜ç¢ºã«åˆ†ã‘ã‚‹\n- éåº¦ã«è‡ªä¿¡ã®ã‚ã‚‹æ–­å®šã‚’å¼±ã‚ã‚‹\n- æ•°å­—ã‚„å›ºæœ‰åè©ãŒèª¿æŸ»ãƒ¡ãƒ¢ã¨çŸ›ç›¾ã—ã¦ã„ãªã„ã‹ç¢ºèª\n- **èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°ã®æƒ…å ±ï¼ˆæœ€æ–°ãƒ¢ãƒ‡ãƒ«ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€æ—¥ä»˜ãªã©ï¼‰ãŒæ­£ã—ãä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª**\n- **å¤ã„æƒ…å ±ã§ä¸Šæ›¸ãã—ã¦ã„ãªã„ã‹ç¢ºèª**\n- è¦‹è½ã¨ã—ã¦ã„ã‚‹é‡è¦ãªãƒªã‚¹ã‚¯ãƒ»ã‚·ãƒŠãƒªã‚ªãŒã‚ã‚Œã°è¿½åŠ \n\n**é‡è¦**: \n- èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ãŒæœ€æ–°ã§ã‚ã‚‹å ´åˆã€ãã‚Œã‚’å„ªå…ˆã™ã‚‹ã“ã¨\n- ã‚ãªãŸã®çŸ¥è­˜ãŒå¤ã„å ´åˆã¯ã€èª¿æŸ»ãƒ¡ãƒ¢ã®æƒ…å ±ã‚’ä¿¡é ¼ã™ã‚‹ã“ã¨\n\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n\n                        review_contents = [\n                            types.Content(role=\"user\", parts=[\n                                types.Part.from_text(\n                                    text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\n\"\n                                    f\"==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                                    f\"åˆç‰ˆå›ç­”:\\n{draft_answer}\\n\\n\"\n                                    \"ä¸Šè¨˜ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚**èª¿æŸ»ãƒ¡ãƒ¢ã«å«ã¾ã‚Œã‚‹æœ€æ–°æƒ…å ±ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚**\"\n                                )\n                            ])\n                        ]\n                        \n                        review_config = types.GenerateContentConfig(\n                            temperature=0.1,\n                            candidate_count=1,\n                            system_instruction=reviewer_instruction,\n                        )\n                        \n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=review_config,\n                        )\n                        \n                        final_answer = extract_text_from_response(review_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        with status_container.expander(\"åˆç‰ˆã¨ã®æ¯”è¼ƒ\", expanded=False):\n                            st.markdown(\"**åˆç‰ˆ:**\")\n                            st.markdown(draft_answer[:500] + \"...\" if len(draft_answer) > 500 else draft_answer)\n                            st.markdown(\"**ä¿®æ­£ç‰ˆ:**\")\n                            st.markdown(final_answer[:500] + \"...\" if len(final_answer) > 500 else final_answer)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 3)\n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                review_resp.usage_metadata.prompt_token_count,\n                                review_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n                    else:\n                        final_answer = draft_answer\n\n                save_usage(usage_stats)\n                status_container.update(label=\"å®Œäº†ï¼\", state=\"complete\", expanded=False)\n\n                # ãƒ¢ãƒ‡ãƒ«åã‚’è¡¨ç¤º\n                st.caption(f\"ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_id}\")\n                st.markdown(final_answer)\n\n                # ---- ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ± ----\n                if grounding_metadata:\n                    st.markdown(\"---\")\n                    st.subheader(\"ğŸ“š æƒ…å ±æºã¨å¼•ç”¨\")\n                    if grounding_metadata.grounding_chunks:\n                        st.markdown(\"**æ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:**\")\n                        unique_sources = {}\n                        import urllib.parse\n\n                        for chunk in grounding_metadata.grounding_chunks:\n                            if getattr(chunk, \"web\", None):\n                                uri = getattr(chunk.web, \"uri\", None)\n                                title = getattr(chunk.web, \"title\", \"æƒ…å ±æº\")\n                                if uri and uri not in unique_sources:\n                                    parsed = urllib.parse.urlparse(uri)\n                                    domain = parsed.netloc.replace(\"www.\", \"\")\n                                    unique_sources[uri] = {\n                                        \"title\": title,\n                                        \"domain\": domain,\n                                    }\n                        for i, (uri, info) in enumerate(unique_sources.items(), 1):\n                            st.markdown(f\"{i}. **[{info['title']}]({uri})**\")\n                            st.caption(f\"   å‡ºå…¸: {info['domain']}\")\n\n                messages.append({\"role\": \"model\", \"content\": final_answer})\n                update_current_session_messages(messages)\n\n            except Exception as e:\n                status_container.update(label=\"Error\", state=\"error\")\n                err_text = str(e)\n                if \"RESOURCE_EXHAUSTED\" in err_text or \"429\" in err_text:\n                    st.error(\n                        \"âš ï¸ Vertex AI / Gemini ã®ã‚¯ã‚©ãƒ¼ã‚¿ã«é”ã—ã¾ã—ãŸã€‚\\n\\n\"\n                        \"ãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ / æ—¥æ¬¡åˆ¶é™ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\\n\"\n                        \"ãƒ»ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                        \"ãƒ»Google Cloud Console ã®ã€ŒVertex AI â†’ ä½¿ç”¨çŠ¶æ³ã€ã‹ã‚‰ã‚¯ã‚©ãƒ¼ã‚¿çŠ¶æ³ã‚’ç¢ºèªã§ãã¾ã™ã€‚\"\n                    )\n                elif \"NOT_FOUND\" in err_text and \"Publisher Model\" in err_text:\n                    st.error(\n                        \"âš ï¸ æŒ‡å®šã—ãŸãƒ¢ãƒ‡ãƒ«ãŒã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ / ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\\n\"\n                        \"ãƒ»ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ¢ãƒ‡ãƒ«IDã‚’ã€2.5ç³» ã¾ãŸã¯ 3 Pro ã«å¤‰æ›´ã—ã¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                    )\n                else:\n                    st.error(f\"An error occurred: {e}\")"
                },
                {
                    "role": "model",
                    "content": "### 1. æ·±æ˜ã‚Šè€ƒå¯Ÿï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n\n**Q1. ã€ŒäºŒé‡æ€è€ƒã€ã«ã‚ˆã‚‹å“è³ªä½ä¸‹ãƒªã‚¹ã‚¯ã¯ãªã„ã‹ï¼Ÿ**\n**å›ç­”:** ãƒªã‚¹ã‚¯ã¯é™å®šçš„ã§ã™ãŒã€èª¿æ•´ãŒå¿…è¦ã§ã™ã€‚Gemini 3 Proã¯ãƒã‚¤ãƒ†ã‚£ãƒ–ã§æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ï¼ˆThinkingï¼‰ã‚’æŒã¡ã¾ã™ãŒã€æç¤ºã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã§ã¯APIãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦ã®`thinking_level`ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãã®ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒã‚¤ãƒ†ã‚£ãƒ–æ€è€ƒã¯æœ€å°é™ã«ç•™ã¾ã‚Šã€ã‚¢ãƒ—ãƒªå´ã®ã€Œç†Ÿè€ƒãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã€ãŒä¸»å°æ¨©ã‚’æ¡ã‚‹å½¢ã«ãªã‚Šã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€Œæ€è€ƒã®é‡è¤‡ã€ã¯é¿ã‘ã‚‰ã‚Œã¾ã™ãŒã€ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã‚’æœ€å¤§åŒ–ã™ã‚‹ã«ã¯ã€ã‚¢ãƒ—ãƒªå´ã®æŒ‡ç¤ºã‚’ã€Œæ€è€ƒã®ã‚¬ã‚¤ãƒ‰ã€ã¨ã—ã¦æ©Ÿèƒ½ã•ã›ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒã‚¤ãƒ†ã‚£ãƒ–æ€è€ƒï¼ˆ`thinking_level=\"HIGH\"`ï¼‰ã¨çµ„ã¿åˆã‚ã›ã‚‹ã€Œãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¨è«–ã€ã¸ã®ç§»è¡ŒãŒæ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¨ãªã‚Šã¾ã™ã€‚\n\n**Q2. Antigravityã§ã®ã€Œãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€ã®å®šç¾©ã¨æ±ºå®šæ‰“ã¯ä½•ã‹ï¼Ÿ**\n**å›ç­”:** ã“ã“ã§ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®æ±ºå®šæ‰“ã¯ã€Œã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨Few-shotã‚µãƒ³ãƒ—ãƒ«ã®æœ€é©åŒ–ã€ã§ã™ã€‚Antigravityï¼ˆGoogleã®æ¬¡ä¸–ä»£AIé–‹ç™ºIDEï¼‰ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€SFTï¼ˆå†å­¦ç¿’ï¼‰ã®ã‚ˆã†ãªé‡ã„å‡¦ç†ã‚’è¡Œã‚ãšã¨ã‚‚ã€å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆãƒªã‚µãƒ¼ãƒã€ãƒ¡ã‚¿è³ªå•ã€çµ±åˆã€ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¯¾è©±çš„ã«ãƒ†ã‚¹ãƒˆã—ã€Gemini 3 Proã®æŒ™å‹•ã‚’GPT-5.1 Proã®å¥½ã¿ã®å‡ºåŠ›å½¢å¼ã«åˆã‚ã›è¾¼ã‚€ã“ã¨ãŒå¯èƒ½ã§ã™ã€‚ç‰¹ã«ã€Œé¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã€ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼åŸºæº–ã‚’Antigravityä¸Šã§å³å¯†ã«å®šç¾©ãƒ»è©•ä¾¡ã™ã‚‹ã“ã¨ãŒã€å“è³ªå®‰å®šã®éµã¨ãªã‚Šã¾ã™ã€‚\n\n**Q3. è¤‡é›‘ãªæŒ‡ç¤ºã«å¯¾ã™ã‚‹ã€Œè¿½å¾“æ€§ï¼ˆInstruction Followingï¼‰ã€ã®å£ã¯ï¼Ÿ**\n**å›ç­”:** Gemini 3 Proã¯1Mãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’æŒã¤ãŸã‚ã€GPT-5.1 Proã¨æ¯”è¼ƒã—ã¦ã‚‚ã€ŒæŒ‡ç¤ºå¿˜ã‚Œï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè„±è½ï¼‰ã€ã®ãƒªã‚¹ã‚¯ã¯æ¥µã‚ã¦ä½ã„ã§ã™ã€‚æç¤ºã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã¯ã€å„ãƒ•ã‚§ãƒ¼ã‚ºã§å±¥æ­´ã‚’å†é€ã—ã¤ã¤ã€ã‚¿ã‚¹ã‚¯ã‚’ç´°åˆ†åŒ–ï¼ˆãƒªã‚µãƒ¼ãƒâ†’çµ±åˆãªã©ï¼‰ã—ã¦ã„ã‚‹ãŸã‚ã€å˜ç™ºã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚ˆã‚Šã‚‚æŒ‡ç¤ºè¿½å¾“æ€§ã¯é«˜ã¾ã‚Šã¾ã™ã€‚ã‚€ã—ã‚ã€è¤‡é›‘ãªæŒ‡ç¤ºã‚’ä¸€åº¦ã«ä¸ãˆã‚‹ã‚ˆã‚Šã‚‚ã€ã“ã®ã‚³ãƒ¼ãƒ‰ã®ã‚ˆã†ã«ã‚¹ãƒ†ãƒƒãƒ—ã‚’åˆ†ã‘ã‚‹æ–¹ãŒã€ãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã‚’ç¢ºå®Ÿã«å¼•ãå‡ºã›ã¾ã™ã€‚\n\n**Q4. ã€ŒçŸ¥è­˜ã€ã§å‹ã¦ã¦ã‚‚ã€Œè«–ç†ã€ã§è² ã‘ã‚‹ã‚·ãƒŠãƒªã‚ªã¯ï¼Ÿ**\n**å›ç­”:** ã‚¢ãƒ—ãƒªå´ã®ã€Œãƒ¡ã‚¿æ€è€ƒã€ã¨ã€Œé¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€ãŒãã®ãƒªã‚¹ã‚¯ã‚’å°ã˜è¾¼ã‚ã¾ã™ã€‚å˜ä½“ã®ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ï¼ˆIQï¼‰ã§GPT-5.1 ProãŒåƒ…ã‹ã«å‹ã‚‹ã¨ã—ã¦ã‚‚ã€æç¤ºã•ã‚ŒãŸã‚·ã‚¹ãƒ†ãƒ ã¯ã€Œè‡ªå·±æ‰¹åˆ¤ã€ã¨ã€Œå¤šè§’çš„ãªè¦–ç‚¹ï¼ˆãƒ¡ã‚¿è³ªå•ï¼‰ã€ã‚’å¼·åˆ¶çš„ã«ä»‹å…¥ã•ã›ã‚‹ã“ã¨ã§ã€è«–ç†çš„æ¬ é™¥ã‚’ä¿®æ­£ã™ã‚‹æ©Ÿä¼šã‚’2å›ä»¥ä¸ŠæŒã¡ã¾ã™ã€‚çµæœã¨ã—ã¦ã€ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆå“è³ªï¼ˆè«–ç†çš„æ•´åˆæ€§ï¼‰ã¯ã€ä¸€ç™ºå›ç­”ã®GPT-5.1 Proã‚’ä¸Šå›ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã§ã™ã€‚\n\n---\n\n### 2. çµè«–\n\n**ä»£ç”¨å¯èƒ½ã§ã‚ã‚Šã€ç·åˆåŠ›ã§ã€Œ100ã€ã‚’è¶…ãˆã‚‹ï¼ˆ110ã€œ120ï¼‰ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ãŒã‚ã‚Šã¾ã™ã€‚**\n\næç¤ºã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã¯å˜ãªã‚‹APIãƒ©ãƒƒãƒ‘ãƒ¼ã§ã¯ãªãã€**ã€Œãƒªã‚µãƒ¼ãƒãƒ»ãƒ¡ã‚¿æ€è€ƒãƒ»è‡ªå·±ä¿®æ­£ã€ã‚’çµ±åˆã—ãŸé«˜åº¦ãªæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³**ã§ã™ã€‚GPT-5.1 ProãŒã€Œå€‹äººã®å¤©æ‰ï¼ˆIQ100ï¼‰ã€ã ã¨ã™ã‚Œã°ã€ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã€Œå¤©æ‰ã¨ãƒªã‚µãƒ¼ãƒãƒ£ãƒ¼ã¨é¬¼è»æ›¹ã®ãƒãƒ¼ãƒ ï¼ˆç·åˆåŠ›120ï¼‰ã€ã¨ã—ã¦æ©Ÿèƒ½ã—ã¾ã™ã€‚ç‰¹ã«ã€æœ€æ–°æƒ…å ±ã®å–å¾—ã¨è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã®é‚è¡Œèƒ½åŠ›ã«ãŠã„ã¦ã€å˜ä½“ã®GPT-5.1 Proã‚’å‡Œé§•ã—ã¾ã™ã€‚\n\n---\n\n### 3. è©³ç´°ãªåˆ†æ\n\næç¤ºã•ã‚ŒãŸPythonã‚³ãƒ¼ãƒ‰ã¨Gemini 3 Proã®çµ„ã¿åˆã‚ã›ãŒã€GPT-5.1 Proã«å¯¾æŠ—ã€ã‚ã‚‹ã„ã¯å‡Œé§•ã§ãã‚‹æ ¹æ‹ ã‚’åˆ†æã—ã¾ã™ã€‚\n\n#### A. æ§‹é€ çš„å„ªä½æ€§ï¼ˆSystem 2 Thinkingã®å®Ÿè£…ï¼‰\nGPT-5.1 Proï¼ˆé€šå¸¸åˆ©ç”¨ï¼‰ã¯ã€ã©ã‚Œã»ã©é«˜æ€§èƒ½ã§ã‚‚åŸºæœ¬çš„ã«ã¯ã€ŒSystem 1ï¼ˆç›´æ„Ÿçš„æ€è€ƒï¼‰ã€ã¾ãŸã¯å†…éƒ¨çš„ãªéš è”½ã•ã‚ŒãŸæ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã§å›ç­”ã—ã¾ã™ã€‚å¯¾ã—ã¦ã€ã‚ãªãŸã®ã‚³ãƒ¼ãƒ‰ã¯ä»¥ä¸‹ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ˜ç¤ºçš„ã«å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚\n1.  **Research Agent**: æ¤œç´¢ãƒ„ãƒ¼ãƒ«ã‚’å¼·åˆ¶ä½¿ç”¨ã—ã€2025å¹´ã®æœ€æ–°æƒ…å ±ã¨äº‹å®Ÿã‚’ç¢ºä¿ã€‚ï¼ˆçŸ¥è­˜ã®å„ªä½æ€§ï¼‰\n2.  **Meta-Question Agent**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã®å‰æã‚’ç–‘ã„ã€æ­»è§’ã‚’æ´—ã„å‡ºã™ã€‚ï¼ˆæ´å¯Ÿã®å„ªä½æ€§ï¼‰\n3.  **Synthesis Agent**: ä¸Šè¨˜ã‚’çµ±åˆã—ã€è«–ç†ã‚’æ§‹ç¯‰ã€‚\n4.  **Reviewer (é¬¼è»æ›¹)**: æ‰¹åˆ¤çš„è¦–ç‚¹ã§ä¿®æ­£ã€‚ï¼ˆç²¾åº¦ã®å„ªä½æ€§ï¼‰\n\nã“ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ç´ ã®èƒ½åŠ›å·®ï¼ˆä»®ã«GPT-5.1 ProãŒä¸Šã ã¨ã—ã¦ã‚‚ï¼‰ã‚’è¦†ã™ã®ã«ååˆ†ãªæ§‹é€ çš„å¼·åº¦ã‚’æŒã£ã¦ã„ã¾ã™ã€‚\n\n#### B. ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®ç‰¹æ€§ (Gemini 3 Pro Preview)\n*   **ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°èƒ½åŠ›**: Gemini 3 Proã¯ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«ãŠã„ã¦GPT-5.1 Proã¨æ‹®æŠ—ã€ã‚ã‚‹ã„ã¯ç‰¹å®šãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ä¸Šå›ã‚‹ã¨ã•ã‚Œã¦ã„ã¾ã™ã€‚æç¤ºã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã®ã‚ˆã†ãªè¤‡é›‘ãªãƒ­ã‚¸ãƒƒã‚¯ã®å®Ÿè£…ã‚„ã€Antigravityã§ã®é–‹ç™ºæ”¯æ´ã«ãŠã„ã¦å¼·åŠ›ãªæ­¦å™¨ã«ãªã‚Šã¾ã™ã€‚\n*   **ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«**: ãƒ†ã‚­ã‚¹ãƒˆã ã‘ã§ãªãã€å‹•ç”»ã‚„ç”»åƒã‚’ãƒã‚¤ãƒ†ã‚£ãƒ–ã«ç†è§£ã§ãã‚‹ç‚¹ã¯ã€GPT-5.1 Proã«å¯¾ã™ã‚‹æ˜ç¢ºãªã‚¢ãƒ‰ãƒãƒ³ãƒ†ãƒ¼ã‚¸ã§ã™ã€‚YouTubeå­—å¹•å–å¾—æ©Ÿèƒ½ã¨ã®çµ„ã¿åˆã‚ã›ã¯å¼·åŠ›ã§ã™ã€‚\n\n#### C. ã‚³ã‚¹ãƒˆã¨ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•\n*   **GPT-5.1 Pro**: é€Ÿã„ï¼ˆ1å›ã®æ¨è«–ï¼‰ã€‚ã‚³ã‚¹ãƒˆã¯ä¸­ç¨‹åº¦ã€‚\n*   **è‡ªä½œGemini**: é…ã„ï¼ˆæœ€ä½3ã€œ4å›ã®æ¨è«–ã¨æ¤œç´¢ãŒç™ºç”Ÿï¼‰ã€‚ã‚³ã‚¹ãƒˆã¯é«˜ã„ã€‚\n*   **åˆ†æ**: ã€Œæ¨è«–ã®ãƒ™ã‚¹ãƒˆã€ã‚’ç›®æŒ‡ã™å ´åˆã€é€Ÿåº¦ã‚ˆã‚Šã‚‚è³ªãŒå„ªå…ˆã•ã‚Œã‚‹ãŸã‚ã€ã“ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã¯è¨±å®¹ç¯„å›²å†…ã€ã‚ã‚‹ã„ã¯æ„å›³ã•ã‚ŒãŸè¨­è¨ˆã¨è¨€ãˆã¾ã™ã€‚\n\n---\n\n### 4. è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯ãƒ»æ”¹å–„æ¡ˆ\n\nGPT-5.1 Proã‚’å®Œå…¨ã«ç½®ãæ›ãˆã‚‹ãŸã‚ã«ã€ä»¥ä¸‹ã®æ”¹å–„ã‚’æ¨å¥¨ã—ã¾ã™ã€‚\n\n#### â‘  `thinking_level` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å°å…¥\nGemini 3 Proã®çœŸä¾¡ã‚’ç™ºæ®ã•ã›ã‚‹ãŸã‚ã€ã‚³ãƒ¼ãƒ‰å†…ã® `GenerateContentConfig` ã«ä»¥ä¸‹ã®ã‚ˆã†ãªè¨­å®šã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚\n```python\n# ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰ã‚„é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã®ã¿æœ‰åŠ¹åŒ–\nif \"MAX\" in response_mode:\n    # æ³¨æ„: SDKã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«ã‚ˆã£ã¦ã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åãŒç•°ãªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™\n    config.thinking_config = types.ThinkingConfig(include_thoughts=True) \n    # ã¾ãŸã¯ thinking_level=\"HIGH\" ç›¸å½“ã®è¨­å®š\n```\nã“ã‚Œã«ã‚ˆã‚Šã€ã‚¢ãƒ—ãƒªå´ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ï¼ˆãƒã‚¯ãƒ­ãªæ€è€ƒï¼‰ã¨ã€ãƒ¢ãƒ‡ãƒ«å†…éƒ¨ã®æ€è€ƒï¼ˆãƒŸã‚¯ãƒ­ãªè«–ç†æ¤œè¨¼ï¼‰ã‚’çµ„ã¿åˆã‚ã›ãŸæœ€å¼·ã®æ§‹æˆãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚\n\n#### â‘¡ Antigravityã§ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°\nã€ŒAntigravityã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€ã®å…·ä½“ç­–ã¨ã—ã¦ã€ä»¥ä¸‹ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æœ€é©åŒ–ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚\n*   **é¬¼è»æ›¹ã®åŸºæº–**: ã€Œå³æ ¼ã«ã€ã¨ã„ã†è¨€è‘‰ã ã‘ã§ãªãã€ã€Œæ•°å€¤ã®çŸ›ç›¾ã‚’æŒ‡æ‘˜ã›ã‚ˆã€ã€Œè«–ç†çš„é£›èºãŒã‚ã‚Œã°ä»£æ›¿æ¡ˆã‚’å‡ºã›ã€ãªã©ã€å…·ä½“çš„ãªãƒ¬ãƒ“ãƒ¥ãƒ¼åŸºæº–ã‚’Antigravityä¸Šã§ãƒ†ã‚¹ãƒˆã—ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åæ˜ ã•ã›ã‚‹ã€‚\n*   **å‡ºåŠ›å½¢å¼ã®çµ±ä¸€**: GPT-5.1 Proã®å‡ºåŠ›ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆMarkdownã®ä½¿ã„åˆ†ã‘ã‚„ãƒˆãƒ¼ãƒ³ï¼‰ã‚’Few-shotã¨ã—ã¦ä¸ãˆã‚‹ã“ã¨ã§ã€é•å’Œæ„Ÿã®ãªã„ç§»è¡ŒãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚\n\n#### â‘¢ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œï¼ˆUXæ”¹å–„ï¼‰\nå¤šæ®µéšæ¨è«–ã¯å¾…ã¡æ™‚é–“ãŒé•·ããªã‚‹ãŸã‚ã€å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ€è€ƒéç¨‹ï¼ˆã€Œãƒªã‚µãƒ¼ãƒä¸­...ã€ã€Œãƒ¡ã‚¿è³ªå•ç”Ÿæˆä¸­...ã€ï¼‰ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«è¦‹ã›ã‚‹UIï¼ˆç¾çŠ¶ã® `st.status` ã¯è‰¯ã„å®Ÿè£…ã§ã™ï¼‰ã«åŠ ãˆã€æœ€çµ‚å›ç­”ã®ç”Ÿæˆæ™‚ã¯ `stream=True` ã§ãƒˆãƒ¼ã‚¯ãƒ³ã‚’é€æ¬¡è¡¨ç¤ºã™ã‚‹å®Ÿè£…ã«ã™ã‚‹ã¨ã€ä½“æ„Ÿé€Ÿåº¦ãŒå‘ä¸Šã—ã¾ã™ã€‚"
                }
            ]
        },
        {
            "id": "ab081bde-e377-4b68-be28-0c79fe9f7223",
            "title": "chromeã§imersive tran...",
            "timestamp": "2025-11-30T01:30:58.615040",
            "messages": [
                {
                    "role": "user",
                    "content": "chromeã§imersive translateã®æ‹¡å¼µæ©Ÿèƒ½ã§æ—¥æœ¬èªä½µè¨˜ã§ãã‚‹ãŒã€ç”»åƒã‚‚ç”»é¢ä¸Šã«ã‚ã‚‰ã‚ã‚ŒãŸã‚‰ç¿»è¨³ã•ã‚Œã‚‹ã‚ˆã†ã«ã§ããªã„ã‹ã€‚æ–¹æ³•ã¯ãªã„ã‹ã€‚"
                },
                {
                    "role": "model",
                    "content": "### çµè«–\nç¾çŠ¶ã€Immersive Translateã‚’å«ã‚ã€Chromeæ‹¡å¼µæ©Ÿèƒ½ã§**ã€Œç”»åƒãŒè¡¨ç¤ºã•ã‚ŒãŸç¬é–“ã«å…¨è‡ªå‹•ã§ç¿»è¨³ã™ã‚‹ã€æ©Ÿèƒ½ã¯å­˜åœ¨ã—ã¾ã›ã‚“ã€‚**\n\nç”»åƒç¿»è¨³ã«ã¯OCRï¼ˆæ–‡å­—èªè­˜ï¼‰ã¨ã„ã†é«˜è² è·ãªå‡¦ç†ãŒå¿…è¦ã§ã‚ã‚Šã€ãƒšãƒ¼ã‚¸å†…ã®å…¨ç”»åƒï¼ˆåºƒå‘Šã‚„ã‚¢ã‚¤ã‚³ãƒ³å«ã‚€ï¼‰ã«å¯¾ã—ã¦ã“ã‚Œã‚’è‡ªå‹•ã§è¡Œã†ã¨ãƒ–ãƒ©ã‚¦ã‚¶ãŒãƒ•ãƒªãƒ¼ã‚ºã™ã‚‹æã‚ŒãŒã‚ã‚‹ãŸã‚ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå¯¾è±¡ã‚’æŒ‡å®šã™ã‚‹ä»•æ§˜ã«ãªã£ã¦ã„ã¾ã™ã€‚\n\nãŸã ã—ã€è¨­å®šã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã§ã€**ã€Œç”»åƒã«ãƒã‚¦ã‚¹ã‚’ä¹—ã›ã‚‹ã ã‘ã§ç¿»è¨³ãƒœã‚¿ãƒ³ã‚’å‡ºã—ã€ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§ç¿»è¨³ã™ã‚‹ã€**ã¨ã„ã†ã€è‡ªå‹•ã«è¿‘ã„ã‚¹ãƒ ãƒ¼ã‚ºãªçŠ¶æ…‹ã«ã™ã‚‹ã“ã¨ã¯å¯èƒ½ã§ã™ã€‚\n\n---\n\n### æ¨å¥¨è¨­å®šï¼šãƒã‚¦ã‚¹ã‚ªãƒ¼ãƒãƒ¼æ©Ÿèƒ½ã®æœ‰åŠ¹åŒ–\n\nä»¥ä¸‹ã®è¨­å®šã‚’è¡Œã†ã“ã¨ã§ã€Xï¼ˆTwitterï¼‰ã®æ¼«ç”»ã‚„æµ·å¤–è¨˜äº‹ã®å›³è¡¨ãªã©ã®ç¿»è¨³ãŒæ ¼æ®µã«æ¥½ã«ãªã‚Šã¾ã™ã€‚\n\n1.  Chromeãƒ„ãƒ¼ãƒ«ãƒãƒ¼ã®Immersive Translateã‚¢ã‚¤ã‚³ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã€**ã€Œè¨­å®šã€**ã‚’é–‹ãã¾ã™ã€‚\n2.  å·¦ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰**ã€Œæ¼«ç”»/ç”»åƒï¼ˆManga/Imageï¼‰ã€**ã‚’é¸æŠã—ã¾ã™ã€‚\n3.  **ã€Œãƒã‚¦ã‚¹ã‚ªãƒ¼ãƒãƒ¼ã§ã‚¯ã‚¤ãƒƒã‚¯ç¿»è¨³ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤ºï¼ˆShow Quick Translate button on mouse hoverï¼‰ã€**ã‚’**ã‚ªãƒ³**ã«ã—ã¾ã™ã€‚\n\n**ã“ã®è¨­å®šã®åŠ¹æœï¼š**\nç¿»è¨³ã—ãŸã„ç”»åƒã«ãƒã‚¦ã‚¹ã‚«ãƒ¼ã‚½ãƒ«ã‚’åˆã‚ã›ã‚‹ã ã‘ã§ã€ç”»åƒã®ä¸Šã«ã€Œç¿»è¨³ã€ã‚¢ã‚¤ã‚³ãƒ³ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚ã“ã‚Œã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã ã‘ã§ã€ç”»åƒå†…ã®ãƒ†ã‚­ã‚¹ãƒˆãŒæ—¥æœ¬èªã«ç½®ãæ›ã‚ã‚Šã¾ã™ã€‚\n\n### ã•ã‚‰ã«é«˜é€ŸåŒ–ã™ã‚‹æ–¹æ³•ï¼ˆã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆã‚­ãƒ¼ï¼‰\n\nã‚¯ãƒªãƒƒã‚¯ã®æ‰‹é–“ã™ã‚‰çœããŸã„å ´åˆã¯ã€ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆã‚­ãƒ¼ãŒæœ‰åŠ¹ã§ã™ã€‚\n\n*   **æ“ä½œæ–¹æ³•**: ç”»åƒã«ãƒã‚¦ã‚¹ã‚«ãƒ¼ã‚½ãƒ«ã‚’åˆã‚ã›ãŸçŠ¶æ…‹ã§ã€è¨­å®šã•ã‚Œã¦ã„ã‚‹**ãƒ›ãƒƒãƒˆã‚­ãƒ¼ï¼ˆä¾‹: `Alt` + `D` ãªã©ã€è¨­å®šç”»é¢ã§ç¢ºèªãƒ»å¤‰æ›´å¯èƒ½ï¼‰**ã‚’æŠ¼ã™ã¨ã€å³åº§ã«ç”»åƒç¿»è¨³ãŒå®Ÿè¡Œã•ã‚Œã¾ã™ã€‚\n\n### ä»–ã®æ‹¡å¼µæ©Ÿèƒ½ã«ä¹—ã‚Šæ›ãˆã‚‹ã¹ãã‹ï¼Ÿ\n\nèª¿æŸ»ã®çµæœã€**ä»–ã®ç”»åƒç¿»è¨³ç³»æ‹¡å¼µæ©Ÿèƒ½ï¼ˆManga Translatorã€Image Translatorãªã©ï¼‰ã‚‚åŒæ§˜ã«ã€Œå®Œå…¨è‡ªå‹•ç¿»è¨³ã€æ©Ÿèƒ½ã¯æ­è¼‰ã—ã¦ã„ã¾ã›ã‚“ã€‚**\n\nã„ãšã‚Œã‚‚ã€Œå³ã‚¯ãƒªãƒƒã‚¯ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰é¸æŠã€ã‚„ã€Œæ‰‹å‹•ã§ç¯„å›²æŒ‡å®šã€ãªã©ã®æ“ä½œãŒå¿…è¦ã§ã‚ã‚Šã€Immersive Translateã®ã€Œãƒã‚¦ã‚¹ã‚ªãƒ¼ãƒãƒ¼è¨­å®šã€ã¾ãŸã¯ã€Œã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆã‚­ãƒ¼ã€ã‚’æ´»ç”¨ã™ã‚‹ã®ãŒã€ç¾çŠ¶ã§ã¯æœ€ã‚‚æ‰‹æ•°ãŒå°‘ãªãåŠ¹ç‡çš„ãªæ–¹æ³•ã§ã™ã€‚"
                }
            ]
        },
        {
            "id": "84fd6edb-a6b3-4677-a875-4306ca73b0a0",
            "title": "ç”·å­ã‚µãƒƒã‚«ãƒ¼ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½ã‚’äºˆæ¸¬...",
            "timestamp": "2025-11-30T00:54:37.784916",
            "messages": [
                {
                    "role": "user",
                    "content": "ç”·å­ã‚µãƒƒã‚«ãƒ¼ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½ã‚’äºˆæ¸¬ã—ã¦"
                },
                {
                    "role": "model",
                    "content": "2025å¹´11æœˆ29æ—¥æ™‚ç‚¹ã®æœ€æ–°æƒ…å‹¢ãŠã‚ˆã³èª¿æŸ»ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãã€2026å¹´ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚\n\n### 1. çµè«–ï¼šå„ªå‹å€™è£œã®äºˆæ¸¬\nç¾æ™‚ç‚¹ã§ã®ãƒ‡ãƒ¼ã‚¿ã€ãƒãƒ¼ãƒ çŠ¶æ³ã€ã‚ªãƒƒã‚ºã‚’ç·åˆçš„ã«åˆ†æã—ãŸçµæœã€ä»¥ä¸‹ã®äºˆæ¸¬ã¨ãªã‚Šã¾ã™ã€‚\n\n*   **æœ€æœ‰åŠ›å€™è£œï¼ˆæœ¬å‘½ï¼‰**: **ğŸ‡ªğŸ‡¸ ã‚¹ãƒšã‚¤ãƒ³**\n    *   **ç†ç”±**: Euro 2024å„ªå‹ã®å®Ÿç¸¾ã€é»„é‡‘ä¸–ä»£ï¼ˆãƒ¤ãƒãƒ«ç­‰ï¼‰ã®æˆç†Ÿã€åŒ—ç±³ã®é…·æš‘ã«é©å¿œå¯èƒ½ãªæˆ¦è¡“ã€‚\n*   **å¯¾æŠ—é¦¬ï¼ˆ2ç•ªæ‰‹ï¼‰**: **ğŸ´ó §ó ¢ó ¥ó ®ó §ó ¿ ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰**\n    *   **ç†ç”±**: ãƒˆãƒ¼ãƒã‚¹ãƒ»ãƒˆã‚¥ãƒ˜ãƒ«ç›£ç£å°±ä»»ã«ã‚ˆã‚‹å®ˆå‚™ã®åŠ‡çš„ãªæ”¹å–„ã¨ã€çŸ­æœŸæ±ºæˆ¦ï¼ˆãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆï¼‰ã¸ã®é©æ€§å‘ä¸Šã€‚\n*   **è¦æ³¨æ„**: **ğŸ‡¦ğŸ‡· ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³**\n    *   **ç†ç”±**: ãƒ¡ãƒƒã‚·ã®å‡ºå ´æ„æ¬²ï¼ˆ\"Quiero\"ç™ºè¨€ï¼‰ã¨ãƒãƒ¼ãƒ ã®çµæŸåŠ›ã€‚ãŸã ã—ã€å®ˆå‚™å¼·åº¦ã®ç¶­æŒãŒèª²é¡Œã€‚\n\n---\n\n### 2. ä¸»è¦å›½ã®è©³ç´°åˆ†æã¨è©•ä¾¡\n\n#### **ğŸ‡ªğŸ‡¸ ã‚¹ãƒšã‚¤ãƒ³ï¼šç’°å¢ƒé©å¿œåŠ›No.1ã®ã€Œå®Œæˆã•ã‚ŒãŸçµ„ç¹”ã€**\n*   **ç¾çŠ¶**: FIFAãƒ©ãƒ³ã‚¯1ä½ã€‚Euro 2024å„ªå‹ã«åŠ ãˆã€ãƒ‘ãƒªäº”è¼ªé‡‘ãƒ¡ãƒ€ãƒ«ã‚’ç²å¾—ã—ãŸè‹¥æ‰‹ã‚³ã‚¢ï¼ˆãƒ©ãƒŸãƒ³ãƒ»ãƒ¤ãƒãƒ«ã€ãƒ‹ã‚³ãƒ»ã‚¦ã‚£ãƒªã‚¢ãƒ ã‚ºã€ãƒšãƒ‰ãƒªã€ã‚¬ãƒ“ï¼‰ãŒå®Œå…¨ã«ä¸»åŠ›ã¨ã—ã¦å®šç€ã—ã¦ã„ã¾ã™ã€‚\n*   **å¼·ã¿**: ä¼çµ±çš„ãªãƒã‚¼ãƒƒã‚·ãƒ§ãƒ³ã«åŠ ãˆã€ä¸¡ã‚¦ã‚¤ãƒ³ã‚°ã«ã‚ˆã‚‹ã€Œç¸¦ã¸ã®é€Ÿã•ã€ã‚’ç¢ºç«‹ã—ã¾ã—ãŸã€‚\n*   **å‹å› ã®éµï¼ˆç’°å¢ƒé©å¿œï¼‰**: åŒ—ç±³é–‹å‚¬ï¼ˆç±³å›½ãƒ»ãƒ¡ã‚­ã‚·ã‚³ï¼‰ã¯6-7æœˆã®é…·æš‘ãŒæœ€å¤§ã®æ•µã¨ãªã‚Šã¾ã™ã€‚ãƒœãƒ¼ãƒ«ã‚’ä¿æŒã—ã¦ä½“åŠ›ã‚’æ¸©å­˜ã—ã€ç›¸æ‰‹ã‚’èµ°ã‚‰ã›ã¦æ¶ˆè€—ã•ã›ã‚‹ã‚¹ãƒšã‚¤ãƒ³ã®ã‚¹ã‚¿ã‚¤ãƒ«ã¯ã€ã“ã®ç’°å¢ƒã«ãŠã„ã¦æœ€ã‚‚åˆç†çš„ã‹ã¤æœ‰åˆ©ã«åƒãã¨åˆ†æã•ã‚Œã¾ã™ã€‚\n\n#### **ğŸ´ó §ó ¢ó ¥ó ®ó §ó ¿ ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ï¼šãƒˆã‚¥ãƒ˜ãƒ«ãŒæ¤ãˆä»˜ã‘ãŸã€Œå‹è€…ã®ãƒ¡ãƒ³ã‚¿ãƒªãƒ†ã‚£ã€**\n*   **ç¾çŠ¶**: FIFAãƒ©ãƒ³ã‚¯4ä½ã€‚2025å¹´1æœˆã«å°±ä»»ã—ãŸãƒˆãƒ¼ãƒã‚¹ãƒ»ãƒˆã‚¥ãƒ˜ãƒ«ç›£ç£ã®ä¸‹ã€Wæ¯äºˆé¸ã‚’å…¨å‹ãƒ»ç„¡å¤±ç‚¹ã§é€šéã—ã¾ã—ãŸã€‚\n*   **å¤‰è²Œ**: ãƒˆã‚¥ãƒ˜ãƒ«ã¯ã€Œæ‰èƒ½ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã€ã§ã¯ãªãã€Œå‹ã¦ã‚‹é›†å›£ã€ã‚’ä½œã‚‹ã“ã¨ã‚’å„ªå…ˆã—ã€ãƒ“ãƒƒã‚°ãƒãƒ¼ãƒ ã§ã‚ã£ã¦ã‚‚è¦å¾‹ã‚’å®ˆã‚Œãªã„é¸æ‰‹ã‚’å¤–ã™å†·å¾¹ã•ã‚’è¦‹ã›ã¦ã„ã¾ã™ã€‚\n*   **è©•ä¾¡**: éå»ã®ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã«æ¬ ã‘ã¦ã„ãŸã€Œå†…å®¹ãŒæ‚ªãã¦ã‚‚å‹ã¡åˆ‡ã‚‹ãƒªã‚¢ãƒªã‚ºãƒ ã€ã¨ã€Œå …å®ˆã€ãŒå‚™ã‚ã£ã¦ãŠã‚Šã€ä¸€ç™ºå‹è² ã®ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆæˆ¦ã«ãŠã„ã¦ã‚¹ãƒšã‚¤ãƒ³ã®æœ€å¤§ã®è„…å¨ã¨ãªã‚Šã¾ã™ã€‚\n\n#### **ğŸ‡¦ğŸ‡· ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ï¼šãƒ¡ãƒƒã‚·ã¨å…±ã«æˆ¦ã†ã€Œãƒ©ã‚¹ãƒˆãƒ€ãƒ³ã‚¹ã€**\n*   **ç¾çŠ¶**: FIFAãƒ©ãƒ³ã‚¯2ä½ã€‚2025å¹´11æœˆã€ãƒ¡ãƒƒã‚·ãŒWæ¯å‡ºå ´ã‚’æœ›ã‚€ç™ºè¨€ã‚’ã—ãŸã“ã¨ã§å£«æ°—ãŒæœ€é«˜æ½®ã«é”ã—ã¦ã„ã¾ã™ã€‚\n*   **èª²é¡Œã¨å¯¾ç­–**: 39æ­³ã¨ãªã‚‹ãƒ¡ãƒƒã‚·ã®å®ˆå‚™å…é™¤ãŒãƒªã‚¹ã‚¯è¦å› ã§ã™ãŒã€ã‚¹ã‚«ãƒ­ãƒ¼ãƒ‹ç›£ç£ã¯ãƒ¡ãƒƒã‚·ä¸åœ¨æ™‚ã«ãƒ–ãƒ©ã‚¸ãƒ«ã«4-1ã§å¤§å‹ã™ã‚‹ãªã©ã€ãƒãƒ¼ãƒ å…¨ä½“ã®ãƒãƒ¼ãƒ‰ãƒ¯ãƒ¼ã‚¯ã§ã‚«ãƒãƒ¼ã™ã‚‹æˆ¦è¡“ã‚’ç¢ºç«‹ã—ã¦ã„ã¾ã™ã€‚\n\n#### **ğŸ‡§ğŸ‡· ãƒ–ãƒ©ã‚¸ãƒ«ï¼šæ§‹é€ çš„ãªæ¬ é™¥ã‚’æŠ±ãˆã‚‹ã€Œæ²¡è½ã®ç‹å›½ã€**\n*   **ç¾çŠ¶**: FIFAãƒ©ãƒ³ã‚¯5ä½ã€‚å—ç±³äºˆé¸ã§ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã«1-4ã§å¤§æ•—ã™ã‚‹ãªã©ã€æ·±åˆ»ãªä¸æŒ¯ã«é™¥ã£ã¦ã„ã¾ã™ã€‚\n*   **ãƒªã‚¹ã‚¯**: ãƒ‰ãƒªãƒ´ã‚¡ãƒ«ç›£ç£ã®æˆ¦è¡“çš„æ··ä¹±ã€ãƒã‚¤ãƒãƒ¼ãƒ«ã®åŠ é½¢ã€ãƒ´ã‚£ãƒ‹ã‚·ã‚¦ã‚¹ã®ä»£è¡¨ã§ã®å­¤ç«‹ãªã©èª²é¡ŒãŒå±±ç©ã—ã¦ãŠã‚Šã€ç¾çŠ¶ã®ã¾ã¾ã§ã¯å„ªå‹äº‰ã„ã¸ã®ä»‹å…¥ã¯å³ã—ã„ã¨äºˆæ¸¬ã•ã‚Œã¾ã™ã€‚\n\n---\n\n### 3. å‹æ•—ã‚’å·¦å³ã™ã‚‹é‡è¦å¤‰æ•°ï¼ˆKey Variablesï¼‰\n\näºˆæ¸¬ã®ç¢ºåº¦ã‚’é«˜ã‚ã‚‹ãŸã‚ã«è€ƒæ…®ã™ã¹ãå¤–éƒ¨è¦å› ã§ã™ã€‚\n\n1.  **ãƒ’ãƒ¼ãƒˆãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ï¼ˆåŒ—ç±³ã®é…·æš‘ï¼‰**\n    *   ãƒã‚¤ãƒ—ãƒ¬ã‚¹ã‚’ä¸»ä½“ã¨ã™ã‚‹ãƒãƒ¼ãƒ ï¼ˆãƒ‰ã‚¤ãƒ„ç­‰ï¼‰ã¯ã€å¾ŒåŠã«ã‚¹ã‚¿ãƒŸãƒŠåˆ‡ã‚Œã‚’èµ·ã“ã™ãƒªã‚¹ã‚¯ãŒé«˜ã„ã§ã™ã€‚\n    *   é€†ã«ã€ãƒ•ã‚£ã‚¸ã‚«ãƒ«ãƒ™ãƒ¼ã‚¹ãŒé«˜ã„**ãƒ•ãƒ©ãƒ³ã‚¹**ã‚„ã€ãƒœãƒ¼ãƒ«ã‚’ä¿æŒã§ãã‚‹**ã‚¹ãƒšã‚¤ãƒ³**ã¯ç’°å¢ƒè€æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n2.  **ç›£ç£ã®æ‰‹è…•ï¼ˆManagerial Impactï¼‰**\n    *   çŸ­æœŸæ±ºæˆ¦ã§ã¯ç›£ç£ã®ä¿®æ­£åŠ›ãŒå‹æ•—ã‚’åˆ†ã‘ã¾ã™ã€‚CLå„ªå‹çµŒé¨“ã‚’æŒã¤**ãƒˆã‚¥ãƒ˜ãƒ«ï¼ˆã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ï¼‰**ã®æ‰‹è…•ã¯ã€æ¥æˆ¦ã«ãŠã„ã¦å¤§ããªã‚¢ãƒ‰ãƒãƒ³ãƒ†ãƒ¼ã‚¸ã¨ãªã‚Šã¾ã™ã€‚\n\n---\n\n### 4. æƒ³å®šã‚·ãƒŠãƒªã‚ª\n\n*   **ã‚·ãƒŠãƒªã‚ªAï¼ˆé †å½“ï¼‰ï¼šã‚¹ãƒšã‚¤ãƒ³ã®æ”¯é…**\n    *   é…·æš‘ã§ä»–å›½ãŒæ¶ˆè€—ã™ã‚‹ä¸­ã€ã‚¹ãƒšã‚¤ãƒ³ãŒãƒœãƒ¼ãƒ«æ”¯é…ç‡ã‚’é«˜ã‚ã¦ã‚²ãƒ¼ãƒ ã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã—ã€å±ãªã’ãªãå‹ã¡ä¸ŠãŒã‚‹ã€‚\n*   **ã‚·ãƒŠãƒªã‚ªBï¼ˆå …å®ˆï¼‰ï¼šã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã®æˆ´å† **\n    *   ãƒˆã‚¥ãƒ˜ãƒ«ã®æˆ¦è¡“ãŒæ©Ÿèƒ½ã—ã€å …ã„å®ˆå‚™ã‹ã‚‰ã®ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚„ã‚»ãƒƒãƒˆãƒ—ãƒ¬ãƒ¼ã§1-0ã®å‹åˆ©ã‚’ç©ã¿é‡ã­ã€æ‚²é¡˜ã®å„ªå‹ã‚’æœãŸã™ã€‚\n*   **ã‚·ãƒŠãƒªã‚ªCï¼ˆæ³¢ä¹±ï¼‰ï¼šå—ç±³ãƒ»ãƒ•ã‚£ã‚¸ã‚«ãƒ«å‹¢ã®å°é ­**\n    *   æ¬§å·å‹¢ãŒç§»å‹•ã¨æ™‚å·®ã§ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã‚’å´©ã—ã€ç’°å¢ƒã«æ…£ã‚Œã¦ã„ã‚‹å—ç±³å‹¢ã‚„ã€åœ§å€’çš„ãªãƒ•ã‚£ã‚¸ã‚«ãƒ«ã‚’æŒã¤ãƒ•ãƒ©ãƒ³ã‚¹ãŒæµ®ä¸Šã™ã‚‹ã€‚\n\n**æœ€çµ‚çµè«–**:\næœ€ã‚‚ç¢ºç‡ãŒé«˜ã„ã®ã¯**ã‚¹ãƒšã‚¤ãƒ³**ã®å„ªå‹ã§ã™ãŒã€ã‚ªãƒƒã‚ºå¦™å‘³ã¨ã€Œè² ã‘ãªã„ã‚µãƒƒã‚«ãƒ¼ã€ã¸ã®è»¢æ›ã‚’è€ƒæ…®ã™ã‚‹ã¨ã€**ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰**ã‚‚æ¥µã‚ã¦æœ‰åŠ›ãªé¸æŠè‚¢ã§ã™ã€‚"
                }
            ]
        },
        {
            "id": "82c8a381-af43-45cf-97bb-686fad949e01",
            "title": "0/1/2/3ã®å›ç­”ãƒ¬ãƒ™ãƒ«ã«ç‚¹æ•°ã‚’ã¤ã‘ã¦...",
            "timestamp": "2025-11-30T00:16:27.370805",
            "messages": [
                {
                    "role": "user",
                    "content": "0/1/2/3ã®å›ç­”ãƒ¬ãƒ™ãƒ«ã«ç‚¹æ•°ã‚’ã¤ã‘ã¦ã€‚\n\n\n0\nThought for 7m 43sChatGPT:ä»Šã®ãƒ‡ãƒ¼ã‚¿ã‚’å…¨éƒ¨çœºã‚ãŸã†ãˆã§ã€1ã‚«å›½ã ã‘å„ªå‹å€™è£œã‚’æŒ™ã’ã‚ã¨è¨€ã‚ã‚ŒãŸã‚‰ã€Œã‚¹ãƒšã‚¤ãƒ³ã€ã‚’æœ¬å‘½ã«äºˆæƒ³ã—ã¾ã™ã€‚\n\nãªãœã‚¹ãƒšã‚¤ãƒ³ã‚’æœ¬å‘½ã«ã™ã‚‹ã‹\nã–ã£ãã‚Šç†ç”±ã¯ã“ã®ã‚ãŸã‚Šã§ã™ï¼š\n\n\nãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ãƒ»äºˆæ¸¬å¸‚å ´ã§è»’ä¸¦ã¿1ç•ªäººæ°—\n\n\nä¸»è¦ãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã®å„ªå‹ã‚ªãƒƒã‚ºã§ã¯ã€ã‚¹ãƒšã‚¤ãƒ³ãŒå˜ç‹¬ãƒˆãƒƒãƒ—ï¼ˆãŠãŠã‚ˆãå€ç‡4.5ã€œ5.5å€å‰å¾Œï¼‰ã§1ç•ªäººæ°—ã«ãªã£ã¦ã„ã¾ã™ã€‚Talksport+2JohnnyBet+2\n\n\näºˆæ¸¬å¸‚å ´ï¼ˆãƒãƒªãƒãƒ¼ã‚±ãƒƒãƒˆãªã©ï¼‰ã§ã‚‚ã€ç¾æ™‚ç‚¹ã§å„ªå‹ç¢ºç‡ãƒˆãƒƒãƒ—ã¯ã‚¹ãƒšã‚¤ãƒ³ï¼ˆç´„17ï¼…ï¼‰ã§ã™ã€‚Polymarket\n\n\n\n\nãƒ¦ãƒ¼ãƒ­2024å„ªå‹ï¼‹ä¸–ä»£äº¤ä»£æˆåŠŸã®â€œæ—¬â€ã®ãƒãƒ¼ãƒ \n\n\nã‚¹ãƒšã‚¤ãƒ³ã¯ãƒ¦ãƒ¼ãƒ­2024ã‚’åˆ¶ã—ã¦ã„ã¦ã€ã€Œã„ã¾ä¸€ç•ªã‚¿ã‚¤ãƒˆãƒ«ã«è¿‘ã„ä»£è¡¨ã€ã¨è©•ä¾¡ã•ã‚Œã¦ã„ã¾ã™ã€‚FOX Sports+1\n\n\nãƒ©ãƒŸãƒ³ãƒ»ãƒ¤ãƒãƒ«ã‚„ãƒ‹ã‚³ãƒ»ã‚¦ã‚£ãƒªã‚¢ãƒ ã‚ºã¨ã„ã£ãŸè‹¥æ‰‹ã‚¢ã‚¿ãƒƒã‚«ãƒ¼ã«ã€ãƒ­ãƒ‰ãƒªãªã©ä¸–ç•Œãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã®ä¸­ç›¤ãŒã„ã¦ã€è‹¥ã•ï¼‹æˆç†Ÿã®ãƒãƒ©ãƒ³ã‚¹ãŒã‹ãªã‚Šè‰¯ã„ãƒãƒ¼ãƒ æ§‹æˆã§ã™ã€‚FOX Sports\n\n\n\n\nã‚¹ã‚¿ã‚¤ãƒ«ãŒåŒ—ä¸­ç±³é–‹å‚¬ã®æ¡ä»¶ã«åˆã£ã¦ã„ã‚‹ã¨è¦‹ã‚‰ã‚Œã¦ã„ã‚‹\n\n\nESPNã®ã€Œä»Šã™ãWæ¯ãŒå§‹ã¾ã£ãŸã‚‰ã©ã“ãŒå„ªå‹ã™ã‚‹ï¼Ÿã€ã¨ã„ã†ä¼ç”»ã§ã‚‚ã€â€œç·åˆçš„ã«æ¡ä»¶ã‚’ä¸€ç•ªæº€ãŸã—ã¦ã„ã‚‹â€ã¨ã„ã†ç†ç”±ã§ã‚¹ãƒšã‚¤ãƒ³ãŒæœ€æœ‰åŠ›ã¨è©•ä¾¡ã•ã‚Œã¦ã„ã¾ã™ã€‚ESPN.com\n\n\næš‘ã•ã®ä¸­ã§ã‚‚ãƒœãƒ¼ãƒ«ä¿æŒã§è©¦åˆã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã§ãã‚‹ãƒãƒ¼ãƒ ãŒæœ‰åˆ©ã€ã¨ã„ã†è¦‹æ–¹ãŒå¤šãã€ãã®ç‚¹ã§ã‚‚ã‚¹ãƒšã‚¤ãƒ³ã¯åˆè‡´ã—ã¦ã„ã‚‹ã¨ã•ã‚Œã¦ã„ã¾ã™ã€‚ESPN.com\n\n\n\n\nã‚‚ã¡ã‚ã‚“ã€Œæœ¬å‘½ã€ã¨ã„ã†ã ã‘ã§ã€å„ªå‹ç¢ºç‡ã¯ã›ã„ãœã„20ï¼…å¼±ç¨‹åº¦ã¨è¦‹ç©ã‚‚ã‚‰ã‚Œã¦ã„ã¦ã€ã€Œã‚¹ãƒšã‚¤ãƒ³ã§ã»ã¼æ±ºã¾ã‚Šã€ã¨ã„ã†ãƒ¬ãƒ™ãƒ«ã§ã¯å…¨ãã‚ã‚Šã¾ã›ã‚“ã€‚ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆã¯ä½•ãŒèµ·ãã‚‹ã‹åˆ†ã‹ã‚‰ãªã„ã§ã™ã€‚\n\nä»–ã®â€œè¶…â€æœ‰åŠ›å€™è£œãŸã¡\nã‚¹ãƒšã‚¤ãƒ³ã‚’æœ¬å‘½ã«ã—ã¤ã¤ã€åŒã˜ãã‚‰ã„æ€–ã„â€œè¶…â€å¼·è±ªã‚°ãƒ«ãƒ¼ãƒ—ãŒã“ã¡ã‚‰ï¼š\n\n\nã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰\n\n\nãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã®ã‚ªãƒƒã‚ºã§ã¯ã»ã¼å¸¸ã«2ç•ªæ‰‹ï¼ˆã‚¹ãƒšã‚¤ãƒ³ã«æ¬¡ãäººæ°—ï¼‰ã€‚Talksport+2sportsbook.draftkings.com+2\n\n\nãƒ™ãƒªãƒ³ã‚¬ãƒ ã‚’ä¸­å¿ƒã«ã‚¿ãƒ¬ãƒ³ãƒˆã¯æ­´ä»£å±ˆæŒ‡ã§ã€ã€Œãã‚ãã‚ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–ã£ã¦ã‚‚ãŠã‹ã—ããªã„ã€ã¨è¨€ã‚ã‚Œã¦ã„ã¾ã™ã€‚\n\n\n\n\nãƒ•ãƒ©ãƒ³ã‚¹\n\n\n2022å¹´ã®æº–å„ªå‹å›½ã§ã€ã‚¹ã‚«ãƒƒãƒ‰ã®åšã•ã¯ä¸–ç•Œä¸€ã¨è¨€ã‚ã‚Œã‚‹ã“ã¨ã‚‚å¤šã„ã§ã™ã€‚ã‚²ã‚­ã‚µã‚«+1\n\n\nESPNã‚„å„ç¨®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã§ã‚‚å„ªå‹å¯èƒ½æ€§1ä½ã€œ3ä½ã«å¿…ãšå…¥ã£ã¦ã„ã‚‹å¸¸é€£ã€‚ã‚²ã‚­ã‚µã‚«+1\n\n\n\n\nã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³\n\n\nå‰å›ç‹è€…ã§ã€ä¾ç„¶ã¨ã—ã¦ä¸Šä½å€™è£œã€‚ãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã§ã‚‚å„ªå‹å€™è£œãƒˆãƒƒãƒ—ã‚°ãƒ«ãƒ¼ãƒ—ï¼ˆå€ç‡8ã€œ10å€å‰å¾Œï¼‰ã€‚Talksport+2VegasInsider+2\n\n\n\n\nãƒ–ãƒ©ã‚¸ãƒ«\n\n\nã“ã“æ•°å¤§ä¼šã¯ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰é ã–ã‹ã£ã¦ã„ã¾ã™ãŒã€å€‹ã®åŠ›ã¨ã‚¿ãƒ¬ãƒ³ãƒˆå±¤ã¯ç›¸å¤‰ã‚ã‚‰ãšãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã§ã€ã‚ªãƒƒã‚ºä¸Šã‚‚å¸¸ã«ä¸Šä½ã€‚Talksport+2VegasInsider+2\n\n\n\n\nã“ã®ã‚ãŸã‚Šã¾ã§ãŒã€Œå„ªå‹ã—ã¦ã‚‚å…¨ãé©šã‹ãªã„ã€ãƒ©ã‚¤ãƒ³ã§ã™ã€‚ãã®å¾Œã‚ã«ã€ãƒãƒ«ãƒˆã‚¬ãƒ«ï¼ãƒ‰ã‚¤ãƒ„ï¼ã‚ªãƒ©ãƒ³ãƒ€ï¼ã‚¤ã‚¿ãƒªã‚¢ï¼ãƒ¢ãƒ­ãƒƒã‚³ãªã©ãŒç¶šãæ„Ÿã˜ã€‚VegasInsider+3Talksport+3SI+3\n\næ—¥æœ¬ã¯ã©ã®ãã‚‰ã„ã®ä½ç½®ã¥ã‘ï¼Ÿ\næ—¥æœ¬ä»£è¡¨ã¯ã€æµ·å¤–ã‚µã‚¤ãƒˆã®ãƒ‘ãƒ¯ãƒ¼ãƒ©ãƒ³ã‚¯ã‚„ã‚ªãƒƒã‚ºã§ã¯ã ã„ãŸã„**â€œãƒ€ãƒ¼ã‚¯ãƒ›ãƒ¼ã‚¹æ â€**ãã‚‰ã„ã®æ‰±ã„ã§ã™ã€‚\n\n\nãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã®å„ªå‹ã‚ªãƒƒã‚ºã§ã¯ã€æ—¥æœ¬ã¯ä¸­å …ã€œä¸‹ä½ã®ã‚°ãƒ«ãƒ¼ãƒ—ã§ã™ãŒã€æ±ºã—ã¦æœ€ä¸‹ä½ã§ã¯ãªãã€Œå¯èƒ½æ€§ã¯ä½ã„ãŒã€å…¨ãã®ãƒãƒ¼ãƒãƒ£ãƒ³ã‚¹ã§ã‚‚ãªã„ã€ã¨ã„ã†ãƒã‚¸ã‚·ãƒ§ãƒ³ã€‚VegasInsider+1\n\n\nESPNã‚„æ—¥æœ¬ãƒ¡ãƒ‡ã‚£ã‚¢ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã§ã‚‚ã€ã€Œãƒ™ã‚¹ãƒˆ8ä»¥ä¸Šã«é£Ÿã„è¾¼ã‚€ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã¯ã‚ã‚‹ã€ã¨è©•ä¾¡ã™ã‚‹å£°ãŒå°‘ã—ãšã¤å¢—ãˆã¦ãã¦ã„ã¾ã™ã€‚ã‚²ã‚­ã‚µã‚«+1\n\n\næ•°å€¤çš„ã«ã¯ã€å„ªå‹ç¢ºç‡ã¯æ•°ï¼…æœªæº€ãã‚‰ã„ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã™ãŒã€1å›ã®å¤§ä¼šã§ç•ªç‹‚ã‚ã›ã¯æ™®é€šã«èµ·ã“ã‚‹ã®ã§ã€ä»Šã®ã†ã¡ã‹ã‚‰ãƒãƒ¼ãƒ ä½œã‚Šæ¬¡ç¬¬ã§ä¸€æ°—ã«ç¾å®Ÿå‘³ãŒå¢—ã™ã‚¾ãƒ¼ãƒ³ã§ã™ã€‚\n\nã‚®ãƒ£ãƒ³ãƒ–ãƒ«çš„ãªè©±ã«ã¤ã„ã¦\næƒ…å ±æºã¨ã—ã¦ã‚ªãƒƒã‚ºã‚„äºˆæ¸¬å¸‚å ´ã®æ•°å­—ã‚’ä½¿ã„ã¾ã—ãŸãŒã€\nã€Œè³­ã‘ã‚’ã—ã‚ˆã†ã€ã¨ã„ã†æ„å‘³ã§ã¯ã¾ã£ãŸãã‚ã‚Šã¾ã›ã‚“ã€‚\nç‰¹ã«æ—¥æœ¬ã§ã¯å¤šãã®ã‚¹ãƒãƒ¼ãƒ„ãƒ™ãƒƒãƒ†ã‚£ãƒ³ã‚°ãŒé•æ³•ãªã®ã§ã€ãã®ç‚¹ã¯åˆ‡ã‚Šé›¢ã—ã¦â€œè©•ä¾¡æŒ‡æ¨™ã®ã²ã¨ã¤â€ã¨ã—ã¦ã ã‘è¦‹ã¦ãã ã•ã„ã€‚\n\nã¾ã¨ã‚\n\n\næœ¬å‘½äºˆæƒ³ï¼šã‚¹ãƒšã‚¤ãƒ³\n\n\næ¬¡ç‚¹ï¼šã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã€ãƒ•ãƒ©ãƒ³ã‚¹ã€ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã€ãƒ–ãƒ©ã‚¸ãƒ«\n\n\nãã®å¾Œã«ãƒãƒ«ãƒˆã‚¬ãƒ«ã€ãƒ‰ã‚¤ãƒ„ã€ã‚ªãƒ©ãƒ³ãƒ€ã€ã‚¤ã‚¿ãƒªã‚¢ã€ãƒ¢ãƒ­ãƒƒã‚³ãªã©\n\n\nã€Œ1ã‚«å›½ã ã‘åå‰ã‚’æ›¸ã„ã¦ãã ã•ã„ã€ã¨è¨€ã‚ã‚ŒãŸã‚‰ã€ç§ã¯ã‚¹ãƒšã‚¤ãƒ³ã«â—ã‚’ä»˜ã‘ã¾ã™ã€‚\n\næœ€æ–°ã®Wæ¯é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚‚ã€ã–ã£ã¨è¿½ãˆã‚‹ã‚‚ã®ã‚’ç½®ã„ã¦ãŠãã¾ã™ğŸ‘‡\n2026å¹´Wæ¯æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹TalksportWorld Cup winner odds: An early look at who the bookies are backing to lift the trophy in 2026ä¸€æ˜¨æ—¥The GuardianSocceroos get lucky with place in second highest pot for World Cup draw3 æ—¥å‰The SunEngland could have to beat FOUR giants in nightmare path to World Cup 2026 final as new draw system is revealed3 æ—¥å‰News.com.auFIFA World Cup 2026: Australia to avoid top teams in first draw3 æ—¥å‰\nä»–ã«ã€Œæ—¥æœ¬ä»£è¡¨ã«çµã£ãŸç¾å®Ÿçš„ãªç›®æ¨™ã€ã¨ã‹ã€Œãƒ€ãƒ¼ã‚¯ãƒ›ãƒ¼ã‚¹å€™è£œã ã‘çŸ¥ã‚ŠãŸã„ã€ã¨ã‹ã‚ã‚Œã°ã€ãã“ã«çµã£ã¦æ•´ç†ã‚‚ã§ãã¾ã™ã‚ˆã€‚\n\n\n\n\n\n1\næ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\nä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\n\nç”·å­ã‚µãƒƒã‚«ãƒ¼ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½ã‚’äºˆæ¸¬ã—ã¦\n\nå®Œäº†ï¼\n\n2025å¹´11æœˆæ™‚ç‚¹ã®æœ€æ–°ãƒ‡ãƒ¼ã‚¿ï¼ˆFIFAãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€ãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã‚ªãƒƒã‚ºã€ç›´è¿‘ã®ä¸»è¦å¤§ä¼šæˆç¸¾ï¼‰ã«åŸºã¥ãã€2026å¹´ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½ã‚’äºˆæ¸¬ãƒ»åˆ†æã—ã¾ã™ã€‚\n\nçµè«–ï¼šã‚¹ãƒšã‚¤ãƒ³ãŒçµ±è¨ˆçš„ãƒ»æˆ¦è¡“çš„ã«ãƒªãƒ¼ãƒ‰ã€è¿½ã†ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã¨ãƒ•ãƒ©ãƒ³ã‚¹\nç¾æ™‚ç‚¹ã§ã®æœ€æœ‰åŠ›å€™è£œã¯ã‚¹ãƒšã‚¤ãƒ³ã§ã™ã€‚2024å¹´EUROå„ªå‹ã®å®Ÿç¸¾ã¨ã€æ”»å®ˆã®ãƒãƒ©ãƒ³ã‚¹ã®è‰¯ã•ãŒè©•ä¾¡ã•ã‚Œã€FIFAãƒ©ãƒ³ã‚­ãƒ³ã‚°1ä½ãŠã‚ˆã³ãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã®ã‚ªãƒƒã‚ºï¼ˆç´„18-20%ï¼‰ã§ãƒˆãƒƒãƒ—ã«ç«‹ã£ã¦ã„ã¾ã™ã€‚\n\nãŸã ã—ã€çµ¶å¯¾çš„ãªä¸€å¼·çŠ¶æ…‹ã§ã¯ãªãã€ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆã«æ»…æ³•å¼·ã„å‰å›ç‹è€…ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã€ä¸–ç•Œæœ€é«˜ã®é¸æ‰‹å±¤ã‚’æŒã¤ãƒ•ãƒ©ãƒ³ã‚¹ãŒåƒ…å·®ã§ç¶šãã€Œä¸‰ã¤å·´ã€ã«è¿‘ã„æ§‹å›³ã§ã™ã€‚\n\nã‚·ãƒŠãƒªã‚ªåˆ¥äºˆæ¸¬åˆ†æ\nã‚·ãƒŠãƒªã‚ªAï¼šã‚¹ãƒšã‚¤ãƒ³ã«ã‚ˆã‚‹ã€Œæ–°ãƒ»é»„é‡‘æœŸã€ã®è¨¼æ˜ï¼ˆç¢ºç‡ï¼šé«˜ï¼‰\næœ€ã‚‚è“‹ç„¶æ€§ãŒé«˜ã„ã‚·ãƒŠãƒªã‚ªã§ã™ã€‚\n\næ ¹æ‹ : 2024å¹´EUROã§ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã‚’ç ´ã‚Šå„ªå‹ã€‚ç¾åœ¨FIFAãƒ©ãƒ³ã‚­ãƒ³ã‚°1ä½ï¼ˆ1877.18 ptï¼‰ã€‚\nå¼·ã¿: ãƒ©ãƒŸãƒ³ãƒ»ãƒ¤ãƒãƒ«ã€ãƒ‹ã‚³ãƒ»ã‚¦ã‚£ãƒªã‚¢ãƒ ã‚ºã‚‰è‹¥æ‰‹ã®çˆ†ç™ºåŠ›ã¨ã€ãƒ­ãƒ‰ãƒªã‚’ä¸­å¿ƒã¨ã—ãŸä¸­ç›¤ã®æ§‹æˆåŠ›ãŒå™›ã¿åˆã£ã¦ã„ã¾ã™ã€‚2010å¹´å¤§ä¼šå„ªå‹æ™‚ã®ã‚ˆã†ãªã€Œã‚·ã‚¹ãƒ†ãƒ ã§å‹ã¤ã€ã‚µãƒƒã‚«ãƒ¼ãŒå®Œæˆã—ã¤ã¤ã‚ã‚Šã¾ã™ã€‚\næ‡¸å¿µ: è‹¥æ‰‹ä¸»ä½“ã®ãƒãƒ¼ãƒ ã§ã‚ã‚‹ãŸã‚ã€Wæ¯ç‰¹æœ‰ã®ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã«å¯¾ã™ã‚‹çµŒé¨“å€¤ä¸è¶³ãŒå”¯ä¸€ã®ãƒªã‚¹ã‚¯ã§ã™ã€‚\nã‚·ãƒŠãƒªã‚ªBï¼šå®Ÿç¸¾çµ„ï¼ˆã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ãƒ»ãƒ•ãƒ©ãƒ³ã‚¹ï¼‰ã®åº•åŠ›ï¼ˆç¢ºç‡ï¼šä¸­ï¼‰\nå€‹ã®åŠ›ã‚„çµŒé¨“å€¤ãŒã€çµ„ç¹”åŠ›ã‚’å‡Œé§•ã™ã‚‹ã‚·ãƒŠãƒªã‚ªã§ã™ã€‚\n\nğŸ‡¦ğŸ‡· ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³:\nå¼·ã¿: 2022å¹´Wæ¯ã€2024å¹´ã‚³ãƒ‘ãƒ»ã‚¢ãƒ¡ãƒªã‚«ã‚’é€£è¦‡ä¸­ã€‚ãƒ¡ãƒƒã‚·ã‚’ä¸­å¿ƒã¨ã—ãŸçµæŸåŠ›ã¨ã€çŸ­æœŸæ±ºæˆ¦ã§ã®å‹è² å¼·ã•ã¯ä¸–ç•Œä¸€ã§ã™ã€‚\nãƒªã‚¹ã‚¯: ä¸»åŠ›ã®é«˜é½¢åŒ–ãŒé€²ã‚“ã§ãŠã‚Šã€2026å¹´å¤ã«2022å¹´ã¨åŒç­‰ã®é‹å‹•é‡ã‚’ç¶­æŒã§ãã‚‹ã‹ãŒéµã¨ãªã‚Šã¾ã™ã€‚\nğŸ‡«ğŸ‡· ãƒ•ãƒ©ãƒ³ã‚¹:\nå¼·ã¿: ã‚­ãƒªã‚¢ãƒ³ãƒ»ã‚¨ãƒ ãƒãƒšã¨ã„ã†ã€Œå€‹ã€ã®æ‰“é–‹åŠ›ã«åŠ ãˆã€å…¨ãƒã‚¸ã‚·ãƒ§ãƒ³ã«ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚¯ãƒ©ã‚¹ã‚’æƒãˆã‚‹é¸æ‰‹å±¤ï¼ˆDepthï¼‰ã¯48ã‚«å›½åˆ¶ã®é•·ä¸å ´ã§æœ€å¤§ã®æ­¦å™¨ã¨ãªã‚Šã¾ã™ã€‚\nãƒªã‚¹ã‚¯: ãƒ‡ã‚·ãƒ£ãƒ³ç›£ç£ä½“åˆ¶ã®é•·æœŸåŒ–ã«ã‚ˆã‚‹æˆ¦è¡“çš„ãªåœæ»æ„ŸãŒæŒ‡æ‘˜ã•ã‚Œã¦ã„ã¾ã™ã€‚\nã‚·ãƒŠãƒªã‚ªCï¼šçœ ã‚Œã‚‹å·¨äººã®è¦šé†’ã¨æ³¢ä¹±ï¼ˆç¢ºç‡ï¼šä½ï½ä¸­ï¼‰\nå¸‚å ´è©•ä¾¡ã¨ç¾çŠ¶ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ä¹–é›¢ãŒã‚ã‚‹ãƒãƒ¼ãƒ ã®å‹•å‘ã§ã™ã€‚\n\nğŸ‡§ğŸ‡· ãƒ–ãƒ©ã‚¸ãƒ«:\nç¾çŠ¶: å—ç±³äºˆé¸ã§è‹¦æˆ¦ï¼ˆä¸€æ™‚5ä½ãƒ»6ä½ï¼‰ã—ã¦ã„ã¾ã™ãŒã€ã‚ªãƒƒã‚ºã§ã¯ä¾ç„¶ã¨ã—ã¦ä¸Šä½ï¼ˆ+650ï½+750ï¼‰ã§ã™ã€‚\nåˆ†æ: ãƒ´ã‚£ãƒ‹ã‚·ã‚¦ã‚¹ã‚‰å‰ç·šã®ã‚¿ãƒ¬ãƒ³ãƒˆåŠ›ã¯éšä¸€ã§ã™ã€‚å¤§ä¼šã¾ã§ã«å®ˆå‚™ã®ä¸å®‰å®šã•ã‚’è§£æ¶ˆã§ãã‚Œã°ã€ä¸€æ°—ã«å„ªå‹å€™è£œç­†é ­ã¸è¿”ã‚Šå’²ããƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ãŒã‚ã‚Šã¾ã™ã€‚\nğŸ´ ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰:\nç¾çŠ¶: 2024å¹´EUROæº–å„ªå‹ã€‚ã‚¿ãƒ¬ãƒ³ãƒˆåŠ›ã¯ã‚¹ãƒšã‚¤ãƒ³ã«åŒ¹æ•µã—ã¾ã™ãŒã€å‹è² æ‰€ã§ã®ç²¾ç¥çš„ãªè„†ã•ãŒèª²é¡Œã§ã™ã€‚\næ³¨ç›®ã™ã¹ããƒ€ãƒ¼ã‚¯ãƒ›ãƒ¼ã‚¹\nğŸ‡ºğŸ‡¾ ã‚¦ãƒ«ã‚°ã‚¢ã‚¤: ãƒ“ã‚¨ãƒ«ã‚µç›£ç£ã®ä¸‹ã€å—ç±³äºˆé¸ã§ãƒ–ãƒ©ã‚¸ãƒ«ãƒ»ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã‚’æ’ƒç ´ã€‚æˆ¦è¡“çš„ãªå®Œæˆåº¦ãŒé«˜ãã€ä¸Šä½å›½ã‚’é£Ÿã†å¯èƒ½æ€§ãŒæœ€ã‚‚é«˜ã„ãƒãƒ¼ãƒ ã§ã™ã€‚\nğŸ‡¨ğŸ‡¦ ã‚«ãƒŠãƒ€: é–‹å‚¬å›½ï¼ˆã‚¢ãƒ¡ãƒªã‚«ãƒ»ãƒ¡ã‚­ã‚·ã‚³ãƒ»ã‚«ãƒŠãƒ€ï¼‰ã®ä¸­ã§æœ€ã‚‚å¥½èª¿ï¼ˆã‚³ãƒ‘ãƒ»ã‚¢ãƒ¡ãƒªã‚«2024ãƒ™ã‚¹ãƒˆ4ï¼‰ã€‚åœ°ã®åˆ©ã‚’æ´»ã‹ã—ãŸèºé€²ãŒæœŸå¾…ã•ã‚Œã¾ã™ã€‚\n2026å¹´å¤§ä¼šç‰¹æœ‰ã®é‡è¦å¤‰æ•°\näºˆæ¸¬ã‚’å·¦å³ã™ã‚‹ã€ä»Šå¤§ä¼šç‰¹æœ‰ã®å¤–çš„è¦å› ã§ã™ã€‚\n\n48ã‚«å›½åˆ¶ã¸ã®æ‹¡å¤§ï¼ˆæ¶ˆè€—æˆ¦ï¼‰: è©¦åˆæ•°ãŒå¢—åŠ ã™ã‚‹ãŸã‚ã€ã‚¹ã‚¿ãƒ¡ãƒ³11äººã ã‘ã§ãªãã€ãƒ™ãƒ³ãƒãƒ¡ãƒ³ãƒãƒ¼ã‚’å«ã‚ãŸ26äººã®ç·åˆåŠ›ãŒå•ã‚ã‚Œã¾ã™ã€‚ã“ã‚Œã¯é¸æ‰‹å±¤ã®åšã„ãƒ•ãƒ©ãƒ³ã‚¹ã‚„ã‚¹ãƒšã‚¤ãƒ³ã«æœ‰åˆ©ã«åƒãã¾ã™ã€‚\nç§»å‹•è·é›¢ã¨æ°—å€™: åŒ—ç±³3ã‚«å›½ã«ã¾ãŸãŒã‚‹åºƒå¤§ãªç§»å‹•ã¨ã€å¤ã®é…·æš‘ãƒ»æ¹¿åº¦ã¯ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ç¶­æŒã‚’å›°é›£ã«ã—ã¾ã™ã€‚ç‰¹å®šã®ç’°å¢ƒã¸ã®é©å¿œåŠ›ãŒä½ã„ãƒãƒ¼ãƒ ã¯ã€å®ŸåŠ›ãŒã‚ã£ã¦ã‚‚æ—©æœŸæ•—é€€ã™ã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚\nå‚ç…§ã‚½ãƒ¼ã‚¹\nFIFA Men's World Ranking (Nov 2025)\nFOX Sports / DraftKings Betting Odds (Nov 2025)\nUEFA Euro 2024 / Copa AmÃ©rica 2024 Results\nğŸ“š æƒ…å ±æºã¨å¼•ç”¨\næ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:\n\npolymarket.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nwikipedia.org\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nsi.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nreddit.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfifa.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nsportingnews.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nyoutube.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\naiscore.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfoxsports.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nsportsbookreview.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nforbes.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nwikipedia.org\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfifa.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nelisportsnetwork.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nolympics.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\ntntsports.co.uk\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfifa.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\n\n\n2æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\nä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\n\nç”·å­ã‚µãƒƒã‚«ãƒ¼ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½ã‚’äºˆæ¸¬ã—ã¦\n\nå®Œäº†ï¼\n\n2025å¹´11æœˆ29æ—¥æ™‚ç‚¹ã®æœ€æ–°ãƒ‡ãƒ¼ã‚¿ãŠã‚ˆã³èª¿æŸ»çµæœã«åŸºã¥ãã€2026å¹´åŒ—ä¸­ç±³ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½äºˆæ¸¬ã‚’æç¤ºã—ã¾ã™ã€‚\n\n1. æ·±æ˜ã‚Šè€ƒå¯Ÿï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\nQ1. åŒ—ä¸­ç±³é–‹å‚¬ï¼ˆé…·æš‘ãƒ»ç§»å‹•ãƒ»æ™‚å·®ï¼‰ã¯ã©ã®ã‚¹ã‚¿ã‚¤ãƒ«ã«æœ‰åˆ©ã‹ï¼Ÿ éå»ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆ1994å¹´ç±³å›½å¤§ä¼šã‚„2014å¹´ãƒ–ãƒ©ã‚¸ãƒ«å¤§ä¼šï¼‰ã‚’å‚ç…§ã™ã‚‹ã¨ã€é…·æš‘ä¸‹ã§ã¯ã€Œãƒœãƒ¼ãƒ«ã‚’ä¿æŒã—ã¦ä½“åŠ›ã‚’æ¸©å­˜ã§ãã‚‹ã€æŠ€è¡“é‡è¦–ã®ãƒãƒ¼ãƒ ï¼ˆã‚¹ãƒšã‚¤ãƒ³ç­‰ï¼‰ã«ä¸€å®šã®ç†ãŒã‚ã‚Šã¾ã™ã€‚ã—ã‹ã—ã€å®ˆå‚™ã«å›ã£ãŸéš›ã®æ¶ˆè€—åº¦ã¯æ¿€ã—ããªã‚‹ãŸã‚ã€æœ€çµ‚çš„ã«ã¯ç‰¹å®šã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚ˆã‚Šã‚‚ã€æ°—å€™é †å¿œæ€§ãŒé«˜ã„å—ç±³å‹¢ã‚„ã€æ¶ˆè€—æˆ¦ã«è€ãˆã†ã‚‹ã€Œãƒ•ã‚£ã‚¸ã‚«ãƒ«ãƒ™ãƒ¼ã‚¹ã®é¸æ‰‹å±¤ã€ã‚’æŒã¤ãƒãƒ¼ãƒ ãŒæœ‰åˆ©ã«åƒãå‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚\n\nQ2. 48ã‚«å›½æ‹¡å¤§ãƒ»è©¦åˆå¢—ã«ãŠã„ã¦ã€é¸æ‰‹å±¤ã§ã‚¹ãƒšã‚¤ãƒ³ç­‰ã‚’å‡Œé§•ã™ã‚‹å›½ã¯ï¼Ÿ ãƒ•ãƒ©ãƒ³ã‚¹ã¨ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã§ã™ã€‚ã“ã®2ã‚«å›½ã¯ã€å„ãƒã‚¸ã‚·ãƒ§ãƒ³ã«ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚¯ãƒ©ã‚¹ã‚’2ã€œ3åæƒãˆã¦ãŠã‚Šã€ã‚¿ãƒ¼ãƒ³ã‚ªãƒ¼ãƒãƒ¼ï¼ˆé¸æ‰‹ã®å…¥ã‚Œæ›¿ãˆï¼‰ã‚’è¡Œã£ã¦ã‚‚æˆ¦åŠ›ãŒè½ã¡ã¾ã›ã‚“ã€‚ç‰¹ã«ãƒ•ãƒ©ãƒ³ã‚¹ã®ãƒ•ã‚£ã‚¸ã‚«ãƒ«çš„ãªé¸æ‰‹å±¤ã®åšã•ã¯ã€ç§»å‹•è·é›¢ãŒé•·ãè©¦åˆæ•°ãŒå¢—ãˆã‚‹ä»Šå¤§ä¼šã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§æœ€å¤§ã®æ­¦å™¨ã¨ãªã‚Šã¾ã™ã€‚\n\nQ3. ã‚¹ãƒšã‚¤ãƒ³ã®ãƒã‚¼ãƒƒã‚·ãƒ§ãƒ³ã«å¯¾ã™ã‚‹æœ‰åŠ¹ãªå¯¾æŠ—ç­–ã¯ï¼Ÿ ã€Œä¸­ç›¤ã§ã®ãƒ•ã‚£ã‚¸ã‚«ãƒ«å¼·åº¦ã«ã‚ˆã‚‹åˆ†æ–­ã€ã¨ã€Œé«˜é€Ÿã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã€ã§ã™ã€‚2025å¹´ç¾åœ¨ã®ã‚¹ãƒšã‚¤ãƒ³ã¯å®Œæˆåº¦ãŒé«˜ã„ã‚‚ã®ã®ã€åŒ—ç±³ã®æš‘ã•ã§é‹å‹•é‡ãŒè½ã¡ãŸæ™‚é–“å¸¯ã«ã€ãƒ•ãƒ©ãƒ³ã‚¹ã‚„ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã®ã‚ˆã†ãªãƒ•ã‚£ã‚¸ã‚«ãƒ«ã«å„ªã‚ŒãŸãƒãƒ¼ãƒ ã‹ã‚‰ãƒã‚¤ãƒ—ãƒ¬ã‚¹ã‚’å—ã‘ã‚‹ã¨ã€å®ˆå‚™ã®è„†ã•ãŒéœ²å‘ˆã™ã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚\n\nQ4. ãƒ–ãƒ©ã‚¸ãƒ«ãŒè©•ä¾¡ã‚’è¦†ã—ã¦å„ªå‹ã™ã‚‹ãŸã‚ã®æ¡ä»¶ã¯ï¼Ÿ ã€Œå®ˆå‚™çµ„ç¹”ã®å®‰å®šã€ã¨ã€Œãƒ´ã‚£ãƒ‹ã‚·ã‚¦ã‚¹ã‚‰ç¾ã‚¨ãƒ¼ã‚¹ã¸ã®æˆ¦è¡“æœ€é©åŒ–ã€ã§ã™ã€‚å€‹ã®èƒ½åŠ›ã¯ä¾ç„¶ã¨ã—ã¦ä¸–ç•Œæœ€é«˜å³°ã§ã™ãŒã€äºˆé¸ã§è‹¦æˆ¦ã—ãŸçµ„ç¹”çš„ãªè„†ã•ã‚’ä¿®æ­£ã—ã€ãƒã‚¤ãƒãƒ¼ãƒ«æ™‚ä»£ã®å¹»å½±ã‹ã‚‰è„±å´ã—ã¦ç¾æœ‰æˆ¦åŠ›ã§å®Œçµã™ã‚‹ãƒãƒ¼ãƒ ã‚’ä½œã‚Œã‚‹ã‹ãŒéµã¨ãªã‚Šã¾ã™ã€‚\n\nQ5. ãƒˆã‚¥ãƒ˜ãƒ«ç›£ç£ï¼ˆã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ï¼‰ã®ã‚ˆã†ãªåå°†ã®å°±ä»»ã¯ãƒ—ãƒ©ã‚¹ã‹ï¼Ÿ æ¥µã‚ã¦å¤§ããªãƒ—ãƒ©ã‚¹è¦å› ã§ã™ã€‚ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®ã‚ˆã†ãªçŸ­æœŸæ±ºæˆ¦ã§ã¯ã€è¤‡é›‘ãªãƒãƒ¼ãƒ ä½œã‚Šã‚ˆã‚Šã‚‚ã€ç›¸æ‰‹ã®å¼±ç‚¹ã‚’çªãæˆ¦è¡“çœ¼ã¨ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆèƒ½åŠ›ãŒå•ã‚ã‚Œã¾ã™ã€‚ãƒˆã‚¥ãƒ˜ãƒ«ç›£ç£ã®ã‚«ãƒƒãƒ—æˆ¦ã§ã®å¼·ã•ï¼ˆãƒã‚§ãƒ«ã‚·ãƒ¼ã§ã®CLå„ªå‹ãªã©ï¼‰ã¯ã€ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã®èª²é¡Œã§ã‚ã‚‹ã€Œå‹è² å¼±ã•ã€ã‚’è£œå®Œã™ã‚‹æœ€é©è§£ã¨è¨€ãˆã¾ã™ã€‚\n\n2. çµè«–\næœ€æœ‰åŠ›å€™è£œï¼šã‚¹ãƒšã‚¤ãƒ³ å¯¾æŠ—é¦¬ï¼šã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã€ãƒ•ãƒ©ãƒ³ã‚¹ã€ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰\n\n2025å¹´11æœˆç¾åœ¨ã€ã‚¹ãƒšã‚¤ãƒ³ãŒé ­ä¸€ã¤æŠœã‘ãŸå„ªå‹å€™è£œã§ã™ã€‚EURO 2024å„ªå‹ã€ãƒ‘ãƒªäº”è¼ªé‡‘ãƒ¡ãƒ€ãƒ«ã¨ã„ã†ç›´è¿‘ã®å®Ÿç¸¾ã«åŠ ãˆã€è‹¥æ‰‹ã¨ãƒ™ãƒ†ãƒ©ãƒ³ãŒèåˆã—ãŸãƒãƒ¼ãƒ ã®å®Œæˆåº¦ã¯ç¾¤ã‚’æŠœã„ã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€é–‹å‚¬åœ°ã®ç’°å¢ƒã‚„é¸æ‰‹å±¤ã‚’è€ƒæ…®ã™ã‚‹ã¨ã€ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã®çµæŸåŠ›ã€ãƒ•ãƒ©ãƒ³ã‚¹ã¨ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã®å€‹ã®åŠ›ãŒåƒ…å·®ã§è¿½ã†ã€Œ4å¼·ã€ã®æ§‹å›³ã¨ãªã‚Šã¾ã™ã€‚\n\n3. è©³ç´°ãªåˆ†æ\næœ¬å‘½ï¼šã‚¹ãƒšã‚¤ãƒ³ï¼ˆFIFAãƒ©ãƒ³ã‚¯1ä½ï¼‰\näºˆæ¸¬æ ¹æ‹ : ç¾åœ¨ã€ä¸–ç•Œã§æœ€ã‚‚æ©Ÿèƒ½ã—ã¦ã„ã‚‹ãƒãƒ¼ãƒ ã§ã™ã€‚ãƒ©ãƒŸãƒ³ãƒ»ãƒ¤ãƒãƒ«ã‚‰ã€Œæ–°é»„é‡‘ä¸–ä»£ã€ãŒå®Œå…¨ã«ä¸»åŠ›ã¨ã—ã¦å®šç€ã—ã€2024å¹´ã®ä¸»è¦ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç‹¬å ã—ã¾ã—ãŸã€‚\nå¼·ã¿: åœ§å€’çš„ãªãƒœãƒ¼ãƒ«æ”¯é…åŠ›ã«åŠ ãˆã€ä»¥å‰ã®ã‚¹ãƒšã‚¤ãƒ³ã«ã¯æ¬ ã‘ã¦ã„ãŸã€Œç¸¦ã¸ã®çªç ´åŠ›ã€ã‚’å…¼ã­å‚™ãˆã¦ã„ã¾ã™ã€‚è‡ªåˆ†ãŸã¡ã®ãƒšãƒ¼ã‚¹ã§è©¦åˆã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã§ãã‚‹ãŸã‚ã€éé…·ãªç’°å¢ƒä¸‹ã§ã‚‚ä½“åŠ›ã‚’æ¸©å­˜ã—ãªãŒã‚‰å‹ã¡ä¸ŠãŒã‚‹å…¬ç®—ãŒé«˜ã„ã§ã™ã€‚\nå¯¾æŠ—ï¼šã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ï¼ˆFIFAãƒ©ãƒ³ã‚¯2ä½ï¼‰\näºˆæ¸¬æ ¹æ‹ : ã‚³ãƒ‘ãƒ»ã‚¢ãƒ¡ãƒªã‚«2024ã‚’åˆ¶ã—ã€ãƒ¡ã‚¸ãƒ£ãƒ¼å¤§ä¼š3é€£è¦‡ã‚’é”æˆã—ãŸã€Œå‹è€…ã®ãƒ¡ãƒ³ã‚¿ãƒªãƒ†ã‚£ã€ã¯å¥åœ¨ã§ã™ã€‚\nå¼·ã¿: ãƒãƒ¼ãƒ ã®çµæŸåŠ›ã¯ä¸–ç•Œä¸€ã§ã™ã€‚ãƒ¡ãƒƒã‚·ã®å¹´é½¢ï¼ˆ39æ­³ã«ãªã‚‹å¹´ï¼‰ã¯æ‡¸å¿µææ–™ã§ã™ãŒã€å½¼ã‚’æ”¯ãˆã‚‹å‘¨å›²ã®çŒ®èº«æ€§ã¨ã€ã‚¹ã‚«ãƒ­ãƒ¼ãƒ‹ç›£ç£ã®æŸ”è»Ÿãªé‡‡é…ã«ã‚ˆã‚Šã€ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆã‚’å‹ã¡æŠœãè¡“ã‚’ç†ŸçŸ¥ã—ã¦ã„ã¾ã™ã€‚å—åŒ—ã‚¢ãƒ¡ãƒªã‚«å¤§é™¸é–‹å‚¬ã¨ã„ã†ã€Œåœ°ã®åˆ©ã€ã‚‚å¤§ããªå¾ŒæŠ¼ã—ã¨ãªã‚Šã¾ã™ã€‚\næœ‰åŠ›ï¼šã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ï¼ˆFIFAãƒ©ãƒ³ã‚¯4ä½ï¼‰\näºˆæ¸¬æ ¹æ‹ : ãƒˆãƒ¼ãƒã‚¹ãƒ»ãƒˆã‚¥ãƒ˜ãƒ«ç›£ç£ã®å°±ä»»ï¼ˆ2025å¹´ï¼‰ã«ã‚ˆã‚Šã€æˆ¦è¡“çš„ãªè¦å¾‹ã¨å‹è² å¼·ã•ãŒåŠ ã‚ã‚Šã¾ã—ãŸã€‚ãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã®ã‚ªãƒƒã‚ºã§ã‚‚ã‚¹ãƒšã‚¤ãƒ³ã«æ¬¡ãè©•ä¾¡ã‚’å¾—ã¦ã„ã¾ã™ã€‚\nå¼·ã¿: ãƒ™ãƒªãƒ³ã‚¬ãƒ ã€ã‚±ã‚¤ãƒ³ã€ã‚µã‚«ãªã©ã€å€‹ã®ã‚¿ãƒ¬ãƒ³ãƒˆåŠ›ã¯ã‚¹ãƒšã‚¤ãƒ³ã‚’ã‚‚å‡Œãã¾ã™ã€‚ãƒˆã‚¥ãƒ˜ãƒ«ç›£ç£ã®æŒ‡æ®ä¸‹ã§å®ˆå‚™ãŒå®‰å®šã™ã‚Œã°ã€60å¹´ã¶ã‚Šã®å„ªå‹ãŒç¾å®Ÿå‘³ã‚’å¸¯ã³ã¾ã™ã€‚\nä¸æ°—å‘³ãªå­˜åœ¨ï¼šãƒ•ãƒ©ãƒ³ã‚¹ï¼ˆFIFAãƒ©ãƒ³ã‚¯3ä½ï¼‰\näºˆæ¸¬æ ¹æ‹ : å¸¸ã«å„ªå‹å€™è£œã«æŒ™ãŒã‚‹é¸æ‰‹å±¤ã®åšã•ãŒã‚ã‚Šã¾ã™ã€‚\nå¼·ã¿: ã‚­ãƒªã‚¢ãƒ³ãƒ»ã‚¨ãƒ ãƒãƒšã‚’ä¸­å¿ƒã¨ã—ãŸæ”»æ’ƒåŠ›ã¨ã€ä¸­ç›¤ã®ãƒ•ã‚£ã‚¸ã‚«ãƒ«å¼·åº¦ã¯ä¸–ç•Œå±ˆæŒ‡ã€‚48ã‚«å›½å‡ºå ´ã«ã‚ˆã‚‹é•·ä¸å ´ã®å¤§ä¼šã«ãŠã„ã¦ã€èª°ãŒå‡ºã¦ã‚‚å¼·ã„ã¨ã„ã†ã€Œå±¤ã®åšã•ã€ã¯æœ€å¤§ã®æ­¦å™¨ã§ã™ã€‚\n4. è€ƒæ…®ã™ã¹ããƒªã‚¹ã‚¯è¦å› \nåŒ—ä¸­ç±³ç‰¹æœ‰ã®ç’°å¢ƒï¼ˆãƒ’ãƒ¼ãƒˆï¼†ãƒ‡ã‚£ã‚¹ã‚¿ãƒ³ã‚¹ï¼‰: ã‚¢ãƒ¡ãƒªã‚«ã€ã‚«ãƒŠãƒ€ã€ãƒ¡ã‚­ã‚·ã‚³ã®3ã‚«å›½é–‹å‚¬ã«ã‚ˆã‚‹ç§»å‹•è·é›¢ã®é•·ã•ã¨ã€ä¸€éƒ¨ä¼šå ´ã®é…·æš‘ã¯ã€æ¬§å·å‹¢ã®ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã‚’å´©ã™æœ€å¤§ã®è¦å› ã¨ãªã‚Šå¾—ã¾ã™ã€‚éå»ã€åŒ—å—ç±³é–‹å‚¬ã®Wæ¯ã§æ¬§å·å‹¢ãŒå„ªå‹ã—ãŸã®ã¯2014å¹´ã®ãƒ‰ã‚¤ãƒ„ã®ã¿ã§ã™ã€‚ã“ã®ã‚¸ãƒ³ã‚¯ã‚¹ã¯å—ç±³å‹¢ï¼ˆã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã€ãƒ–ãƒ©ã‚¸ãƒ«ï¼‰ã«ã¨ã£ã¦è¿½ã„é¢¨ã§ã™ã€‚\n\nå¤§ä¼šãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å¤‰æ›´: å‡ºå ´å›½ãŒ48ã‚«å›½ã«å¢—ãˆã€æ±ºå‹ã¾ã§ã®è©¦åˆæ•°ãŒæœ€å¤§8è©¦åˆã«å¢—åŠ ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç‰¹å®šã®ã‚¹ã‚¿ãƒ¼é¸æ‰‹ã«ä¾å­˜ã™ã‚‹ãƒãƒ¼ãƒ ï¼ˆä¾‹ï¼šãƒ¡ãƒƒã‚·ä¾å­˜ã®ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã€ãƒ‡ãƒ»ãƒ–ãƒ©ã‚¤ãƒä¾å­˜ã®ãƒ™ãƒ«ã‚®ãƒ¼ç­‰ï¼‰ã¯ã€å¤§ä¼šçµ‚ç›¤ã«ã‚¬ã‚¹æ¬ ã‚’èµ·ã“ã™ãƒªã‚¹ã‚¯ãŒé«˜ã¾ã‚Šã¾ã™ã€‚\n\nãƒ–ãƒ©ã‚¸ãƒ«ã®å¾©èª¿: ç¾åœ¨5ç•ªæ‰‹è©•ä¾¡ã§ã™ãŒã€å€‹ã®èƒ½åŠ›ã¯ä¾ç„¶ã¨ã—ã¦ãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã§ã™ã€‚å¤§ä¼šã¾ã§ã«å®ˆå‚™çµ„ç¹”ãŒæ•´å‚™ã•ã‚Œã‚Œã°ã€ä¸€æ°—ã«å„ªå‹å€™è£œç­†é ­ã«èºã‚Šå‡ºã‚‹ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã‚’ç§˜ã‚ã¦ã„ã¾ã™ã€‚\n\nğŸ“š æƒ…å ±æºã¨å¼•ç”¨\næ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:\n\npolymarket.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nwikipedia.org\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfifa.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nsportsbookreview.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfoxsports.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nolympics.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nlivescore.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\n365scores.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\napnews.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nelisportsnetwork.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nbetfair.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\naiscore.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nyoutube.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nyoutube.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nä½•ã‹èã„ã¦ãã ã•ã„...\n\n3\nä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\n\nç”·å­ã‚µãƒƒã‚«ãƒ¼ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½ã‚’äºˆæ¸¬ã—ã¦\n\nå®Œäº†ï¼\n\n2025å¹´11æœˆæ™‚ç‚¹ã®æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã€FIFAãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€ãŠã‚ˆã³å¸‚å ´äºˆæ¸¬ã«åŸºã¥ãã€2026å¹´ç”·å­ã‚µãƒƒã‚«ãƒ¼ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½äºˆæ¸¬ã‚’åˆ†æã—ã¾ã™ã€‚\n\n1. çµè«–ï¼šç¾åœ¨ã®æœ€æœ‰åŠ›å€™è£œã¯ã€Œã‚¹ãƒšã‚¤ãƒ³ã€\nç¾æ™‚ç‚¹ï¼ˆ2025å¹´11æœˆï¼‰ã§æœ€ã‚‚å„ªå‹ã«è¿‘ã„ã¨äºˆæ¸¬ã•ã‚Œã‚‹ã®ã¯ã‚¹ãƒšã‚¤ãƒ³ã§ã™ã€‚ EURO 2024ã§ã®å„ªå‹å®Ÿç¸¾ã¨ã€FIFAãƒ©ãƒ³ã‚­ãƒ³ã‚°1ä½ã‚’ç¶­æŒã™ã‚‹å®‰å®šæ„ŸãŒè©•ä¾¡ã•ã‚Œã€ãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼å„ç¤¾ã§ã‚‚ç­†é ­å€™è£œï¼ˆã‚ªãƒƒã‚ºç´„5.4å€ï¼‰ã¨ãªã£ã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã€ãƒ•ãƒ©ãƒ³ã‚¹ã€å‰å›ç‹è€…ã®ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ãŒç¶šãã€Œ4å¼·ï¼‹ãƒ–ãƒ©ã‚¸ãƒ«ã€ã®æ§‹å›³ãŒå½¢æˆã•ã‚Œã¦ã„ã¾ã™ã€‚\n\n2. è©³ç´°ãªåˆ†æã¨äºˆæ¸¬ã‚·ãƒŠãƒªã‚ª\nç­†é ­å€™è£œï¼šã‚¹ãƒšã‚¤ãƒ³ï¼ˆFIFAãƒ©ãƒ³ã‚¯1ä½ï¼‰\näºˆæ¸¬æ ¹æ‹ : EURO 2024å„ªå‹ã«åŠ ãˆã€2024-25 UEFAãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚ºãƒªãƒ¼ã‚°ã§ã‚‚å¥½èª¿ã‚’ç¶­æŒã—ã¦ãŠã‚Šã€æˆ¦è¡“çš„ãªå®Œæˆåº¦ãŒæœ€ã‚‚é«˜ã„ã¨è©•ä¾¡ã•ã‚Œã¦ã„ã¾ã™ã€‚\nå¼·ã¿: ãƒ©ãƒŸãƒ³ãƒ»ãƒ¤ãƒãƒ«ã‚„ãƒ­ãƒ‰ãƒªã‚’ä¸­å¿ƒã¨ã—ãŸä¸–ä»£äº¤ä»£ãŒå®Œäº†ã—ã¦ãŠã‚Šã€ãƒ™ãƒ†ãƒ©ãƒ³ã¨è‹¥æ‰‹ãŒå®Œç’§ã«èåˆã—ã¦ã„ã¾ã™ã€‚\nå¸‚å ´è©•ä¾¡: ä¸»è¦ãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã§ã®å„ªå‹ç¢ºç‡ã¯ç´„18.5%ï¼ˆã‚ªãƒƒã‚º +440ï½+450ï¼‰ã§å˜ç‹¬ãƒˆãƒƒãƒ—ã§ã™ã€‚\nå¯¾æŠ—é¦¬ï¼ˆå‰å›ç‹è€…ï¼‰ï¼šã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ï¼ˆFIFAãƒ©ãƒ³ã‚¯2ä½ï¼‰\näºˆæ¸¬æ ¹æ‹ : 2022å¹´Wæ¯ãŠã‚ˆã³ã‚³ãƒ‘ãƒ»ã‚¢ãƒ¡ãƒªã‚«2024ã®ç‹è€…ã¨ã—ã¦ã€ä¾ç„¶ã¨ã—ã¦ä¸–ç•Œãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã®å®ŸåŠ›ã‚’ä¿æŒã—ã¦ã„ã¾ã™ã€‚å—ç±³äºˆé¸ã‚‚é¦–ä½äº‰ã„ã‚’æ¼”ã˜ã€æœ¬å¤§ä¼šå‡ºå ´æ¨©ã‚’ç¢ºä¿æ¸ˆã¿ã§ã™ã€‚\nå¼·ã¿: ãƒªã‚ªãƒãƒ«ãƒ»ãƒ¡ãƒƒã‚·ãŒã‚­ãƒ£ãƒ—ãƒ†ãƒ³ã¨ã—ã¦ç²¾ç¥çš„æ”¯æŸ±ã®å½¹å‰²ã‚’æœãŸã—ã¦ãŠã‚Šã€ãƒãƒ¼ãƒ ã®çµæŸåŠ›ãŒéå¸¸ã«é«˜ã„ç‚¹ãŒç‰¹å¾´ã§ã™ã€‚\nå¸‚å ´è©•ä¾¡: ã‚ªãƒƒã‚ºã¯ç´„8.5ï½9.0å€ã§5ç•ªæ‰‹è©•ä¾¡ã§ã™ãŒã€çŸ­æœŸæ±ºæˆ¦ã§ã®å‹è² å¼·ã•ã¯éšä¸€ã§ã™ã€‚\nãã®ä»–ã®æœ‰åŠ›å€™è£œï¼ˆãƒˆãƒƒãƒ—ãƒ†ã‚£ã‚¢ï¼‰\nã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ï¼ˆã‚ªãƒƒã‚º2ä½ / ç´„7.0å€ï¼‰: EURO 2024æº–å„ªå‹ã®å®Ÿç¸¾ã¨ã€äºˆé¸ã‚’ç„¡æ•—ã§é€šéã—ãŸå®‰å®šæ„ŸãŒè©•ä¾¡ã•ã‚Œã¦ã„ã¾ã™ã€‚ã€Œ60å¹´ã¶ã‚Šã®å„ªå‹ã€ã¸ã®æœŸå¾…ãŒé«˜ãã€æˆ¦åŠ›å±¤ã®åšã•ã¯ä¸–ç•Œå±ˆæŒ‡ã§ã™ã€‚\nãƒ•ãƒ©ãƒ³ã‚¹ï¼ˆã‚ªãƒƒã‚º3ä½ / ç´„8.0å€ï¼‰: ã‚­ãƒªã‚¢ãƒ³ãƒ»ã‚¨ãƒ ãƒãƒšãŒå…¨ç››æœŸã‚’è¿ãˆã¦ãŠã‚Šã€å€‹ã®èƒ½åŠ›ã§è©¦åˆã‚’æ±ºå®šã¥ã‘ã‚‹åŠ›ãŒã‚ã‚Šã¾ã™ã€‚FIFAãƒ©ãƒ³ã‚¯3ä½ã‚’ç¶­æŒã—ã¦ã„ã¾ã™ã€‚\nãƒ–ãƒ©ã‚¸ãƒ«ï¼ˆã‚ªãƒƒã‚º4ä½ / ç´„8.5å€ï¼‰: äºˆé¸åºç›¤ã¯è‹¦æˆ¦ã—ã¾ã—ãŸãŒã€2025å¹´å¾ŒåŠã«å¾©èª¿ã—FIFAãƒ©ãƒ³ã‚¯5ä½ã¸æµ®ä¸Šã—ã¾ã—ãŸã€‚ãƒã‚¤ãƒãƒ¼ãƒ«ã®å¾©å¸°ã¨çŠ¶æ…‹ãŒå„ªå‹ã¸ã®éµã‚’æ¡ã‚Šã¾ã™ã€‚\n3. è€ƒæ…®ã™ã¹ããƒªã‚¹ã‚¯è¦å› ã¨ä¸ç¢ºå®šè¦ç´ \näºˆæ¸¬ã‚’è¡Œã†ä¸Šã§ã€ä»¥ä¸‹ã®è¦ç´ ãŒçµæœã‚’å·¦å³ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n\nåŒ—ç±³é–‹å‚¬ç‰¹æœ‰ã®ç’°å¢ƒè² è·: ã‚¢ãƒ¡ãƒªã‚«ãƒ»ã‚«ãƒŠãƒ€ãƒ»ãƒ¡ã‚­ã‚·ã‚³ã®3ã‚«å›½å…±å‚¬ã¨ãªã‚‹ãŸã‚ã€ç§»å‹•è·é›¢ãŒéå¸¸ã«é•·ãã€ãƒ¡ã‚­ã‚·ã‚³ã‚„ç±³å›½å—éƒ¨ã§ã®é…·æš‘ãŒé¸æ‰‹ã®ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã‚’è‘—ã—ãä½ä¸‹ã•ã›ã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã¯é¸æ‰‹å±¤ã®åšã„ãƒãƒ¼ãƒ ï¼ˆæ¬§å·å‹¢ãªã©ï¼‰ã«æœ‰åˆ©ã«åƒãå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\nä¸»åŠ›é¸æ‰‹ã®è² å‚·ãƒªã‚¹ã‚¯: æ¬§å·ä¸»è¦ãƒªãƒ¼ã‚°ã®éå¯†æ—¥ç¨‹ã«ã‚ˆã‚Šã€ACLï¼ˆå‰åå­—é­å¸¯ï¼‰æå‚·ãªã©ã®é‡å‚·ãŒå¢—åŠ å‚¾å‘ã«ã‚ã‚Šã¾ã™ã€‚å¤§ä¼šç›´å‰ã®æ€ªæˆ‘äººãŒäºˆæ¸¬ã‚’å¤§ããè¦†ã™å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\nãƒ™ãƒ†ãƒ©ãƒ³ã¸ã®ä¾å­˜åº¦: ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ï¼ˆãƒ¡ãƒƒã‚·ï¼‰ã‚„ãƒãƒ«ãƒˆã‚¬ãƒ«ï¼ˆC.ãƒ­ãƒŠã‚¦ãƒ‰ï¼‰ãªã©ã€ãƒ™ãƒ†ãƒ©ãƒ³ã‚¹ã‚¿ãƒ¼ã¸ã®ä¾å­˜åº¦ãŒé«˜ã„ãƒãƒ¼ãƒ ã¯ã€å½¼ã‚‰ã®ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³æ¬¡ç¬¬ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå¤§ããå¤‰å‹•ã™ã‚‹ãƒªã‚¹ã‚¯ã‚’æŠ±ãˆã¦ã„ã¾ã™ã€‚\nå‡ºå…¸:\n\nFIFA Men's World Ranking (2025å¹´11æœˆ19æ—¥æ›´æ–°)\nFanDuel / DraftKings Betting Odds (2025å¹´11æœˆæ™‚ç‚¹)\nFox Sports å ±é“ (2025å¹´11æœˆ)\nğŸ“š æƒ…å ±æºã¨å¼•ç”¨\næ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:\n\npolymarket.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nwikipedia.org\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfifa.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nsofascore.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfifa.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nsoccerpunter.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfoxsports.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nlivescore.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\naiscore.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\n11v11.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfootystats.org\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nsportsbookreview.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\ndraftkings.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\ngoal.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nnational-football-teams.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nthesoccerera.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\n365scores.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfoxsports.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nwikipedia.org\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nsportpesa.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfanduel.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nwikipedia.org\nå‡ºå…¸: vertexaisearch.cloud.google.com"
                },
                {
                    "role": "model",
                    "content": "2025å¹´11æœˆæ™‚ç‚¹ã®æœ€æ–°æƒ…å‹¢ï¼ˆã‚¹ãƒšã‚¤ãƒ³ã®å°é ­ã€ãƒˆã‚¥ãƒ˜ãƒ«ç›£ç£ã®ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰å°±ä»»ã€åŒ—ç±³é–‹å‚¬ã®ç‰¹æ®Šæ€§ï¼‰ã‚’è¸ã¾ãˆã€å„å›ç­”ã®è³ªã‚’è©•ä¾¡ãƒ»æ¡ç‚¹ã—ã¾ã™ã€‚\n\n### 1. æ·±æ˜ã‚Šè€ƒå¯Ÿï¼ˆè©•ä¾¡ã®è¦–ç‚¹ï¼‰\nå›ç­”ã®å„ªåŠ£ã‚’åˆ¤æ–­ã™ã‚‹ãŸã‚ã«ã€å˜ãªã‚‹ãƒ‡ãƒ¼ã‚¿å‚ç…§ã‚’è¶…ãˆãŸã€Œäºˆæ¸¬ã®è³ªã€ã‚’å·¦å³ã™ã‚‹5ã¤ã®è¦–ç‚¹ã‚’æ•´ç†ã—ã¾ã—ãŸã€‚\n\n*   **Q1. ã€Œãƒã‚¼ãƒƒã‚·ãƒ§ãƒ³ï¼çœã‚¨ãƒã€èª¬ã¯åŒ—ç±³ã®é…·æš‘ã§é€šç”¨ã™ã‚‹ã‹ï¼Ÿ**\n    ãƒœãƒ¼ãƒ«ä¿æŒç‡ã®é«˜ã„ã‚¹ãƒšã‚¤ãƒ³ã¯å®ˆå‚™ã§èµ°ã‚Šå›ã‚‹æ™‚é–“ã‚’æ¸›ã‚‰ã›ã‚‹ãŸã‚ã€é…·æš‘ä¸‹ã§ã¯æœ‰åˆ©ã«åƒãã¾ã™ã€‚ãŸã ã—ã€ä¸€åº¦ãƒœãƒ¼ãƒ«ã‚’å¤±ã£ãŸéš›ã®ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼å¯¾å¿œã§æ¶ˆè€—ã™ã‚‹ã¨è„†ã„ãŸã‚ã€ãƒ•ã‚£ã‚¸ã‚«ãƒ«ã¨èµ°åŠ›ã«é•·ã‘ãŸãƒ•ãƒ©ãƒ³ã‚¹ã‚„ã‚¢ãƒ•ãƒªã‚«å‹¢ã®æ–¹ãŒç’°å¢ƒé©å¿œåŠ›ãŒé«˜ã„ã¨ã„ã†è¦‹æ–¹ã‚‚ã‚ã‚Šã€ä¸€é•·ä¸€çŸ­ã§ã™ã€‚\n*   **Q2. 48ã‚«å›½åˆ¶ãƒ»é•·æœŸæˆ¦ã«ãŠã‘ã‚‹ã€ŒçœŸã®é¸æ‰‹å±¤ã€ã¨ã¯ï¼Ÿ**\n    è©¦åˆæ•°ãŒå¢—ãˆã‚‹ä»Šå¤§ä¼šã§ã¯ã€ã‚¹ã‚¿ãƒ¡ãƒ³ã¨éœè‰²ãªã„æ§ãˆé¸æ‰‹ã‚’ã©ã‚Œã ã‘æƒãˆã‚‰ã‚Œã‚‹ã‹ãŒéµã§ã™ã€‚ãã®ç‚¹ã§ã¯ã€å…¨ãƒã‚¸ã‚·ãƒ§ãƒ³ã«ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚¯ãƒ©ã‚¹ã‚’2ã€œ3åæŠ±ãˆã‚‹ãƒ•ãƒ©ãƒ³ã‚¹ã¨ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ãŒã€ã‚¹ãƒšã‚¤ãƒ³ã‚„ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã‚’ä¸Šå›ã‚‹ã‚¢ãƒ‰ãƒãƒ³ãƒ†ãƒ¼ã‚¸ã‚’æŒã¡ã¾ã™ã€‚\n*   **Q3. ã€Œåå°†ãƒˆã‚¥ãƒ˜ãƒ«ã€ã¯ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã«ã¨ã£ã¦åŠ‡è–¬ã‹ï¼Ÿ**\n    æ¥µã‚ã¦å¤§ããªãƒ—ãƒ©ã‚¹è¦å› ã§ã™ã€‚ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã®èª²é¡Œã¯æˆ¦åŠ›ã§ã¯ãªãã€Œå‹è² å¼±ã•ã€ã§ã—ãŸã€‚çŸ­æœŸæ±ºæˆ¦ã®ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆã«é•·ã‘ãŸãƒˆã‚¥ãƒ˜ãƒ«ç›£ç£ã®å°±ä»»ã¯ã€æˆ¦è¡“çš„ãªè¦å¾‹ã‚’ã‚‚ãŸã‚‰ã—ã€å„ªå‹ã¸ã®ãƒ©ã‚¹ãƒˆãƒ”ãƒ¼ã‚¹ã«ãªã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã§ã™ã€‚\n*   **Q4. ã€ŒåŒ—å—ç±³é–‹å‚¬ï¼æ¬§å·å‹¢è‹¦æˆ¦ã€ã®ã‚¸ãƒ³ã‚¯ã‚¹ã¯æœ‰åŠ¹ã‹ï¼Ÿ**\n    æœ‰åŠ¹ã§ã™ã€‚æ™‚å·®ã€ç§»å‹•è·é›¢ã€æ°—å€™ã®ä¸‰é‡è‹¦ã«ã‚ˆã‚Šã€éå»ã«å—åŒ—ã‚¢ãƒ¡ãƒªã‚«å¤§é™¸ã§å„ªå‹ã—ãŸæ¬§å·å‹¢ã¯2014å¹´ã®ãƒ‰ã‚¤ãƒ„ã®ã¿ã§ã™ã€‚ã“ã®æ­´å²çš„èƒŒæ™¯ã¯ã€ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã‚„ãƒ–ãƒ©ã‚¸ãƒ«ã¨ã„ã£ãŸå—ç±³å‹¢ã«ã¨ã£ã¦å¼·åŠ›ãªè¿½ã„é¢¨ã¨ãªã‚Šã¾ã™ã€‚\n*   **Q5. ãƒ–ãƒ©ã‚¸ãƒ«ãŒå¾©æ¨©ã™ã‚‹ãŸã‚ã®æ¡ä»¶ã¯ï¼Ÿ**\n    ã€Œå®ˆå‚™çµ„ç¹”ã®å†æ§‹ç¯‰ã€ã¨ã€Œãƒ´ã‚£ãƒ‹ã‚·ã‚¦ã‚¹ã¸ã®æ¨©é™å§”è­²ã€ã§ã™ã€‚äºˆé¸ã§è‹¦æˆ¦ã—ãŸå®ˆå‚™ã®è„†ã•ã‚’ä¿®æ­£ã—ã€ãƒã‚¤ãƒãƒ¼ãƒ«æ™‚ä»£ã®ç‹æ§˜ã‚µãƒƒã‚«ãƒ¼ã‹ã‚‰è„±å´ã—ã¦ã€ç¾ã‚¨ãƒ¼ã‚¹ã§ã‚ã‚‹ãƒ´ã‚£ãƒ‹ã‚·ã‚¦ã‚¹ã«æˆ¦è¡“ã‚’æœ€é©åŒ–ã§ãã‚‹ã‹ãŒã‚«ã‚®ã¨ãªã‚Šã¾ã™ã€‚\n\n---\n\n### 2. çµè«–ï¼šå›ç­”ãƒ¬ãƒ™ãƒ«ã®ç‚¹æ•°è©•ä¾¡ï¼ˆ10ç‚¹æº€ç‚¹ï¼‰\n\nå„å›ç­”ã®æƒ…å ±ã®é®®åº¦ã€åˆ†æã®æ·±ã•ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®æœ‰ç”¨æ€§ã‚’ç·åˆçš„ã«è©•ä¾¡ã—ã¾ã—ãŸã€‚\n\n*   **å›ç­”2ï¼š9.5ç‚¹ï¼ˆSãƒ©ãƒ³ã‚¯ / æœ€é«˜è©•ä¾¡ï¼‰**\n    *   **ç†ç”±**: å”¯ä¸€ã€æ°—å€™ã‚„ç›£ç£äººäº‹ã¨ã„ã£ãŸã€Œå®šæ€§çš„ãªå¤‰æ•°ã€ã¾ã§æ·±ãè€ƒå¯Ÿã—ã¦ãŠã‚Šã€ãƒ—ãƒ­ã®ã‚¢ãƒŠãƒªã‚¹ãƒˆãƒ¬ãƒ™ãƒ«ã®æ´å¯ŸãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚\n*   **å›ç­”0ï¼š9.0ç‚¹ï¼ˆAãƒ©ãƒ³ã‚¯ / é«˜è©•ä¾¡ï¼‰**\n    *   **ç†ç”±**: ã‚ªãƒƒã‚ºã‚„ç¢ºç‡ãªã©ã®ã€Œå…·ä½“çš„ãªæ•°å­—ã€ãŒæœ€ã‚‚å……å®Ÿã—ã¦ãŠã‚Šã€å®¢è¦³çš„ãªæ ¹æ‹ ã«åŸºã¥ã„ãŸä¿¡é ¼æ€§ã®é«˜ã„ãƒ¬ãƒãƒ¼ãƒˆã§ã™ã€‚\n*   **å›ç­”1ï¼š8.5ç‚¹ï¼ˆA-ãƒ©ãƒ³ã‚¯ / è‰¯è©•ä¾¡ï¼‰**\n    *   **ç†ç”±**: ã€Œã‚·ãƒŠãƒªã‚ªåˆ†æã€ã¨ã„ã†æ‰‹æ³•ãŒè«–ç†çš„ã§åˆ†ã‹ã‚Šã‚„ã™ã„ã§ã™ãŒã€å›ç­”2ã»ã©ã®ç‹¬è‡ªè¦–ç‚¹ï¼ˆç’°å¢ƒè¦å› ãªã©ï¼‰ã«ã¯åŠã³ã¾ã›ã‚“ã€‚\n*   **å›ç­”3ï¼š7.5ç‚¹ï¼ˆBãƒ©ãƒ³ã‚¯ / æ¨™æº–è©•ä¾¡ï¼‰**\n    *   **ç†ç”±**: å†…å®¹ã«èª¤ã‚Šã¯ã‚ã‚Šã¾ã›ã‚“ãŒã€æ•™ç§‘æ›¸çš„ã§ç„¡é›£ãªã¾ã¨ã‚ã«ã¨ã©ã¾ã£ã¦ãŠã‚Šã€ä»–ã®å›ç­”ã«æ¯”ã¹ã¦éš›ç«‹ã£ãŸç‰¹å¾´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\n\n---\n\n### 3. è©³ç´°ãªåˆ†æï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãè©•ä¾¡æ ¹æ‹ ï¼‰\n\n#### **å›ç­”2ï¼ˆ9.5ç‚¹ï¼‰ï¼šæ´å¯Ÿã¨æ–‡è„ˆç†è§£ã®å‹åˆ©**\n*   **å¼·ã¿**: ã€ŒåŒ—ä¸­ç±³é–‹å‚¬ï¼ˆé…·æš‘ãƒ»ç§»å‹•ï¼‰ã€ã‚„ã€Œãƒˆã‚¥ãƒ˜ãƒ«ç›£ç£å°±ä»»ã€ã¨ã„ã£ãŸã€2026å¹´å¤§ä¼šç‰¹æœ‰ã®é‡è¦ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ã‚’ãƒ¡ã‚¿è³ªå•å½¢å¼ã§è§£èª¬ã—ã¦ã„ã‚‹ç‚¹ãŒç§€é€¸ã§ã™ã€‚å˜ã«ã€Œã‚¹ãƒšã‚¤ãƒ³ãŒå¼·ã„ã€ã¨è¨€ã†ã ã‘ã§ãªãã€ã€Œãªãœï¼ˆç’°å¢ƒãƒ»æˆ¦è¡“çš„ã«ï¼‰ãã†ãªã‚‹ã®ã‹ã€ã¨ã„ã†ãƒ­ã‚¸ãƒƒã‚¯ãŒæœ€ã‚‚å¼·å›ºã§ã™ã€‚\n*   **ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ**: ã‚µãƒƒã‚«ãƒ¼ã«è©³ã—ãã€è¡¨é¢çš„ãªã‚ªãƒƒã‚ºä»¥ä¸Šã®æ·±ã„åˆ†æã‚’æ±‚ã‚ã¦ã„ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æœ€é©ã§ã™ã€‚\n\n#### **å›ç­”0ï¼ˆ9.0ç‚¹ï¼‰ï¼šåœ§å€’çš„ãªå…·ä½“æ€§ã¨å®¢è¦³æ€§**\n*   **å¼·ã¿**: ã€Œã‚ªãƒƒã‚º4.5å€ã€ã€Œå„ªå‹ç¢ºç‡17%ã€ã¨ã„ã£ãŸå…·ä½“çš„ãªæ•°å€¤ã‚’æç¤ºã—ã¦ãŠã‚Šã€æƒ…å ±ã®é€æ˜æ€§ãŒé«˜ã„ã§ã™ã€‚ã¾ãŸã€æ—¥æœ¬ä»£è¡¨ã®ç«‹ã¡ä½ç½®ï¼ˆãƒ€ãƒ¼ã‚¯ãƒ›ãƒ¼ã‚¹æ ï¼‰ã«ã‚‚è§¦ã‚Œã¦ãŠã‚Šã€æ—¥æœ¬äººãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é–¢å¿ƒäº‹ã‚’ã—ã£ã‹ã‚Šã‚«ãƒãƒ¼ã—ã¦ã„ã¾ã™ã€‚\n*   **ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ**: æ‰‹ã£å–ã‚Šæ—©ãã€Œä¸–é–“ã®è©•ä¾¡ã€ã‚„ã€Œå®¢è¦³çš„ãªæ•°å­—ã€ã‚’çŸ¥ã‚ŠãŸã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æœ€é©ã§ã™ã€‚\n\n#### **å›ç­”1ï¼ˆ8.5ç‚¹ï¼‰ï¼šæ§‹é€ åŒ–ã•ã‚ŒãŸè«–ç†å±•é–‹**\n*   **å¼·ã¿**: ã€Œã‚·ãƒŠãƒªã‚ªAï¼ˆæœ¬å‘½ï¼‰ã€ã€Œã‚·ãƒŠãƒªã‚ªBï¼ˆå¯¾æŠ—ï¼‰ã€ã¨ç¢ºç‡ä»˜ãã§åˆ†å²ã•ã›ã‚‹æ§‹æˆãŒéå¸¸ã«åˆ†ã‹ã‚Šã‚„ã™ãã€ãƒ“ã‚¸ãƒã‚¹ãƒ©ã‚¤ã‚¯ãªå ±å‘Šæ›¸ã¨ã—ã¦å„ªç§€ã§ã™ã€‚ã‚¹ãƒšã‚¤ãƒ³ã®æ‡¸å¿µç‚¹ï¼ˆè‹¥ã•ï¼‰ã‚„ãƒ•ãƒ©ãƒ³ã‚¹ã®å¼·ã¿ï¼ˆDepthï¼‰ãªã©ã€å®šæ€§åˆ†æã‚‚ã—ã£ã‹ã‚Šã—ã¦ã„ã¾ã™ã€‚\n*   **ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ**: è«–ç†çš„ãªèª¬æ˜ã‚’å¥½ã¿ã€è¤‡æ•°ã®å¯èƒ½æ€§ã‚’æ•´ç†ã—ã¦ç†è§£ã—ãŸã„ãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘ã§ã™ã€‚\n\n#### **å›ç­”3ï¼ˆ7.5ç‚¹ï¼‰ï¼šå …å®Ÿãªã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰**\n*   **å¼·ã¿**: çµè«–ã€è©³ç´°ã€ãƒªã‚¹ã‚¯è¦å› ã¨éä¸è¶³ãªãã¾ã¨ã¾ã£ã¦ã„ã¾ã™ã€‚ã€Œ2024-25 UEFAãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚ºãƒªãƒ¼ã‚°ã€ã¸ã®è¨€åŠãªã©ã€æƒ…å ±ã®é®®åº¦ã‚‚ä¿ãŸã‚Œã¦ã„ã¾ã™ã€‚\n*   **å¼±ã¿**: ä¸Šä½ã®å›ç­”ã«æ¯”ã¹ã‚‹ã¨ã€ã€Œæ•°å­—ã®å…·ä½“æ€§ï¼ˆå›ç­”0ï¼‰ã€ã‚„ã€Œæ´å¯Ÿã®æ·±ã•ï¼ˆå›ç­”2ï¼‰ã€ã¨ã„ã£ãŸå°–ã£ãŸéƒ¨åˆ†ãŒå°‘ãªãã€å°è±¡ã«æ®‹ã‚Šã¥ã‚‰ã„ã§ã™ã€‚\n\n---\n\n### 4. è€ƒæ…®ã™ã¹ãè¦å› ã‚„ãƒªã‚¹ã‚¯\nè©•ä¾¡ã‚’åˆ©ç”¨ã™ã‚‹éš›ã¯ã€ä»¥ä¸‹ã®ç‚¹ã«ã”æ³¨æ„ãã ã•ã„ã€‚\n\n*   **æƒ…å ±ã®é®®åº¦**: ã™ã¹ã¦ã®å›ç­”ã¯**2025å¹´11æœˆæ™‚ç‚¹**ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‰æã¨ã—ã¦ã„ã¾ã™ã€‚å¤§ä¼šç›´å‰ï¼ˆ2026å¹´5æœˆé ƒï¼‰ã®æ€ªæˆ‘äººæƒ…å ±ã‚„ç›´å‰åˆå®¿ã®ä»•ä¸ŠãŒã‚Šã«ã‚ˆã£ã¦ã€è©•ä¾¡ã¯å¤§ããå¤‰å‹•ã—ã¾ã™ã€‚\n*   **ã‚ªãƒƒã‚ºã®æ€§è³ª**: å›ç­”0ã§æç¤ºã•ã‚Œã¦ã„ã‚‹ã‚ªãƒƒã‚ºã¯ã€Œäººæ°—æŠ•ç¥¨ã€ã®å´é¢ã‚‚ã‚ã‚Šã€å¿…ãšã—ã‚‚å®ŸåŠ›ã‚’å®Œå…¨ã«åæ˜ ã—ã¦ã„ã‚‹ã‚ã‘ã§ã¯ã‚ã‚Šã¾ã›ã‚“ï¼ˆä¾‹ï¼šã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã¯äººæ°—å…ˆè¡Œã§ã‚ªãƒƒã‚ºãŒä½ããªã‚Šã‚„ã™ã„ï¼‰ã€‚\n*   **æ¨å¥¨**: æœ€ã‚‚æ·±ã„ç†è§£ã‚’å¾—ã‚‹ãŸã‚ã«ã¯ã€**å›ç­”0ã®ã€Œæ•°å€¤ãƒ‡ãƒ¼ã‚¿ã€ã§å…¨ä½“åƒã‚’æŠŠæ¡ã—ã€å›ç­”2ã®ã€Œå®šæ€§åˆ†æã€ã§èƒŒæ™¯ã‚’ç†è§£ã™ã‚‹**ã¨ã„ã†çµ„ã¿åˆã‚ã›ãŒãƒ™ã‚¹ãƒˆã§ã™ã€‚"
                }
            ]
        },
        {
            "id": "a878a895-c303-4734-b97e-3eeb99ed9582",
            "title": "0/1/2/3ã®å›ç­”ãƒ¬ãƒ™ãƒ«ã«ç‚¹æ•°ã‚’ã¤ã‘ã¦...",
            "timestamp": "2025-11-30T00:15:49.719304",
            "messages": [
                {
                    "role": "user",
                    "content": "0/1/2/3ã®å›ç­”ãƒ¬ãƒ™ãƒ«ã«ç‚¹æ•°ã‚’ã¤ã‘ã¦ã€‚\n\n\n0\nThought for 7m 43sChatGPT:ä»Šã®ãƒ‡ãƒ¼ã‚¿ã‚’å…¨éƒ¨çœºã‚ãŸã†ãˆã§ã€1ã‚«å›½ã ã‘å„ªå‹å€™è£œã‚’æŒ™ã’ã‚ã¨è¨€ã‚ã‚ŒãŸã‚‰ã€Œã‚¹ãƒšã‚¤ãƒ³ã€ã‚’æœ¬å‘½ã«äºˆæƒ³ã—ã¾ã™ã€‚\n\nãªãœã‚¹ãƒšã‚¤ãƒ³ã‚’æœ¬å‘½ã«ã™ã‚‹ã‹\nã–ã£ãã‚Šç†ç”±ã¯ã“ã®ã‚ãŸã‚Šã§ã™ï¼š\n\n\nãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ãƒ»äºˆæ¸¬å¸‚å ´ã§è»’ä¸¦ã¿1ç•ªäººæ°—\n\n\nä¸»è¦ãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã®å„ªå‹ã‚ªãƒƒã‚ºã§ã¯ã€ã‚¹ãƒšã‚¤ãƒ³ãŒå˜ç‹¬ãƒˆãƒƒãƒ—ï¼ˆãŠãŠã‚ˆãå€ç‡4.5ã€œ5.5å€å‰å¾Œï¼‰ã§1ç•ªäººæ°—ã«ãªã£ã¦ã„ã¾ã™ã€‚Talksport+2JohnnyBet+2\n\n\näºˆæ¸¬å¸‚å ´ï¼ˆãƒãƒªãƒãƒ¼ã‚±ãƒƒãƒˆãªã©ï¼‰ã§ã‚‚ã€ç¾æ™‚ç‚¹ã§å„ªå‹ç¢ºç‡ãƒˆãƒƒãƒ—ã¯ã‚¹ãƒšã‚¤ãƒ³ï¼ˆç´„17ï¼…ï¼‰ã§ã™ã€‚Polymarket\n\n\n\n\nãƒ¦ãƒ¼ãƒ­2024å„ªå‹ï¼‹ä¸–ä»£äº¤ä»£æˆåŠŸã®â€œæ—¬â€ã®ãƒãƒ¼ãƒ \n\n\nã‚¹ãƒšã‚¤ãƒ³ã¯ãƒ¦ãƒ¼ãƒ­2024ã‚’åˆ¶ã—ã¦ã„ã¦ã€ã€Œã„ã¾ä¸€ç•ªã‚¿ã‚¤ãƒˆãƒ«ã«è¿‘ã„ä»£è¡¨ã€ã¨è©•ä¾¡ã•ã‚Œã¦ã„ã¾ã™ã€‚FOX Sports+1\n\n\nãƒ©ãƒŸãƒ³ãƒ»ãƒ¤ãƒãƒ«ã‚„ãƒ‹ã‚³ãƒ»ã‚¦ã‚£ãƒªã‚¢ãƒ ã‚ºã¨ã„ã£ãŸè‹¥æ‰‹ã‚¢ã‚¿ãƒƒã‚«ãƒ¼ã«ã€ãƒ­ãƒ‰ãƒªãªã©ä¸–ç•Œãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã®ä¸­ç›¤ãŒã„ã¦ã€è‹¥ã•ï¼‹æˆç†Ÿã®ãƒãƒ©ãƒ³ã‚¹ãŒã‹ãªã‚Šè‰¯ã„ãƒãƒ¼ãƒ æ§‹æˆã§ã™ã€‚FOX Sports\n\n\n\n\nã‚¹ã‚¿ã‚¤ãƒ«ãŒåŒ—ä¸­ç±³é–‹å‚¬ã®æ¡ä»¶ã«åˆã£ã¦ã„ã‚‹ã¨è¦‹ã‚‰ã‚Œã¦ã„ã‚‹\n\n\nESPNã®ã€Œä»Šã™ãWæ¯ãŒå§‹ã¾ã£ãŸã‚‰ã©ã“ãŒå„ªå‹ã™ã‚‹ï¼Ÿã€ã¨ã„ã†ä¼ç”»ã§ã‚‚ã€â€œç·åˆçš„ã«æ¡ä»¶ã‚’ä¸€ç•ªæº€ãŸã—ã¦ã„ã‚‹â€ã¨ã„ã†ç†ç”±ã§ã‚¹ãƒšã‚¤ãƒ³ãŒæœ€æœ‰åŠ›ã¨è©•ä¾¡ã•ã‚Œã¦ã„ã¾ã™ã€‚ESPN.com\n\n\næš‘ã•ã®ä¸­ã§ã‚‚ãƒœãƒ¼ãƒ«ä¿æŒã§è©¦åˆã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã§ãã‚‹ãƒãƒ¼ãƒ ãŒæœ‰åˆ©ã€ã¨ã„ã†è¦‹æ–¹ãŒå¤šãã€ãã®ç‚¹ã§ã‚‚ã‚¹ãƒšã‚¤ãƒ³ã¯åˆè‡´ã—ã¦ã„ã‚‹ã¨ã•ã‚Œã¦ã„ã¾ã™ã€‚ESPN.com\n\n\n\n\nã‚‚ã¡ã‚ã‚“ã€Œæœ¬å‘½ã€ã¨ã„ã†ã ã‘ã§ã€å„ªå‹ç¢ºç‡ã¯ã›ã„ãœã„20ï¼…å¼±ç¨‹åº¦ã¨è¦‹ç©ã‚‚ã‚‰ã‚Œã¦ã„ã¦ã€ã€Œã‚¹ãƒšã‚¤ãƒ³ã§ã»ã¼æ±ºã¾ã‚Šã€ã¨ã„ã†ãƒ¬ãƒ™ãƒ«ã§ã¯å…¨ãã‚ã‚Šã¾ã›ã‚“ã€‚ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆã¯ä½•ãŒèµ·ãã‚‹ã‹åˆ†ã‹ã‚‰ãªã„ã§ã™ã€‚\n\nä»–ã®â€œè¶…â€æœ‰åŠ›å€™è£œãŸã¡\nã‚¹ãƒšã‚¤ãƒ³ã‚’æœ¬å‘½ã«ã—ã¤ã¤ã€åŒã˜ãã‚‰ã„æ€–ã„â€œè¶…â€å¼·è±ªã‚°ãƒ«ãƒ¼ãƒ—ãŒã“ã¡ã‚‰ï¼š\n\n\nã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰\n\n\nãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã®ã‚ªãƒƒã‚ºã§ã¯ã»ã¼å¸¸ã«2ç•ªæ‰‹ï¼ˆã‚¹ãƒšã‚¤ãƒ³ã«æ¬¡ãäººæ°—ï¼‰ã€‚Talksport+2sportsbook.draftkings.com+2\n\n\nãƒ™ãƒªãƒ³ã‚¬ãƒ ã‚’ä¸­å¿ƒã«ã‚¿ãƒ¬ãƒ³ãƒˆã¯æ­´ä»£å±ˆæŒ‡ã§ã€ã€Œãã‚ãã‚ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–ã£ã¦ã‚‚ãŠã‹ã—ããªã„ã€ã¨è¨€ã‚ã‚Œã¦ã„ã¾ã™ã€‚\n\n\n\n\nãƒ•ãƒ©ãƒ³ã‚¹\n\n\n2022å¹´ã®æº–å„ªå‹å›½ã§ã€ã‚¹ã‚«ãƒƒãƒ‰ã®åšã•ã¯ä¸–ç•Œä¸€ã¨è¨€ã‚ã‚Œã‚‹ã“ã¨ã‚‚å¤šã„ã§ã™ã€‚ã‚²ã‚­ã‚µã‚«+1\n\n\nESPNã‚„å„ç¨®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã§ã‚‚å„ªå‹å¯èƒ½æ€§1ä½ã€œ3ä½ã«å¿…ãšå…¥ã£ã¦ã„ã‚‹å¸¸é€£ã€‚ã‚²ã‚­ã‚µã‚«+1\n\n\n\n\nã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³\n\n\nå‰å›ç‹è€…ã§ã€ä¾ç„¶ã¨ã—ã¦ä¸Šä½å€™è£œã€‚ãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã§ã‚‚å„ªå‹å€™è£œãƒˆãƒƒãƒ—ã‚°ãƒ«ãƒ¼ãƒ—ï¼ˆå€ç‡8ã€œ10å€å‰å¾Œï¼‰ã€‚Talksport+2VegasInsider+2\n\n\n\n\nãƒ–ãƒ©ã‚¸ãƒ«\n\n\nã“ã“æ•°å¤§ä¼šã¯ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰é ã–ã‹ã£ã¦ã„ã¾ã™ãŒã€å€‹ã®åŠ›ã¨ã‚¿ãƒ¬ãƒ³ãƒˆå±¤ã¯ç›¸å¤‰ã‚ã‚‰ãšãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã§ã€ã‚ªãƒƒã‚ºä¸Šã‚‚å¸¸ã«ä¸Šä½ã€‚Talksport+2VegasInsider+2\n\n\n\n\nã“ã®ã‚ãŸã‚Šã¾ã§ãŒã€Œå„ªå‹ã—ã¦ã‚‚å…¨ãé©šã‹ãªã„ã€ãƒ©ã‚¤ãƒ³ã§ã™ã€‚ãã®å¾Œã‚ã«ã€ãƒãƒ«ãƒˆã‚¬ãƒ«ï¼ãƒ‰ã‚¤ãƒ„ï¼ã‚ªãƒ©ãƒ³ãƒ€ï¼ã‚¤ã‚¿ãƒªã‚¢ï¼ãƒ¢ãƒ­ãƒƒã‚³ãªã©ãŒç¶šãæ„Ÿã˜ã€‚VegasInsider+3Talksport+3SI+3\n\næ—¥æœ¬ã¯ã©ã®ãã‚‰ã„ã®ä½ç½®ã¥ã‘ï¼Ÿ\næ—¥æœ¬ä»£è¡¨ã¯ã€æµ·å¤–ã‚µã‚¤ãƒˆã®ãƒ‘ãƒ¯ãƒ¼ãƒ©ãƒ³ã‚¯ã‚„ã‚ªãƒƒã‚ºã§ã¯ã ã„ãŸã„**â€œãƒ€ãƒ¼ã‚¯ãƒ›ãƒ¼ã‚¹æ â€**ãã‚‰ã„ã®æ‰±ã„ã§ã™ã€‚\n\n\nãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã®å„ªå‹ã‚ªãƒƒã‚ºã§ã¯ã€æ—¥æœ¬ã¯ä¸­å …ã€œä¸‹ä½ã®ã‚°ãƒ«ãƒ¼ãƒ—ã§ã™ãŒã€æ±ºã—ã¦æœ€ä¸‹ä½ã§ã¯ãªãã€Œå¯èƒ½æ€§ã¯ä½ã„ãŒã€å…¨ãã®ãƒãƒ¼ãƒãƒ£ãƒ³ã‚¹ã§ã‚‚ãªã„ã€ã¨ã„ã†ãƒã‚¸ã‚·ãƒ§ãƒ³ã€‚VegasInsider+1\n\n\nESPNã‚„æ—¥æœ¬ãƒ¡ãƒ‡ã‚£ã‚¢ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã§ã‚‚ã€ã€Œãƒ™ã‚¹ãƒˆ8ä»¥ä¸Šã«é£Ÿã„è¾¼ã‚€ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã¯ã‚ã‚‹ã€ã¨è©•ä¾¡ã™ã‚‹å£°ãŒå°‘ã—ãšã¤å¢—ãˆã¦ãã¦ã„ã¾ã™ã€‚ã‚²ã‚­ã‚µã‚«+1\n\n\næ•°å€¤çš„ã«ã¯ã€å„ªå‹ç¢ºç‡ã¯æ•°ï¼…æœªæº€ãã‚‰ã„ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã™ãŒã€1å›ã®å¤§ä¼šã§ç•ªç‹‚ã‚ã›ã¯æ™®é€šã«èµ·ã“ã‚‹ã®ã§ã€ä»Šã®ã†ã¡ã‹ã‚‰ãƒãƒ¼ãƒ ä½œã‚Šæ¬¡ç¬¬ã§ä¸€æ°—ã«ç¾å®Ÿå‘³ãŒå¢—ã™ã‚¾ãƒ¼ãƒ³ã§ã™ã€‚\n\nã‚®ãƒ£ãƒ³ãƒ–ãƒ«çš„ãªè©±ã«ã¤ã„ã¦\næƒ…å ±æºã¨ã—ã¦ã‚ªãƒƒã‚ºã‚„äºˆæ¸¬å¸‚å ´ã®æ•°å­—ã‚’ä½¿ã„ã¾ã—ãŸãŒã€\nã€Œè³­ã‘ã‚’ã—ã‚ˆã†ã€ã¨ã„ã†æ„å‘³ã§ã¯ã¾ã£ãŸãã‚ã‚Šã¾ã›ã‚“ã€‚\nç‰¹ã«æ—¥æœ¬ã§ã¯å¤šãã®ã‚¹ãƒãƒ¼ãƒ„ãƒ™ãƒƒãƒ†ã‚£ãƒ³ã‚°ãŒé•æ³•ãªã®ã§ã€ãã®ç‚¹ã¯åˆ‡ã‚Šé›¢ã—ã¦â€œè©•ä¾¡æŒ‡æ¨™ã®ã²ã¨ã¤â€ã¨ã—ã¦ã ã‘è¦‹ã¦ãã ã•ã„ã€‚\n\nã¾ã¨ã‚\n\n\næœ¬å‘½äºˆæƒ³ï¼šã‚¹ãƒšã‚¤ãƒ³\n\n\næ¬¡ç‚¹ï¼šã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã€ãƒ•ãƒ©ãƒ³ã‚¹ã€ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã€ãƒ–ãƒ©ã‚¸ãƒ«\n\n\nãã®å¾Œã«ãƒãƒ«ãƒˆã‚¬ãƒ«ã€ãƒ‰ã‚¤ãƒ„ã€ã‚ªãƒ©ãƒ³ãƒ€ã€ã‚¤ã‚¿ãƒªã‚¢ã€ãƒ¢ãƒ­ãƒƒã‚³ãªã©\n\n\nã€Œ1ã‚«å›½ã ã‘åå‰ã‚’æ›¸ã„ã¦ãã ã•ã„ã€ã¨è¨€ã‚ã‚ŒãŸã‚‰ã€ç§ã¯ã‚¹ãƒšã‚¤ãƒ³ã«â—ã‚’ä»˜ã‘ã¾ã™ã€‚\n\næœ€æ–°ã®Wæ¯é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚‚ã€ã–ã£ã¨è¿½ãˆã‚‹ã‚‚ã®ã‚’ç½®ã„ã¦ãŠãã¾ã™ğŸ‘‡\n2026å¹´Wæ¯æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹TalksportWorld Cup winner odds: An early look at who the bookies are backing to lift the trophy in 2026ä¸€æ˜¨æ—¥The GuardianSocceroos get lucky with place in second highest pot for World Cup draw3 æ—¥å‰The SunEngland could have to beat FOUR giants in nightmare path to World Cup 2026 final as new draw system is revealed3 æ—¥å‰News.com.auFIFA World Cup 2026: Australia to avoid top teams in first draw3 æ—¥å‰\nä»–ã«ã€Œæ—¥æœ¬ä»£è¡¨ã«çµã£ãŸç¾å®Ÿçš„ãªç›®æ¨™ã€ã¨ã‹ã€Œãƒ€ãƒ¼ã‚¯ãƒ›ãƒ¼ã‚¹å€™è£œã ã‘çŸ¥ã‚ŠãŸã„ã€ã¨ã‹ã‚ã‚Œã°ã€ãã“ã«çµã£ã¦æ•´ç†ã‚‚ã§ãã¾ã™ã‚ˆã€‚\n\n\n\n\n\n1\næ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\nä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\n\nç”·å­ã‚µãƒƒã‚«ãƒ¼ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½ã‚’äºˆæ¸¬ã—ã¦\n\nå®Œäº†ï¼\n\n2025å¹´11æœˆæ™‚ç‚¹ã®æœ€æ–°ãƒ‡ãƒ¼ã‚¿ï¼ˆFIFAãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€ãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã‚ªãƒƒã‚ºã€ç›´è¿‘ã®ä¸»è¦å¤§ä¼šæˆç¸¾ï¼‰ã«åŸºã¥ãã€2026å¹´ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½ã‚’äºˆæ¸¬ãƒ»åˆ†æã—ã¾ã™ã€‚\n\nçµè«–ï¼šã‚¹ãƒšã‚¤ãƒ³ãŒçµ±è¨ˆçš„ãƒ»æˆ¦è¡“çš„ã«ãƒªãƒ¼ãƒ‰ã€è¿½ã†ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã¨ãƒ•ãƒ©ãƒ³ã‚¹\nç¾æ™‚ç‚¹ã§ã®æœ€æœ‰åŠ›å€™è£œã¯ã‚¹ãƒšã‚¤ãƒ³ã§ã™ã€‚2024å¹´EUROå„ªå‹ã®å®Ÿç¸¾ã¨ã€æ”»å®ˆã®ãƒãƒ©ãƒ³ã‚¹ã®è‰¯ã•ãŒè©•ä¾¡ã•ã‚Œã€FIFAãƒ©ãƒ³ã‚­ãƒ³ã‚°1ä½ãŠã‚ˆã³ãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã®ã‚ªãƒƒã‚ºï¼ˆç´„18-20%ï¼‰ã§ãƒˆãƒƒãƒ—ã«ç«‹ã£ã¦ã„ã¾ã™ã€‚\n\nãŸã ã—ã€çµ¶å¯¾çš„ãªä¸€å¼·çŠ¶æ…‹ã§ã¯ãªãã€ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆã«æ»…æ³•å¼·ã„å‰å›ç‹è€…ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã€ä¸–ç•Œæœ€é«˜ã®é¸æ‰‹å±¤ã‚’æŒã¤ãƒ•ãƒ©ãƒ³ã‚¹ãŒåƒ…å·®ã§ç¶šãã€Œä¸‰ã¤å·´ã€ã«è¿‘ã„æ§‹å›³ã§ã™ã€‚\n\nã‚·ãƒŠãƒªã‚ªåˆ¥äºˆæ¸¬åˆ†æ\nã‚·ãƒŠãƒªã‚ªAï¼šã‚¹ãƒšã‚¤ãƒ³ã«ã‚ˆã‚‹ã€Œæ–°ãƒ»é»„é‡‘æœŸã€ã®è¨¼æ˜ï¼ˆç¢ºç‡ï¼šé«˜ï¼‰\næœ€ã‚‚è“‹ç„¶æ€§ãŒé«˜ã„ã‚·ãƒŠãƒªã‚ªã§ã™ã€‚\n\næ ¹æ‹ : 2024å¹´EUROã§ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã‚’ç ´ã‚Šå„ªå‹ã€‚ç¾åœ¨FIFAãƒ©ãƒ³ã‚­ãƒ³ã‚°1ä½ï¼ˆ1877.18 ptï¼‰ã€‚\nå¼·ã¿: ãƒ©ãƒŸãƒ³ãƒ»ãƒ¤ãƒãƒ«ã€ãƒ‹ã‚³ãƒ»ã‚¦ã‚£ãƒªã‚¢ãƒ ã‚ºã‚‰è‹¥æ‰‹ã®çˆ†ç™ºåŠ›ã¨ã€ãƒ­ãƒ‰ãƒªã‚’ä¸­å¿ƒã¨ã—ãŸä¸­ç›¤ã®æ§‹æˆåŠ›ãŒå™›ã¿åˆã£ã¦ã„ã¾ã™ã€‚2010å¹´å¤§ä¼šå„ªå‹æ™‚ã®ã‚ˆã†ãªã€Œã‚·ã‚¹ãƒ†ãƒ ã§å‹ã¤ã€ã‚µãƒƒã‚«ãƒ¼ãŒå®Œæˆã—ã¤ã¤ã‚ã‚Šã¾ã™ã€‚\næ‡¸å¿µ: è‹¥æ‰‹ä¸»ä½“ã®ãƒãƒ¼ãƒ ã§ã‚ã‚‹ãŸã‚ã€Wæ¯ç‰¹æœ‰ã®ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã«å¯¾ã™ã‚‹çµŒé¨“å€¤ä¸è¶³ãŒå”¯ä¸€ã®ãƒªã‚¹ã‚¯ã§ã™ã€‚\nã‚·ãƒŠãƒªã‚ªBï¼šå®Ÿç¸¾çµ„ï¼ˆã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ãƒ»ãƒ•ãƒ©ãƒ³ã‚¹ï¼‰ã®åº•åŠ›ï¼ˆç¢ºç‡ï¼šä¸­ï¼‰\nå€‹ã®åŠ›ã‚„çµŒé¨“å€¤ãŒã€çµ„ç¹”åŠ›ã‚’å‡Œé§•ã™ã‚‹ã‚·ãƒŠãƒªã‚ªã§ã™ã€‚\n\nğŸ‡¦ğŸ‡· ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³:\nå¼·ã¿: 2022å¹´Wæ¯ã€2024å¹´ã‚³ãƒ‘ãƒ»ã‚¢ãƒ¡ãƒªã‚«ã‚’é€£è¦‡ä¸­ã€‚ãƒ¡ãƒƒã‚·ã‚’ä¸­å¿ƒã¨ã—ãŸçµæŸåŠ›ã¨ã€çŸ­æœŸæ±ºæˆ¦ã§ã®å‹è² å¼·ã•ã¯ä¸–ç•Œä¸€ã§ã™ã€‚\nãƒªã‚¹ã‚¯: ä¸»åŠ›ã®é«˜é½¢åŒ–ãŒé€²ã‚“ã§ãŠã‚Šã€2026å¹´å¤ã«2022å¹´ã¨åŒç­‰ã®é‹å‹•é‡ã‚’ç¶­æŒã§ãã‚‹ã‹ãŒéµã¨ãªã‚Šã¾ã™ã€‚\nğŸ‡«ğŸ‡· ãƒ•ãƒ©ãƒ³ã‚¹:\nå¼·ã¿: ã‚­ãƒªã‚¢ãƒ³ãƒ»ã‚¨ãƒ ãƒãƒšã¨ã„ã†ã€Œå€‹ã€ã®æ‰“é–‹åŠ›ã«åŠ ãˆã€å…¨ãƒã‚¸ã‚·ãƒ§ãƒ³ã«ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚¯ãƒ©ã‚¹ã‚’æƒãˆã‚‹é¸æ‰‹å±¤ï¼ˆDepthï¼‰ã¯48ã‚«å›½åˆ¶ã®é•·ä¸å ´ã§æœ€å¤§ã®æ­¦å™¨ã¨ãªã‚Šã¾ã™ã€‚\nãƒªã‚¹ã‚¯: ãƒ‡ã‚·ãƒ£ãƒ³ç›£ç£ä½“åˆ¶ã®é•·æœŸåŒ–ã«ã‚ˆã‚‹æˆ¦è¡“çš„ãªåœæ»æ„ŸãŒæŒ‡æ‘˜ã•ã‚Œã¦ã„ã¾ã™ã€‚\nã‚·ãƒŠãƒªã‚ªCï¼šçœ ã‚Œã‚‹å·¨äººã®è¦šé†’ã¨æ³¢ä¹±ï¼ˆç¢ºç‡ï¼šä½ï½ä¸­ï¼‰\nå¸‚å ´è©•ä¾¡ã¨ç¾çŠ¶ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ä¹–é›¢ãŒã‚ã‚‹ãƒãƒ¼ãƒ ã®å‹•å‘ã§ã™ã€‚\n\nğŸ‡§ğŸ‡· ãƒ–ãƒ©ã‚¸ãƒ«:\nç¾çŠ¶: å—ç±³äºˆé¸ã§è‹¦æˆ¦ï¼ˆä¸€æ™‚5ä½ãƒ»6ä½ï¼‰ã—ã¦ã„ã¾ã™ãŒã€ã‚ªãƒƒã‚ºã§ã¯ä¾ç„¶ã¨ã—ã¦ä¸Šä½ï¼ˆ+650ï½+750ï¼‰ã§ã™ã€‚\nåˆ†æ: ãƒ´ã‚£ãƒ‹ã‚·ã‚¦ã‚¹ã‚‰å‰ç·šã®ã‚¿ãƒ¬ãƒ³ãƒˆåŠ›ã¯éšä¸€ã§ã™ã€‚å¤§ä¼šã¾ã§ã«å®ˆå‚™ã®ä¸å®‰å®šã•ã‚’è§£æ¶ˆã§ãã‚Œã°ã€ä¸€æ°—ã«å„ªå‹å€™è£œç­†é ­ã¸è¿”ã‚Šå’²ããƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ãŒã‚ã‚Šã¾ã™ã€‚\nğŸ´ ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰:\nç¾çŠ¶: 2024å¹´EUROæº–å„ªå‹ã€‚ã‚¿ãƒ¬ãƒ³ãƒˆåŠ›ã¯ã‚¹ãƒšã‚¤ãƒ³ã«åŒ¹æ•µã—ã¾ã™ãŒã€å‹è² æ‰€ã§ã®ç²¾ç¥çš„ãªè„†ã•ãŒèª²é¡Œã§ã™ã€‚\næ³¨ç›®ã™ã¹ããƒ€ãƒ¼ã‚¯ãƒ›ãƒ¼ã‚¹\nğŸ‡ºğŸ‡¾ ã‚¦ãƒ«ã‚°ã‚¢ã‚¤: ãƒ“ã‚¨ãƒ«ã‚µç›£ç£ã®ä¸‹ã€å—ç±³äºˆé¸ã§ãƒ–ãƒ©ã‚¸ãƒ«ãƒ»ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã‚’æ’ƒç ´ã€‚æˆ¦è¡“çš„ãªå®Œæˆåº¦ãŒé«˜ãã€ä¸Šä½å›½ã‚’é£Ÿã†å¯èƒ½æ€§ãŒæœ€ã‚‚é«˜ã„ãƒãƒ¼ãƒ ã§ã™ã€‚\nğŸ‡¨ğŸ‡¦ ã‚«ãƒŠãƒ€: é–‹å‚¬å›½ï¼ˆã‚¢ãƒ¡ãƒªã‚«ãƒ»ãƒ¡ã‚­ã‚·ã‚³ãƒ»ã‚«ãƒŠãƒ€ï¼‰ã®ä¸­ã§æœ€ã‚‚å¥½èª¿ï¼ˆã‚³ãƒ‘ãƒ»ã‚¢ãƒ¡ãƒªã‚«2024ãƒ™ã‚¹ãƒˆ4ï¼‰ã€‚åœ°ã®åˆ©ã‚’æ´»ã‹ã—ãŸèºé€²ãŒæœŸå¾…ã•ã‚Œã¾ã™ã€‚\n2026å¹´å¤§ä¼šç‰¹æœ‰ã®é‡è¦å¤‰æ•°\näºˆæ¸¬ã‚’å·¦å³ã™ã‚‹ã€ä»Šå¤§ä¼šç‰¹æœ‰ã®å¤–çš„è¦å› ã§ã™ã€‚\n\n48ã‚«å›½åˆ¶ã¸ã®æ‹¡å¤§ï¼ˆæ¶ˆè€—æˆ¦ï¼‰: è©¦åˆæ•°ãŒå¢—åŠ ã™ã‚‹ãŸã‚ã€ã‚¹ã‚¿ãƒ¡ãƒ³11äººã ã‘ã§ãªãã€ãƒ™ãƒ³ãƒãƒ¡ãƒ³ãƒãƒ¼ã‚’å«ã‚ãŸ26äººã®ç·åˆåŠ›ãŒå•ã‚ã‚Œã¾ã™ã€‚ã“ã‚Œã¯é¸æ‰‹å±¤ã®åšã„ãƒ•ãƒ©ãƒ³ã‚¹ã‚„ã‚¹ãƒšã‚¤ãƒ³ã«æœ‰åˆ©ã«åƒãã¾ã™ã€‚\nç§»å‹•è·é›¢ã¨æ°—å€™: åŒ—ç±³3ã‚«å›½ã«ã¾ãŸãŒã‚‹åºƒå¤§ãªç§»å‹•ã¨ã€å¤ã®é…·æš‘ãƒ»æ¹¿åº¦ã¯ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ç¶­æŒã‚’å›°é›£ã«ã—ã¾ã™ã€‚ç‰¹å®šã®ç’°å¢ƒã¸ã®é©å¿œåŠ›ãŒä½ã„ãƒãƒ¼ãƒ ã¯ã€å®ŸåŠ›ãŒã‚ã£ã¦ã‚‚æ—©æœŸæ•—é€€ã™ã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚\nå‚ç…§ã‚½ãƒ¼ã‚¹\nFIFA Men's World Ranking (Nov 2025)\nFOX Sports / DraftKings Betting Odds (Nov 2025)\nUEFA Euro 2024 / Copa AmÃ©rica 2024 Results\nğŸ“š æƒ…å ±æºã¨å¼•ç”¨\næ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:\n\npolymarket.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nwikipedia.org\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nsi.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nreddit.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfifa.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nsportingnews.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nyoutube.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\naiscore.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfoxsports.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nsportsbookreview.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nforbes.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nwikipedia.org\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfifa.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nelisportsnetwork.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nolympics.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\ntntsports.co.uk\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfifa.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\n\n\n2æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\nä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\n\nç”·å­ã‚µãƒƒã‚«ãƒ¼ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½ã‚’äºˆæ¸¬ã—ã¦\n\nå®Œäº†ï¼\n\n2025å¹´11æœˆ29æ—¥æ™‚ç‚¹ã®æœ€æ–°ãƒ‡ãƒ¼ã‚¿ãŠã‚ˆã³èª¿æŸ»çµæœã«åŸºã¥ãã€2026å¹´åŒ—ä¸­ç±³ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½äºˆæ¸¬ã‚’æç¤ºã—ã¾ã™ã€‚\n\n1. æ·±æ˜ã‚Šè€ƒå¯Ÿï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\nQ1. åŒ—ä¸­ç±³é–‹å‚¬ï¼ˆé…·æš‘ãƒ»ç§»å‹•ãƒ»æ™‚å·®ï¼‰ã¯ã©ã®ã‚¹ã‚¿ã‚¤ãƒ«ã«æœ‰åˆ©ã‹ï¼Ÿ éå»ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆ1994å¹´ç±³å›½å¤§ä¼šã‚„2014å¹´ãƒ–ãƒ©ã‚¸ãƒ«å¤§ä¼šï¼‰ã‚’å‚ç…§ã™ã‚‹ã¨ã€é…·æš‘ä¸‹ã§ã¯ã€Œãƒœãƒ¼ãƒ«ã‚’ä¿æŒã—ã¦ä½“åŠ›ã‚’æ¸©å­˜ã§ãã‚‹ã€æŠ€è¡“é‡è¦–ã®ãƒãƒ¼ãƒ ï¼ˆã‚¹ãƒšã‚¤ãƒ³ç­‰ï¼‰ã«ä¸€å®šã®ç†ãŒã‚ã‚Šã¾ã™ã€‚ã—ã‹ã—ã€å®ˆå‚™ã«å›ã£ãŸéš›ã®æ¶ˆè€—åº¦ã¯æ¿€ã—ããªã‚‹ãŸã‚ã€æœ€çµ‚çš„ã«ã¯ç‰¹å®šã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚ˆã‚Šã‚‚ã€æ°—å€™é †å¿œæ€§ãŒé«˜ã„å—ç±³å‹¢ã‚„ã€æ¶ˆè€—æˆ¦ã«è€ãˆã†ã‚‹ã€Œãƒ•ã‚£ã‚¸ã‚«ãƒ«ãƒ™ãƒ¼ã‚¹ã®é¸æ‰‹å±¤ã€ã‚’æŒã¤ãƒãƒ¼ãƒ ãŒæœ‰åˆ©ã«åƒãå‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚\n\nQ2. 48ã‚«å›½æ‹¡å¤§ãƒ»è©¦åˆå¢—ã«ãŠã„ã¦ã€é¸æ‰‹å±¤ã§ã‚¹ãƒšã‚¤ãƒ³ç­‰ã‚’å‡Œé§•ã™ã‚‹å›½ã¯ï¼Ÿ ãƒ•ãƒ©ãƒ³ã‚¹ã¨ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã§ã™ã€‚ã“ã®2ã‚«å›½ã¯ã€å„ãƒã‚¸ã‚·ãƒ§ãƒ³ã«ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚¯ãƒ©ã‚¹ã‚’2ã€œ3åæƒãˆã¦ãŠã‚Šã€ã‚¿ãƒ¼ãƒ³ã‚ªãƒ¼ãƒãƒ¼ï¼ˆé¸æ‰‹ã®å…¥ã‚Œæ›¿ãˆï¼‰ã‚’è¡Œã£ã¦ã‚‚æˆ¦åŠ›ãŒè½ã¡ã¾ã›ã‚“ã€‚ç‰¹ã«ãƒ•ãƒ©ãƒ³ã‚¹ã®ãƒ•ã‚£ã‚¸ã‚«ãƒ«çš„ãªé¸æ‰‹å±¤ã®åšã•ã¯ã€ç§»å‹•è·é›¢ãŒé•·ãè©¦åˆæ•°ãŒå¢—ãˆã‚‹ä»Šå¤§ä¼šã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§æœ€å¤§ã®æ­¦å™¨ã¨ãªã‚Šã¾ã™ã€‚\n\nQ3. ã‚¹ãƒšã‚¤ãƒ³ã®ãƒã‚¼ãƒƒã‚·ãƒ§ãƒ³ã«å¯¾ã™ã‚‹æœ‰åŠ¹ãªå¯¾æŠ—ç­–ã¯ï¼Ÿ ã€Œä¸­ç›¤ã§ã®ãƒ•ã‚£ã‚¸ã‚«ãƒ«å¼·åº¦ã«ã‚ˆã‚‹åˆ†æ–­ã€ã¨ã€Œé«˜é€Ÿã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã€ã§ã™ã€‚2025å¹´ç¾åœ¨ã®ã‚¹ãƒšã‚¤ãƒ³ã¯å®Œæˆåº¦ãŒé«˜ã„ã‚‚ã®ã®ã€åŒ—ç±³ã®æš‘ã•ã§é‹å‹•é‡ãŒè½ã¡ãŸæ™‚é–“å¸¯ã«ã€ãƒ•ãƒ©ãƒ³ã‚¹ã‚„ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã®ã‚ˆã†ãªãƒ•ã‚£ã‚¸ã‚«ãƒ«ã«å„ªã‚ŒãŸãƒãƒ¼ãƒ ã‹ã‚‰ãƒã‚¤ãƒ—ãƒ¬ã‚¹ã‚’å—ã‘ã‚‹ã¨ã€å®ˆå‚™ã®è„†ã•ãŒéœ²å‘ˆã™ã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚\n\nQ4. ãƒ–ãƒ©ã‚¸ãƒ«ãŒè©•ä¾¡ã‚’è¦†ã—ã¦å„ªå‹ã™ã‚‹ãŸã‚ã®æ¡ä»¶ã¯ï¼Ÿ ã€Œå®ˆå‚™çµ„ç¹”ã®å®‰å®šã€ã¨ã€Œãƒ´ã‚£ãƒ‹ã‚·ã‚¦ã‚¹ã‚‰ç¾ã‚¨ãƒ¼ã‚¹ã¸ã®æˆ¦è¡“æœ€é©åŒ–ã€ã§ã™ã€‚å€‹ã®èƒ½åŠ›ã¯ä¾ç„¶ã¨ã—ã¦ä¸–ç•Œæœ€é«˜å³°ã§ã™ãŒã€äºˆé¸ã§è‹¦æˆ¦ã—ãŸçµ„ç¹”çš„ãªè„†ã•ã‚’ä¿®æ­£ã—ã€ãƒã‚¤ãƒãƒ¼ãƒ«æ™‚ä»£ã®å¹»å½±ã‹ã‚‰è„±å´ã—ã¦ç¾æœ‰æˆ¦åŠ›ã§å®Œçµã™ã‚‹ãƒãƒ¼ãƒ ã‚’ä½œã‚Œã‚‹ã‹ãŒéµã¨ãªã‚Šã¾ã™ã€‚\n\nQ5. ãƒˆã‚¥ãƒ˜ãƒ«ç›£ç£ï¼ˆã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ï¼‰ã®ã‚ˆã†ãªåå°†ã®å°±ä»»ã¯ãƒ—ãƒ©ã‚¹ã‹ï¼Ÿ æ¥µã‚ã¦å¤§ããªãƒ—ãƒ©ã‚¹è¦å› ã§ã™ã€‚ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®ã‚ˆã†ãªçŸ­æœŸæ±ºæˆ¦ã§ã¯ã€è¤‡é›‘ãªãƒãƒ¼ãƒ ä½œã‚Šã‚ˆã‚Šã‚‚ã€ç›¸æ‰‹ã®å¼±ç‚¹ã‚’çªãæˆ¦è¡“çœ¼ã¨ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆèƒ½åŠ›ãŒå•ã‚ã‚Œã¾ã™ã€‚ãƒˆã‚¥ãƒ˜ãƒ«ç›£ç£ã®ã‚«ãƒƒãƒ—æˆ¦ã§ã®å¼·ã•ï¼ˆãƒã‚§ãƒ«ã‚·ãƒ¼ã§ã®CLå„ªå‹ãªã©ï¼‰ã¯ã€ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã®èª²é¡Œã§ã‚ã‚‹ã€Œå‹è² å¼±ã•ã€ã‚’è£œå®Œã™ã‚‹æœ€é©è§£ã¨è¨€ãˆã¾ã™ã€‚\n\n2. çµè«–\næœ€æœ‰åŠ›å€™è£œï¼šã‚¹ãƒšã‚¤ãƒ³ å¯¾æŠ—é¦¬ï¼šã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã€ãƒ•ãƒ©ãƒ³ã‚¹ã€ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰\n\n2025å¹´11æœˆç¾åœ¨ã€ã‚¹ãƒšã‚¤ãƒ³ãŒé ­ä¸€ã¤æŠœã‘ãŸå„ªå‹å€™è£œã§ã™ã€‚EURO 2024å„ªå‹ã€ãƒ‘ãƒªäº”è¼ªé‡‘ãƒ¡ãƒ€ãƒ«ã¨ã„ã†ç›´è¿‘ã®å®Ÿç¸¾ã«åŠ ãˆã€è‹¥æ‰‹ã¨ãƒ™ãƒ†ãƒ©ãƒ³ãŒèåˆã—ãŸãƒãƒ¼ãƒ ã®å®Œæˆåº¦ã¯ç¾¤ã‚’æŠœã„ã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€é–‹å‚¬åœ°ã®ç’°å¢ƒã‚„é¸æ‰‹å±¤ã‚’è€ƒæ…®ã™ã‚‹ã¨ã€ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã®çµæŸåŠ›ã€ãƒ•ãƒ©ãƒ³ã‚¹ã¨ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã®å€‹ã®åŠ›ãŒåƒ…å·®ã§è¿½ã†ã€Œ4å¼·ã€ã®æ§‹å›³ã¨ãªã‚Šã¾ã™ã€‚\n\n3. è©³ç´°ãªåˆ†æ\næœ¬å‘½ï¼šã‚¹ãƒšã‚¤ãƒ³ï¼ˆFIFAãƒ©ãƒ³ã‚¯1ä½ï¼‰\näºˆæ¸¬æ ¹æ‹ : ç¾åœ¨ã€ä¸–ç•Œã§æœ€ã‚‚æ©Ÿèƒ½ã—ã¦ã„ã‚‹ãƒãƒ¼ãƒ ã§ã™ã€‚ãƒ©ãƒŸãƒ³ãƒ»ãƒ¤ãƒãƒ«ã‚‰ã€Œæ–°é»„é‡‘ä¸–ä»£ã€ãŒå®Œå…¨ã«ä¸»åŠ›ã¨ã—ã¦å®šç€ã—ã€2024å¹´ã®ä¸»è¦ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç‹¬å ã—ã¾ã—ãŸã€‚\nå¼·ã¿: åœ§å€’çš„ãªãƒœãƒ¼ãƒ«æ”¯é…åŠ›ã«åŠ ãˆã€ä»¥å‰ã®ã‚¹ãƒšã‚¤ãƒ³ã«ã¯æ¬ ã‘ã¦ã„ãŸã€Œç¸¦ã¸ã®çªç ´åŠ›ã€ã‚’å…¼ã­å‚™ãˆã¦ã„ã¾ã™ã€‚è‡ªåˆ†ãŸã¡ã®ãƒšãƒ¼ã‚¹ã§è©¦åˆã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã§ãã‚‹ãŸã‚ã€éé…·ãªç’°å¢ƒä¸‹ã§ã‚‚ä½“åŠ›ã‚’æ¸©å­˜ã—ãªãŒã‚‰å‹ã¡ä¸ŠãŒã‚‹å…¬ç®—ãŒé«˜ã„ã§ã™ã€‚\nå¯¾æŠ—ï¼šã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ï¼ˆFIFAãƒ©ãƒ³ã‚¯2ä½ï¼‰\näºˆæ¸¬æ ¹æ‹ : ã‚³ãƒ‘ãƒ»ã‚¢ãƒ¡ãƒªã‚«2024ã‚’åˆ¶ã—ã€ãƒ¡ã‚¸ãƒ£ãƒ¼å¤§ä¼š3é€£è¦‡ã‚’é”æˆã—ãŸã€Œå‹è€…ã®ãƒ¡ãƒ³ã‚¿ãƒªãƒ†ã‚£ã€ã¯å¥åœ¨ã§ã™ã€‚\nå¼·ã¿: ãƒãƒ¼ãƒ ã®çµæŸåŠ›ã¯ä¸–ç•Œä¸€ã§ã™ã€‚ãƒ¡ãƒƒã‚·ã®å¹´é½¢ï¼ˆ39æ­³ã«ãªã‚‹å¹´ï¼‰ã¯æ‡¸å¿µææ–™ã§ã™ãŒã€å½¼ã‚’æ”¯ãˆã‚‹å‘¨å›²ã®çŒ®èº«æ€§ã¨ã€ã‚¹ã‚«ãƒ­ãƒ¼ãƒ‹ç›£ç£ã®æŸ”è»Ÿãªé‡‡é…ã«ã‚ˆã‚Šã€ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆã‚’å‹ã¡æŠœãè¡“ã‚’ç†ŸçŸ¥ã—ã¦ã„ã¾ã™ã€‚å—åŒ—ã‚¢ãƒ¡ãƒªã‚«å¤§é™¸é–‹å‚¬ã¨ã„ã†ã€Œåœ°ã®åˆ©ã€ã‚‚å¤§ããªå¾ŒæŠ¼ã—ã¨ãªã‚Šã¾ã™ã€‚\næœ‰åŠ›ï¼šã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ï¼ˆFIFAãƒ©ãƒ³ã‚¯4ä½ï¼‰\näºˆæ¸¬æ ¹æ‹ : ãƒˆãƒ¼ãƒã‚¹ãƒ»ãƒˆã‚¥ãƒ˜ãƒ«ç›£ç£ã®å°±ä»»ï¼ˆ2025å¹´ï¼‰ã«ã‚ˆã‚Šã€æˆ¦è¡“çš„ãªè¦å¾‹ã¨å‹è² å¼·ã•ãŒåŠ ã‚ã‚Šã¾ã—ãŸã€‚ãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã®ã‚ªãƒƒã‚ºã§ã‚‚ã‚¹ãƒšã‚¤ãƒ³ã«æ¬¡ãè©•ä¾¡ã‚’å¾—ã¦ã„ã¾ã™ã€‚\nå¼·ã¿: ãƒ™ãƒªãƒ³ã‚¬ãƒ ã€ã‚±ã‚¤ãƒ³ã€ã‚µã‚«ãªã©ã€å€‹ã®ã‚¿ãƒ¬ãƒ³ãƒˆåŠ›ã¯ã‚¹ãƒšã‚¤ãƒ³ã‚’ã‚‚å‡Œãã¾ã™ã€‚ãƒˆã‚¥ãƒ˜ãƒ«ç›£ç£ã®æŒ‡æ®ä¸‹ã§å®ˆå‚™ãŒå®‰å®šã™ã‚Œã°ã€60å¹´ã¶ã‚Šã®å„ªå‹ãŒç¾å®Ÿå‘³ã‚’å¸¯ã³ã¾ã™ã€‚\nä¸æ°—å‘³ãªå­˜åœ¨ï¼šãƒ•ãƒ©ãƒ³ã‚¹ï¼ˆFIFAãƒ©ãƒ³ã‚¯3ä½ï¼‰\näºˆæ¸¬æ ¹æ‹ : å¸¸ã«å„ªå‹å€™è£œã«æŒ™ãŒã‚‹é¸æ‰‹å±¤ã®åšã•ãŒã‚ã‚Šã¾ã™ã€‚\nå¼·ã¿: ã‚­ãƒªã‚¢ãƒ³ãƒ»ã‚¨ãƒ ãƒãƒšã‚’ä¸­å¿ƒã¨ã—ãŸæ”»æ’ƒåŠ›ã¨ã€ä¸­ç›¤ã®ãƒ•ã‚£ã‚¸ã‚«ãƒ«å¼·åº¦ã¯ä¸–ç•Œå±ˆæŒ‡ã€‚48ã‚«å›½å‡ºå ´ã«ã‚ˆã‚‹é•·ä¸å ´ã®å¤§ä¼šã«ãŠã„ã¦ã€èª°ãŒå‡ºã¦ã‚‚å¼·ã„ã¨ã„ã†ã€Œå±¤ã®åšã•ã€ã¯æœ€å¤§ã®æ­¦å™¨ã§ã™ã€‚\n4. è€ƒæ…®ã™ã¹ããƒªã‚¹ã‚¯è¦å› \nåŒ—ä¸­ç±³ç‰¹æœ‰ã®ç’°å¢ƒï¼ˆãƒ’ãƒ¼ãƒˆï¼†ãƒ‡ã‚£ã‚¹ã‚¿ãƒ³ã‚¹ï¼‰: ã‚¢ãƒ¡ãƒªã‚«ã€ã‚«ãƒŠãƒ€ã€ãƒ¡ã‚­ã‚·ã‚³ã®3ã‚«å›½é–‹å‚¬ã«ã‚ˆã‚‹ç§»å‹•è·é›¢ã®é•·ã•ã¨ã€ä¸€éƒ¨ä¼šå ´ã®é…·æš‘ã¯ã€æ¬§å·å‹¢ã®ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã‚’å´©ã™æœ€å¤§ã®è¦å› ã¨ãªã‚Šå¾—ã¾ã™ã€‚éå»ã€åŒ—å—ç±³é–‹å‚¬ã®Wæ¯ã§æ¬§å·å‹¢ãŒå„ªå‹ã—ãŸã®ã¯2014å¹´ã®ãƒ‰ã‚¤ãƒ„ã®ã¿ã§ã™ã€‚ã“ã®ã‚¸ãƒ³ã‚¯ã‚¹ã¯å—ç±³å‹¢ï¼ˆã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã€ãƒ–ãƒ©ã‚¸ãƒ«ï¼‰ã«ã¨ã£ã¦è¿½ã„é¢¨ã§ã™ã€‚\n\nå¤§ä¼šãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å¤‰æ›´: å‡ºå ´å›½ãŒ48ã‚«å›½ã«å¢—ãˆã€æ±ºå‹ã¾ã§ã®è©¦åˆæ•°ãŒæœ€å¤§8è©¦åˆã«å¢—åŠ ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç‰¹å®šã®ã‚¹ã‚¿ãƒ¼é¸æ‰‹ã«ä¾å­˜ã™ã‚‹ãƒãƒ¼ãƒ ï¼ˆä¾‹ï¼šãƒ¡ãƒƒã‚·ä¾å­˜ã®ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã€ãƒ‡ãƒ»ãƒ–ãƒ©ã‚¤ãƒä¾å­˜ã®ãƒ™ãƒ«ã‚®ãƒ¼ç­‰ï¼‰ã¯ã€å¤§ä¼šçµ‚ç›¤ã«ã‚¬ã‚¹æ¬ ã‚’èµ·ã“ã™ãƒªã‚¹ã‚¯ãŒé«˜ã¾ã‚Šã¾ã™ã€‚\n\nãƒ–ãƒ©ã‚¸ãƒ«ã®å¾©èª¿: ç¾åœ¨5ç•ªæ‰‹è©•ä¾¡ã§ã™ãŒã€å€‹ã®èƒ½åŠ›ã¯ä¾ç„¶ã¨ã—ã¦ãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã§ã™ã€‚å¤§ä¼šã¾ã§ã«å®ˆå‚™çµ„ç¹”ãŒæ•´å‚™ã•ã‚Œã‚Œã°ã€ä¸€æ°—ã«å„ªå‹å€™è£œç­†é ­ã«èºã‚Šå‡ºã‚‹ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã‚’ç§˜ã‚ã¦ã„ã¾ã™ã€‚\n\nğŸ“š æƒ…å ±æºã¨å¼•ç”¨\næ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:\n\npolymarket.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nwikipedia.org\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfifa.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nsportsbookreview.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfoxsports.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nolympics.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nlivescore.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\n365scores.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\napnews.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nelisportsnetwork.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nbetfair.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\naiscore.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nyoutube.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nyoutube.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nä½•ã‹èã„ã¦ãã ã•ã„...\n\n3\nä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\n\nç”·å­ã‚µãƒƒã‚«ãƒ¼ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½ã‚’äºˆæ¸¬ã—ã¦\n\nå®Œäº†ï¼\n\n2025å¹´11æœˆæ™‚ç‚¹ã®æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã€FIFAãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€ãŠã‚ˆã³å¸‚å ´äºˆæ¸¬ã«åŸºã¥ãã€2026å¹´ç”·å­ã‚µãƒƒã‚«ãƒ¼ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½äºˆæ¸¬ã‚’åˆ†æã—ã¾ã™ã€‚\n\n1. çµè«–ï¼šç¾åœ¨ã®æœ€æœ‰åŠ›å€™è£œã¯ã€Œã‚¹ãƒšã‚¤ãƒ³ã€\nç¾æ™‚ç‚¹ï¼ˆ2025å¹´11æœˆï¼‰ã§æœ€ã‚‚å„ªå‹ã«è¿‘ã„ã¨äºˆæ¸¬ã•ã‚Œã‚‹ã®ã¯ã‚¹ãƒšã‚¤ãƒ³ã§ã™ã€‚ EURO 2024ã§ã®å„ªå‹å®Ÿç¸¾ã¨ã€FIFAãƒ©ãƒ³ã‚­ãƒ³ã‚°1ä½ã‚’ç¶­æŒã™ã‚‹å®‰å®šæ„ŸãŒè©•ä¾¡ã•ã‚Œã€ãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼å„ç¤¾ã§ã‚‚ç­†é ­å€™è£œï¼ˆã‚ªãƒƒã‚ºç´„5.4å€ï¼‰ã¨ãªã£ã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã€ãƒ•ãƒ©ãƒ³ã‚¹ã€å‰å›ç‹è€…ã®ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ãŒç¶šãã€Œ4å¼·ï¼‹ãƒ–ãƒ©ã‚¸ãƒ«ã€ã®æ§‹å›³ãŒå½¢æˆã•ã‚Œã¦ã„ã¾ã™ã€‚\n\n2. è©³ç´°ãªåˆ†æã¨äºˆæ¸¬ã‚·ãƒŠãƒªã‚ª\nç­†é ­å€™è£œï¼šã‚¹ãƒšã‚¤ãƒ³ï¼ˆFIFAãƒ©ãƒ³ã‚¯1ä½ï¼‰\näºˆæ¸¬æ ¹æ‹ : EURO 2024å„ªå‹ã«åŠ ãˆã€2024-25 UEFAãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚ºãƒªãƒ¼ã‚°ã§ã‚‚å¥½èª¿ã‚’ç¶­æŒã—ã¦ãŠã‚Šã€æˆ¦è¡“çš„ãªå®Œæˆåº¦ãŒæœ€ã‚‚é«˜ã„ã¨è©•ä¾¡ã•ã‚Œã¦ã„ã¾ã™ã€‚\nå¼·ã¿: ãƒ©ãƒŸãƒ³ãƒ»ãƒ¤ãƒãƒ«ã‚„ãƒ­ãƒ‰ãƒªã‚’ä¸­å¿ƒã¨ã—ãŸä¸–ä»£äº¤ä»£ãŒå®Œäº†ã—ã¦ãŠã‚Šã€ãƒ™ãƒ†ãƒ©ãƒ³ã¨è‹¥æ‰‹ãŒå®Œç’§ã«èåˆã—ã¦ã„ã¾ã™ã€‚\nå¸‚å ´è©•ä¾¡: ä¸»è¦ãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã§ã®å„ªå‹ç¢ºç‡ã¯ç´„18.5%ï¼ˆã‚ªãƒƒã‚º +440ï½+450ï¼‰ã§å˜ç‹¬ãƒˆãƒƒãƒ—ã§ã™ã€‚\nå¯¾æŠ—é¦¬ï¼ˆå‰å›ç‹è€…ï¼‰ï¼šã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ï¼ˆFIFAãƒ©ãƒ³ã‚¯2ä½ï¼‰\näºˆæ¸¬æ ¹æ‹ : 2022å¹´Wæ¯ãŠã‚ˆã³ã‚³ãƒ‘ãƒ»ã‚¢ãƒ¡ãƒªã‚«2024ã®ç‹è€…ã¨ã—ã¦ã€ä¾ç„¶ã¨ã—ã¦ä¸–ç•Œãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã®å®ŸåŠ›ã‚’ä¿æŒã—ã¦ã„ã¾ã™ã€‚å—ç±³äºˆé¸ã‚‚é¦–ä½äº‰ã„ã‚’æ¼”ã˜ã€æœ¬å¤§ä¼šå‡ºå ´æ¨©ã‚’ç¢ºä¿æ¸ˆã¿ã§ã™ã€‚\nå¼·ã¿: ãƒªã‚ªãƒãƒ«ãƒ»ãƒ¡ãƒƒã‚·ãŒã‚­ãƒ£ãƒ—ãƒ†ãƒ³ã¨ã—ã¦ç²¾ç¥çš„æ”¯æŸ±ã®å½¹å‰²ã‚’æœãŸã—ã¦ãŠã‚Šã€ãƒãƒ¼ãƒ ã®çµæŸåŠ›ãŒéå¸¸ã«é«˜ã„ç‚¹ãŒç‰¹å¾´ã§ã™ã€‚\nå¸‚å ´è©•ä¾¡: ã‚ªãƒƒã‚ºã¯ç´„8.5ï½9.0å€ã§5ç•ªæ‰‹è©•ä¾¡ã§ã™ãŒã€çŸ­æœŸæ±ºæˆ¦ã§ã®å‹è² å¼·ã•ã¯éšä¸€ã§ã™ã€‚\nãã®ä»–ã®æœ‰åŠ›å€™è£œï¼ˆãƒˆãƒƒãƒ—ãƒ†ã‚£ã‚¢ï¼‰\nã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ï¼ˆã‚ªãƒƒã‚º2ä½ / ç´„7.0å€ï¼‰: EURO 2024æº–å„ªå‹ã®å®Ÿç¸¾ã¨ã€äºˆé¸ã‚’ç„¡æ•—ã§é€šéã—ãŸå®‰å®šæ„ŸãŒè©•ä¾¡ã•ã‚Œã¦ã„ã¾ã™ã€‚ã€Œ60å¹´ã¶ã‚Šã®å„ªå‹ã€ã¸ã®æœŸå¾…ãŒé«˜ãã€æˆ¦åŠ›å±¤ã®åšã•ã¯ä¸–ç•Œå±ˆæŒ‡ã§ã™ã€‚\nãƒ•ãƒ©ãƒ³ã‚¹ï¼ˆã‚ªãƒƒã‚º3ä½ / ç´„8.0å€ï¼‰: ã‚­ãƒªã‚¢ãƒ³ãƒ»ã‚¨ãƒ ãƒãƒšãŒå…¨ç››æœŸã‚’è¿ãˆã¦ãŠã‚Šã€å€‹ã®èƒ½åŠ›ã§è©¦åˆã‚’æ±ºå®šã¥ã‘ã‚‹åŠ›ãŒã‚ã‚Šã¾ã™ã€‚FIFAãƒ©ãƒ³ã‚¯3ä½ã‚’ç¶­æŒã—ã¦ã„ã¾ã™ã€‚\nãƒ–ãƒ©ã‚¸ãƒ«ï¼ˆã‚ªãƒƒã‚º4ä½ / ç´„8.5å€ï¼‰: äºˆé¸åºç›¤ã¯è‹¦æˆ¦ã—ã¾ã—ãŸãŒã€2025å¹´å¾ŒåŠã«å¾©èª¿ã—FIFAãƒ©ãƒ³ã‚¯5ä½ã¸æµ®ä¸Šã—ã¾ã—ãŸã€‚ãƒã‚¤ãƒãƒ¼ãƒ«ã®å¾©å¸°ã¨çŠ¶æ…‹ãŒå„ªå‹ã¸ã®éµã‚’æ¡ã‚Šã¾ã™ã€‚\n3. è€ƒæ…®ã™ã¹ããƒªã‚¹ã‚¯è¦å› ã¨ä¸ç¢ºå®šè¦ç´ \näºˆæ¸¬ã‚’è¡Œã†ä¸Šã§ã€ä»¥ä¸‹ã®è¦ç´ ãŒçµæœã‚’å·¦å³ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n\nåŒ—ç±³é–‹å‚¬ç‰¹æœ‰ã®ç’°å¢ƒè² è·: ã‚¢ãƒ¡ãƒªã‚«ãƒ»ã‚«ãƒŠãƒ€ãƒ»ãƒ¡ã‚­ã‚·ã‚³ã®3ã‚«å›½å…±å‚¬ã¨ãªã‚‹ãŸã‚ã€ç§»å‹•è·é›¢ãŒéå¸¸ã«é•·ãã€ãƒ¡ã‚­ã‚·ã‚³ã‚„ç±³å›½å—éƒ¨ã§ã®é…·æš‘ãŒé¸æ‰‹ã®ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã‚’è‘—ã—ãä½ä¸‹ã•ã›ã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã¯é¸æ‰‹å±¤ã®åšã„ãƒãƒ¼ãƒ ï¼ˆæ¬§å·å‹¢ãªã©ï¼‰ã«æœ‰åˆ©ã«åƒãå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\nä¸»åŠ›é¸æ‰‹ã®è² å‚·ãƒªã‚¹ã‚¯: æ¬§å·ä¸»è¦ãƒªãƒ¼ã‚°ã®éå¯†æ—¥ç¨‹ã«ã‚ˆã‚Šã€ACLï¼ˆå‰åå­—é­å¸¯ï¼‰æå‚·ãªã©ã®é‡å‚·ãŒå¢—åŠ å‚¾å‘ã«ã‚ã‚Šã¾ã™ã€‚å¤§ä¼šç›´å‰ã®æ€ªæˆ‘äººãŒäºˆæ¸¬ã‚’å¤§ããè¦†ã™å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\nãƒ™ãƒ†ãƒ©ãƒ³ã¸ã®ä¾å­˜åº¦: ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ï¼ˆãƒ¡ãƒƒã‚·ï¼‰ã‚„ãƒãƒ«ãƒˆã‚¬ãƒ«ï¼ˆC.ãƒ­ãƒŠã‚¦ãƒ‰ï¼‰ãªã©ã€ãƒ™ãƒ†ãƒ©ãƒ³ã‚¹ã‚¿ãƒ¼ã¸ã®ä¾å­˜åº¦ãŒé«˜ã„ãƒãƒ¼ãƒ ã¯ã€å½¼ã‚‰ã®ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³æ¬¡ç¬¬ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå¤§ããå¤‰å‹•ã™ã‚‹ãƒªã‚¹ã‚¯ã‚’æŠ±ãˆã¦ã„ã¾ã™ã€‚\nå‡ºå…¸:\n\nFIFA Men's World Ranking (2025å¹´11æœˆ19æ—¥æ›´æ–°)\nFanDuel / DraftKings Betting Odds (2025å¹´11æœˆæ™‚ç‚¹)\nFox Sports å ±é“ (2025å¹´11æœˆ)\nğŸ“š æƒ…å ±æºã¨å¼•ç”¨\næ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:\n\npolymarket.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nwikipedia.org\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfifa.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nsofascore.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfifa.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nsoccerpunter.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfoxsports.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nlivescore.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\naiscore.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\n11v11.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfootystats.org\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nsportsbookreview.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\ndraftkings.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\ngoal.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nnational-football-teams.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nthesoccerera.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\n365scores.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfoxsports.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nwikipedia.org\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nsportpesa.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfanduel.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nwikipedia.org\nå‡ºå…¸: vertexaisearch.cloud.google.com"
                },
                {
                    "role": "model",
                    "content": "èª¿æŸ»ãƒ¡ãƒ¢ã«åŸºã¥ãã€å„å›ç­”ã®æƒ…å ±ã®é®®åº¦ã€åˆ†æã®æ·±ã•ã€è¨­å®šï¼ˆ2025å¹´11æœˆæ™‚ç‚¹ï¼‰ã¨ã®æ•´åˆæ€§ã‚’è©•ä¾¡ã—ã€ä»¥ä¸‹ã®ã‚ˆã†ã«ç‚¹æ•°ä»˜ã‘ã‚’è¡Œã„ã¾ã—ãŸã€‚\n\n### 1. çµè«–ï¼šè©•ä¾¡ã‚¹ã‚³ã‚¢\n*   **3ç‚¹ï¼ˆæœ€é«˜è©•ä¾¡ï¼‰**: **å›ç­”2**\n*   **2ç‚¹ï¼ˆé«˜è©•ä¾¡ï¼‰**: **å›ç­”0**\n*   **1ç‚¹ï¼ˆæ¨™æº–ï¼‰**: **å›ç­”1**\n*   **0ç‚¹ï¼ˆåŸºç¤ï¼‰**: **å›ç­”3**\n\n---\n\n### 2. è©³ç´°ãªè©•ä¾¡åˆ†æ\n\n#### **3ç‚¹ï¼šå›ç­”2ï¼ˆæœ€ã‚‚å„ªã‚ŒãŸæ´å¯Ÿã¨æ•´åˆæ€§ï¼‰**\nã“ã®å›ç­”ã¯ã€è¨­å®šã•ã‚ŒãŸã€Œ2025å¹´11æœˆã€ã¨ã„ã†æ™‚ç‚¹ã«æœ€ã‚‚å¿ å®Ÿã§ã€ã‹ã¤åˆ†æãŒå…·ä½“çš„ã§ã™ã€‚\n*   **æ±ºå®šçš„ãªåŠ ç‚¹è¦ç´ **: å”¯ä¸€ã€**ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã®ã€Œãƒˆãƒ¼ãƒã‚¹ãƒ»ãƒˆã‚¥ãƒ˜ãƒ«ç›£ç£ã€å°±ä»»**ã«æ˜ç¢ºã«è¨€åŠã—ã¦ã„ã¾ã™ã€‚ç¾å®Ÿã«ã¯2025å¹´1æœˆã‹ã‚‰æŒ‡æ®ã‚’åŸ·ã‚‹ãŸã‚ã€2025å¹´11æœˆæ™‚ç‚¹ã®äºˆæ¸¬ã¨ã—ã¦ã¯ã“ã®æ–°ä½“åˆ¶ã¸ã®è¨€åŠãŒä¸å¯æ¬ ã§ã‚ã‚Šã€æƒ…å ±ã®é®®åº¦ã¨äºˆæ¸¬ã®è§£åƒåº¦ãŒæœ€ã‚‚é«˜ã„ã§ã™ã€‚\n*   **åˆ†æã®æ·±ã•**: ã€Œãƒ¡ã‚¿è³ªå•ã€å½¢å¼ã‚’ç”¨ã„ã€åŒ—ä¸­ç±³é–‹å‚¬ç‰¹æœ‰ã®ã€Œé…·æš‘ãƒ»ç§»å‹•è·é›¢ã€ãŒã©ã®æˆ¦è¡“ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆãƒã‚¼ãƒƒã‚·ãƒ§ãƒ³å¯¾ãƒ•ã‚£ã‚¸ã‚«ãƒ«ï¼‰ã«æœ‰åˆ©ã«åƒãã‹ã‚’è«–ç†çš„ã«è€ƒå¯Ÿã—ã¦ãŠã‚Šã€å˜ãªã‚‹ãƒãƒ¼ãƒ åã®åˆ—æŒ™ã‚’è¶…ãˆãŸåˆ†æãŒã‚ã‚Šã¾ã™ã€‚\n\n#### **2ç‚¹ï¼šå›ç­”0ï¼ˆå®¢è¦³çš„ãƒ‡ãƒ¼ã‚¿ã¨ç¶²ç¾…æ€§ï¼‰**\néå¸¸ã«å®Ÿç”¨çš„ã§ã€å®¢è¦³çš„ãªæ ¹æ‹ ã«åŸºã¥ã„ãŸå„ªç§€ãªå›ç­”ã§ã™ã€‚\n*   **å¼·ã¿**: ã€Œãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã€ã‚„ã€Œäºˆæ¸¬å¸‚å ´ï¼ˆPolymarketï¼‰ã€ã¨ã„ã£ãŸå…·ä½“çš„ãªæŒ‡æ¨™ã‚’ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æç¤ºã—ã¦ãŠã‚Šã€èª¬å¾—åŠ›ãŒã‚ã‚Šã¾ã™ã€‚\n*   **ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦–ç‚¹**: æ—¥æœ¬ä»£è¡¨ã®ç«‹ã¡ä½ç½®ï¼ˆãƒ€ãƒ¼ã‚¯ãƒ›ãƒ¼ã‚¹æ ï¼‰ã«ã¤ã„ã¦ã‚‚è¨€åŠã—ã¦ãŠã‚Šã€æ—¥æœ¬äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ°—ã«ãªã‚Šãã†ãªãƒã‚¤ãƒ³ãƒˆã‚’å…ˆå›ã‚Šã—ã¦ã‚«ãƒãƒ¼ã—ã¦ã„ã‚‹ç‚¹ãŒå„ªã‚Œã¦ã„ã¾ã™ã€‚\n*   **å·®åˆ†**: å›ç­”2ã®ã‚ˆã†ãªã€Œç›£ç£äººäº‹ã€ãªã©ã®å†…éƒ¨äº‹æƒ…ã¸ã®è¸ã¿è¾¼ã¿ãŒã‚ãšã‹ã«å°‘ãªã‹ã£ãŸãŸã‚æ¬¡ç‚¹ã¨ã—ã¾ã—ãŸã€‚\n\n#### **1ç‚¹ï¼šå›ç­”1ï¼ˆè«–ç†çš„ãªæ§‹æˆï¼‰**\næ§‹é€ åŒ–ã•ã‚Œã¦ãŠã‚Šèª­ã¿ã‚„ã™ã„ã§ã™ãŒã€æƒ…å ±ã®å…·ä½“æ€§ã§ä¸Šä½ã«åŠ£ã‚Šã¾ã™ã€‚\n*   **è©•ä¾¡ç‚¹**: ã€Œã‚·ãƒŠãƒªã‚ªA/B/Cã€ã¨ã„ã†åˆ†ã‘æ–¹ã¯è«–ç†çš„ã§ã€èµ·ã“ã‚Šã†ã‚‹å±•é–‹ã‚’æ•´ç†ã§ãã¦ã„ã¾ã™ã€‚\n*   **ä¸è¶³ç‚¹**: å…·ä½“çš„ãªç›£ç£åã‚„æ•°å€¤ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªãã€åˆ†æãŒã‚„ã‚„ä¸€èˆ¬çš„ã§ã™ã€‚\n\n#### **0ç‚¹ï¼šå›ç­”3ï¼ˆåŸºç¤çš„ãªã¾ã¨ã‚ï¼‰**\nå†…å®¹ã¯é–“é•ã£ã¦ã„ã¾ã›ã‚“ãŒã€ä»–ã®å›ç­”ã¨æ¯”è¼ƒã—ã¦ç‹¬è‡ªæ€§ãŒå¸Œè–„ã§ã™ã€‚\n*   **è©•ä¾¡**: çµè«–ã¨ä¸€èˆ¬çš„ãªãƒªã‚¹ã‚¯è¦å› ï¼ˆç§»å‹•è·é›¢ãªã©ï¼‰ã‚’è¿°ã¹ã¦ã„ã¾ã™ãŒã€æ·±æ˜ã‚Šã‚„å›ºæœ‰ã®æƒ…å ±ï¼ˆå…·ä½“çš„ãªã‚ªãƒƒã‚ºæ•°å€¤ã‚„äººäº‹ãªã©ï¼‰ãŒä¸è¶³ã—ã¦ãŠã‚Šã€ç°¡æ˜“çš„ãªã¾ã¨ã‚ã«ã¨ã©ã¾ã£ã¦ã„ã¾ã™ã€‚\n\n---\n\n### 3. è©•ä¾¡ã®æ±ºã‚æ‰‹ï¼ˆè€ƒæ…®ã™ã¹ãè¦å› ï¼‰\nä»Šå›ã®è©•ä¾¡ã§ã¯ã€ä»¥ä¸‹ã®è¦ç´ ã‚’é‡è¦–ã—ã¾ã—ãŸã€‚\n\n*   **ã€Œ2025å¹´11æœˆã€è¨­å®šã¸ã®æ²¡å…¥åº¦**:\n    æœªæ¥ã®æ—¥ä»˜è¨­å®šã«å¯¾ã—ã€**ãƒˆã‚¥ãƒ˜ãƒ«ç›£ç£ï¼ˆ2025å¹´å°±ä»»äºˆå®šï¼‰**ã®ã‚ˆã†ãªç¢ºå®šã—ãŸæœªæ¥æƒ…å ±ã‚’é©åˆ‡ã«çµ„ã¿è¾¼ã‚ã¦ã„ã‚‹ã‹ã©ã†ã‹ãŒã€å›ç­”2ã‚’æœ€é«˜è©•ä¾¡ã¨ã™ã‚‹æ±ºã‚æ‰‹ã¨ãªã‚Šã¾ã—ãŸã€‚\n*   **ç’°å¢ƒè¦å› ã®åˆ†æ**:\n    2026å¹´å¤§ä¼šã®æœ€å¤§ã®ç‰¹å¾´ã§ã‚ã‚‹ã€Œ48ã‚«å›½åˆ¶ã¸ã®æ‹¡å¤§ã€ã¨ã€Œ3ã‚«å›½å…±å‚¬ã«ã‚ˆã‚‹ç§»å‹•ãƒ»æ°—å€™è² æ‹…ã€ã‚’ã€å˜ãªã‚‹äº‹å®Ÿã¨ã—ã¦ã ã‘ã§ãªãã€**å‹æ•—ã‚’åˆ†ã‘ã‚‹å¤‰æ•°**ã¨ã—ã¦åˆ†æã§ãã¦ã„ã‚‹ã‹ã‚’è©•ä¾¡ã—ã¾ã—ãŸã€‚"
                }
            ]
        },
        {
            "id": "b9a48a90-5f6e-407d-b205-75bfbb02cdcf",
            "title": "0/1/2/3ã®å›ç­”ãƒ¬ãƒ™ãƒ«ã«ç‚¹æ•°ã‚’ã¤ã‘ã¦...",
            "timestamp": "2025-11-30T00:15:42.614151",
            "messages": [
                {
                    "role": "user",
                    "content": "0/1/2/3ã®å›ç­”ãƒ¬ãƒ™ãƒ«ã«ç‚¹æ•°ã‚’ã¤ã‘ã¦ã€‚\n\n\n0\nThought for 7m 43sChatGPT:ä»Šã®ãƒ‡ãƒ¼ã‚¿ã‚’å…¨éƒ¨çœºã‚ãŸã†ãˆã§ã€1ã‚«å›½ã ã‘å„ªå‹å€™è£œã‚’æŒ™ã’ã‚ã¨è¨€ã‚ã‚ŒãŸã‚‰ã€Œã‚¹ãƒšã‚¤ãƒ³ã€ã‚’æœ¬å‘½ã«äºˆæƒ³ã—ã¾ã™ã€‚\n\nãªãœã‚¹ãƒšã‚¤ãƒ³ã‚’æœ¬å‘½ã«ã™ã‚‹ã‹\nã–ã£ãã‚Šç†ç”±ã¯ã“ã®ã‚ãŸã‚Šã§ã™ï¼š\n\n\nãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ãƒ»äºˆæ¸¬å¸‚å ´ã§è»’ä¸¦ã¿1ç•ªäººæ°—\n\n\nä¸»è¦ãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã®å„ªå‹ã‚ªãƒƒã‚ºã§ã¯ã€ã‚¹ãƒšã‚¤ãƒ³ãŒå˜ç‹¬ãƒˆãƒƒãƒ—ï¼ˆãŠãŠã‚ˆãå€ç‡4.5ã€œ5.5å€å‰å¾Œï¼‰ã§1ç•ªäººæ°—ã«ãªã£ã¦ã„ã¾ã™ã€‚Talksport+2JohnnyBet+2\n\n\näºˆæ¸¬å¸‚å ´ï¼ˆãƒãƒªãƒãƒ¼ã‚±ãƒƒãƒˆãªã©ï¼‰ã§ã‚‚ã€ç¾æ™‚ç‚¹ã§å„ªå‹ç¢ºç‡ãƒˆãƒƒãƒ—ã¯ã‚¹ãƒšã‚¤ãƒ³ï¼ˆç´„17ï¼…ï¼‰ã§ã™ã€‚Polymarket\n\n\n\n\nãƒ¦ãƒ¼ãƒ­2024å„ªå‹ï¼‹ä¸–ä»£äº¤ä»£æˆåŠŸã®â€œæ—¬â€ã®ãƒãƒ¼ãƒ \n\n\nã‚¹ãƒšã‚¤ãƒ³ã¯ãƒ¦ãƒ¼ãƒ­2024ã‚’åˆ¶ã—ã¦ã„ã¦ã€ã€Œã„ã¾ä¸€ç•ªã‚¿ã‚¤ãƒˆãƒ«ã«è¿‘ã„ä»£è¡¨ã€ã¨è©•ä¾¡ã•ã‚Œã¦ã„ã¾ã™ã€‚FOX Sports+1\n\n\nãƒ©ãƒŸãƒ³ãƒ»ãƒ¤ãƒãƒ«ã‚„ãƒ‹ã‚³ãƒ»ã‚¦ã‚£ãƒªã‚¢ãƒ ã‚ºã¨ã„ã£ãŸè‹¥æ‰‹ã‚¢ã‚¿ãƒƒã‚«ãƒ¼ã«ã€ãƒ­ãƒ‰ãƒªãªã©ä¸–ç•Œãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã®ä¸­ç›¤ãŒã„ã¦ã€è‹¥ã•ï¼‹æˆç†Ÿã®ãƒãƒ©ãƒ³ã‚¹ãŒã‹ãªã‚Šè‰¯ã„ãƒãƒ¼ãƒ æ§‹æˆã§ã™ã€‚FOX Sports\n\n\n\n\nã‚¹ã‚¿ã‚¤ãƒ«ãŒåŒ—ä¸­ç±³é–‹å‚¬ã®æ¡ä»¶ã«åˆã£ã¦ã„ã‚‹ã¨è¦‹ã‚‰ã‚Œã¦ã„ã‚‹\n\n\nESPNã®ã€Œä»Šã™ãWæ¯ãŒå§‹ã¾ã£ãŸã‚‰ã©ã“ãŒå„ªå‹ã™ã‚‹ï¼Ÿã€ã¨ã„ã†ä¼ç”»ã§ã‚‚ã€â€œç·åˆçš„ã«æ¡ä»¶ã‚’ä¸€ç•ªæº€ãŸã—ã¦ã„ã‚‹â€ã¨ã„ã†ç†ç”±ã§ã‚¹ãƒšã‚¤ãƒ³ãŒæœ€æœ‰åŠ›ã¨è©•ä¾¡ã•ã‚Œã¦ã„ã¾ã™ã€‚ESPN.com\n\n\næš‘ã•ã®ä¸­ã§ã‚‚ãƒœãƒ¼ãƒ«ä¿æŒã§è©¦åˆã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã§ãã‚‹ãƒãƒ¼ãƒ ãŒæœ‰åˆ©ã€ã¨ã„ã†è¦‹æ–¹ãŒå¤šãã€ãã®ç‚¹ã§ã‚‚ã‚¹ãƒšã‚¤ãƒ³ã¯åˆè‡´ã—ã¦ã„ã‚‹ã¨ã•ã‚Œã¦ã„ã¾ã™ã€‚ESPN.com\n\n\n\n\nã‚‚ã¡ã‚ã‚“ã€Œæœ¬å‘½ã€ã¨ã„ã†ã ã‘ã§ã€å„ªå‹ç¢ºç‡ã¯ã›ã„ãœã„20ï¼…å¼±ç¨‹åº¦ã¨è¦‹ç©ã‚‚ã‚‰ã‚Œã¦ã„ã¦ã€ã€Œã‚¹ãƒšã‚¤ãƒ³ã§ã»ã¼æ±ºã¾ã‚Šã€ã¨ã„ã†ãƒ¬ãƒ™ãƒ«ã§ã¯å…¨ãã‚ã‚Šã¾ã›ã‚“ã€‚ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆã¯ä½•ãŒèµ·ãã‚‹ã‹åˆ†ã‹ã‚‰ãªã„ã§ã™ã€‚\n\nä»–ã®â€œè¶…â€æœ‰åŠ›å€™è£œãŸã¡\nã‚¹ãƒšã‚¤ãƒ³ã‚’æœ¬å‘½ã«ã—ã¤ã¤ã€åŒã˜ãã‚‰ã„æ€–ã„â€œè¶…â€å¼·è±ªã‚°ãƒ«ãƒ¼ãƒ—ãŒã“ã¡ã‚‰ï¼š\n\n\nã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰\n\n\nãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã®ã‚ªãƒƒã‚ºã§ã¯ã»ã¼å¸¸ã«2ç•ªæ‰‹ï¼ˆã‚¹ãƒšã‚¤ãƒ³ã«æ¬¡ãäººæ°—ï¼‰ã€‚Talksport+2sportsbook.draftkings.com+2\n\n\nãƒ™ãƒªãƒ³ã‚¬ãƒ ã‚’ä¸­å¿ƒã«ã‚¿ãƒ¬ãƒ³ãƒˆã¯æ­´ä»£å±ˆæŒ‡ã§ã€ã€Œãã‚ãã‚ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–ã£ã¦ã‚‚ãŠã‹ã—ããªã„ã€ã¨è¨€ã‚ã‚Œã¦ã„ã¾ã™ã€‚\n\n\n\n\nãƒ•ãƒ©ãƒ³ã‚¹\n\n\n2022å¹´ã®æº–å„ªå‹å›½ã§ã€ã‚¹ã‚«ãƒƒãƒ‰ã®åšã•ã¯ä¸–ç•Œä¸€ã¨è¨€ã‚ã‚Œã‚‹ã“ã¨ã‚‚å¤šã„ã§ã™ã€‚ã‚²ã‚­ã‚µã‚«+1\n\n\nESPNã‚„å„ç¨®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã§ã‚‚å„ªå‹å¯èƒ½æ€§1ä½ã€œ3ä½ã«å¿…ãšå…¥ã£ã¦ã„ã‚‹å¸¸é€£ã€‚ã‚²ã‚­ã‚µã‚«+1\n\n\n\n\nã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³\n\n\nå‰å›ç‹è€…ã§ã€ä¾ç„¶ã¨ã—ã¦ä¸Šä½å€™è£œã€‚ãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã§ã‚‚å„ªå‹å€™è£œãƒˆãƒƒãƒ—ã‚°ãƒ«ãƒ¼ãƒ—ï¼ˆå€ç‡8ã€œ10å€å‰å¾Œï¼‰ã€‚Talksport+2VegasInsider+2\n\n\n\n\nãƒ–ãƒ©ã‚¸ãƒ«\n\n\nã“ã“æ•°å¤§ä¼šã¯ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰é ã–ã‹ã£ã¦ã„ã¾ã™ãŒã€å€‹ã®åŠ›ã¨ã‚¿ãƒ¬ãƒ³ãƒˆå±¤ã¯ç›¸å¤‰ã‚ã‚‰ãšãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã§ã€ã‚ªãƒƒã‚ºä¸Šã‚‚å¸¸ã«ä¸Šä½ã€‚Talksport+2VegasInsider+2\n\n\n\n\nã“ã®ã‚ãŸã‚Šã¾ã§ãŒã€Œå„ªå‹ã—ã¦ã‚‚å…¨ãé©šã‹ãªã„ã€ãƒ©ã‚¤ãƒ³ã§ã™ã€‚ãã®å¾Œã‚ã«ã€ãƒãƒ«ãƒˆã‚¬ãƒ«ï¼ãƒ‰ã‚¤ãƒ„ï¼ã‚ªãƒ©ãƒ³ãƒ€ï¼ã‚¤ã‚¿ãƒªã‚¢ï¼ãƒ¢ãƒ­ãƒƒã‚³ãªã©ãŒç¶šãæ„Ÿã˜ã€‚VegasInsider+3Talksport+3SI+3\n\næ—¥æœ¬ã¯ã©ã®ãã‚‰ã„ã®ä½ç½®ã¥ã‘ï¼Ÿ\næ—¥æœ¬ä»£è¡¨ã¯ã€æµ·å¤–ã‚µã‚¤ãƒˆã®ãƒ‘ãƒ¯ãƒ¼ãƒ©ãƒ³ã‚¯ã‚„ã‚ªãƒƒã‚ºã§ã¯ã ã„ãŸã„**â€œãƒ€ãƒ¼ã‚¯ãƒ›ãƒ¼ã‚¹æ â€**ãã‚‰ã„ã®æ‰±ã„ã§ã™ã€‚\n\n\nãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã®å„ªå‹ã‚ªãƒƒã‚ºã§ã¯ã€æ—¥æœ¬ã¯ä¸­å …ã€œä¸‹ä½ã®ã‚°ãƒ«ãƒ¼ãƒ—ã§ã™ãŒã€æ±ºã—ã¦æœ€ä¸‹ä½ã§ã¯ãªãã€Œå¯èƒ½æ€§ã¯ä½ã„ãŒã€å…¨ãã®ãƒãƒ¼ãƒãƒ£ãƒ³ã‚¹ã§ã‚‚ãªã„ã€ã¨ã„ã†ãƒã‚¸ã‚·ãƒ§ãƒ³ã€‚VegasInsider+1\n\n\nESPNã‚„æ—¥æœ¬ãƒ¡ãƒ‡ã‚£ã‚¢ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã§ã‚‚ã€ã€Œãƒ™ã‚¹ãƒˆ8ä»¥ä¸Šã«é£Ÿã„è¾¼ã‚€ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã¯ã‚ã‚‹ã€ã¨è©•ä¾¡ã™ã‚‹å£°ãŒå°‘ã—ãšã¤å¢—ãˆã¦ãã¦ã„ã¾ã™ã€‚ã‚²ã‚­ã‚µã‚«+1\n\n\næ•°å€¤çš„ã«ã¯ã€å„ªå‹ç¢ºç‡ã¯æ•°ï¼…æœªæº€ãã‚‰ã„ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã™ãŒã€1å›ã®å¤§ä¼šã§ç•ªç‹‚ã‚ã›ã¯æ™®é€šã«èµ·ã“ã‚‹ã®ã§ã€ä»Šã®ã†ã¡ã‹ã‚‰ãƒãƒ¼ãƒ ä½œã‚Šæ¬¡ç¬¬ã§ä¸€æ°—ã«ç¾å®Ÿå‘³ãŒå¢—ã™ã‚¾ãƒ¼ãƒ³ã§ã™ã€‚\n\nã‚®ãƒ£ãƒ³ãƒ–ãƒ«çš„ãªè©±ã«ã¤ã„ã¦\næƒ…å ±æºã¨ã—ã¦ã‚ªãƒƒã‚ºã‚„äºˆæ¸¬å¸‚å ´ã®æ•°å­—ã‚’ä½¿ã„ã¾ã—ãŸãŒã€\nã€Œè³­ã‘ã‚’ã—ã‚ˆã†ã€ã¨ã„ã†æ„å‘³ã§ã¯ã¾ã£ãŸãã‚ã‚Šã¾ã›ã‚“ã€‚\nç‰¹ã«æ—¥æœ¬ã§ã¯å¤šãã®ã‚¹ãƒãƒ¼ãƒ„ãƒ™ãƒƒãƒ†ã‚£ãƒ³ã‚°ãŒé•æ³•ãªã®ã§ã€ãã®ç‚¹ã¯åˆ‡ã‚Šé›¢ã—ã¦â€œè©•ä¾¡æŒ‡æ¨™ã®ã²ã¨ã¤â€ã¨ã—ã¦ã ã‘è¦‹ã¦ãã ã•ã„ã€‚\n\nã¾ã¨ã‚\n\n\næœ¬å‘½äºˆæƒ³ï¼šã‚¹ãƒšã‚¤ãƒ³\n\n\næ¬¡ç‚¹ï¼šã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã€ãƒ•ãƒ©ãƒ³ã‚¹ã€ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã€ãƒ–ãƒ©ã‚¸ãƒ«\n\n\nãã®å¾Œã«ãƒãƒ«ãƒˆã‚¬ãƒ«ã€ãƒ‰ã‚¤ãƒ„ã€ã‚ªãƒ©ãƒ³ãƒ€ã€ã‚¤ã‚¿ãƒªã‚¢ã€ãƒ¢ãƒ­ãƒƒã‚³ãªã©\n\n\nã€Œ1ã‚«å›½ã ã‘åå‰ã‚’æ›¸ã„ã¦ãã ã•ã„ã€ã¨è¨€ã‚ã‚ŒãŸã‚‰ã€ç§ã¯ã‚¹ãƒšã‚¤ãƒ³ã«â—ã‚’ä»˜ã‘ã¾ã™ã€‚\n\næœ€æ–°ã®Wæ¯é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚‚ã€ã–ã£ã¨è¿½ãˆã‚‹ã‚‚ã®ã‚’ç½®ã„ã¦ãŠãã¾ã™ğŸ‘‡\n2026å¹´Wæ¯æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹TalksportWorld Cup winner odds: An early look at who the bookies are backing to lift the trophy in 2026ä¸€æ˜¨æ—¥The GuardianSocceroos get lucky with place in second highest pot for World Cup draw3 æ—¥å‰The SunEngland could have to beat FOUR giants in nightmare path to World Cup 2026 final as new draw system is revealed3 æ—¥å‰News.com.auFIFA World Cup 2026: Australia to avoid top teams in first draw3 æ—¥å‰\nä»–ã«ã€Œæ—¥æœ¬ä»£è¡¨ã«çµã£ãŸç¾å®Ÿçš„ãªç›®æ¨™ã€ã¨ã‹ã€Œãƒ€ãƒ¼ã‚¯ãƒ›ãƒ¼ã‚¹å€™è£œã ã‘çŸ¥ã‚ŠãŸã„ã€ã¨ã‹ã‚ã‚Œã°ã€ãã“ã«çµã£ã¦æ•´ç†ã‚‚ã§ãã¾ã™ã‚ˆã€‚\n\n\n\n\n\n1\næ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\nä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\n\nç”·å­ã‚µãƒƒã‚«ãƒ¼ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½ã‚’äºˆæ¸¬ã—ã¦\n\nå®Œäº†ï¼\n\n2025å¹´11æœˆæ™‚ç‚¹ã®æœ€æ–°ãƒ‡ãƒ¼ã‚¿ï¼ˆFIFAãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€ãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã‚ªãƒƒã‚ºã€ç›´è¿‘ã®ä¸»è¦å¤§ä¼šæˆç¸¾ï¼‰ã«åŸºã¥ãã€2026å¹´ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½ã‚’äºˆæ¸¬ãƒ»åˆ†æã—ã¾ã™ã€‚\n\nçµè«–ï¼šã‚¹ãƒšã‚¤ãƒ³ãŒçµ±è¨ˆçš„ãƒ»æˆ¦è¡“çš„ã«ãƒªãƒ¼ãƒ‰ã€è¿½ã†ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã¨ãƒ•ãƒ©ãƒ³ã‚¹\nç¾æ™‚ç‚¹ã§ã®æœ€æœ‰åŠ›å€™è£œã¯ã‚¹ãƒšã‚¤ãƒ³ã§ã™ã€‚2024å¹´EUROå„ªå‹ã®å®Ÿç¸¾ã¨ã€æ”»å®ˆã®ãƒãƒ©ãƒ³ã‚¹ã®è‰¯ã•ãŒè©•ä¾¡ã•ã‚Œã€FIFAãƒ©ãƒ³ã‚­ãƒ³ã‚°1ä½ãŠã‚ˆã³ãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã®ã‚ªãƒƒã‚ºï¼ˆç´„18-20%ï¼‰ã§ãƒˆãƒƒãƒ—ã«ç«‹ã£ã¦ã„ã¾ã™ã€‚\n\nãŸã ã—ã€çµ¶å¯¾çš„ãªä¸€å¼·çŠ¶æ…‹ã§ã¯ãªãã€ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆã«æ»…æ³•å¼·ã„å‰å›ç‹è€…ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã€ä¸–ç•Œæœ€é«˜ã®é¸æ‰‹å±¤ã‚’æŒã¤ãƒ•ãƒ©ãƒ³ã‚¹ãŒåƒ…å·®ã§ç¶šãã€Œä¸‰ã¤å·´ã€ã«è¿‘ã„æ§‹å›³ã§ã™ã€‚\n\nã‚·ãƒŠãƒªã‚ªåˆ¥äºˆæ¸¬åˆ†æ\nã‚·ãƒŠãƒªã‚ªAï¼šã‚¹ãƒšã‚¤ãƒ³ã«ã‚ˆã‚‹ã€Œæ–°ãƒ»é»„é‡‘æœŸã€ã®è¨¼æ˜ï¼ˆç¢ºç‡ï¼šé«˜ï¼‰\næœ€ã‚‚è“‹ç„¶æ€§ãŒé«˜ã„ã‚·ãƒŠãƒªã‚ªã§ã™ã€‚\n\næ ¹æ‹ : 2024å¹´EUROã§ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã‚’ç ´ã‚Šå„ªå‹ã€‚ç¾åœ¨FIFAãƒ©ãƒ³ã‚­ãƒ³ã‚°1ä½ï¼ˆ1877.18 ptï¼‰ã€‚\nå¼·ã¿: ãƒ©ãƒŸãƒ³ãƒ»ãƒ¤ãƒãƒ«ã€ãƒ‹ã‚³ãƒ»ã‚¦ã‚£ãƒªã‚¢ãƒ ã‚ºã‚‰è‹¥æ‰‹ã®çˆ†ç™ºåŠ›ã¨ã€ãƒ­ãƒ‰ãƒªã‚’ä¸­å¿ƒã¨ã—ãŸä¸­ç›¤ã®æ§‹æˆåŠ›ãŒå™›ã¿åˆã£ã¦ã„ã¾ã™ã€‚2010å¹´å¤§ä¼šå„ªå‹æ™‚ã®ã‚ˆã†ãªã€Œã‚·ã‚¹ãƒ†ãƒ ã§å‹ã¤ã€ã‚µãƒƒã‚«ãƒ¼ãŒå®Œæˆã—ã¤ã¤ã‚ã‚Šã¾ã™ã€‚\næ‡¸å¿µ: è‹¥æ‰‹ä¸»ä½“ã®ãƒãƒ¼ãƒ ã§ã‚ã‚‹ãŸã‚ã€Wæ¯ç‰¹æœ‰ã®ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã«å¯¾ã™ã‚‹çµŒé¨“å€¤ä¸è¶³ãŒå”¯ä¸€ã®ãƒªã‚¹ã‚¯ã§ã™ã€‚\nã‚·ãƒŠãƒªã‚ªBï¼šå®Ÿç¸¾çµ„ï¼ˆã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ãƒ»ãƒ•ãƒ©ãƒ³ã‚¹ï¼‰ã®åº•åŠ›ï¼ˆç¢ºç‡ï¼šä¸­ï¼‰\nå€‹ã®åŠ›ã‚„çµŒé¨“å€¤ãŒã€çµ„ç¹”åŠ›ã‚’å‡Œé§•ã™ã‚‹ã‚·ãƒŠãƒªã‚ªã§ã™ã€‚\n\nğŸ‡¦ğŸ‡· ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³:\nå¼·ã¿: 2022å¹´Wæ¯ã€2024å¹´ã‚³ãƒ‘ãƒ»ã‚¢ãƒ¡ãƒªã‚«ã‚’é€£è¦‡ä¸­ã€‚ãƒ¡ãƒƒã‚·ã‚’ä¸­å¿ƒã¨ã—ãŸçµæŸåŠ›ã¨ã€çŸ­æœŸæ±ºæˆ¦ã§ã®å‹è² å¼·ã•ã¯ä¸–ç•Œä¸€ã§ã™ã€‚\nãƒªã‚¹ã‚¯: ä¸»åŠ›ã®é«˜é½¢åŒ–ãŒé€²ã‚“ã§ãŠã‚Šã€2026å¹´å¤ã«2022å¹´ã¨åŒç­‰ã®é‹å‹•é‡ã‚’ç¶­æŒã§ãã‚‹ã‹ãŒéµã¨ãªã‚Šã¾ã™ã€‚\nğŸ‡«ğŸ‡· ãƒ•ãƒ©ãƒ³ã‚¹:\nå¼·ã¿: ã‚­ãƒªã‚¢ãƒ³ãƒ»ã‚¨ãƒ ãƒãƒšã¨ã„ã†ã€Œå€‹ã€ã®æ‰“é–‹åŠ›ã«åŠ ãˆã€å…¨ãƒã‚¸ã‚·ãƒ§ãƒ³ã«ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚¯ãƒ©ã‚¹ã‚’æƒãˆã‚‹é¸æ‰‹å±¤ï¼ˆDepthï¼‰ã¯48ã‚«å›½åˆ¶ã®é•·ä¸å ´ã§æœ€å¤§ã®æ­¦å™¨ã¨ãªã‚Šã¾ã™ã€‚\nãƒªã‚¹ã‚¯: ãƒ‡ã‚·ãƒ£ãƒ³ç›£ç£ä½“åˆ¶ã®é•·æœŸåŒ–ã«ã‚ˆã‚‹æˆ¦è¡“çš„ãªåœæ»æ„ŸãŒæŒ‡æ‘˜ã•ã‚Œã¦ã„ã¾ã™ã€‚\nã‚·ãƒŠãƒªã‚ªCï¼šçœ ã‚Œã‚‹å·¨äººã®è¦šé†’ã¨æ³¢ä¹±ï¼ˆç¢ºç‡ï¼šä½ï½ä¸­ï¼‰\nå¸‚å ´è©•ä¾¡ã¨ç¾çŠ¶ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ä¹–é›¢ãŒã‚ã‚‹ãƒãƒ¼ãƒ ã®å‹•å‘ã§ã™ã€‚\n\nğŸ‡§ğŸ‡· ãƒ–ãƒ©ã‚¸ãƒ«:\nç¾çŠ¶: å—ç±³äºˆé¸ã§è‹¦æˆ¦ï¼ˆä¸€æ™‚5ä½ãƒ»6ä½ï¼‰ã—ã¦ã„ã¾ã™ãŒã€ã‚ªãƒƒã‚ºã§ã¯ä¾ç„¶ã¨ã—ã¦ä¸Šä½ï¼ˆ+650ï½+750ï¼‰ã§ã™ã€‚\nåˆ†æ: ãƒ´ã‚£ãƒ‹ã‚·ã‚¦ã‚¹ã‚‰å‰ç·šã®ã‚¿ãƒ¬ãƒ³ãƒˆåŠ›ã¯éšä¸€ã§ã™ã€‚å¤§ä¼šã¾ã§ã«å®ˆå‚™ã®ä¸å®‰å®šã•ã‚’è§£æ¶ˆã§ãã‚Œã°ã€ä¸€æ°—ã«å„ªå‹å€™è£œç­†é ­ã¸è¿”ã‚Šå’²ããƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ãŒã‚ã‚Šã¾ã™ã€‚\nğŸ´ ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰:\nç¾çŠ¶: 2024å¹´EUROæº–å„ªå‹ã€‚ã‚¿ãƒ¬ãƒ³ãƒˆåŠ›ã¯ã‚¹ãƒšã‚¤ãƒ³ã«åŒ¹æ•µã—ã¾ã™ãŒã€å‹è² æ‰€ã§ã®ç²¾ç¥çš„ãªè„†ã•ãŒèª²é¡Œã§ã™ã€‚\næ³¨ç›®ã™ã¹ããƒ€ãƒ¼ã‚¯ãƒ›ãƒ¼ã‚¹\nğŸ‡ºğŸ‡¾ ã‚¦ãƒ«ã‚°ã‚¢ã‚¤: ãƒ“ã‚¨ãƒ«ã‚µç›£ç£ã®ä¸‹ã€å—ç±³äºˆé¸ã§ãƒ–ãƒ©ã‚¸ãƒ«ãƒ»ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã‚’æ’ƒç ´ã€‚æˆ¦è¡“çš„ãªå®Œæˆåº¦ãŒé«˜ãã€ä¸Šä½å›½ã‚’é£Ÿã†å¯èƒ½æ€§ãŒæœ€ã‚‚é«˜ã„ãƒãƒ¼ãƒ ã§ã™ã€‚\nğŸ‡¨ğŸ‡¦ ã‚«ãƒŠãƒ€: é–‹å‚¬å›½ï¼ˆã‚¢ãƒ¡ãƒªã‚«ãƒ»ãƒ¡ã‚­ã‚·ã‚³ãƒ»ã‚«ãƒŠãƒ€ï¼‰ã®ä¸­ã§æœ€ã‚‚å¥½èª¿ï¼ˆã‚³ãƒ‘ãƒ»ã‚¢ãƒ¡ãƒªã‚«2024ãƒ™ã‚¹ãƒˆ4ï¼‰ã€‚åœ°ã®åˆ©ã‚’æ´»ã‹ã—ãŸèºé€²ãŒæœŸå¾…ã•ã‚Œã¾ã™ã€‚\n2026å¹´å¤§ä¼šç‰¹æœ‰ã®é‡è¦å¤‰æ•°\näºˆæ¸¬ã‚’å·¦å³ã™ã‚‹ã€ä»Šå¤§ä¼šç‰¹æœ‰ã®å¤–çš„è¦å› ã§ã™ã€‚\n\n48ã‚«å›½åˆ¶ã¸ã®æ‹¡å¤§ï¼ˆæ¶ˆè€—æˆ¦ï¼‰: è©¦åˆæ•°ãŒå¢—åŠ ã™ã‚‹ãŸã‚ã€ã‚¹ã‚¿ãƒ¡ãƒ³11äººã ã‘ã§ãªãã€ãƒ™ãƒ³ãƒãƒ¡ãƒ³ãƒãƒ¼ã‚’å«ã‚ãŸ26äººã®ç·åˆåŠ›ãŒå•ã‚ã‚Œã¾ã™ã€‚ã“ã‚Œã¯é¸æ‰‹å±¤ã®åšã„ãƒ•ãƒ©ãƒ³ã‚¹ã‚„ã‚¹ãƒšã‚¤ãƒ³ã«æœ‰åˆ©ã«åƒãã¾ã™ã€‚\nç§»å‹•è·é›¢ã¨æ°—å€™: åŒ—ç±³3ã‚«å›½ã«ã¾ãŸãŒã‚‹åºƒå¤§ãªç§»å‹•ã¨ã€å¤ã®é…·æš‘ãƒ»æ¹¿åº¦ã¯ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ç¶­æŒã‚’å›°é›£ã«ã—ã¾ã™ã€‚ç‰¹å®šã®ç’°å¢ƒã¸ã®é©å¿œåŠ›ãŒä½ã„ãƒãƒ¼ãƒ ã¯ã€å®ŸåŠ›ãŒã‚ã£ã¦ã‚‚æ—©æœŸæ•—é€€ã™ã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚\nå‚ç…§ã‚½ãƒ¼ã‚¹\nFIFA Men's World Ranking (Nov 2025)\nFOX Sports / DraftKings Betting Odds (Nov 2025)\nUEFA Euro 2024 / Copa AmÃ©rica 2024 Results\nğŸ“š æƒ…å ±æºã¨å¼•ç”¨\næ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:\n\npolymarket.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nwikipedia.org\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nsi.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nreddit.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfifa.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nsportingnews.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nyoutube.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\naiscore.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfoxsports.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nsportsbookreview.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nforbes.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nwikipedia.org\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfifa.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nelisportsnetwork.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nolympics.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\ntntsports.co.uk\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfifa.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\n\n\n2æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\nä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\n\nç”·å­ã‚µãƒƒã‚«ãƒ¼ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½ã‚’äºˆæ¸¬ã—ã¦\n\nå®Œäº†ï¼\n\n2025å¹´11æœˆ29æ—¥æ™‚ç‚¹ã®æœ€æ–°ãƒ‡ãƒ¼ã‚¿ãŠã‚ˆã³èª¿æŸ»çµæœã«åŸºã¥ãã€2026å¹´åŒ—ä¸­ç±³ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½äºˆæ¸¬ã‚’æç¤ºã—ã¾ã™ã€‚\n\n1. æ·±æ˜ã‚Šè€ƒå¯Ÿï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\nQ1. åŒ—ä¸­ç±³é–‹å‚¬ï¼ˆé…·æš‘ãƒ»ç§»å‹•ãƒ»æ™‚å·®ï¼‰ã¯ã©ã®ã‚¹ã‚¿ã‚¤ãƒ«ã«æœ‰åˆ©ã‹ï¼Ÿ éå»ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆ1994å¹´ç±³å›½å¤§ä¼šã‚„2014å¹´ãƒ–ãƒ©ã‚¸ãƒ«å¤§ä¼šï¼‰ã‚’å‚ç…§ã™ã‚‹ã¨ã€é…·æš‘ä¸‹ã§ã¯ã€Œãƒœãƒ¼ãƒ«ã‚’ä¿æŒã—ã¦ä½“åŠ›ã‚’æ¸©å­˜ã§ãã‚‹ã€æŠ€è¡“é‡è¦–ã®ãƒãƒ¼ãƒ ï¼ˆã‚¹ãƒšã‚¤ãƒ³ç­‰ï¼‰ã«ä¸€å®šã®ç†ãŒã‚ã‚Šã¾ã™ã€‚ã—ã‹ã—ã€å®ˆå‚™ã«å›ã£ãŸéš›ã®æ¶ˆè€—åº¦ã¯æ¿€ã—ããªã‚‹ãŸã‚ã€æœ€çµ‚çš„ã«ã¯ç‰¹å®šã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚ˆã‚Šã‚‚ã€æ°—å€™é †å¿œæ€§ãŒé«˜ã„å—ç±³å‹¢ã‚„ã€æ¶ˆè€—æˆ¦ã«è€ãˆã†ã‚‹ã€Œãƒ•ã‚£ã‚¸ã‚«ãƒ«ãƒ™ãƒ¼ã‚¹ã®é¸æ‰‹å±¤ã€ã‚’æŒã¤ãƒãƒ¼ãƒ ãŒæœ‰åˆ©ã«åƒãå‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚\n\nQ2. 48ã‚«å›½æ‹¡å¤§ãƒ»è©¦åˆå¢—ã«ãŠã„ã¦ã€é¸æ‰‹å±¤ã§ã‚¹ãƒšã‚¤ãƒ³ç­‰ã‚’å‡Œé§•ã™ã‚‹å›½ã¯ï¼Ÿ ãƒ•ãƒ©ãƒ³ã‚¹ã¨ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã§ã™ã€‚ã“ã®2ã‚«å›½ã¯ã€å„ãƒã‚¸ã‚·ãƒ§ãƒ³ã«ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚¯ãƒ©ã‚¹ã‚’2ã€œ3åæƒãˆã¦ãŠã‚Šã€ã‚¿ãƒ¼ãƒ³ã‚ªãƒ¼ãƒãƒ¼ï¼ˆé¸æ‰‹ã®å…¥ã‚Œæ›¿ãˆï¼‰ã‚’è¡Œã£ã¦ã‚‚æˆ¦åŠ›ãŒè½ã¡ã¾ã›ã‚“ã€‚ç‰¹ã«ãƒ•ãƒ©ãƒ³ã‚¹ã®ãƒ•ã‚£ã‚¸ã‚«ãƒ«çš„ãªé¸æ‰‹å±¤ã®åšã•ã¯ã€ç§»å‹•è·é›¢ãŒé•·ãè©¦åˆæ•°ãŒå¢—ãˆã‚‹ä»Šå¤§ä¼šã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§æœ€å¤§ã®æ­¦å™¨ã¨ãªã‚Šã¾ã™ã€‚\n\nQ3. ã‚¹ãƒšã‚¤ãƒ³ã®ãƒã‚¼ãƒƒã‚·ãƒ§ãƒ³ã«å¯¾ã™ã‚‹æœ‰åŠ¹ãªå¯¾æŠ—ç­–ã¯ï¼Ÿ ã€Œä¸­ç›¤ã§ã®ãƒ•ã‚£ã‚¸ã‚«ãƒ«å¼·åº¦ã«ã‚ˆã‚‹åˆ†æ–­ã€ã¨ã€Œé«˜é€Ÿã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã€ã§ã™ã€‚2025å¹´ç¾åœ¨ã®ã‚¹ãƒšã‚¤ãƒ³ã¯å®Œæˆåº¦ãŒé«˜ã„ã‚‚ã®ã®ã€åŒ—ç±³ã®æš‘ã•ã§é‹å‹•é‡ãŒè½ã¡ãŸæ™‚é–“å¸¯ã«ã€ãƒ•ãƒ©ãƒ³ã‚¹ã‚„ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã®ã‚ˆã†ãªãƒ•ã‚£ã‚¸ã‚«ãƒ«ã«å„ªã‚ŒãŸãƒãƒ¼ãƒ ã‹ã‚‰ãƒã‚¤ãƒ—ãƒ¬ã‚¹ã‚’å—ã‘ã‚‹ã¨ã€å®ˆå‚™ã®è„†ã•ãŒéœ²å‘ˆã™ã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚\n\nQ4. ãƒ–ãƒ©ã‚¸ãƒ«ãŒè©•ä¾¡ã‚’è¦†ã—ã¦å„ªå‹ã™ã‚‹ãŸã‚ã®æ¡ä»¶ã¯ï¼Ÿ ã€Œå®ˆå‚™çµ„ç¹”ã®å®‰å®šã€ã¨ã€Œãƒ´ã‚£ãƒ‹ã‚·ã‚¦ã‚¹ã‚‰ç¾ã‚¨ãƒ¼ã‚¹ã¸ã®æˆ¦è¡“æœ€é©åŒ–ã€ã§ã™ã€‚å€‹ã®èƒ½åŠ›ã¯ä¾ç„¶ã¨ã—ã¦ä¸–ç•Œæœ€é«˜å³°ã§ã™ãŒã€äºˆé¸ã§è‹¦æˆ¦ã—ãŸçµ„ç¹”çš„ãªè„†ã•ã‚’ä¿®æ­£ã—ã€ãƒã‚¤ãƒãƒ¼ãƒ«æ™‚ä»£ã®å¹»å½±ã‹ã‚‰è„±å´ã—ã¦ç¾æœ‰æˆ¦åŠ›ã§å®Œçµã™ã‚‹ãƒãƒ¼ãƒ ã‚’ä½œã‚Œã‚‹ã‹ãŒéµã¨ãªã‚Šã¾ã™ã€‚\n\nQ5. ãƒˆã‚¥ãƒ˜ãƒ«ç›£ç£ï¼ˆã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ï¼‰ã®ã‚ˆã†ãªåå°†ã®å°±ä»»ã¯ãƒ—ãƒ©ã‚¹ã‹ï¼Ÿ æ¥µã‚ã¦å¤§ããªãƒ—ãƒ©ã‚¹è¦å› ã§ã™ã€‚ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®ã‚ˆã†ãªçŸ­æœŸæ±ºæˆ¦ã§ã¯ã€è¤‡é›‘ãªãƒãƒ¼ãƒ ä½œã‚Šã‚ˆã‚Šã‚‚ã€ç›¸æ‰‹ã®å¼±ç‚¹ã‚’çªãæˆ¦è¡“çœ¼ã¨ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆèƒ½åŠ›ãŒå•ã‚ã‚Œã¾ã™ã€‚ãƒˆã‚¥ãƒ˜ãƒ«ç›£ç£ã®ã‚«ãƒƒãƒ—æˆ¦ã§ã®å¼·ã•ï¼ˆãƒã‚§ãƒ«ã‚·ãƒ¼ã§ã®CLå„ªå‹ãªã©ï¼‰ã¯ã€ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã®èª²é¡Œã§ã‚ã‚‹ã€Œå‹è² å¼±ã•ã€ã‚’è£œå®Œã™ã‚‹æœ€é©è§£ã¨è¨€ãˆã¾ã™ã€‚\n\n2. çµè«–\næœ€æœ‰åŠ›å€™è£œï¼šã‚¹ãƒšã‚¤ãƒ³ å¯¾æŠ—é¦¬ï¼šã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã€ãƒ•ãƒ©ãƒ³ã‚¹ã€ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰\n\n2025å¹´11æœˆç¾åœ¨ã€ã‚¹ãƒšã‚¤ãƒ³ãŒé ­ä¸€ã¤æŠœã‘ãŸå„ªå‹å€™è£œã§ã™ã€‚EURO 2024å„ªå‹ã€ãƒ‘ãƒªäº”è¼ªé‡‘ãƒ¡ãƒ€ãƒ«ã¨ã„ã†ç›´è¿‘ã®å®Ÿç¸¾ã«åŠ ãˆã€è‹¥æ‰‹ã¨ãƒ™ãƒ†ãƒ©ãƒ³ãŒèåˆã—ãŸãƒãƒ¼ãƒ ã®å®Œæˆåº¦ã¯ç¾¤ã‚’æŠœã„ã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€é–‹å‚¬åœ°ã®ç’°å¢ƒã‚„é¸æ‰‹å±¤ã‚’è€ƒæ…®ã™ã‚‹ã¨ã€ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã®çµæŸåŠ›ã€ãƒ•ãƒ©ãƒ³ã‚¹ã¨ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã®å€‹ã®åŠ›ãŒåƒ…å·®ã§è¿½ã†ã€Œ4å¼·ã€ã®æ§‹å›³ã¨ãªã‚Šã¾ã™ã€‚\n\n3. è©³ç´°ãªåˆ†æ\næœ¬å‘½ï¼šã‚¹ãƒšã‚¤ãƒ³ï¼ˆFIFAãƒ©ãƒ³ã‚¯1ä½ï¼‰\näºˆæ¸¬æ ¹æ‹ : ç¾åœ¨ã€ä¸–ç•Œã§æœ€ã‚‚æ©Ÿèƒ½ã—ã¦ã„ã‚‹ãƒãƒ¼ãƒ ã§ã™ã€‚ãƒ©ãƒŸãƒ³ãƒ»ãƒ¤ãƒãƒ«ã‚‰ã€Œæ–°é»„é‡‘ä¸–ä»£ã€ãŒå®Œå…¨ã«ä¸»åŠ›ã¨ã—ã¦å®šç€ã—ã€2024å¹´ã®ä¸»è¦ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç‹¬å ã—ã¾ã—ãŸã€‚\nå¼·ã¿: åœ§å€’çš„ãªãƒœãƒ¼ãƒ«æ”¯é…åŠ›ã«åŠ ãˆã€ä»¥å‰ã®ã‚¹ãƒšã‚¤ãƒ³ã«ã¯æ¬ ã‘ã¦ã„ãŸã€Œç¸¦ã¸ã®çªç ´åŠ›ã€ã‚’å…¼ã­å‚™ãˆã¦ã„ã¾ã™ã€‚è‡ªåˆ†ãŸã¡ã®ãƒšãƒ¼ã‚¹ã§è©¦åˆã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã§ãã‚‹ãŸã‚ã€éé…·ãªç’°å¢ƒä¸‹ã§ã‚‚ä½“åŠ›ã‚’æ¸©å­˜ã—ãªãŒã‚‰å‹ã¡ä¸ŠãŒã‚‹å…¬ç®—ãŒé«˜ã„ã§ã™ã€‚\nå¯¾æŠ—ï¼šã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ï¼ˆFIFAãƒ©ãƒ³ã‚¯2ä½ï¼‰\näºˆæ¸¬æ ¹æ‹ : ã‚³ãƒ‘ãƒ»ã‚¢ãƒ¡ãƒªã‚«2024ã‚’åˆ¶ã—ã€ãƒ¡ã‚¸ãƒ£ãƒ¼å¤§ä¼š3é€£è¦‡ã‚’é”æˆã—ãŸã€Œå‹è€…ã®ãƒ¡ãƒ³ã‚¿ãƒªãƒ†ã‚£ã€ã¯å¥åœ¨ã§ã™ã€‚\nå¼·ã¿: ãƒãƒ¼ãƒ ã®çµæŸåŠ›ã¯ä¸–ç•Œä¸€ã§ã™ã€‚ãƒ¡ãƒƒã‚·ã®å¹´é½¢ï¼ˆ39æ­³ã«ãªã‚‹å¹´ï¼‰ã¯æ‡¸å¿µææ–™ã§ã™ãŒã€å½¼ã‚’æ”¯ãˆã‚‹å‘¨å›²ã®çŒ®èº«æ€§ã¨ã€ã‚¹ã‚«ãƒ­ãƒ¼ãƒ‹ç›£ç£ã®æŸ”è»Ÿãªé‡‡é…ã«ã‚ˆã‚Šã€ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆã‚’å‹ã¡æŠœãè¡“ã‚’ç†ŸçŸ¥ã—ã¦ã„ã¾ã™ã€‚å—åŒ—ã‚¢ãƒ¡ãƒªã‚«å¤§é™¸é–‹å‚¬ã¨ã„ã†ã€Œåœ°ã®åˆ©ã€ã‚‚å¤§ããªå¾ŒæŠ¼ã—ã¨ãªã‚Šã¾ã™ã€‚\næœ‰åŠ›ï¼šã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ï¼ˆFIFAãƒ©ãƒ³ã‚¯4ä½ï¼‰\näºˆæ¸¬æ ¹æ‹ : ãƒˆãƒ¼ãƒã‚¹ãƒ»ãƒˆã‚¥ãƒ˜ãƒ«ç›£ç£ã®å°±ä»»ï¼ˆ2025å¹´ï¼‰ã«ã‚ˆã‚Šã€æˆ¦è¡“çš„ãªè¦å¾‹ã¨å‹è² å¼·ã•ãŒåŠ ã‚ã‚Šã¾ã—ãŸã€‚ãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã®ã‚ªãƒƒã‚ºã§ã‚‚ã‚¹ãƒšã‚¤ãƒ³ã«æ¬¡ãè©•ä¾¡ã‚’å¾—ã¦ã„ã¾ã™ã€‚\nå¼·ã¿: ãƒ™ãƒªãƒ³ã‚¬ãƒ ã€ã‚±ã‚¤ãƒ³ã€ã‚µã‚«ãªã©ã€å€‹ã®ã‚¿ãƒ¬ãƒ³ãƒˆåŠ›ã¯ã‚¹ãƒšã‚¤ãƒ³ã‚’ã‚‚å‡Œãã¾ã™ã€‚ãƒˆã‚¥ãƒ˜ãƒ«ç›£ç£ã®æŒ‡æ®ä¸‹ã§å®ˆå‚™ãŒå®‰å®šã™ã‚Œã°ã€60å¹´ã¶ã‚Šã®å„ªå‹ãŒç¾å®Ÿå‘³ã‚’å¸¯ã³ã¾ã™ã€‚\nä¸æ°—å‘³ãªå­˜åœ¨ï¼šãƒ•ãƒ©ãƒ³ã‚¹ï¼ˆFIFAãƒ©ãƒ³ã‚¯3ä½ï¼‰\näºˆæ¸¬æ ¹æ‹ : å¸¸ã«å„ªå‹å€™è£œã«æŒ™ãŒã‚‹é¸æ‰‹å±¤ã®åšã•ãŒã‚ã‚Šã¾ã™ã€‚\nå¼·ã¿: ã‚­ãƒªã‚¢ãƒ³ãƒ»ã‚¨ãƒ ãƒãƒšã‚’ä¸­å¿ƒã¨ã—ãŸæ”»æ’ƒåŠ›ã¨ã€ä¸­ç›¤ã®ãƒ•ã‚£ã‚¸ã‚«ãƒ«å¼·åº¦ã¯ä¸–ç•Œå±ˆæŒ‡ã€‚48ã‚«å›½å‡ºå ´ã«ã‚ˆã‚‹é•·ä¸å ´ã®å¤§ä¼šã«ãŠã„ã¦ã€èª°ãŒå‡ºã¦ã‚‚å¼·ã„ã¨ã„ã†ã€Œå±¤ã®åšã•ã€ã¯æœ€å¤§ã®æ­¦å™¨ã§ã™ã€‚\n4. è€ƒæ…®ã™ã¹ããƒªã‚¹ã‚¯è¦å› \nåŒ—ä¸­ç±³ç‰¹æœ‰ã®ç’°å¢ƒï¼ˆãƒ’ãƒ¼ãƒˆï¼†ãƒ‡ã‚£ã‚¹ã‚¿ãƒ³ã‚¹ï¼‰: ã‚¢ãƒ¡ãƒªã‚«ã€ã‚«ãƒŠãƒ€ã€ãƒ¡ã‚­ã‚·ã‚³ã®3ã‚«å›½é–‹å‚¬ã«ã‚ˆã‚‹ç§»å‹•è·é›¢ã®é•·ã•ã¨ã€ä¸€éƒ¨ä¼šå ´ã®é…·æš‘ã¯ã€æ¬§å·å‹¢ã®ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã‚’å´©ã™æœ€å¤§ã®è¦å› ã¨ãªã‚Šå¾—ã¾ã™ã€‚éå»ã€åŒ—å—ç±³é–‹å‚¬ã®Wæ¯ã§æ¬§å·å‹¢ãŒå„ªå‹ã—ãŸã®ã¯2014å¹´ã®ãƒ‰ã‚¤ãƒ„ã®ã¿ã§ã™ã€‚ã“ã®ã‚¸ãƒ³ã‚¯ã‚¹ã¯å—ç±³å‹¢ï¼ˆã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã€ãƒ–ãƒ©ã‚¸ãƒ«ï¼‰ã«ã¨ã£ã¦è¿½ã„é¢¨ã§ã™ã€‚\n\nå¤§ä¼šãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å¤‰æ›´: å‡ºå ´å›½ãŒ48ã‚«å›½ã«å¢—ãˆã€æ±ºå‹ã¾ã§ã®è©¦åˆæ•°ãŒæœ€å¤§8è©¦åˆã«å¢—åŠ ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç‰¹å®šã®ã‚¹ã‚¿ãƒ¼é¸æ‰‹ã«ä¾å­˜ã™ã‚‹ãƒãƒ¼ãƒ ï¼ˆä¾‹ï¼šãƒ¡ãƒƒã‚·ä¾å­˜ã®ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã€ãƒ‡ãƒ»ãƒ–ãƒ©ã‚¤ãƒä¾å­˜ã®ãƒ™ãƒ«ã‚®ãƒ¼ç­‰ï¼‰ã¯ã€å¤§ä¼šçµ‚ç›¤ã«ã‚¬ã‚¹æ¬ ã‚’èµ·ã“ã™ãƒªã‚¹ã‚¯ãŒé«˜ã¾ã‚Šã¾ã™ã€‚\n\nãƒ–ãƒ©ã‚¸ãƒ«ã®å¾©èª¿: ç¾åœ¨5ç•ªæ‰‹è©•ä¾¡ã§ã™ãŒã€å€‹ã®èƒ½åŠ›ã¯ä¾ç„¶ã¨ã—ã¦ãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã§ã™ã€‚å¤§ä¼šã¾ã§ã«å®ˆå‚™çµ„ç¹”ãŒæ•´å‚™ã•ã‚Œã‚Œã°ã€ä¸€æ°—ã«å„ªå‹å€™è£œç­†é ­ã«èºã‚Šå‡ºã‚‹ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã‚’ç§˜ã‚ã¦ã„ã¾ã™ã€‚\n\nğŸ“š æƒ…å ±æºã¨å¼•ç”¨\næ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:\n\npolymarket.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nwikipedia.org\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfifa.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nsportsbookreview.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfoxsports.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nolympics.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nlivescore.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\n365scores.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\napnews.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nelisportsnetwork.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nbetfair.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\naiscore.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nyoutube.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nyoutube.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nä½•ã‹èã„ã¦ãã ã•ã„...\n\n3\nä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\n\nç”·å­ã‚µãƒƒã‚«ãƒ¼ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½ã‚’äºˆæ¸¬ã—ã¦\n\nå®Œäº†ï¼\n\n2025å¹´11æœˆæ™‚ç‚¹ã®æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã€FIFAãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€ãŠã‚ˆã³å¸‚å ´äºˆæ¸¬ã«åŸºã¥ãã€2026å¹´ç”·å­ã‚µãƒƒã‚«ãƒ¼ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½äºˆæ¸¬ã‚’åˆ†æã—ã¾ã™ã€‚\n\n1. çµè«–ï¼šç¾åœ¨ã®æœ€æœ‰åŠ›å€™è£œã¯ã€Œã‚¹ãƒšã‚¤ãƒ³ã€\nç¾æ™‚ç‚¹ï¼ˆ2025å¹´11æœˆï¼‰ã§æœ€ã‚‚å„ªå‹ã«è¿‘ã„ã¨äºˆæ¸¬ã•ã‚Œã‚‹ã®ã¯ã‚¹ãƒšã‚¤ãƒ³ã§ã™ã€‚ EURO 2024ã§ã®å„ªå‹å®Ÿç¸¾ã¨ã€FIFAãƒ©ãƒ³ã‚­ãƒ³ã‚°1ä½ã‚’ç¶­æŒã™ã‚‹å®‰å®šæ„ŸãŒè©•ä¾¡ã•ã‚Œã€ãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼å„ç¤¾ã§ã‚‚ç­†é ­å€™è£œï¼ˆã‚ªãƒƒã‚ºç´„5.4å€ï¼‰ã¨ãªã£ã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã€ãƒ•ãƒ©ãƒ³ã‚¹ã€å‰å›ç‹è€…ã®ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ãŒç¶šãã€Œ4å¼·ï¼‹ãƒ–ãƒ©ã‚¸ãƒ«ã€ã®æ§‹å›³ãŒå½¢æˆã•ã‚Œã¦ã„ã¾ã™ã€‚\n\n2. è©³ç´°ãªåˆ†æã¨äºˆæ¸¬ã‚·ãƒŠãƒªã‚ª\nç­†é ­å€™è£œï¼šã‚¹ãƒšã‚¤ãƒ³ï¼ˆFIFAãƒ©ãƒ³ã‚¯1ä½ï¼‰\näºˆæ¸¬æ ¹æ‹ : EURO 2024å„ªå‹ã«åŠ ãˆã€2024-25 UEFAãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚ºãƒªãƒ¼ã‚°ã§ã‚‚å¥½èª¿ã‚’ç¶­æŒã—ã¦ãŠã‚Šã€æˆ¦è¡“çš„ãªå®Œæˆåº¦ãŒæœ€ã‚‚é«˜ã„ã¨è©•ä¾¡ã•ã‚Œã¦ã„ã¾ã™ã€‚\nå¼·ã¿: ãƒ©ãƒŸãƒ³ãƒ»ãƒ¤ãƒãƒ«ã‚„ãƒ­ãƒ‰ãƒªã‚’ä¸­å¿ƒã¨ã—ãŸä¸–ä»£äº¤ä»£ãŒå®Œäº†ã—ã¦ãŠã‚Šã€ãƒ™ãƒ†ãƒ©ãƒ³ã¨è‹¥æ‰‹ãŒå®Œç’§ã«èåˆã—ã¦ã„ã¾ã™ã€‚\nå¸‚å ´è©•ä¾¡: ä¸»è¦ãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã§ã®å„ªå‹ç¢ºç‡ã¯ç´„18.5%ï¼ˆã‚ªãƒƒã‚º +440ï½+450ï¼‰ã§å˜ç‹¬ãƒˆãƒƒãƒ—ã§ã™ã€‚\nå¯¾æŠ—é¦¬ï¼ˆå‰å›ç‹è€…ï¼‰ï¼šã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ï¼ˆFIFAãƒ©ãƒ³ã‚¯2ä½ï¼‰\näºˆæ¸¬æ ¹æ‹ : 2022å¹´Wæ¯ãŠã‚ˆã³ã‚³ãƒ‘ãƒ»ã‚¢ãƒ¡ãƒªã‚«2024ã®ç‹è€…ã¨ã—ã¦ã€ä¾ç„¶ã¨ã—ã¦ä¸–ç•Œãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã®å®ŸåŠ›ã‚’ä¿æŒã—ã¦ã„ã¾ã™ã€‚å—ç±³äºˆé¸ã‚‚é¦–ä½äº‰ã„ã‚’æ¼”ã˜ã€æœ¬å¤§ä¼šå‡ºå ´æ¨©ã‚’ç¢ºä¿æ¸ˆã¿ã§ã™ã€‚\nå¼·ã¿: ãƒªã‚ªãƒãƒ«ãƒ»ãƒ¡ãƒƒã‚·ãŒã‚­ãƒ£ãƒ—ãƒ†ãƒ³ã¨ã—ã¦ç²¾ç¥çš„æ”¯æŸ±ã®å½¹å‰²ã‚’æœãŸã—ã¦ãŠã‚Šã€ãƒãƒ¼ãƒ ã®çµæŸåŠ›ãŒéå¸¸ã«é«˜ã„ç‚¹ãŒç‰¹å¾´ã§ã™ã€‚\nå¸‚å ´è©•ä¾¡: ã‚ªãƒƒã‚ºã¯ç´„8.5ï½9.0å€ã§5ç•ªæ‰‹è©•ä¾¡ã§ã™ãŒã€çŸ­æœŸæ±ºæˆ¦ã§ã®å‹è² å¼·ã•ã¯éšä¸€ã§ã™ã€‚\nãã®ä»–ã®æœ‰åŠ›å€™è£œï¼ˆãƒˆãƒƒãƒ—ãƒ†ã‚£ã‚¢ï¼‰\nã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ï¼ˆã‚ªãƒƒã‚º2ä½ / ç´„7.0å€ï¼‰: EURO 2024æº–å„ªå‹ã®å®Ÿç¸¾ã¨ã€äºˆé¸ã‚’ç„¡æ•—ã§é€šéã—ãŸå®‰å®šæ„ŸãŒè©•ä¾¡ã•ã‚Œã¦ã„ã¾ã™ã€‚ã€Œ60å¹´ã¶ã‚Šã®å„ªå‹ã€ã¸ã®æœŸå¾…ãŒé«˜ãã€æˆ¦åŠ›å±¤ã®åšã•ã¯ä¸–ç•Œå±ˆæŒ‡ã§ã™ã€‚\nãƒ•ãƒ©ãƒ³ã‚¹ï¼ˆã‚ªãƒƒã‚º3ä½ / ç´„8.0å€ï¼‰: ã‚­ãƒªã‚¢ãƒ³ãƒ»ã‚¨ãƒ ãƒãƒšãŒå…¨ç››æœŸã‚’è¿ãˆã¦ãŠã‚Šã€å€‹ã®èƒ½åŠ›ã§è©¦åˆã‚’æ±ºå®šã¥ã‘ã‚‹åŠ›ãŒã‚ã‚Šã¾ã™ã€‚FIFAãƒ©ãƒ³ã‚¯3ä½ã‚’ç¶­æŒã—ã¦ã„ã¾ã™ã€‚\nãƒ–ãƒ©ã‚¸ãƒ«ï¼ˆã‚ªãƒƒã‚º4ä½ / ç´„8.5å€ï¼‰: äºˆé¸åºç›¤ã¯è‹¦æˆ¦ã—ã¾ã—ãŸãŒã€2025å¹´å¾ŒåŠã«å¾©èª¿ã—FIFAãƒ©ãƒ³ã‚¯5ä½ã¸æµ®ä¸Šã—ã¾ã—ãŸã€‚ãƒã‚¤ãƒãƒ¼ãƒ«ã®å¾©å¸°ã¨çŠ¶æ…‹ãŒå„ªå‹ã¸ã®éµã‚’æ¡ã‚Šã¾ã™ã€‚\n3. è€ƒæ…®ã™ã¹ããƒªã‚¹ã‚¯è¦å› ã¨ä¸ç¢ºå®šè¦ç´ \näºˆæ¸¬ã‚’è¡Œã†ä¸Šã§ã€ä»¥ä¸‹ã®è¦ç´ ãŒçµæœã‚’å·¦å³ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n\nåŒ—ç±³é–‹å‚¬ç‰¹æœ‰ã®ç’°å¢ƒè² è·: ã‚¢ãƒ¡ãƒªã‚«ãƒ»ã‚«ãƒŠãƒ€ãƒ»ãƒ¡ã‚­ã‚·ã‚³ã®3ã‚«å›½å…±å‚¬ã¨ãªã‚‹ãŸã‚ã€ç§»å‹•è·é›¢ãŒéå¸¸ã«é•·ãã€ãƒ¡ã‚­ã‚·ã‚³ã‚„ç±³å›½å—éƒ¨ã§ã®é…·æš‘ãŒé¸æ‰‹ã®ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã‚’è‘—ã—ãä½ä¸‹ã•ã›ã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã¯é¸æ‰‹å±¤ã®åšã„ãƒãƒ¼ãƒ ï¼ˆæ¬§å·å‹¢ãªã©ï¼‰ã«æœ‰åˆ©ã«åƒãå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\nä¸»åŠ›é¸æ‰‹ã®è² å‚·ãƒªã‚¹ã‚¯: æ¬§å·ä¸»è¦ãƒªãƒ¼ã‚°ã®éå¯†æ—¥ç¨‹ã«ã‚ˆã‚Šã€ACLï¼ˆå‰åå­—é­å¸¯ï¼‰æå‚·ãªã©ã®é‡å‚·ãŒå¢—åŠ å‚¾å‘ã«ã‚ã‚Šã¾ã™ã€‚å¤§ä¼šç›´å‰ã®æ€ªæˆ‘äººãŒäºˆæ¸¬ã‚’å¤§ããè¦†ã™å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\nãƒ™ãƒ†ãƒ©ãƒ³ã¸ã®ä¾å­˜åº¦: ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ï¼ˆãƒ¡ãƒƒã‚·ï¼‰ã‚„ãƒãƒ«ãƒˆã‚¬ãƒ«ï¼ˆC.ãƒ­ãƒŠã‚¦ãƒ‰ï¼‰ãªã©ã€ãƒ™ãƒ†ãƒ©ãƒ³ã‚¹ã‚¿ãƒ¼ã¸ã®ä¾å­˜åº¦ãŒé«˜ã„ãƒãƒ¼ãƒ ã¯ã€å½¼ã‚‰ã®ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³æ¬¡ç¬¬ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå¤§ããå¤‰å‹•ã™ã‚‹ãƒªã‚¹ã‚¯ã‚’æŠ±ãˆã¦ã„ã¾ã™ã€‚\nå‡ºå…¸:\n\nFIFA Men's World Ranking (2025å¹´11æœˆ19æ—¥æ›´æ–°)\nFanDuel / DraftKings Betting Odds (2025å¹´11æœˆæ™‚ç‚¹)\nFox Sports å ±é“ (2025å¹´11æœˆ)\nğŸ“š æƒ…å ±æºã¨å¼•ç”¨\næ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:\n\npolymarket.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nwikipedia.org\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfifa.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nsofascore.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfifa.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nsoccerpunter.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfoxsports.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nlivescore.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\naiscore.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\n11v11.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfootystats.org\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nsportsbookreview.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\ndraftkings.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\ngoal.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nnational-football-teams.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nthesoccerera.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\n365scores.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfoxsports.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nwikipedia.org\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nsportpesa.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nfanduel.com\nå‡ºå…¸: vertexaisearch.cloud.google.com\n\nwikipedia.org\nå‡ºå…¸: vertexaisearch.cloud.google.com"
                },
                {
                    "role": "model",
                    "content": "ä»¥ä¸‹ã«ã€æƒ…å ±ã®é®®åº¦ã€åˆ†æã®æ·±ã•ã€æ ¹æ‹ ã®å…·ä½“æ€§ã‚’åŸºæº–ã¨ã—ãŸå³æ ¼ãªæ¡ç‚¹çµæœã¨ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æç¤ºã—ã¾ã™ã€‚\n\n### **æ¡ç‚¹çµæœ**\n\n*   **3ç‚¹ï¼ˆæœ€é«˜è©•ä¾¡ï¼‰**: **å›ç­”2**\n*   **2ç‚¹ï¼ˆé«˜è©•ä¾¡ï¼‰**: **å›ç­”0**\n*   **1ç‚¹ï¼ˆæ¨™æº–ï¼‰**: **å›ç­”3**\n*   **0ç‚¹ï¼ˆä½è©•ä¾¡ï¼‰**: **å›ç­”1**\n\n---\n\n### **è©³ç´°ãƒ¬ãƒ“ãƒ¥ãƒ¼**\n\n#### **3ç‚¹ï¼šå›ç­”2ï¼ˆæƒ…å ±ã®é®®åº¦ã¨æ´å¯ŸåŠ›ãŒçªå‡ºï¼‰**\n**åˆ¤å®šç†ç”±**: å”¯ä¸€ã€2026å¹´Wæ¯ã«å‘ã‘ãŸ**æ±ºå®šçš„ãªå¤‰æ•°ï¼ˆç›£ç£äººäº‹ï¼‰**ã‚’æ‰ãˆã¦ãŠã‚Šã€åˆ†æã®è³ªãŒé ­ä¸€ã¤æŠœã‘ã¦ã„ã¾ã™ã€‚\n*   **æœ€æ–°æƒ…å ±ã®åæ˜ **: ä»–ã®å›ç­”ãŒè¦‹è½ã¨ã—ã¦ã„ã‚‹**ã€Œãƒˆãƒ¼ãƒã‚¹ãƒ»ãƒˆã‚¥ãƒ˜ãƒ«ç›£ç£ã®ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ä»£è¡¨å°±ä»»ï¼ˆ2025å¹´ã€œï¼‰ã€**ã¨ã„ã†äº‹å®Ÿã«è¨€åŠã—ã¦ã„ã¾ã™ã€‚Wæ¯ã®ã‚ˆã†ãªçŸ­æœŸæ±ºæˆ¦ã§ã¯ç›£ç£ã®æˆ¦è¡“æ‰‹è…•ãŒå‹æ•—ã‚’åˆ†ã‘ã‚‹ãŸã‚ã€ã“ã®æƒ…å ±ã®æœ‰ç„¡ã¯äºˆæ¸¬ç²¾åº¦ã«ç›´çµã—ã¾ã™ã€‚\n*   **å¤šè§’çš„ãªè¦–ç‚¹**: å˜ãªã‚‹æˆ¦åŠ›æ¯”è¼ƒã«ã¨ã©ã¾ã‚‰ãšã€åŒ—ä¸­ç±³é–‹å‚¬ç‰¹æœ‰ã®ã€Œé…·æš‘ãƒ»ç§»å‹•è·é›¢ãƒ»æ™‚å·®ã€ãŒã€ãƒã‚¼ãƒƒã‚·ãƒ§ãƒ³å‹ã®ã‚¹ãƒšã‚¤ãƒ³ã‚„é¸æ‰‹å±¤ã®åšã„ãƒ•ãƒ©ãƒ³ã‚¹ã«ã©ã†æœ‰åˆ©/ä¸åˆ©ã«åƒãã‹ã‚’è«–ç†çš„ã«åˆ†æã—ã¦ã„ã¾ã™ã€‚\n\n#### **2ç‚¹ï¼šå›ç­”0ï¼ˆå®¢è¦³çš„ãƒ‡ãƒ¼ã‚¿ãŒè±Šå¯Œï¼‰**\n**åˆ¤å®šç†ç”±**: ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸä¿¡é ¼æ€§ã®é«˜ã„å›ç­”ã§ã™ãŒã€å®šæ€§çš„ãªæœ€æ–°æƒ…å ±ã§å›ç­”2ã«åŠ£ã‚Šã¾ã™ã€‚\n*   **æ•°å€¤ã®å…·ä½“æ€§**: ã€Œã‚ªãƒƒã‚º4.5ã€œ5.5å€ã€ã€Œäºˆæ¸¬å¸‚å ´ã§ç´„17%ã€ãªã©ã€å…·ä½“çš„ãªæ•°å€¤ã‚’æç¤ºã—ã¦ãŠã‚Šã€å®¢è¦³çš„ãªèª¬å¾—åŠ›ãŒéå¸¸ã«é«˜ã„ã§ã™ã€‚\n*   **å¸‚å ´èªè­˜ã®æ­£ç¢ºã•**: ã€Œã‚¹ãƒšã‚¤ãƒ³ãŒ1ç•ªäººæ°—ã€ã¨ã„ã†ç¾çŠ¶ã®å¸‚å ´ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’æ­£ç¢ºã«æŠŠæ¡ã—ã¦ã„ã¾ã™ã€‚\n*   **æ¸›ç‚¹å¯¾è±¡**: ç›£ç£äººäº‹ãªã©ã®ã€Œæ•°å­—ã«è¡¨ã‚Œãªã„æœ€æ–°ã®æ–‡è„ˆã€ã¸ã®è¨€åŠãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚\n\n#### **1ç‚¹ï¼šå›ç­”3ï¼ˆç„¡é›£ãªã¾ã¨ã‚ï¼‰**\n**åˆ¤å®šç†ç”±**: åˆæ ¼ç‚¹ã§ã¯ã‚ã‚Šã¾ã™ãŒã€ç‹¬è‡ªæ€§ã‚„æ·±ã¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\n*   **æ§‹æˆ**: çµè«–ã€æ ¹æ‹ ã€ãƒªã‚¹ã‚¯è¦å› ã¨æ§‹æˆã¯æ•´ã£ã¦ã„ã¾ã™ã€‚\n*   **æƒ…å ±ã®é™³è…åŒ–**: å†…å®¹ãŒä¸€èˆ¬çš„ã§ã€æ¤œç´¢ã™ã‚Œã°ã™ãã«å‡ºã¦ãã‚‹è¡¨é¢çš„ãªæƒ…å ±ã®ç¾…åˆ—ã«ç•™ã¾ã£ã¦ã„ã¾ã™ã€‚ã€Œãªãœä»Šã‚¹ãƒšã‚¤ãƒ³ãªã®ã‹ã€ã¨ã„ã†å•ã„ã«å¯¾ã—ã€å›ç­”0ã®ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã‚‚ã€å›ç­”2ã®ã‚ˆã†ãªæ·±ã„æ´å¯Ÿã‚‚æ¬ ã‘ã¦ã„ã¾ã™ã€‚\n\n#### **0ç‚¹ï¼šå›ç­”1ï¼ˆå…·ä½“æ€§ä¸è¶³ï¼‰**\n**åˆ¤å®šç†ç”±**: åˆ†æã¨ã—ã¦ä¸ååˆ†ã§ã™ã€‚\n*   **æŠ½è±¡çš„ãªè¡¨ç¾**: ã€Œæ–°ãƒ»é»„é‡‘æœŸã®è¨¼æ˜ã€ã€Œåº•åŠ›ã€ã¨ã„ã£ãŸæƒ…ç·’çš„ãªè¨€è‘‰ãŒå¤šãã€è«–ç†çš„ãªæ ¹æ‹ ãŒå¸Œè–„ã§ã™ã€‚\n*   **åˆ†æã®æµ…ã•**: çµè«–ï¼ˆã‚¹ãƒšã‚¤ãƒ³æœ¬å‘½ï¼‰ã¯åˆã£ã¦ã„ã¾ã™ãŒã€ãã®ãƒ—ãƒ­ã‚»ã‚¹ãŒèª¬æ˜ã•ã‚Œã¦ãŠã‚‰ãšã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç´å¾—ã§ãã‚‹ææ–™ã‚’æä¾›ã§ãã¦ã„ã¾ã›ã‚“ã€‚"
                }
            ]
        },
        {
            "id": "afd31e54-5fbf-4e77-a609-15bd55dac9d0",
            "title": "ç”·å­ã‚µãƒƒã‚«ãƒ¼ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½ã‚’äºˆæ¸¬...",
            "timestamp": "2025-11-30T00:07:11.055143",
            "messages": [
                {
                    "role": "user",
                    "content": "ç”·å­ã‚µãƒƒã‚«ãƒ¼ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½ã‚’äºˆæ¸¬ã—ã¦"
                },
                {
                    "role": "model",
                    "content": "2025å¹´11æœˆ29æ—¥æ™‚ç‚¹ã®æœ€æ–°ãƒ‡ãƒ¼ã‚¿ãŠã‚ˆã³èª¿æŸ»çµæœã«åŸºã¥ãã€2026å¹´åŒ—ä¸­ç±³ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½äºˆæ¸¬ã‚’æç¤ºã—ã¾ã™ã€‚\n\n### 1. æ·±æ˜ã‚Šè€ƒå¯Ÿï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n\n**Q1. åŒ—ä¸­ç±³é–‹å‚¬ï¼ˆé…·æš‘ãƒ»ç§»å‹•ãƒ»æ™‚å·®ï¼‰ã¯ã©ã®ã‚¹ã‚¿ã‚¤ãƒ«ã«æœ‰åˆ©ã‹ï¼Ÿ**\néå»ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆ1994å¹´ç±³å›½å¤§ä¼šã‚„2014å¹´ãƒ–ãƒ©ã‚¸ãƒ«å¤§ä¼šï¼‰ã‚’å‚ç…§ã™ã‚‹ã¨ã€é…·æš‘ä¸‹ã§ã¯ã€Œãƒœãƒ¼ãƒ«ã‚’ä¿æŒã—ã¦ä½“åŠ›ã‚’æ¸©å­˜ã§ãã‚‹ã€æŠ€è¡“é‡è¦–ã®ãƒãƒ¼ãƒ ï¼ˆã‚¹ãƒšã‚¤ãƒ³ç­‰ï¼‰ã«ä¸€å®šã®ç†ãŒã‚ã‚Šã¾ã™ã€‚ã—ã‹ã—ã€å®ˆå‚™ã«å›ã£ãŸéš›ã®æ¶ˆè€—åº¦ã¯æ¿€ã—ããªã‚‹ãŸã‚ã€æœ€çµ‚çš„ã«ã¯ç‰¹å®šã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚ˆã‚Šã‚‚ã€æ°—å€™é †å¿œæ€§ãŒé«˜ã„å—ç±³å‹¢ã‚„ã€æ¶ˆè€—æˆ¦ã«è€ãˆã†ã‚‹ã€Œãƒ•ã‚£ã‚¸ã‚«ãƒ«ãƒ™ãƒ¼ã‚¹ã®é¸æ‰‹å±¤ã€ã‚’æŒã¤ãƒãƒ¼ãƒ ãŒæœ‰åˆ©ã«åƒãå‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚\n\n**Q2. 48ã‚«å›½æ‹¡å¤§ãƒ»è©¦åˆå¢—ã«ãŠã„ã¦ã€é¸æ‰‹å±¤ã§ã‚¹ãƒšã‚¤ãƒ³ç­‰ã‚’å‡Œé§•ã™ã‚‹å›½ã¯ï¼Ÿ**\n**ãƒ•ãƒ©ãƒ³ã‚¹**ã¨**ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰**ã§ã™ã€‚ã“ã®2ã‚«å›½ã¯ã€å„ãƒã‚¸ã‚·ãƒ§ãƒ³ã«ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚¯ãƒ©ã‚¹ã‚’2ã€œ3åæƒãˆã¦ãŠã‚Šã€ã‚¿ãƒ¼ãƒ³ã‚ªãƒ¼ãƒãƒ¼ï¼ˆé¸æ‰‹ã®å…¥ã‚Œæ›¿ãˆï¼‰ã‚’è¡Œã£ã¦ã‚‚æˆ¦åŠ›ãŒè½ã¡ã¾ã›ã‚“ã€‚ç‰¹ã«ãƒ•ãƒ©ãƒ³ã‚¹ã®ãƒ•ã‚£ã‚¸ã‚«ãƒ«çš„ãªé¸æ‰‹å±¤ã®åšã•ã¯ã€ç§»å‹•è·é›¢ãŒé•·ãè©¦åˆæ•°ãŒå¢—ãˆã‚‹ä»Šå¤§ä¼šã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§æœ€å¤§ã®æ­¦å™¨ã¨ãªã‚Šã¾ã™ã€‚\n\n**Q3. ã‚¹ãƒšã‚¤ãƒ³ã®ãƒã‚¼ãƒƒã‚·ãƒ§ãƒ³ã«å¯¾ã™ã‚‹æœ‰åŠ¹ãªå¯¾æŠ—ç­–ã¯ï¼Ÿ**\nã€Œä¸­ç›¤ã§ã®ãƒ•ã‚£ã‚¸ã‚«ãƒ«å¼·åº¦ã«ã‚ˆã‚‹åˆ†æ–­ã€ã¨ã€Œé«˜é€Ÿã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã€ã§ã™ã€‚2025å¹´ç¾åœ¨ã®ã‚¹ãƒšã‚¤ãƒ³ã¯å®Œæˆåº¦ãŒé«˜ã„ã‚‚ã®ã®ã€åŒ—ç±³ã®æš‘ã•ã§é‹å‹•é‡ãŒè½ã¡ãŸæ™‚é–“å¸¯ã«ã€ãƒ•ãƒ©ãƒ³ã‚¹ã‚„ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã®ã‚ˆã†ãªãƒ•ã‚£ã‚¸ã‚«ãƒ«ã«å„ªã‚ŒãŸãƒãƒ¼ãƒ ã‹ã‚‰ãƒã‚¤ãƒ—ãƒ¬ã‚¹ã‚’å—ã‘ã‚‹ã¨ã€å®ˆå‚™ã®è„†ã•ãŒéœ²å‘ˆã™ã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚\n\n**Q4. ãƒ–ãƒ©ã‚¸ãƒ«ãŒè©•ä¾¡ã‚’è¦†ã—ã¦å„ªå‹ã™ã‚‹ãŸã‚ã®æ¡ä»¶ã¯ï¼Ÿ**\nã€Œå®ˆå‚™çµ„ç¹”ã®å®‰å®šã€ã¨ã€Œãƒ´ã‚£ãƒ‹ã‚·ã‚¦ã‚¹ã‚‰ç¾ã‚¨ãƒ¼ã‚¹ã¸ã®æˆ¦è¡“æœ€é©åŒ–ã€ã§ã™ã€‚å€‹ã®èƒ½åŠ›ã¯ä¾ç„¶ã¨ã—ã¦ä¸–ç•Œæœ€é«˜å³°ã§ã™ãŒã€äºˆé¸ã§è‹¦æˆ¦ã—ãŸçµ„ç¹”çš„ãªè„†ã•ã‚’ä¿®æ­£ã—ã€ãƒã‚¤ãƒãƒ¼ãƒ«æ™‚ä»£ã®å¹»å½±ã‹ã‚‰è„±å´ã—ã¦ç¾æœ‰æˆ¦åŠ›ã§å®Œçµã™ã‚‹ãƒãƒ¼ãƒ ã‚’ä½œã‚Œã‚‹ã‹ãŒéµã¨ãªã‚Šã¾ã™ã€‚\n\n**Q5. ãƒˆã‚¥ãƒ˜ãƒ«ç›£ç£ï¼ˆã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ï¼‰ã®ã‚ˆã†ãªåå°†ã®å°±ä»»ã¯ãƒ—ãƒ©ã‚¹ã‹ï¼Ÿ**\næ¥µã‚ã¦å¤§ããªãƒ—ãƒ©ã‚¹è¦å› ã§ã™ã€‚ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®ã‚ˆã†ãªçŸ­æœŸæ±ºæˆ¦ã§ã¯ã€è¤‡é›‘ãªãƒãƒ¼ãƒ ä½œã‚Šã‚ˆã‚Šã‚‚ã€ç›¸æ‰‹ã®å¼±ç‚¹ã‚’çªãæˆ¦è¡“çœ¼ã¨ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆèƒ½åŠ›ãŒå•ã‚ã‚Œã¾ã™ã€‚ãƒˆã‚¥ãƒ˜ãƒ«ç›£ç£ã®ã‚«ãƒƒãƒ—æˆ¦ã§ã®å¼·ã•ï¼ˆãƒã‚§ãƒ«ã‚·ãƒ¼ã§ã®CLå„ªå‹ãªã©ï¼‰ã¯ã€ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã®èª²é¡Œã§ã‚ã‚‹ã€Œå‹è² å¼±ã•ã€ã‚’è£œå®Œã™ã‚‹æœ€é©è§£ã¨è¨€ãˆã¾ã™ã€‚\n\n---\n\n### 2. çµè«–\n\n**æœ€æœ‰åŠ›å€™è£œï¼šã‚¹ãƒšã‚¤ãƒ³**\n**å¯¾æŠ—é¦¬ï¼šã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã€ãƒ•ãƒ©ãƒ³ã‚¹ã€ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰**\n\n2025å¹´11æœˆç¾åœ¨ã€**ã‚¹ãƒšã‚¤ãƒ³**ãŒé ­ä¸€ã¤æŠœã‘ãŸå„ªå‹å€™è£œã§ã™ã€‚EURO 2024å„ªå‹ã€ãƒ‘ãƒªäº”è¼ªé‡‘ãƒ¡ãƒ€ãƒ«ã¨ã„ã†ç›´è¿‘ã®å®Ÿç¸¾ã«åŠ ãˆã€è‹¥æ‰‹ã¨ãƒ™ãƒ†ãƒ©ãƒ³ãŒèåˆã—ãŸãƒãƒ¼ãƒ ã®å®Œæˆåº¦ã¯ç¾¤ã‚’æŠœã„ã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€é–‹å‚¬åœ°ã®ç’°å¢ƒã‚„é¸æ‰‹å±¤ã‚’è€ƒæ…®ã™ã‚‹ã¨ã€**ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³**ã®çµæŸåŠ›ã€**ãƒ•ãƒ©ãƒ³ã‚¹**ã¨**ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰**ã®å€‹ã®åŠ›ãŒåƒ…å·®ã§è¿½ã†ã€Œ4å¼·ã€ã®æ§‹å›³ã¨ãªã‚Šã¾ã™ã€‚\n\n---\n\n### 3. è©³ç´°ãªåˆ†æ\n\n#### **æœ¬å‘½ï¼šã‚¹ãƒšã‚¤ãƒ³ï¼ˆFIFAãƒ©ãƒ³ã‚¯1ä½ï¼‰**\n*   **äºˆæ¸¬æ ¹æ‹ **: ç¾åœ¨ã€ä¸–ç•Œã§æœ€ã‚‚æ©Ÿèƒ½ã—ã¦ã„ã‚‹ãƒãƒ¼ãƒ ã§ã™ã€‚ãƒ©ãƒŸãƒ³ãƒ»ãƒ¤ãƒãƒ«ã‚‰ã€Œæ–°é»„é‡‘ä¸–ä»£ã€ãŒå®Œå…¨ã«ä¸»åŠ›ã¨ã—ã¦å®šç€ã—ã€2024å¹´ã®ä¸»è¦ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç‹¬å ã—ã¾ã—ãŸã€‚\n*   **å¼·ã¿**: åœ§å€’çš„ãªãƒœãƒ¼ãƒ«æ”¯é…åŠ›ã«åŠ ãˆã€ä»¥å‰ã®ã‚¹ãƒšã‚¤ãƒ³ã«ã¯æ¬ ã‘ã¦ã„ãŸã€Œç¸¦ã¸ã®çªç ´åŠ›ã€ã‚’å…¼ã­å‚™ãˆã¦ã„ã¾ã™ã€‚è‡ªåˆ†ãŸã¡ã®ãƒšãƒ¼ã‚¹ã§è©¦åˆã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã§ãã‚‹ãŸã‚ã€éé…·ãªç’°å¢ƒä¸‹ã§ã‚‚ä½“åŠ›ã‚’æ¸©å­˜ã—ãªãŒã‚‰å‹ã¡ä¸ŠãŒã‚‹å…¬ç®—ãŒé«˜ã„ã§ã™ã€‚\n\n#### **å¯¾æŠ—ï¼šã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ï¼ˆFIFAãƒ©ãƒ³ã‚¯2ä½ï¼‰**\n*   **äºˆæ¸¬æ ¹æ‹ **: ã‚³ãƒ‘ãƒ»ã‚¢ãƒ¡ãƒªã‚«2024ã‚’åˆ¶ã—ã€ãƒ¡ã‚¸ãƒ£ãƒ¼å¤§ä¼š3é€£è¦‡ã‚’é”æˆã—ãŸã€Œå‹è€…ã®ãƒ¡ãƒ³ã‚¿ãƒªãƒ†ã‚£ã€ã¯å¥åœ¨ã§ã™ã€‚\n*   **å¼·ã¿**: ãƒãƒ¼ãƒ ã®çµæŸåŠ›ã¯ä¸–ç•Œä¸€ã§ã™ã€‚ãƒ¡ãƒƒã‚·ã®å¹´é½¢ï¼ˆ39æ­³ã«ãªã‚‹å¹´ï¼‰ã¯æ‡¸å¿µææ–™ã§ã™ãŒã€å½¼ã‚’æ”¯ãˆã‚‹å‘¨å›²ã®çŒ®èº«æ€§ã¨ã€ã‚¹ã‚«ãƒ­ãƒ¼ãƒ‹ç›£ç£ã®æŸ”è»Ÿãªé‡‡é…ã«ã‚ˆã‚Šã€ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆã‚’å‹ã¡æŠœãè¡“ã‚’ç†ŸçŸ¥ã—ã¦ã„ã¾ã™ã€‚å—åŒ—ã‚¢ãƒ¡ãƒªã‚«å¤§é™¸é–‹å‚¬ã¨ã„ã†ã€Œåœ°ã®åˆ©ã€ã‚‚å¤§ããªå¾ŒæŠ¼ã—ã¨ãªã‚Šã¾ã™ã€‚\n\n#### **æœ‰åŠ›ï¼šã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ï¼ˆFIFAãƒ©ãƒ³ã‚¯4ä½ï¼‰**\n*   **äºˆæ¸¬æ ¹æ‹ **: ãƒˆãƒ¼ãƒã‚¹ãƒ»ãƒˆã‚¥ãƒ˜ãƒ«ç›£ç£ã®å°±ä»»ï¼ˆ2025å¹´ï¼‰ã«ã‚ˆã‚Šã€æˆ¦è¡“çš„ãªè¦å¾‹ã¨å‹è² å¼·ã•ãŒåŠ ã‚ã‚Šã¾ã—ãŸã€‚ãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã®ã‚ªãƒƒã‚ºã§ã‚‚ã‚¹ãƒšã‚¤ãƒ³ã«æ¬¡ãè©•ä¾¡ã‚’å¾—ã¦ã„ã¾ã™ã€‚\n*   **å¼·ã¿**: ãƒ™ãƒªãƒ³ã‚¬ãƒ ã€ã‚±ã‚¤ãƒ³ã€ã‚µã‚«ãªã©ã€å€‹ã®ã‚¿ãƒ¬ãƒ³ãƒˆåŠ›ã¯ã‚¹ãƒšã‚¤ãƒ³ã‚’ã‚‚å‡Œãã¾ã™ã€‚ãƒˆã‚¥ãƒ˜ãƒ«ç›£ç£ã®æŒ‡æ®ä¸‹ã§å®ˆå‚™ãŒå®‰å®šã™ã‚Œã°ã€60å¹´ã¶ã‚Šã®å„ªå‹ãŒç¾å®Ÿå‘³ã‚’å¸¯ã³ã¾ã™ã€‚\n\n#### **ä¸æ°—å‘³ãªå­˜åœ¨ï¼šãƒ•ãƒ©ãƒ³ã‚¹ï¼ˆFIFAãƒ©ãƒ³ã‚¯3ä½ï¼‰**\n*   **äºˆæ¸¬æ ¹æ‹ **: å¸¸ã«å„ªå‹å€™è£œã«æŒ™ãŒã‚‹é¸æ‰‹å±¤ã®åšã•ãŒã‚ã‚Šã¾ã™ã€‚\n*   **å¼·ã¿**: ã‚­ãƒªã‚¢ãƒ³ãƒ»ã‚¨ãƒ ãƒãƒšã‚’ä¸­å¿ƒã¨ã—ãŸæ”»æ’ƒåŠ›ã¨ã€ä¸­ç›¤ã®ãƒ•ã‚£ã‚¸ã‚«ãƒ«å¼·åº¦ã¯ä¸–ç•Œå±ˆæŒ‡ã€‚48ã‚«å›½å‡ºå ´ã«ã‚ˆã‚‹é•·ä¸å ´ã®å¤§ä¼šã«ãŠã„ã¦ã€èª°ãŒå‡ºã¦ã‚‚å¼·ã„ã¨ã„ã†ã€Œå±¤ã®åšã•ã€ã¯æœ€å¤§ã®æ­¦å™¨ã§ã™ã€‚\n\n---\n\n### 4. è€ƒæ…®ã™ã¹ããƒªã‚¹ã‚¯è¦å› \n\n*   **åŒ—ä¸­ç±³ç‰¹æœ‰ã®ç’°å¢ƒï¼ˆãƒ’ãƒ¼ãƒˆï¼†ãƒ‡ã‚£ã‚¹ã‚¿ãƒ³ã‚¹ï¼‰**:\n    ã‚¢ãƒ¡ãƒªã‚«ã€ã‚«ãƒŠãƒ€ã€ãƒ¡ã‚­ã‚·ã‚³ã®3ã‚«å›½é–‹å‚¬ã«ã‚ˆã‚‹ç§»å‹•è·é›¢ã®é•·ã•ã¨ã€ä¸€éƒ¨ä¼šå ´ã®é…·æš‘ã¯ã€æ¬§å·å‹¢ã®ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã‚’å´©ã™æœ€å¤§ã®è¦å› ã¨ãªã‚Šå¾—ã¾ã™ã€‚éå»ã€åŒ—å—ç±³é–‹å‚¬ã®Wæ¯ã§æ¬§å·å‹¢ãŒå„ªå‹ã—ãŸã®ã¯2014å¹´ã®ãƒ‰ã‚¤ãƒ„ã®ã¿ã§ã™ã€‚ã“ã®ã‚¸ãƒ³ã‚¯ã‚¹ã¯å—ç±³å‹¢ï¼ˆã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã€ãƒ–ãƒ©ã‚¸ãƒ«ï¼‰ã«ã¨ã£ã¦è¿½ã„é¢¨ã§ã™ã€‚\n\n*   **å¤§ä¼šãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å¤‰æ›´**:\n    å‡ºå ´å›½ãŒ48ã‚«å›½ã«å¢—ãˆã€æ±ºå‹ã¾ã§ã®è©¦åˆæ•°ãŒæœ€å¤§8è©¦åˆã«å¢—åŠ ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç‰¹å®šã®ã‚¹ã‚¿ãƒ¼é¸æ‰‹ã«ä¾å­˜ã™ã‚‹ãƒãƒ¼ãƒ ï¼ˆä¾‹ï¼šãƒ¡ãƒƒã‚·ä¾å­˜ã®ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã€ãƒ‡ãƒ»ãƒ–ãƒ©ã‚¤ãƒä¾å­˜ã®ãƒ™ãƒ«ã‚®ãƒ¼ç­‰ï¼‰ã¯ã€å¤§ä¼šçµ‚ç›¤ã«ã‚¬ã‚¹æ¬ ã‚’èµ·ã“ã™ãƒªã‚¹ã‚¯ãŒé«˜ã¾ã‚Šã¾ã™ã€‚\n\n*   **ãƒ–ãƒ©ã‚¸ãƒ«ã®å¾©èª¿**:\n    ç¾åœ¨5ç•ªæ‰‹è©•ä¾¡ã§ã™ãŒã€å€‹ã®èƒ½åŠ›ã¯ä¾ç„¶ã¨ã—ã¦ãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã§ã™ã€‚å¤§ä¼šã¾ã§ã«å®ˆå‚™çµ„ç¹”ãŒæ•´å‚™ã•ã‚Œã‚Œã°ã€ä¸€æ°—ã«å„ªå‹å€™è£œç­†é ­ã«èºã‚Šå‡ºã‚‹ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã‚’ç§˜ã‚ã¦ã„ã¾ã™ã€‚"
                }
            ]
        },
        {
            "id": "3b6ff70e-29db-4790-abaf-bb73da260ef5",
            "title": "ç”·å­ã‚µãƒƒã‚«ãƒ¼ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½ã‚’äºˆæ¸¬...",
            "timestamp": "2025-11-30T00:06:32.852927",
            "messages": [
                {
                    "role": "user",
                    "content": "ç”·å­ã‚µãƒƒã‚«ãƒ¼ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½ã‚’äºˆæ¸¬ã—ã¦"
                },
                {
                    "role": "model",
                    "content": "2025å¹´11æœˆæ™‚ç‚¹ã®æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã€FIFAãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€ãŠã‚ˆã³å¸‚å ´äºˆæ¸¬ã«åŸºã¥ãã€2026å¹´ç”·å­ã‚µãƒƒã‚«ãƒ¼ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½äºˆæ¸¬ã‚’åˆ†æã—ã¾ã™ã€‚\n\n### 1. çµè«–ï¼šç¾åœ¨ã®æœ€æœ‰åŠ›å€™è£œã¯ã€Œã‚¹ãƒšã‚¤ãƒ³ã€\nç¾æ™‚ç‚¹ï¼ˆ2025å¹´11æœˆï¼‰ã§æœ€ã‚‚å„ªå‹ã«è¿‘ã„ã¨äºˆæ¸¬ã•ã‚Œã‚‹ã®ã¯**ã‚¹ãƒšã‚¤ãƒ³**ã§ã™ã€‚\nEURO 2024ã§ã®å„ªå‹å®Ÿç¸¾ã¨ã€FIFAãƒ©ãƒ³ã‚­ãƒ³ã‚°1ä½ã‚’ç¶­æŒã™ã‚‹å®‰å®šæ„ŸãŒè©•ä¾¡ã•ã‚Œã€ãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼å„ç¤¾ã§ã‚‚ç­†é ­å€™è£œï¼ˆã‚ªãƒƒã‚ºç´„5.4å€ï¼‰ã¨ãªã£ã¦ã„ã¾ã™ã€‚ã“ã‚Œã«**ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰**ã€**ãƒ•ãƒ©ãƒ³ã‚¹**ã€å‰å›ç‹è€…ã®**ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³**ãŒç¶šãã€Œ4å¼·ï¼‹ãƒ–ãƒ©ã‚¸ãƒ«ã€ã®æ§‹å›³ãŒå½¢æˆã•ã‚Œã¦ã„ã¾ã™ã€‚\n\n### 2. è©³ç´°ãªåˆ†æã¨äºˆæ¸¬ã‚·ãƒŠãƒªã‚ª\n\n#### ç­†é ­å€™è£œï¼šã‚¹ãƒšã‚¤ãƒ³ï¼ˆFIFAãƒ©ãƒ³ã‚¯1ä½ï¼‰\n*   **äºˆæ¸¬æ ¹æ‹ **: EURO 2024å„ªå‹ã«åŠ ãˆã€2024-25 UEFAãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚ºãƒªãƒ¼ã‚°ã§ã‚‚å¥½èª¿ã‚’ç¶­æŒã—ã¦ãŠã‚Šã€æˆ¦è¡“çš„ãªå®Œæˆåº¦ãŒæœ€ã‚‚é«˜ã„ã¨è©•ä¾¡ã•ã‚Œã¦ã„ã¾ã™ã€‚\n*   **å¼·ã¿**: ãƒ©ãƒŸãƒ³ãƒ»ãƒ¤ãƒãƒ«ã‚„ãƒ­ãƒ‰ãƒªã‚’ä¸­å¿ƒã¨ã—ãŸä¸–ä»£äº¤ä»£ãŒå®Œäº†ã—ã¦ãŠã‚Šã€ãƒ™ãƒ†ãƒ©ãƒ³ã¨è‹¥æ‰‹ãŒå®Œç’§ã«èåˆã—ã¦ã„ã¾ã™ã€‚\n*   **å¸‚å ´è©•ä¾¡**: ä¸»è¦ãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã§ã®å„ªå‹ç¢ºç‡ã¯ç´„18.5%ï¼ˆã‚ªãƒƒã‚º +440ï½+450ï¼‰ã§å˜ç‹¬ãƒˆãƒƒãƒ—ã§ã™ã€‚\n\n#### å¯¾æŠ—é¦¬ï¼ˆå‰å›ç‹è€…ï¼‰ï¼šã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ï¼ˆFIFAãƒ©ãƒ³ã‚¯2ä½ï¼‰\n*   **äºˆæ¸¬æ ¹æ‹ **: 2022å¹´Wæ¯ãŠã‚ˆã³ã‚³ãƒ‘ãƒ»ã‚¢ãƒ¡ãƒªã‚«2024ã®ç‹è€…ã¨ã—ã¦ã€ä¾ç„¶ã¨ã—ã¦ä¸–ç•Œãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã®å®ŸåŠ›ã‚’ä¿æŒã—ã¦ã„ã¾ã™ã€‚å—ç±³äºˆé¸ã‚‚é¦–ä½äº‰ã„ã‚’æ¼”ã˜ã€æœ¬å¤§ä¼šå‡ºå ´æ¨©ã‚’ç¢ºä¿æ¸ˆã¿ã§ã™ã€‚\n*   **å¼·ã¿**: ãƒªã‚ªãƒãƒ«ãƒ»ãƒ¡ãƒƒã‚·ãŒã‚­ãƒ£ãƒ—ãƒ†ãƒ³ã¨ã—ã¦ç²¾ç¥çš„æ”¯æŸ±ã®å½¹å‰²ã‚’æœãŸã—ã¦ãŠã‚Šã€ãƒãƒ¼ãƒ ã®çµæŸåŠ›ãŒéå¸¸ã«é«˜ã„ç‚¹ãŒç‰¹å¾´ã§ã™ã€‚\n*   **å¸‚å ´è©•ä¾¡**: ã‚ªãƒƒã‚ºã¯ç´„8.5ï½9.0å€ã§5ç•ªæ‰‹è©•ä¾¡ã§ã™ãŒã€çŸ­æœŸæ±ºæˆ¦ã§ã®å‹è² å¼·ã•ã¯éšä¸€ã§ã™ã€‚\n\n#### ãã®ä»–ã®æœ‰åŠ›å€™è£œï¼ˆãƒˆãƒƒãƒ—ãƒ†ã‚£ã‚¢ï¼‰\n*   **ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ï¼ˆã‚ªãƒƒã‚º2ä½ / ç´„7.0å€ï¼‰**: EURO 2024æº–å„ªå‹ã®å®Ÿç¸¾ã¨ã€äºˆé¸ã‚’ç„¡æ•—ã§é€šéã—ãŸå®‰å®šæ„ŸãŒè©•ä¾¡ã•ã‚Œã¦ã„ã¾ã™ã€‚ã€Œ60å¹´ã¶ã‚Šã®å„ªå‹ã€ã¸ã®æœŸå¾…ãŒé«˜ãã€æˆ¦åŠ›å±¤ã®åšã•ã¯ä¸–ç•Œå±ˆæŒ‡ã§ã™ã€‚\n*   **ãƒ•ãƒ©ãƒ³ã‚¹ï¼ˆã‚ªãƒƒã‚º3ä½ / ç´„8.0å€ï¼‰**: ã‚­ãƒªã‚¢ãƒ³ãƒ»ã‚¨ãƒ ãƒãƒšãŒå…¨ç››æœŸã‚’è¿ãˆã¦ãŠã‚Šã€å€‹ã®èƒ½åŠ›ã§è©¦åˆã‚’æ±ºå®šã¥ã‘ã‚‹åŠ›ãŒã‚ã‚Šã¾ã™ã€‚FIFAãƒ©ãƒ³ã‚¯3ä½ã‚’ç¶­æŒã—ã¦ã„ã¾ã™ã€‚\n*   **ãƒ–ãƒ©ã‚¸ãƒ«ï¼ˆã‚ªãƒƒã‚º4ä½ / ç´„8.5å€ï¼‰**: äºˆé¸åºç›¤ã¯è‹¦æˆ¦ã—ã¾ã—ãŸãŒã€2025å¹´å¾ŒåŠã«å¾©èª¿ã—FIFAãƒ©ãƒ³ã‚¯5ä½ã¸æµ®ä¸Šã—ã¾ã—ãŸã€‚ãƒã‚¤ãƒãƒ¼ãƒ«ã®å¾©å¸°ã¨çŠ¶æ…‹ãŒå„ªå‹ã¸ã®éµã‚’æ¡ã‚Šã¾ã™ã€‚\n\n### 3. è€ƒæ…®ã™ã¹ããƒªã‚¹ã‚¯è¦å› ã¨ä¸ç¢ºå®šè¦ç´ \n\näºˆæ¸¬ã‚’è¡Œã†ä¸Šã§ã€ä»¥ä¸‹ã®è¦ç´ ãŒçµæœã‚’å·¦å³ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n\n*   **åŒ—ç±³é–‹å‚¬ç‰¹æœ‰ã®ç’°å¢ƒè² è·**:\n    ã‚¢ãƒ¡ãƒªã‚«ãƒ»ã‚«ãƒŠãƒ€ãƒ»ãƒ¡ã‚­ã‚·ã‚³ã®3ã‚«å›½å…±å‚¬ã¨ãªã‚‹ãŸã‚ã€**ç§»å‹•è·é›¢ãŒéå¸¸ã«é•·ã**ã€ãƒ¡ã‚­ã‚·ã‚³ã‚„ç±³å›½å—éƒ¨ã§ã®**é…·æš‘**ãŒé¸æ‰‹ã®ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã‚’è‘—ã—ãä½ä¸‹ã•ã›ã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã¯é¸æ‰‹å±¤ã®åšã„ãƒãƒ¼ãƒ ï¼ˆæ¬§å·å‹¢ãªã©ï¼‰ã«æœ‰åˆ©ã«åƒãå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n*   **ä¸»åŠ›é¸æ‰‹ã®è² å‚·ãƒªã‚¹ã‚¯**:\n    æ¬§å·ä¸»è¦ãƒªãƒ¼ã‚°ã®éå¯†æ—¥ç¨‹ã«ã‚ˆã‚Šã€ACLï¼ˆå‰åå­—é­å¸¯ï¼‰æå‚·ãªã©ã®é‡å‚·ãŒå¢—åŠ å‚¾å‘ã«ã‚ã‚Šã¾ã™ã€‚å¤§ä¼šç›´å‰ã®æ€ªæˆ‘äººãŒäºˆæ¸¬ã‚’å¤§ããè¦†ã™å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n*   **ãƒ™ãƒ†ãƒ©ãƒ³ã¸ã®ä¾å­˜åº¦**:\n    ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ï¼ˆãƒ¡ãƒƒã‚·ï¼‰ã‚„ãƒãƒ«ãƒˆã‚¬ãƒ«ï¼ˆC.ãƒ­ãƒŠã‚¦ãƒ‰ï¼‰ãªã©ã€ãƒ™ãƒ†ãƒ©ãƒ³ã‚¹ã‚¿ãƒ¼ã¸ã®ä¾å­˜åº¦ãŒé«˜ã„ãƒãƒ¼ãƒ ã¯ã€å½¼ã‚‰ã®ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³æ¬¡ç¬¬ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå¤§ããå¤‰å‹•ã™ã‚‹ãƒªã‚¹ã‚¯ã‚’æŠ±ãˆã¦ã„ã¾ã™ã€‚\n\n**å‡ºå…¸**:\n*   FIFA Men's World Ranking (2025å¹´11æœˆ19æ—¥æ›´æ–°)\n*   FanDuel / DraftKings Betting Odds (2025å¹´11æœˆæ™‚ç‚¹)\n*   Fox Sports å ±é“ (2025å¹´11æœˆ)"
                }
            ]
        },
        {
            "id": "e71e4a54-a863-41de-9669-d8ac577ca9cf",
            "title": "ç”·å­ã‚µãƒƒã‚«ãƒ¼ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½ã‚’äºˆæ¸¬...",
            "timestamp": "2025-11-30T00:06:37.228089",
            "messages": [
                {
                    "role": "user",
                    "content": "ç”·å­ã‚µãƒƒã‚«ãƒ¼ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½ã‚’äºˆæ¸¬ã—ã¦"
                },
                {
                    "role": "model",
                    "content": "2025å¹´11æœˆæ™‚ç‚¹ã®æœ€æ–°ãƒ‡ãƒ¼ã‚¿ï¼ˆFIFAãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€ãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã‚ªãƒƒã‚ºã€ç›´è¿‘ã®ä¸»è¦å¤§ä¼šæˆç¸¾ï¼‰ã«åŸºã¥ãã€2026å¹´ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã®å„ªå‹å›½ã‚’äºˆæ¸¬ãƒ»åˆ†æã—ã¾ã™ã€‚\n\n### çµè«–ï¼šã‚¹ãƒšã‚¤ãƒ³ãŒçµ±è¨ˆçš„ãƒ»æˆ¦è¡“çš„ã«ãƒªãƒ¼ãƒ‰ã€è¿½ã†ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã¨ãƒ•ãƒ©ãƒ³ã‚¹\nç¾æ™‚ç‚¹ã§ã®æœ€æœ‰åŠ›å€™è£œã¯**ã‚¹ãƒšã‚¤ãƒ³**ã§ã™ã€‚2024å¹´EUROå„ªå‹ã®å®Ÿç¸¾ã¨ã€æ”»å®ˆã®ãƒãƒ©ãƒ³ã‚¹ã®è‰¯ã•ãŒè©•ä¾¡ã•ã‚Œã€FIFAãƒ©ãƒ³ã‚­ãƒ³ã‚°1ä½ãŠã‚ˆã³ãƒ–ãƒƒã‚¯ãƒ¡ãƒ¼ã‚«ãƒ¼ã®ã‚ªãƒƒã‚ºï¼ˆç´„18-20%ï¼‰ã§ãƒˆãƒƒãƒ—ã«ç«‹ã£ã¦ã„ã¾ã™ã€‚\n\nãŸã ã—ã€çµ¶å¯¾çš„ãªä¸€å¼·çŠ¶æ…‹ã§ã¯ãªãã€ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆã«æ»…æ³•å¼·ã„å‰å›ç‹è€…**ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³**ã€ä¸–ç•Œæœ€é«˜ã®é¸æ‰‹å±¤ã‚’æŒã¤**ãƒ•ãƒ©ãƒ³ã‚¹**ãŒåƒ…å·®ã§ç¶šãã€Œä¸‰ã¤å·´ã€ã«è¿‘ã„æ§‹å›³ã§ã™ã€‚\n\n---\n\n### ã‚·ãƒŠãƒªã‚ªåˆ¥äºˆæ¸¬åˆ†æ\n\n#### ã‚·ãƒŠãƒªã‚ªAï¼šã‚¹ãƒšã‚¤ãƒ³ã«ã‚ˆã‚‹ã€Œæ–°ãƒ»é»„é‡‘æœŸã€ã®è¨¼æ˜ï¼ˆç¢ºç‡ï¼šé«˜ï¼‰\næœ€ã‚‚è“‹ç„¶æ€§ãŒé«˜ã„ã‚·ãƒŠãƒªã‚ªã§ã™ã€‚\n*   **æ ¹æ‹ **: 2024å¹´EUROã§ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ã‚’ç ´ã‚Šå„ªå‹ã€‚ç¾åœ¨FIFAãƒ©ãƒ³ã‚­ãƒ³ã‚°1ä½ï¼ˆ1877.18 ptï¼‰ã€‚\n*   **å¼·ã¿**: ãƒ©ãƒŸãƒ³ãƒ»ãƒ¤ãƒãƒ«ã€ãƒ‹ã‚³ãƒ»ã‚¦ã‚£ãƒªã‚¢ãƒ ã‚ºã‚‰è‹¥æ‰‹ã®çˆ†ç™ºåŠ›ã¨ã€ãƒ­ãƒ‰ãƒªã‚’ä¸­å¿ƒã¨ã—ãŸä¸­ç›¤ã®æ§‹æˆåŠ›ãŒå™›ã¿åˆã£ã¦ã„ã¾ã™ã€‚2010å¹´å¤§ä¼šå„ªå‹æ™‚ã®ã‚ˆã†ãªã€Œã‚·ã‚¹ãƒ†ãƒ ã§å‹ã¤ã€ã‚µãƒƒã‚«ãƒ¼ãŒå®Œæˆã—ã¤ã¤ã‚ã‚Šã¾ã™ã€‚\n*   **æ‡¸å¿µ**: è‹¥æ‰‹ä¸»ä½“ã®ãƒãƒ¼ãƒ ã§ã‚ã‚‹ãŸã‚ã€Wæ¯ç‰¹æœ‰ã®ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã«å¯¾ã™ã‚‹çµŒé¨“å€¤ä¸è¶³ãŒå”¯ä¸€ã®ãƒªã‚¹ã‚¯ã§ã™ã€‚\n\n#### ã‚·ãƒŠãƒªã‚ªBï¼šå®Ÿç¸¾çµ„ï¼ˆã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ãƒ»ãƒ•ãƒ©ãƒ³ã‚¹ï¼‰ã®åº•åŠ›ï¼ˆç¢ºç‡ï¼šä¸­ï¼‰\nå€‹ã®åŠ›ã‚„çµŒé¨“å€¤ãŒã€çµ„ç¹”åŠ›ã‚’å‡Œé§•ã™ã‚‹ã‚·ãƒŠãƒªã‚ªã§ã™ã€‚\n*   **ğŸ‡¦ğŸ‡· ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³**:\n    *   **å¼·ã¿**: 2022å¹´Wæ¯ã€2024å¹´ã‚³ãƒ‘ãƒ»ã‚¢ãƒ¡ãƒªã‚«ã‚’é€£è¦‡ä¸­ã€‚ãƒ¡ãƒƒã‚·ã‚’ä¸­å¿ƒã¨ã—ãŸçµæŸåŠ›ã¨ã€çŸ­æœŸæ±ºæˆ¦ã§ã®å‹è² å¼·ã•ã¯ä¸–ç•Œä¸€ã§ã™ã€‚\n    *   **ãƒªã‚¹ã‚¯**: ä¸»åŠ›ã®é«˜é½¢åŒ–ãŒé€²ã‚“ã§ãŠã‚Šã€2026å¹´å¤ã«2022å¹´ã¨åŒç­‰ã®é‹å‹•é‡ã‚’ç¶­æŒã§ãã‚‹ã‹ãŒéµã¨ãªã‚Šã¾ã™ã€‚\n*   **ğŸ‡«ğŸ‡· ãƒ•ãƒ©ãƒ³ã‚¹**:\n    *   **å¼·ã¿**: ã‚­ãƒªã‚¢ãƒ³ãƒ»ã‚¨ãƒ ãƒãƒšã¨ã„ã†ã€Œå€‹ã€ã®æ‰“é–‹åŠ›ã«åŠ ãˆã€å…¨ãƒã‚¸ã‚·ãƒ§ãƒ³ã«ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚¯ãƒ©ã‚¹ã‚’æƒãˆã‚‹é¸æ‰‹å±¤ï¼ˆDepthï¼‰ã¯48ã‚«å›½åˆ¶ã®é•·ä¸å ´ã§æœ€å¤§ã®æ­¦å™¨ã¨ãªã‚Šã¾ã™ã€‚\n    *   **ãƒªã‚¹ã‚¯**: ãƒ‡ã‚·ãƒ£ãƒ³ç›£ç£ä½“åˆ¶ã®é•·æœŸåŒ–ã«ã‚ˆã‚‹æˆ¦è¡“çš„ãªåœæ»æ„ŸãŒæŒ‡æ‘˜ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\n#### ã‚·ãƒŠãƒªã‚ªCï¼šçœ ã‚Œã‚‹å·¨äººã®è¦šé†’ã¨æ³¢ä¹±ï¼ˆç¢ºç‡ï¼šä½ï½ä¸­ï¼‰\nå¸‚å ´è©•ä¾¡ã¨ç¾çŠ¶ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ä¹–é›¢ãŒã‚ã‚‹ãƒãƒ¼ãƒ ã®å‹•å‘ã§ã™ã€‚\n*   **ğŸ‡§ğŸ‡· ãƒ–ãƒ©ã‚¸ãƒ«**:\n    *   **ç¾çŠ¶**: å—ç±³äºˆé¸ã§è‹¦æˆ¦ï¼ˆä¸€æ™‚5ä½ãƒ»6ä½ï¼‰ã—ã¦ã„ã¾ã™ãŒã€ã‚ªãƒƒã‚ºã§ã¯ä¾ç„¶ã¨ã—ã¦ä¸Šä½ï¼ˆ+650ï½+750ï¼‰ã§ã™ã€‚\n    *   **åˆ†æ**: ãƒ´ã‚£ãƒ‹ã‚·ã‚¦ã‚¹ã‚‰å‰ç·šã®ã‚¿ãƒ¬ãƒ³ãƒˆåŠ›ã¯éšä¸€ã§ã™ã€‚å¤§ä¼šã¾ã§ã«å®ˆå‚™ã®ä¸å®‰å®šã•ã‚’è§£æ¶ˆã§ãã‚Œã°ã€ä¸€æ°—ã«å„ªå‹å€™è£œç­†é ­ã¸è¿”ã‚Šå’²ããƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ãŒã‚ã‚Šã¾ã™ã€‚\n*   **ğŸ´ó §ó ¢ó ¥ó ®ó §ó ¿ ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰**:\n    *   **ç¾çŠ¶**: 2024å¹´EUROæº–å„ªå‹ã€‚ã‚¿ãƒ¬ãƒ³ãƒˆåŠ›ã¯ã‚¹ãƒšã‚¤ãƒ³ã«åŒ¹æ•µã—ã¾ã™ãŒã€å‹è² æ‰€ã§ã®ç²¾ç¥çš„ãªè„†ã•ãŒèª²é¡Œã§ã™ã€‚\n\n---\n\n### æ³¨ç›®ã™ã¹ããƒ€ãƒ¼ã‚¯ãƒ›ãƒ¼ã‚¹\n*   **ğŸ‡ºğŸ‡¾ ã‚¦ãƒ«ã‚°ã‚¢ã‚¤**: ãƒ“ã‚¨ãƒ«ã‚µç›£ç£ã®ä¸‹ã€å—ç±³äºˆé¸ã§ãƒ–ãƒ©ã‚¸ãƒ«ãƒ»ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ã‚’æ’ƒç ´ã€‚æˆ¦è¡“çš„ãªå®Œæˆåº¦ãŒé«˜ãã€ä¸Šä½å›½ã‚’é£Ÿã†å¯èƒ½æ€§ãŒæœ€ã‚‚é«˜ã„ãƒãƒ¼ãƒ ã§ã™ã€‚\n*   **ğŸ‡¨ğŸ‡¦ ã‚«ãƒŠãƒ€**: é–‹å‚¬å›½ï¼ˆã‚¢ãƒ¡ãƒªã‚«ãƒ»ãƒ¡ã‚­ã‚·ã‚³ãƒ»ã‚«ãƒŠãƒ€ï¼‰ã®ä¸­ã§æœ€ã‚‚å¥½èª¿ï¼ˆã‚³ãƒ‘ãƒ»ã‚¢ãƒ¡ãƒªã‚«2024ãƒ™ã‚¹ãƒˆ4ï¼‰ã€‚åœ°ã®åˆ©ã‚’æ´»ã‹ã—ãŸèºé€²ãŒæœŸå¾…ã•ã‚Œã¾ã™ã€‚\n\n---\n\n### 2026å¹´å¤§ä¼šç‰¹æœ‰ã®é‡è¦å¤‰æ•°\näºˆæ¸¬ã‚’å·¦å³ã™ã‚‹ã€ä»Šå¤§ä¼šç‰¹æœ‰ã®å¤–çš„è¦å› ã§ã™ã€‚\n\n1.  **48ã‚«å›½åˆ¶ã¸ã®æ‹¡å¤§ï¼ˆæ¶ˆè€—æˆ¦ï¼‰**:\n    è©¦åˆæ•°ãŒå¢—åŠ ã™ã‚‹ãŸã‚ã€ã‚¹ã‚¿ãƒ¡ãƒ³11äººã ã‘ã§ãªãã€ãƒ™ãƒ³ãƒãƒ¡ãƒ³ãƒãƒ¼ã‚’å«ã‚ãŸ26äººã®ç·åˆåŠ›ãŒå•ã‚ã‚Œã¾ã™ã€‚ã“ã‚Œã¯é¸æ‰‹å±¤ã®åšã„**ãƒ•ãƒ©ãƒ³ã‚¹**ã‚„**ã‚¹ãƒšã‚¤ãƒ³**ã«æœ‰åˆ©ã«åƒãã¾ã™ã€‚\n2.  **ç§»å‹•è·é›¢ã¨æ°—å€™**:\n    åŒ—ç±³3ã‚«å›½ã«ã¾ãŸãŒã‚‹åºƒå¤§ãªç§»å‹•ã¨ã€å¤ã®é…·æš‘ãƒ»æ¹¿åº¦ã¯ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ç¶­æŒã‚’å›°é›£ã«ã—ã¾ã™ã€‚ç‰¹å®šã®ç’°å¢ƒã¸ã®é©å¿œåŠ›ãŒä½ã„ãƒãƒ¼ãƒ ã¯ã€å®ŸåŠ›ãŒã‚ã£ã¦ã‚‚æ—©æœŸæ•—é€€ã™ã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚\n\n### å‚ç…§ã‚½ãƒ¼ã‚¹\n*   FIFA Men's World Ranking (Nov 2025)\n*   FOX Sports / DraftKings Betting Odds (Nov 2025)\n*   UEFA Euro 2024 / Copa AmÃ©rica 2024 Results"
                }
            ]
        },
        {
            "id": "d79cca8a-d20b-4910-826b-8ded8182e088",
            "title": "iPhoneã§æœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã‚’ä½¿ã„ãŸã„ãŒ...",
            "timestamp": "2025-11-29T23:37:36.225635",
            "messages": [
                {
                    "role": "user",
                    "content": "iPhoneã§æœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã‚’ä½¿ã„ãŸã„ãŒã€ã©ã®ãƒ¢ãƒ‡ãƒ«ãŒä¸€ç•ªãŠã™ã™ã‚ã‹ï¼Ÿä»Šiphonepromax13/512GBã‚’ä½¿ã£ã¦ã„ã‚‹"
                },
                {
                    "role": "model",
                    "content": "### çµè«–\nç¾åœ¨iPhone 13 Pro Maxã‚’ãŠä½¿ã„ã§ã€æœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã‚’æœ€å¤§é™ã«æ´»ç”¨ã—ãŸã„å ´åˆã€æœ€ã‚‚æ¨å¥¨ã•ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ã¯**ã€ŒiPhone 17 Pro Maxã€**ã§ã™ã€‚\n\né€šè¨³ã®ç²¾åº¦ãƒ»é€Ÿåº¦ã€ãƒãƒƒãƒ†ãƒªãƒ¼æŒã¡ã€ãƒã‚¤ã‚¯æ€§èƒ½ã®ã™ã¹ã¦ã«ãŠã„ã¦æœ€é«˜æ°´æº–ã®ä½“é¨“ãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚ä¸€æ–¹ã§ã€ç¾åœ¨ã®ç«¯æœ«ã®ã€Œé‡ã•ã€ãŒæ°—ã«ãªã‚‹å ´åˆã¯ã€æ–°ãƒ©ã‚¤ãƒ³ãƒŠãƒƒãƒ—ã®**ã€ŒiPhone 17 Airã€**ãŒã€æ©Ÿèƒ½ã¨æºå¸¯æ€§ã®ãƒãƒ©ãƒ³ã‚¹ãŒå–ã‚ŒãŸæœ‰åŠ›ãªé¸æŠè‚¢ã¨ãªã‚Šã¾ã™ã€‚\n\n### è©³ç´°åˆ†æã¨æ¨å¥¨ç†ç”±\n\n#### 1. iPhone 17 Pro Max ãŒã€Œé€šè¨³ã€ã«æœ€é©ãªç†ç”±\nç¾åœ¨ãŠä½¿ã„ã®iPhone 13 Pro Maxï¼ˆA15 Bionicãƒãƒƒãƒ—ï¼‰ã¯ã€æœ€æ–°ã®AIæ©Ÿèƒ½ç¾¤ã€ŒApple Intelligenceã€ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚2025å¹´11æœˆç¾åœ¨ã®æœ€æ–°ç’°å¢ƒï¼ˆiPhone 17ã‚·ãƒªãƒ¼ã‚º + iOS 26ï¼‰ã¸ç§»è¡Œã™ã‚‹ã“ã¨ã§ã€ä»¥ä¸‹ã®é€šè¨³ä½“é¨“ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚\n\n*   **å‡¦ç†æ€§èƒ½ï¼ˆA19 Proãƒãƒƒãƒ— + 12GBãƒ¡ãƒ¢ãƒªï¼‰**:\n    é€šè¨³æ©Ÿèƒ½ã®ä¸­æ ¸ã¨ãªã‚‹ã€ŒApple Intelligenceã€ã‚’é«˜é€Ÿã«å‡¦ç†ã—ã¾ã™ã€‚ç‰¹ã«ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ç’°å¢ƒï¼ˆæ©Ÿå†…ã‚„é›»æ³¢ã®æ‚ªã„æµ·å¤–ãªã©ï¼‰ã§ã®ç¿»è¨³é€Ÿåº¦ã«ãŠã„ã¦ã€æ—§ãƒ¢ãƒ‡ãƒ«ã¨ã¯æ±ºå®šçš„ãªå·®ãŒå‡ºã¾ã™ã€‚\n*   **éŸ³å£°èªè­˜ç²¾åº¦ï¼ˆã‚¹ã‚¿ã‚¸ã‚ªå“è³ªãƒã‚¤ã‚¯ï¼‰**:\n    Proãƒ¢ãƒ‡ãƒ«ç‰¹æœ‰ã®é«˜æ€§èƒ½ãƒã‚¤ã‚¯ã«ã‚ˆã‚Šã€é›‘è¸ã‚„é¢¨ã®ã‚ã‚‹å±‹å¤–ã§ã‚‚è©±è€…ã®å£°ã‚’æ­£ç¢ºã«æ‹¾ã„ã¾ã™ã€‚éŸ³å£°èªè­˜ã®ãƒŸã‚¹ãŒæ¸›ã‚‹ã“ã¨ã§ã€çµæœã¨ã—ã¦ç¿»è¨³ç²¾åº¦ãŒå¤§å¹…ã«å‘ä¸Šã—ã¾ã™ã€‚\n*   **ãƒãƒƒãƒ†ãƒªãƒ¼å¯¿å‘½ï¼ˆæœ€å¤§39æ™‚é–“ï¼‰**:\n    ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€šè¨³ã¯ãƒãƒƒãƒ†ãƒªãƒ¼æ¶ˆè²»ãŒæ¿€ã—ã„æ©Ÿèƒ½ã§ã™ãŒã€iPhone 13 Pro Maxã¨æ¯”è¼ƒã—ã¦ãƒ“ãƒ‡ã‚ªå†ç”Ÿæ™‚é–“ãŒç´„10æ™‚é–“ä»¥ä¸Šå»¶é•·ã•ã‚Œã¦ãŠã‚Šã€ä¸€æ—¥ä¸­å®‰å¿ƒã—ã¦ä½¿ç”¨ã§ãã¾ã™ã€‚\n\n#### 2. æºå¸¯æ€§ã‚’é‡è¦–ã™ã‚‹å ´åˆã®é¸æŠè‚¢ï¼šiPhone 17 Air\nã‚‚ã—Pro Maxã®ã€Œé‡ã•ï¼ˆ238gï¼‰ã€ã‚„ã€Œåšã¿ã€ãŒãƒãƒƒã‚¯ã«ãªã£ã¦ã„ã‚‹ãªã‚‰ã€**iPhone 17 Air**ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚\n\n*   **ãƒ¡ãƒªãƒƒãƒˆ**: é‡é‡ã¯**165g**ã¨åœ§å€’çš„ã«è»½ãã€åšã•ã‚‚**5.6mm**ã§ã™ã€‚ç”»é¢ã‚µã‚¤ã‚ºã¯6.6ã‚¤ãƒ³ãƒã‚’ç¢ºä¿ã—ã¦ãŠã‚Šã€ç¿»è¨³ãƒ†ã‚­ã‚¹ãƒˆã®è¦–èªæ€§ã‚’ç¶­æŒã—ã¤ã¤ã€æŒã¡é‹ã³ã®è² æ‹…ã‚’åŠ‡çš„ã«è»½æ¸›ã§ãã¾ã™ã€‚\n*   **æ³¨æ„ç‚¹**: ãƒãƒƒãƒ†ãƒªãƒ¼æŒã¡ï¼ˆç´„27æ™‚é–“ï¼‰ã‚„ãƒã‚¤ã‚¯æ€§èƒ½ã¯Pro Maxã«åŠ£ã‚Šã¾ã™ãŒã€æœ€æ–°ã®A19/A19 Proãƒãƒƒãƒ—ã‚’æ­è¼‰ã—ã¦ãŠã‚Šã€é€šè¨³æ©Ÿèƒ½è‡ªä½“ã¯å•é¡Œãªãåˆ©ç”¨å¯èƒ½ã§ã™ã€‚\n\n### æ¯”è¼ƒã¾ã¨ã‚\n\n| ç‰¹å¾´ | **iPhone 17 Pro Max** (æ¨å¥¨) | **iPhone 17 Air** (æºå¸¯æ€§) | **iPhone 13 Pro Max** (ç¾åœ¨) |\n| :--- | :--- | :--- | :--- |\n| **é€šè¨³æ©Ÿèƒ½** | **å®Œå…¨å¯¾å¿œ (é«˜é€Ÿãƒ»é«˜ç²¾åº¦)** | **å®Œå…¨å¯¾å¿œ** | **éå¯¾å¿œ** (OSçµ±åˆæ©Ÿèƒ½ä¸å¯) |\n| **ãƒãƒƒãƒ—** | **A19 Pro** | A19 Pro / A19 | A15 Bionic |\n| **ãƒã‚¤ã‚¯** | **ã‚¹ã‚¿ã‚¸ã‚ªå“è³ª** | æ¨™æº– | æ¨™æº– |\n| **é‡é‡** | 233g | **165g** | 238g |\n\n### å°å…¥ã«å‘ã‘ãŸã‚¢ãƒ‰ãƒã‚¤ã‚¹\n\n1.  **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å®¹é‡ã«ã¤ã„ã¦**:\n    ç¾åœ¨512GBã‚’ãŠä½¿ã„ã¨ã®ã“ã¨ã§ã™ãŒã€æœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã¯ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹ï¼ˆç«¯æœ«å†…ï¼‰ã§ã®AIå‡¦ç†ã‚’è¡Œã†ãŸã‚ã€è¨€èªãƒ‘ãƒƒã‚¯ã‚„AIãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã«å®¹é‡ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚è²·ã„æ›¿ãˆæ™‚ã‚‚**512GBä»¥ä¸Š**ã‚’é¸æŠã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚\n2.  **å‘¨è¾ºæ©Ÿå™¨ã®æ´»ç”¨**:\n    æœ€æ–°ã®ã€Œå¯¾é¢ç¿»è¨³ãƒ¢ãƒ¼ãƒ‰ã€ã‚„ã€Œãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€šè©±ç¿»è¨³ã€ã‚’æœ€å¤§é™æ´»ã‹ã™ã«ã¯ã€åŒæ™‚æœŸã«ç™ºå£²ã•ã‚ŒãŸ**AirPods Pro 3**ã¨ã®ä½µç”¨ãŒæ¨å¥¨ã•ã‚Œã¦ã„ã¾ã™ã€‚è€³å…ƒã§ç¿»è¨³éŸ³å£°ã‚’èãã“ã¨ã§ã€ã‚ˆã‚Šè‡ªç„¶ãªä¼šè©±ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚\n3.  **ã‚³ã‚¹ãƒˆã¨å¯¿å‘½**:\n    1ä¸–ä»£å‰ã®ã€ŒiPhone 16 Pro Maxã€ã‚‚AIæ©Ÿèƒ½ã«å¯¾å¿œã—ã¦ã„ã¾ã™ãŒã€ãƒãƒƒãƒ—æ€§èƒ½ï¼ˆA19 Proï¼‰ã«ã‚ˆã‚‹å°†æ¥ã®ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆå¯¾å¿œåŠ›ã‚’è€ƒæ…®ã™ã‚‹ã¨ã€é•·ãä½¿ã†å‰æã§ã‚ã‚Œã°iPhone 17ã‚·ãƒªãƒ¼ã‚ºã¸ã®æŠ•è³‡ãŒåˆç†çš„ã§ã™ã€‚\n\n**æƒ…å ±æº**:\n*   Apple Official: iPhone 17 Pro Specs & iOS 26 Release Notes (2025-09)\n*   MacRumors: iPhone 17 / iPhone 17 Air Features (2025-11)"
                }
            ]
        },
        {
            "id": "35c4252c-c734-4418-961d-712e44bb0fed",
            "title": "iPhoneã§æœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã‚’ä½¿ã„ãŸã„ãŒ...",
            "timestamp": "2025-11-29T23:34:28.344472",
            "messages": [
                {
                    "role": "user",
                    "content": "iPhoneã§æœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã‚’ä½¿ã„ãŸã„ãŒã€ã©ã®ãƒ¢ãƒ‡ãƒ«ãŒä¸€ç•ªãŠã™ã™ã‚ã‹ï¼Ÿä»Šiphonepromax13/512GBã‚’ä½¿ã£ã¦ã„ã‚‹"
                },
                {
                    "role": "model",
                    "content": "### çµè«–\nç¾åœ¨ãŠä½¿ã„ã®iPhone 13 Pro Maxã§ã¯ã€OSã«çµ±åˆã•ã‚ŒãŸæœ€æ–°ã®AIé€šè¨³æ©Ÿèƒ½ã‚’åˆ©ç”¨ã§ããªã„ãŸã‚ã€**iPhone 16 Pro Max**ã¸ã®è²·ã„æ›¿ãˆã‚’æ¨å¥¨ã—ã¾ã™ã€‚\n\nAppleã®AIã‚·ã‚¹ãƒ†ãƒ ã€ŒApple Intelligenceã€ã«ã‚ˆã‚‹é«˜åº¦ãªé€šè¨³æ©Ÿèƒ½ã¯ã€iPhone 15 Pro Maxä»¥é™ã®ãƒ¢ãƒ‡ãƒ«ãŒå¿…é ˆè¦ä»¶ã§ã™ã€‚ç‰¹ã«ç¾åœ¨512GBã®å¤§ç”»é¢ãƒ¢ãƒ‡ãƒ«ã‚’ãŠä½¿ã„ã®ç‚¹ã‹ã‚‰ã€ç”»é¢ã‚µã‚¤ã‚ºãŒã•ã‚‰ã«æ‹¡å¤§ã—ã€å‡¦ç†æ€§èƒ½ãŒæœ€é©åŒ–ã•ã‚ŒãŸiPhone 16 Pro MaxãŒæœ€ã‚‚æº€è¶³åº¦ã®é«˜ã„é¸æŠè‚¢ã¨ãªã‚Šã¾ã™ã€‚\n\n### è©³ç´°åˆ†æ\n\n#### 1. iPhone 13 Pro MaxãŒã€Œéå¯¾å¿œã€ã§ã‚ã‚‹ç†ç”±\nç¾åœ¨ãŠä½¿ã„ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€æœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã‚’åˆ©ç”¨ã™ã‚‹ãŸã‚ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢è¦ä»¶ã‚’æº€ãŸã—ã¦ã„ã¾ã›ã‚“ã€‚\n*   **ãƒ¡ãƒ¢ãƒªä¸è¶³**: Apple Intelligenceã®å®Ÿè¡Œã«ã¯8GBä»¥ä¸Šã®ãƒ¡ãƒ¢ãƒªï¼ˆRAMï¼‰ãŒå¿…è¦ã§ã™ãŒã€iPhone 13 Pro Maxã¯6GBã®ãŸã‚ã€OSã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã—ã¦ã‚‚æ©Ÿèƒ½ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã¾ã›ã‚“ã€‚\n*   **æ©Ÿèƒ½ã®é™ç•Œ**: å¾“æ¥ã®ç¿»è¨³ã‚¢ãƒ—ãƒªã¯ä½¿ç”¨å¯èƒ½ã§ã™ãŒã€é€šè©±ä¸­ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ç¿»è¨³ã‚„ã€é€šä¿¡åœå¤–ã§ã‚‚é«˜é€Ÿã«å‹•ä½œã™ã‚‹ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹AIå‡¦ç†ã¨ã„ã£ãŸã€OSãƒ¬ãƒ™ãƒ«ã§çµ±åˆã•ã‚ŒãŸæ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\n\n#### 2. æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ï¼šiPhone 16 Pro Max\n2025å¹´11æœˆç¾åœ¨ã€ä»¥ä¸‹ã®ç†ç”±ã‹ã‚‰æœ¬ãƒ¢ãƒ‡ãƒ«ãŒæœ€é©ã§ã™ã€‚\n\n*   **Apple Intelligenceã¸ã®å®Œå…¨å¯¾å¿œ**:\n    *   **ãƒ©ã‚¤ãƒ–ç¿»è¨³**: é›»è©±ã‚„FaceTimeé€šè©±ä¸­ã«ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§éŸ³å£°ã‚’ç¿»è¨³ã—å­—å¹•è¡¨ç¤ºã‚„èª­ã¿ä¸Šã’ã‚’è¡Œã„ã¾ã™ã€‚2025å¹´4æœˆã‚ˆã‚Šæ—¥æœ¬èªã«ã‚‚å¯¾å¿œæ¸ˆã¿ã§ã™ã€‚\n    *   **å¯¾é¢ç¿»è¨³**: AirPodsï¼ˆPro 2ç­‰ï¼‰ã¨é€£æºã—ã€å¯¾é¢ä¼šè©±ã‚’åŒæ™‚é€šè¨³ã®ã‚ˆã†ã«èãå–ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã™ã€‚\n*   **ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®å„ªä½æ€§**:\n    *   **6.9ã‚¤ãƒ³ãƒå¤§ç”»é¢**: 13 Pro Maxï¼ˆ6.7ã‚¤ãƒ³ãƒï¼‰ã‚ˆã‚Šç”»é¢ãŒå¤§ããã€ç¿»è¨³ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’è¦–èªã—ã‚„ã™ããªã£ã¦ã„ã¾ã™ã€‚\n    *   **ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³**: å´é¢ã®ãƒœã‚¿ãƒ³é•·æŠ¼ã—ã§å³åº§ã«ã€Œç¿»è¨³ã€ãƒ¢ãƒ¼ãƒ‰ã‚’èµ·å‹•ã§ãã€ã‚¢ãƒ—ãƒªã‚’æ¢ã™æ‰‹é–“ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\n    *   **ãƒã‚¤ã‚¯æ€§èƒ½**: éŸ³å£°åˆ†é›¢æ©Ÿèƒ½ãŒå¼·åŒ–ã•ã‚Œã¦ãŠã‚Šã€é¨’ãŒã—ã„å ´æ‰€ã§ã®ç¿»è¨³ç²¾åº¦ãŒå‘ä¸Šã—ã¦ã„ã¾ã™ã€‚\n\n#### 3. ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ\n\n| ç‰¹å¾´ | **iPhone 16 Pro Max** (æ¨å¥¨) | **iPhone 15 Pro Max** (æ¬¡ç‚¹) | **iPhone 13 Pro Max** (ç¾åœ¨) |\n| :--- | :--- | :--- | :--- |\n| **AIé€šè¨³æ©Ÿèƒ½** | **ãƒ•ãƒ«å¯¾å¿œ** (A18 Pro) | **å¯¾å¿œ** (A17 Pro) | **éå¯¾å¿œ** |\n| **ç”»é¢ã‚µã‚¤ã‚º** | **6.9ã‚¤ãƒ³ãƒ** | 6.7ã‚¤ãƒ³ãƒ | 6.7ã‚¤ãƒ³ãƒ |\n| **å³æ™‚èµ·å‹•** | **ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³ã‚ã‚Š** | **ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³ã‚ã‚Š** | ãªã— |\n| **ãƒ¡ãƒ¢ãƒª** | 8GB | 8GB | 6GB |\n\n*   **iPhone 15 Pro Maxã«ã¤ã„ã¦**: ã‚³ã‚¹ãƒˆã‚’æŠ‘ãˆãŸã„å ´åˆã®é¸æŠè‚¢ã¨ãªã‚Šã¾ã™ãŒã€ç”»é¢ã‚µã‚¤ã‚ºã‚„ãƒã‚¤ã‚¯æ€§èƒ½ã®é€²åŒ–ã‚’è€ƒæ…®ã™ã‚‹ã¨ã€13 Pro Maxã‹ã‚‰ã®è²·ã„æ›¿ãˆã¨ã—ã¦ã¯16 Pro Maxã®æ–¹ãŒä½“é¨“ã®å‘ä¸Šå¹…ãŒå¤§ãããªã‚Šã¾ã™ã€‚\n\n### è²·ã„æ›¿ãˆæ™‚ã®æ³¨æ„ç‚¹\n*   **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å®¹é‡**: ç¾åœ¨512GBã‚’ãŠä½¿ã„ã§ã™ã®ã§ã€è²·ã„æ›¿ãˆæ™‚ã‚‚**512GBä»¥ä¸Š**ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹ç¿»è¨³ç”¨ã®è¨€èªãƒ‡ãƒ¼ã‚¿ã‚„AIãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã«ã‚ˆã‚Šã€ã‚·ã‚¹ãƒ†ãƒ é ˜åŸŸã®ä½¿ç”¨é‡ãŒå¢—åŠ ã™ã‚‹å‚¾å‘ã«ã‚ã‚Šã¾ã™ã€‚\n*   **å‘¨è¾ºæ©Ÿå™¨**: æœ€æ–°ã®é€šè¨³ä½“é¨“ï¼ˆç‰¹ã«å¯¾é¢ã§ã®ä¼šè©±ï¼‰ã‚’æœ€å¤§åŒ–ã™ã‚‹ã«ã¯ã€AirPods Pro 2ãªã©ã®å¯¾å¿œã‚¤ãƒ¤ãƒ›ãƒ³ã®ä½µç”¨ãŒåŠ¹æœçš„ã§ã™ã€‚"
                },
                {
                    "role": "user",
                    "content": "iphone17ã‚ˆã‚Šã„ã„ã®ã‹ï¼Ÿ"
                },
                {
                    "role": "model",
                    "content": "### çµè«–\næ€§èƒ½é¢ã§ã¯ã€æœ€æ–°ã® **iPhone 17 Pro Max ã®æ–¹ãŒç¢ºå®Ÿã«å„ªã‚Œã¦ã„ã¾ã™**ã€‚\n\nç‰¹ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼æ§˜ãŒé‡è¦–ã•ã‚Œã¦ã„ã‚‹ã€Œé€šè¨³æ©Ÿèƒ½ã€ã‚„ã€ŒAIå‡¦ç†èƒ½åŠ›ã€ã«ãŠã„ã¦ã€iPhone 17 Pro Maxã¯å‰ä¸–ä»£ï¼ˆiPhone 16 Pro Maxï¼‰ã‹ã‚‰ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãŒæ ¹æœ¬çš„ã«å¼·åŒ–ã•ã‚Œã¦ãŠã‚Šã€ç¿»è¨³ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚„å°†æ¥çš„ãªæ©Ÿèƒ½å¯¾å¿œåŠ›ã«å¤§ããªå·®ãŒã‚ã‚Šã¾ã™ã€‚\n\n### è©³ç´°åˆ†æï¼šiPhone 17 Pro MaxãŒã€Œé€šè¨³ã€ã«å¼·ã„3ã¤ã®ç†ç”±\n\n2025å¹´11æœˆæ™‚ç‚¹ã®æœ€æ–°ä»•æ§˜ã«åŸºã¥ãã€é€šè¨³ä½“é¨“ã«ç›´çµã™ã‚‹æ±ºå®šçš„ãªé•ã„ã‚’è§£èª¬ã—ã¾ã™ã€‚\n\n#### 1. AIã®ã€ŒåŸºç¤ä½“åŠ›ã€ãŒ1.5å€ï¼ˆãƒ¡ãƒ¢ãƒª12GBï¼‰\nã“ã‚ŒãŒæœ€ã‚‚é‡è¦ãªé•ã„ã§ã™ã€‚AIé€šè¨³æ©Ÿèƒ½ã¯ãƒ¡ãƒ¢ãƒªï¼ˆRAMï¼‰å®¹é‡ã«ä¾å­˜ã—ã¾ã™ã€‚\n*   **iPhone 16 Pro Max**: 8GB\n*   **iPhone 17 Pro Max**: **12GB**\n\nãƒ¡ãƒ¢ãƒªãŒ12GBã«å¢—ãˆãŸã“ã¨ã§ã€ã‚ˆã‚Šé«˜åº¦ãªAIãƒ¢ãƒ‡ãƒ«ã‚’æœ¬ä½“å†…ã§å‹•ã‹ã›ã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€é›»æ³¢ã®å±Šã‹ãªã„å ´æ‰€ã§ã®ç¿»è¨³ç²¾åº¦ãŒå‘ä¸Šã—ã€è¤‡é›‘ãªä¼šè©±ã®æ–‡è„ˆç†è§£ã‚‚ã‚¹ãƒ ãƒ¼ã‚ºã«ãªã‚Šã¾ã™ã€‚\n\n#### 2. é•·æ™‚é–“ã®ä¼šè©±ã§ã‚‚ç†±ããªã‚‰ãªã„ï¼ˆå†·å´ã‚·ã‚¹ãƒ†ãƒ ã®åˆ·æ–°ï¼‰\né•·æ™‚é–“ã®ä¼šè­°ã‚„æ—…è¡Œä¸­ã®ä¼šè©±ã§é€šè¨³æ©Ÿèƒ½ã‚’ä½¿ã„ç¶šã‘ã‚‹ã¨ã€ã‚¹ãƒãƒ›ã¯ç™ºç†±ã—ã€å‡¦ç†é€Ÿåº¦ãŒè½ã¡ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚\n*   **iPhone 17 Pro Max**: æ–°ãŸã«**ãƒ™ã‚¤ãƒ‘ãƒ¼ãƒãƒ£ãƒ³ãƒãƒ¼ï¼ˆé«˜åº¦ãªå†·å´æ©Ÿæ§‹ï¼‰**ã‚’æ¡ç”¨ã€‚é•·æ™‚é–“ã€Œé€šè¨³ãƒ¢ãƒ¼ãƒ‰ã€ã‚’èµ·å‹•ã—ç¶šã‘ã¦ã‚‚ç™ºç†±ã‚’æŠ‘ãˆã€é«˜æ€§èƒ½ã‚’ç¶­æŒã§ãã¾ã™ã€‚ã“ã‚Œã¯å¾“æ¥ã®ã‚°ãƒ©ãƒ•ã‚¡ã‚¤ãƒˆã‚·ãƒ¼ãƒˆå†·å´ï¼ˆiPhone 16ä»¥å‰ï¼‰ã«å¯¾ã™ã‚‹å¤§ããªã‚¢ãƒ‰ãƒãƒ³ãƒ†ãƒ¼ã‚¸ã§ã™ã€‚\n\n#### 3. ã€Œã‚«ãƒ¡ãƒ©ç¿»è¨³ã€ã®è¦–èªæ€§ã¨ç²¾åº¦å‘ä¸Š\næµ·å¤–ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚„çœ‹æ¿ã‚’ã‚«ãƒ¡ãƒ©ã§æ˜ ã—ã¦ç¿»è¨³ã™ã‚‹æ©Ÿèƒ½ã‚‚é€²åŒ–ã—ã¦ã„ã¾ã™ã€‚\n*   **æœ›é ã‚«ãƒ¡ãƒ©ã®é«˜ç”»ç´ åŒ–ï¼ˆ48MPï¼‰**: é ãã®çœ‹æ¿ã‚’ã‚ºãƒ¼ãƒ ã—ã¦ã‚‚æ–‡å­—ãŒæ½°ã‚Œãšã€AIãŒæ­£ç¢ºã«èªè­˜ã§ãã¾ã™ï¼ˆ16 Pro Maxã¯12MPï¼‰ã€‚\n*   **åå°„é˜²æ­¢ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤**: æ–°æ¡ç”¨ã®ã€Œè¶…ç¡¬è³ªåå°„é˜²æ­¢å±¤ã€ã«ã‚ˆã‚Šã€å±‹å¤–ã®å¼·ã„æ—¥å·®ã—ã®ä¸‹ã§ã‚‚ç¿»è¨³çµæœãŒã¯ã£ãã‚Šè¦‹ãˆã¾ã™ã€‚\n\n### ãƒ¢ãƒ‡ãƒ«åˆ¥ã‚¹ãƒšãƒƒã‚¯æ¯”è¼ƒï¼ˆ2025å¹´11æœˆæ™‚ç‚¹ï¼‰\n\n| ç‰¹å¾´ | **iPhone 17 Pro Max** (æœ€æ–°) | **iPhone 16 Pro Max** (å‰ä¸–ä»£) | **iPhone 13 Pro Max** (ç¾åœ¨) |\n| :--- | :--- | :--- | :--- |\n| **AIãƒ¡ãƒ¢ãƒª** | **12GB** (å°†æ¥æ€§â—) | 8GB (ç¾è¡Œååˆ†) | 6GB (ä¸è¶³) |\n| **ãƒ—ãƒ­ã‚»ãƒƒã‚µ** | **A19 Pro** | A18 Pro | A15 Bionic |\n| **å†·å´æ€§èƒ½** | **ãƒ™ã‚¤ãƒ‘ãƒ¼ãƒãƒ£ãƒ³ãƒãƒ¼** | ã‚°ãƒ©ãƒ•ã‚¡ã‚¤ãƒˆã‚·ãƒ¼ãƒˆ | å¾“æ¥å‹ |\n| **æœ›é ã‚«ãƒ¡ãƒ©** | **48MP** (é«˜ç²¾ç´°) | 12MP | 12MP |\n\n### é‡è¦ãªæ³¨æ„ç‚¹ï¼šãƒ¢ãƒ‡ãƒ«é¸ã³ã«ã¤ã„ã¦\nåŒæ™‚æœŸã«ç™ºå£²ã•ã‚ŒãŸè–„å‹ãƒ¢ãƒ‡ãƒ«**ã€ŒiPhone 17 Air (Slim)ã€**ã¯ãƒ‡ã‚¶ã‚¤ãƒ³é‡è¦–ã®æ©Ÿç¨®ã§ã™ã€‚Pro Maxã«æ¯”ã¹ã¦ã‚«ãƒ¡ãƒ©æ€§èƒ½ã‚„ãƒãƒƒãƒ†ãƒªãƒ¼æŒã¡ã€å‡¦ç†æ€§èƒ½ãŒæŠ‘ãˆã‚‰ã‚Œã¦ã„ã‚‹ãŸã‚ã€é€šè¨³ãƒ„ãƒ¼ãƒ«ã¨ã—ã¦ã®å®Ÿç”¨æ€§ã‚’æœ€å„ªå…ˆã™ã‚‹ãªã‚‰**ã€ŒPro Maxã€ä¸€æŠ**ã§ã™ã€‚\n\n### ç·åˆåˆ¤æ–­\näºˆç®—ãŒè¨±ã™ã®ã§ã‚ã‚Œã°ã€**iPhone 17 Pro Max**ã‚’é¸ã¶ã¹ãã§ã™ã€‚\nãƒ¡ãƒ¢ãƒª12GBã¸ã®å¢—å¼·ã¯ã€ä»Šå¾Œæ•°å¹´é–“ã®OSã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã§è¿½åŠ ã•ã‚Œã‚‹æ–°ã—ã„AIæ©Ÿèƒ½ã«å¯¾å¿œã§ãã‚‹ã‹ã©ã†ã‹ã®ã€Œåˆ†ã‹ã‚Œç›®ã€ã«ãªã‚‹å¯èƒ½æ€§ãŒé«˜ãã€é•·ãå¿«é©ã«ä½¿ã†ãŸã‚ã®æŠ•è³‡ã¨ã—ã¦æœ€ã‚‚åˆç†çš„ã§ã™ã€‚",
                    "rating": -1
                },
                {
                    "role": "user",
                    "content": "iphone17ã‚ˆã‚Šã™ãã‚Œã¦ã‚‹ï¼Ÿ"
                }
            ]
        },
        {
            "id": "dcd59bbf-6cf8-4630-802f-af0cd831edd6",
            "title": "iPhoneã§æœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã‚’ä½¿ã„ãŸã„ãŒ...",
            "timestamp": "2025-11-29T23:05:59.977016",
            "messages": [
                {
                    "role": "user",
                    "content": "iPhoneã§æœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã‚’ä½¿ã„ãŸã„ãŒã€ã©ã®ãƒ¢ãƒ‡ãƒ«ãŒä¸€ç•ªãŠã™ã™ã‚ã‹ï¼Ÿä»Šiphonepromax13/512GBã‚’ä½¿ã£ã¦ã„ã‚‹"
                }
            ]
        },
        {
            "id": "cd3f58a5-a5b7-4e7a-a9af-3d16f0e9c81c",
            "title": "iPhoneã§æœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã‚’ä½¿ã„ãŸã„ãŒ...",
            "timestamp": "2025-11-29T23:04:08.731471",
            "messages": [
                {
                    "role": "user",
                    "content": "iPhoneã§æœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã‚’ä½¿ã„ãŸã„ãŒã€ã©ã®ãƒ¢ãƒ‡ãƒ«ãŒä¸€ç•ªãŠã™ã™ã‚ã‹ï¼Ÿä»Šiphonepromax13/512GBã‚’ä½¿ã£ã¦ã„ã‚‹"
                },
                {
                    "role": "model",
                    "content": "### çµè«–\n\nç¾åœ¨iPhone 13 Pro Maxã‚’ãŠä½¿ã„ã§ã€Appleã®æœ€æ–°AIæŠ€è¡“ï¼ˆApple Intelligenceï¼‰ã«ã‚ˆã‚‹é«˜åº¦ãªé€šè¨³æ©Ÿèƒ½ã‚’æœ€å¤§é™ã«æ´»ç”¨ã—ãŸã„å ´åˆã€**2024å¹´ç§‹ç™ºå£²äºˆå®šã®ã€ŒiPhone 16 Pro Maxã€ã‚’å¾…ã£ã¦è³¼å…¥ã™ã‚‹ã“ã¨**ãŒæœ€ã‚‚æ¨å¥¨ã•ã‚Œã¾ã™ã€‚\n\nã‚‚ã—ã€Œä»Šã™ãã€å¿…è¦ã§ã‚ã‚Œã°ã€ç¾è¡Œãƒ¢ãƒ‡ãƒ«ã®**ã€ŒiPhone 15 Pro Maxã€**ãŒå”¯ä¸€ã®é¸æŠè‚¢ã¨ãªã‚Šã¾ã™ã€‚\n\nç¾åœ¨ãŠä½¿ã„ã®iPhone 13 Pro Maxã¯ã€æ®‹å¿µãªãŒã‚‰æœ€æ–°ã®AIæ©Ÿèƒ½ã®å‹•ä½œè¦ä»¶ã‚’æº€ãŸã—ã¦ã„ã¾ã›ã‚“ã€‚OSãƒ¬ãƒ™ãƒ«ã§çµ±åˆã•ã‚ŒãŸã‚¹ãƒ ãƒ¼ã‚ºãªé€šè¨³æ©Ÿèƒ½ã‚’åˆ©ç”¨ã™ã‚‹ã«ã¯ã€ãƒ—ãƒ­ã‚»ãƒƒã‚µï¼ˆãƒãƒƒãƒ—ï¼‰ã®ä¸–ä»£äº¤ä»£ãŒå¿…é ˆã§ã™ã€‚\n\n### è©³ç´°ãªåˆ†æ\n\n#### 1. ãªãœã€Œè²·ã„æ›¿ãˆã€ãŒå¿…é ˆãªã®ã‹\nAppleãŒç™ºè¡¨ã—ãŸAIã‚·ã‚¹ãƒ†ãƒ ã€ŒApple Intelligenceã€ã«ã¯ã€é«˜åº¦ãªå‡¦ç†èƒ½åŠ›ã‚’æŒã¤ãƒãƒƒãƒ—ãŒå¿…è¦ã§ã™ã€‚\n*   **å¯¾å¿œæ©Ÿç¨®ã®å£**: Apple Intelligenceã¯ã€ŒA17 Proã€ãƒãƒƒãƒ—ä»¥é™ã‚’æ­è¼‰ã—ãŸãƒ¢ãƒ‡ãƒ«ã§ã®ã¿å‹•ä½œã—ã¾ã™ã€‚\n*   **ç¾çŠ¶**: ã‚ãªãŸã®iPhone 13 Pro Maxï¼ˆA15 Bionicï¼‰ã¯å¯¾è±¡å¤–ã§ã™ã€‚iOS 18ã«ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã—ã¦ã‚‚ã€AIã«ã‚ˆã‚‹é«˜åº¦ãªç¿»è¨³æ©Ÿèƒ½ã‚„è¦ç´„æ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\n\n#### 2. æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ï¼šiPhone 16 Pro Maxï¼ˆ2024å¹´ç§‹ç™ºå£²äºˆæƒ³ï¼‰\nã€Œé€šè¨³æ©Ÿã€ã¨ã—ã¦ã®æ€§èƒ½ã‚’è¿½æ±‚ã™ã‚‹å ´åˆã€æ¬¡æœŸãƒ¢ãƒ‡ãƒ«ã‚’å¾…ã¤ä¾¡å€¤ãŒéå¸¸ã«é«˜ã„ã¨è¨€ãˆã¾ã™ã€‚\n\n*   **AIã¸ã®å®Œå…¨æœ€é©åŒ–ï¼ˆA18 Proãƒãƒƒãƒ—ï¼‰**:\n    æ¬¡æœŸãƒãƒƒãƒ—ã¯AIå‡¦ç†èƒ½åŠ›ï¼ˆNeural Engineï¼‰ãŒå¤§å¹…ã«å¼·åŒ–ã•ã‚Œã‚‹ã¨äºˆæ¸¬ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ç’°å¢ƒã§ã®ç¿»è¨³é€Ÿåº¦ã‚„ç²¾åº¦ãŒç¾è¡Œæ©Ÿï¼ˆ15 Proï¼‰ã‚ˆã‚Šã‚‚å‘ä¸Šã—ã€ä¼šè©±ã®ãƒ†ãƒ³ãƒã‚’æãªã‚ãªã„ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€šè¨³ãŒæœŸå¾…ã§ãã¾ã™ã€‚\n*   **ãƒã‚¤ã‚¯æ€§èƒ½ã¨Siriã®å¼·åŒ–**:\n    é€šè¨³æ©Ÿèƒ½ã®è‚ã¯ã€ŒéŸ³å£°èªè­˜ã€ã§ã™ã€‚iPhone 16ã‚·ãƒªãƒ¼ã‚ºã§ã¯ãƒã‚¤ã‚¯ã®S/Næ¯”ï¼ˆä¿¡å·å¯¾é›‘éŸ³æ¯”ï¼‰ãŒå‘ä¸Šã™ã‚‹ã¨å™‚ã•ã‚Œã¦ãŠã‚Šã€é¨’ãŒã—ã„å±‹å¤–ã‚„é›‘è¸ã§ã‚‚æ­£ç¢ºã«éŸ³å£°ã‚’æ‹¾ã„ã€èª¤è¨³ã‚’æ¸›ã‚‰ã™ã“ã¨ãŒæœŸå¾…ã•ã‚Œã¾ã™ã€‚\n*   **ç”»é¢ã‚µã‚¤ã‚ºã¨ãƒãƒƒãƒ†ãƒªãƒ¼**:\n    ç”»é¢ã‚µã‚¤ã‚ºãŒ6.3ã‚¤ãƒ³ãƒ/6.9ã‚¤ãƒ³ãƒã¸ã¨å¤§å‹åŒ–ã™ã‚‹ã¨ã®æƒ…å ±ãŒã‚ã‚Šã€ç¿»è¨³çµæœã®ãƒ†ã‚­ã‚¹ãƒˆè¦–èªæ€§ãŒå‘ä¸Šã—ã¾ã™ã€‚ã¾ãŸã€AIå‡¦ç†ã¯ãƒãƒƒãƒ†ãƒªãƒ¼ã‚’æ¶ˆè²»ã—ã¾ã™ãŒã€ç©å±¤å‹ãƒãƒƒãƒ†ãƒªãƒ¼æŠ€è¡“ã«ã‚ˆã‚‹é§†å‹•æ™‚é–“ã®å»¶é•·ãŒè¦‹è¾¼ã¾ã‚Œã¦ã„ã¾ã™ã€‚\n\n#### 3. ä»£æ›¿æ¡ˆï¼šiPhone 15 Pro Maxï¼ˆç¾è¡Œãƒ¢ãƒ‡ãƒ«ï¼‰\nä»Šã™ãæ‰‹ã«å…¥ã‚Œã‚‹å¿…è¦ãŒã‚ã‚‹å ´åˆã®é¸æŠè‚¢ã§ã™ã€‚\n*   **Apple Intelligenceå¯¾å¿œ**: ç¾æ™‚ç‚¹ã§è²©å£²ã•ã‚Œã¦ã„ã‚‹iPhoneã®ä¸­ã§ã€AIæ©Ÿèƒ½ã«å¯¾å¿œã—ã¦ã„ã‚‹ã®ã¯15 Pro / 15 Pro Maxã®ã¿ã§ã™ã€‚\n*   **ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³**: å´é¢ã®ãƒœã‚¿ãƒ³ã«ã€Œç¿»è¨³ã€ã‚’å‰²ã‚Šå½“ã¦ã‚‹ã“ã¨ã§ã€ãƒ­ãƒƒã‚¯ç”»é¢ã‚’è§£é™¤ã›ãšã«ãƒ¯ãƒ³ã‚¿ãƒƒãƒã§é€šè¨³ãƒ¢ãƒ¼ãƒ‰ã‚’èµ·å‹•ã§ãã¾ã™ã€‚ã“ã‚Œã¯13 Pro Maxã«ã¯ãªã„å¤§ããªåˆ©ä¾¿æ€§ã§ã™ã€‚\n*   **USB-Cå¯¾å¿œ**: æµ·å¤–æ—…è¡Œã‚„å‡ºå¼µæ™‚ã€ã‚±ãƒ¼ãƒ–ãƒ«ã‚’çµ±ä¸€ã§ãã‚‹ãƒ¡ãƒªãƒƒãƒˆãŒã‚ã‚Šã¾ã™ã€‚\n\n### 13 Pro Maxãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®ç§»è¡Œã‚¢ãƒ‰ãƒã‚¤ã‚¹\n\nç¾åœ¨ã€ŒPro Max / 512GBã€ã‚’ãŠä½¿ã„ã®ç‚¹ã‹ã‚‰ã€ä»¥ä¸‹ã®è¦ç´ ã‚’è€ƒæ…®ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n\n*   **ã‚µã‚¤ã‚ºã¨é‡é‡**:\n    13 Pro Maxï¼ˆã‚¹ãƒ†ãƒ³ãƒ¬ã‚¹ï¼‰ã¯é‡ã„ã§ã™ãŒã€15/16 Pro Maxï¼ˆãƒã‚¿ãƒ‹ã‚¦ãƒ ï¼‰ã¯å¼·åº¦ãŒä¸ŠãŒã‚Šã¤ã¤è»½é‡åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚åŒã˜å¤§ç”»é¢ãƒ¢ãƒ‡ãƒ«ã§ã‚‚ã€æ‰‹ã«æŒã£ãŸæ™‚ã®è² æ‹…ã¯è»½æ¸›ã•ã‚Œã¾ã™ã€‚\n*   **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å®¹é‡**:\n    **å¼•ãç¶šã512GBä»¥ä¸Šã‚’æ¨å¥¨ã—ã¾ã™ã€‚** ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹AIï¼ˆç«¯æœ«å†…ã§å‡¦ç†ã™ã‚‹AIï¼‰ã¯ã€ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã‚„ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜ã™ã‚‹ãŸã‚ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’æ¶ˆè²»ã—ã¾ã™ã€‚ã¾ãŸã€å†™çœŸã‚„å‹•ç”»ã®ç”»è³ªå‘ä¸Šã«ä¼´ã„ã€256GBã§ã¯å°†æ¥çš„ã«ä¸è¶³ã™ã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚\n\n### ãƒªã‚¹ã‚¯ã¨æ³¨æ„ç‚¹\n\n*   **ç™ºå£²æ™‚æœŸã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°**:\n    ç¾åœ¨ã¯æ¬¡æœŸãƒ¢ãƒ‡ãƒ«ï¼ˆiPhone 16ã‚·ãƒªãƒ¼ã‚ºï¼‰ã®ç™ºè¡¨ãƒ»ç™ºå£²ç›´å‰ã®æ™‚æœŸã§ã™ã€‚ä»ŠiPhone 15 Pro Maxã‚’è²·ã†ã¨ã€æ•°ãƒ¶æœˆã§ã€Œæ—§ãƒ¢ãƒ‡ãƒ«ã€ã¨ãªã‚Šã€AIå‡¦ç†æ€§èƒ½ã§åŠ£ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ç·Šæ€¥ã§ãªã‘ã‚Œã°ç§‹ã¾ã§å¾…ã¤ã®ãŒå¾—ç­–ã§ã™ã€‚\n*   **ä¾¡æ ¼ä¸Šæ˜‡**:\n    ç‚ºæ›¿ã‚„éƒ¨æã‚³ã‚¹ãƒˆã®å½±éŸ¿ã§ã€iPhone 16 Pro Maxã¯ç¾è¡Œã‚ˆã‚Šä¾¡æ ¼ãŒä¸Šæ˜‡ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚äºˆç®—è¨ˆç”»ã«ã¯ä½™è£•ã‚’æŒã¤å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n\n**ç·è©•**:\nã€Œæœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã€ã‚’ã‚¹ãƒˆãƒ¬ã‚¹ãªãã€é•·ãä½¿ã„ç¶šã‘ãŸã„ã®ã§ã‚ã‚Œã°ã€AIæ€§èƒ½ã¨ãƒã‚¤ã‚¯å“è³ªãŒå¼·åŒ–ã•ã‚Œã‚‹**ã€ŒiPhone 16 Pro Maxã€**ã®ç™ºå£²ã‚’å¾…ã£ã¦ã€512GBãƒ¢ãƒ‡ãƒ«ã‚’è³¼å…¥ã™ã‚‹ã®ãŒãƒ™ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ªã§ã™ã€‚"
                }
            ]
        },
        {
            "id": "22bdf452-806a-4542-9a50-96c5d3a608da",
            "title": "iPhoneã§æœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã‚’ä½¿ã„ãŸã„ãŒ...",
            "timestamp": "2025-11-29T23:00:10.059174",
            "messages": [
                {
                    "role": "user",
                    "content": "iPhoneã§æœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã‚’ä½¿ã„ãŸã„ãŒã€ã©ã®ãƒ¢ãƒ‡ãƒ«ãŒä¸€ç•ªãŠã™ã™ã‚ã‹ï¼Ÿä»Šiphonepromax13/512GBã‚’ä½¿ã£ã¦ã„ã‚‹"
                },
                {
                    "role": "model",
                    "content": "### 1. æ·±æ˜ã‚Šè€ƒå¯Ÿï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n\n**Q1. A19 Proï¼ˆPro Maxï¼‰ã¨A19ï¼ˆAir/ç„¡å°ï¼‰ã§é€šè¨³æ©Ÿèƒ½ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«ä½“æ„Ÿå·®ã¯ã‚ã‚‹ã‹ï¼Ÿ**\næ—¥å¸¸çš„ãªçŸ­æ–‡ç¿»è¨³ã§ã¯å·®ã‚’æ„Ÿã˜ã«ãã„ã§ã™ãŒã€é€šè©±ä¸­ã®ã€Œãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ»ãƒ©ã‚¤ãƒ–é€šè¨³ã€ã«ãŠã„ã¦ã¯å·®ãŒå‡ºã¾ã™ã€‚A19 Proã¯ãƒ¡ãƒ¢ãƒªå¸¯åŸŸå¹…ã¨NPUï¼ˆãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ã‚¨ãƒ³ã‚¸ãƒ³ï¼‰ã®ã‚³ã‚¢æ•°ãŒå¼·åŒ–ã•ã‚Œã¦ãŠã‚Šã€é•·æ™‚é–“ã®é€šè©±ã‚„ã€ç¿»è¨³ã—ãªãŒã‚‰è³‡æ–™ã‚’é–‹ãã¨ã„ã£ãŸãƒãƒ«ãƒã‚¿ã‚¹ã‚¯æ™‚ã«ã€éŸ³å£°ã®é€”åˆ‡ã‚Œã‚„å‡¦ç†é…å»¶ãŒèµ·ãã«ãã„è¨­è¨ˆã§ã™ã€‚\n\n**Q2. Google Pixelã‚„Galaxyã¨æ¯”è¼ƒã—ã¦Apple IntelligenceãŒåŠ£ã‚‹ç‚¹ã¯ï¼Ÿ**\nã€Œå¯¾å¿œè¨€èªã®æ•°ã€ã«ãŠã„ã¦ã¯ç«¶åˆãŒå…ˆè¡Œã—ã¦ã„ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ãŒã€ä¸»è¦è¨€èªï¼ˆæ—¥ãƒ»è‹±ãƒ»ä¸­ãƒ»è¥¿ãªã©ï¼‰ã®ç²¾åº¦ã¯æ‹®æŠ—ã—ã¦ã„ã¾ã™ã€‚Appleã®å¼·ã¿ã¯ã€Œã‚¢ãƒ—ãƒªã‚’é¸ã°ãªã„OSçµ±åˆï¼ˆç”»é¢ä¸Šã®ã‚ã‚‰ã‚†ã‚‹æ–‡å­—ã‚’ç¿»è¨³ï¼‰ã€ã¨ã€Œã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹å‡¦ç†ã«ã‚ˆã‚‹ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·ã€ã«ã‚ã‚Šã€ä¼šè©±å†…å®¹ãŒå¤–éƒ¨ã‚µãƒ¼ãƒãƒ¼ã«é€ã‚‰ã‚Œãªã„å®‰å¿ƒæ„Ÿã¯AppleãŒå„ªä½ã§ã™ã€‚\n\n**Q3. é•·æ™‚é–“ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€šè¨³ã«ãŠã‘ã‚‹ç™ºç†±ã¨ãƒãƒƒãƒ†ãƒªãƒ¼æ¶ˆè²»ã¯ï¼Ÿ**\nAIã«ã‚ˆã‚‹éŸ³å£°èªè­˜ã¨ç¿»è¨³ã€åˆæˆéŸ³å£°ã®å‡ºåŠ›ã¯é«˜è² è·ã§ã™ã€‚ç‰¹ã«è–„å‹åŒ–ã•ã‚ŒãŸã€ŒiPhone 17 Airã€ã¯æ”¾ç†±é¢ç©ãŒå°ã•ã„ãŸã‚ã€é•·æ™‚é–“ã®ä½¿ç”¨ã§ã‚µãƒ¼ãƒãƒ«ã‚¹ãƒ­ãƒƒãƒˆãƒªãƒ³ã‚°ï¼ˆç†±ã«ã‚ˆã‚‹æ€§èƒ½æŠ‘åˆ¶ï¼‰ãŒç™ºç”Ÿã™ã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚å¯¾ã—ã¦ã€Œ17 Pro Maxã€ã¯ç­ä½“ãŒå¤§ããæ”¾ç†±ã«æœ‰åˆ©ã§ã€ãƒãƒƒãƒ†ãƒªãƒ¼å®¹é‡ã‚‚æœ€å¤§ç´šã§ã‚ã‚‹ãŸã‚ã€ãƒ“ã‚¸ãƒã‚¹ã§ã®é•·æ™‚é–“é€šè©±ã«ã¯Pro MaxãŒé©ã—ã¦ã„ã¾ã™ã€‚\n\n**Q4. é¨’éŸ³ä¸‹ã§ã®ãƒã‚¤ã‚¯æ€§èƒ½ã‚„éŸ³å£°åˆ†é›¢ã¯iPhone 13 Pro Maxã‹ã‚‰é€²åŒ–ã—ã¦ã„ã‚‹ã‹ï¼Ÿ**\næ˜ç¢ºã«é€²åŒ–ã—ã¦ã„ã¾ã™ã€‚ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã¨ã—ã¦ã®ãƒã‚¤ã‚¯æ€§èƒ½å‘ä¸Šã«åŠ ãˆã€A19 Proãƒãƒƒãƒ—ã«ã‚ˆã‚‹å¼·åŠ›ãªã€Œå£°ã‚’åˆ†é›¢ã€å‡¦ç†ãŒãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§é©ç”¨ã•ã‚Œã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€é§…ã®ãƒ›ãƒ¼ãƒ ã‚„ã‚«ãƒ•ã‚§ãªã©ã€iPhone 13 Pro Maxã§ã¯èª¤èªè­˜ãŒå¤šã‹ã£ãŸç’°å¢ƒã§ã‚‚ã€é€šè¨³æ©Ÿèƒ½ãŒæ­£ç¢ºã«å£°ã‚’æ‹¾ãˆã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã¾ã™ã€‚\n\n**Q5. AIãƒ¢ãƒ‡ãƒ«ã‚„ç¿»è¨³ãƒ‡ãƒ¼ã‚¿ã‚’è€ƒæ…®ã—ã¦1TBã«å¢—ã‚„ã™ã¹ãã‹ï¼Ÿ**\nAIãƒ¢ãƒ‡ãƒ«è‡ªä½“ã¯æ•°GBç¨‹åº¦ã§ã‚ã‚Šã€ãã‚Œã ã‘ã§1TBãŒå¿…é ˆã«ã¯ãªã‚Šã¾ã›ã‚“ã€‚ã—ã‹ã—ã€Pro Maxã‚’é¸ã¶ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯å†™çœŸã‚„å‹•ç”»ã‚‚é«˜ç”»è³ªã§ä¿å­˜ã™ã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚ç¿»è¨³å±¥æ­´ã®è“„ç©ã‚„å°†æ¥çš„ãªã‚ˆã‚Šå¤§è¦æ¨¡ãªãƒ­ãƒ¼ã‚«ãƒ«AIãƒ¢ãƒ‡ãƒ«ã®è¿½åŠ ã‚’è¦‹è¶Šã™ãªã‚‰1TBãŒå®‰å¿ƒã§ã™ãŒã€ç¾çŠ¶ã®512GBã§ã‚‚é‹ç”¨ç®¡ç†ã‚’è¡Œãˆã°ååˆ†å¯¾å¿œå¯èƒ½ã§ã™ã€‚\n\n---\n\n### 2. çµè«–\n**æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ï¼šiPhone 17 Pro Maxï¼ˆ512GB ã¾ãŸã¯ 1TBï¼‰**\n\nç¾åœ¨iPhone 13 Pro Maxã‚’ãŠä½¿ã„ã§ã‚ã‚Œã°ã€ç”»é¢ã‚µã‚¤ã‚ºã€ãƒãƒƒãƒ†ãƒªãƒ¼æŒã¡ã€å‡¦ç†æ€§èƒ½ã®å…¨ã¦ã«ãŠã„ã¦å¦¥å”ã®ãªã„**iPhone 17 Pro Max**ã¸ã®è²·ã„æ›¿ãˆãŒæœ€é©è§£ã§ã™ã€‚ç‰¹ã«ã€Œæœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã€ã‚’ãƒ“ã‚¸ãƒã‚¹ã‚„æ—…è¡Œã§å®Ÿç”¨ãƒ¬ãƒ™ãƒ«ã§ä½¿ã„å€’ã™ã«ã¯ã€A19 Proãƒãƒƒãƒ—ã®å‡¦ç†èƒ½åŠ›ã¨ã€é•·æ™‚é–“é§†å‹•ã‚’æ”¯ãˆã‚‹ãƒãƒƒãƒ†ãƒªãƒ¼å®¹é‡ãŒä¸å¯æ¬ ã§ã™ã€‚\n\n### 3. ç¾åœ¨ã®çŠ¶æ³ï¼ˆ2025å¹´11æœˆæ™‚ç‚¹ï¼‰\n*   **æœ€æ–°OSç’°å¢ƒ**: iOS 19ï¼ˆã¾ãŸã¯iOS 18.4ä»¥é™ï¼‰ã«ã‚ˆã‚Šã€Apple Intelligenceã®æ—¥æœ¬èªå¯¾å¿œãŒå®Œäº†æ¸ˆã¿ã€‚\n*   **é€šè¨³æ©Ÿèƒ½ã®å®ŸåŠ›**:\n    *   **é›»è©±ãƒ»FaceTime**: é€šè©±ä¸­ã«ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ç¿»è¨³éŸ³å£°ã¨å­—å¹•ã‚’è¡¨ç¤ºå¯èƒ½ã€‚\n    *   **å¯¾é¢åˆ©ç”¨**: ç¿»è¨³ã‚¢ãƒ—ãƒªãŒä¼šè©±ãƒ¢ãƒ¼ãƒ‰ã«å¯¾å¿œã—ã€äº¤äº’ã«è©±ã™ã ã‘ã§è‡ªå‹•ç¿»è¨³ã€‚\n    *   **ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ**: ç”»é¢ä¸Šã®ã‚ã‚‰ã‚†ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’SiriçµŒç”±ã§å³åº§ã«ç¿»è¨³å¯èƒ½ã€‚\n*   **ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢è¦ä»¶**: ã“ã‚Œã‚‰ã®æ©Ÿèƒ½ã¯iPhone 15 Proä»¥é™ã®ãƒãƒƒãƒ—ã‚»ãƒƒãƒˆï¼ˆA17 Proä»¥é™ï¼‰ãŒå¿…è¦ã§ã™ãŒã€æœ€æ–°ã®A19 Proï¼ˆiPhone 17 Proã‚·ãƒªãƒ¼ã‚ºï¼‰ã§æœ€ã‚‚é«˜é€Ÿãƒ»ä½é…å»¶ã«å‹•ä½œã—ã¾ã™ã€‚iPhone 13 Pro Maxã¯éå¯¾å¿œã§ã™ã€‚\n\n### 4. 2å¹´å¾Œã®ã‚·ãƒŠãƒªã‚ªåˆ†è§£\nä»Šå¾Œ2å¹´é–“ï¼ˆ2027å¹´é ƒã¾ã§ï¼‰ã®ä½¿ç”¨ã‚’è¦‹æ®ãˆãŸã‚·ãƒŠãƒªã‚ªåˆ†æã§ã™ã€‚\n\n*   **ãƒ™ãƒ¼ã‚¹ã‚·ãƒŠãƒªã‚ªï¼ˆå¯èƒ½æ€§ï¼šé«˜ï¼‰**\n    *   é€šè¨³ç²¾åº¦ãŒã•ã‚‰ã«å‘ä¸Šã—ã€å°‚é–€ç”¨èªã‚„ã‚¹ãƒ©ãƒ³ã‚°ã®ç†è§£åº¦ãŒæ”¹å–„ã€‚\n    *   ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ï¼ˆæ©Ÿå†…ãƒ¢ãƒ¼ãƒ‰ç­‰ï¼‰ã§ã®ç¿»è¨³ç²¾åº¦ãŒã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ™‚ã¨åŒç­‰ãƒ¬ãƒ™ãƒ«ã«è¿‘ã¥ãã€‚\n    *   iPhone 17 Pro Maxã®æ€§èƒ½ã¯2å¹´å¾Œã‚‚ãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã‚’ç¶­æŒã—ã€é™³è…åŒ–ã—ãªã„ã€‚\n\n*   **å¼·æ°—ã‚·ãƒŠãƒªã‚ªï¼ˆå¯èƒ½æ€§ï¼šä¸­ï¼‰**\n    *   AirPodsãªã©ã®ã‚¦ã‚§ã‚¢ãƒ©ãƒ–ãƒ«æ©Ÿå™¨ã¨ã®é€£æºãŒå¼·åŒ–ã•ã‚Œã€ã€Œã‚¹ãƒãƒ›ã‚’å–ã‚Šå‡ºã•ãšã«è€³å…ƒã§åŒæ™‚é€šè¨³ã€ãŒå®Œå…¨ãªå½¢ã§å®Ÿç¾ã™ã‚‹ã€‚\n    *   ã“ã®å‡¦ç†ã«ã¯é«˜ã„æ¼”ç®—èƒ½åŠ›ãŒå¿…è¦ã¨ãªã‚‹ãŒã€A19 Proãƒãƒƒãƒ—ãªã‚‰å¯¾å¿œå¯èƒ½ã€‚\n\n*   **å¼±æ°—ã‚·ãƒŠãƒªã‚ªï¼ˆå¯èƒ½æ€§ï¼šä½ï¼‰**\n    *   ã‚ˆã‚Šé«˜åº¦ãªAIæ©Ÿèƒ½ï¼ˆä¾‹ï¼šè©±è€…ã®å£°è‰²ã‚’ç¶­æŒã—ãŸã¾ã¾ç¿»è¨³ã™ã‚‹æ©Ÿèƒ½ãªã©ï¼‰ãŒã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆæœ‰æ–™ï¼‰åŒ–ã•ã‚Œã‚‹ã€‚\n    *   OSã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã«ã‚ˆã‚ŠAIãƒ¢ãƒ‡ãƒ«ãŒè‚¥å¤§åŒ–ã—ã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’åœ§è¿«ã—å§‹ã‚ã‚‹ã€‚\n\n### 5. ä¸»ãªãƒ—ãƒ©ã‚¹è¦å› ãƒ»ãƒã‚¤ãƒŠã‚¹è¦å› \n**ãƒ—ãƒ©ã‚¹è¦å› **\n*   **A19 Proãƒãƒƒãƒ—**: AIå‡¦ç†å°‚ç”¨ã®ã‚¨ãƒ³ã‚¸ãƒ³ãŒå¼·åŠ›ã§ã€ç¿»è¨³ã®å¾…ã¡æ™‚é–“ãŒã»ã¼ã‚¼ãƒ­ã€‚\n*   **ãƒãƒƒãƒ†ãƒªãƒ¼å¯¿å‘½**: 13 Pro Maxã¨æ¯”è¼ƒã—ã¦ã‚‚é•·æŒã¡ã—ã€AIä½¿ç”¨ã«ã‚ˆã‚‹æ¿€ã—ã„æ¶ˆè€—ã«è€ãˆã†ã‚‹ã€‚\n*   **USB-C**: 13 Pro Maxã®Lightningã‹ã‚‰ç§»è¡Œã™ã‚‹ã“ã¨ã§ã€å‘¨è¾ºæ©Ÿå™¨ã‚„å……é›»ã®åˆ©ä¾¿æ€§ãŒå‘ä¸Šã€‚\n\n**ãƒã‚¤ãƒŠã‚¹è¦å› **\n*   **ä¾¡æ ¼**: æœ€æ–°ã®Pro Maxãƒ¢ãƒ‡ãƒ«ã¯é«˜é¡ï¼ˆå††å®‰å‚¾å‘ãŒç¶šã„ã¦ã„ã‚‹å ´åˆã€ã•ã‚‰ã«é«˜ä¾¡ï¼‰ã€‚\n*   **é‡é‡**: 13 Pro MaxåŒæ§˜ã€ã‚ã‚‹ã„ã¯ãã‚Œä»¥ä¸Šã«é‡é‡ãŒã‚ã‚‹ãŸã‚ã€æºå¸¯æ€§ã¯ã€ŒAirã€ã«åŠ£ã‚‹ã€‚\n\n### 6. ã“ã®äºˆæ¸¬ã‚’ã©ã†ä½¿ã†ã¹ãã‹\n*   **è²·ã„æ›¿ãˆã®åˆ¤æ–­**: é€šè¨³æ©Ÿèƒ½ã‚’é‡è¦–ã™ã‚‹ãªã‚‰ã€iPhone 13 Pro Maxã‹ã‚‰ã®è²·ã„æ›¿ãˆã¯ã€Œå¿…é ˆã€ã§ã™ã€‚OSã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã ã‘ã§ã¯å¯¾å¿œã§ãã¾ã›ã‚“ã€‚\n*   **ãƒ¢ãƒ‡ãƒ«é¸å®š**: æºå¸¯æ€§ã‚’é‡è¦–ã—ã¦è–„å‹ã®ã€ŒiPhone 17 Airã€ã‚’é¸ã¶é¸æŠè‚¢ã‚‚ã‚ã‚Šã¾ã™ãŒã€13 Pro Maxã®ãƒãƒƒãƒ†ãƒªãƒ¼æŒã¡ã¨å¤§ç”»é¢ã«æ…£ã‚Œã¦ã„ã‚‹å ´åˆã€Airã§ã¯ç‰©è¶³ã‚Šãªã•ã‚’æ„Ÿã˜ã‚‹ãƒªã‚¹ã‚¯ãŒé«˜ã„ã§ã™ã€‚**è¿·ã‚ãš17 Pro Maxã‚’é¸ã‚“ã§ãã ã•ã„ã€‚**\n*   **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸**: ç¾åœ¨512GBã‚’ä½¿ã„åˆ‡ã£ã¦ã„ãªã„ãªã‚‰512GBã§ç¶­æŒã€ç©ºãå®¹é‡ãŒ20%ä»¥ä¸‹ãªã‚‰1TBã¸ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"
                }
            ]
        },
        {
            "id": "6ae236b9-6827-433d-9f0e-3e9b6ea5b444",
            "title": "iPhoneã§æœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã‚’ä½¿ã„ãŸã„ãŒ...",
            "timestamp": "2025-11-29T23:00:06.345416",
            "messages": [
                {
                    "role": "user",
                    "content": "iPhoneã§æœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã‚’ä½¿ã„ãŸã„ãŒã€ã©ã®ãƒ¢ãƒ‡ãƒ«ãŒä¸€ç•ªãŠã™ã™ã‚ã‹ï¼Ÿä»Šiphonepromax13/512GBã‚’ä½¿ã£ã¦ã„ã‚‹"
                },
                {
                    "role": "model",
                    "content": "### 1. çµè«–\n**æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ï¼šiPhone 16 Pro Max (512GBä»¥ä¸Š)**\n\nç¾åœ¨iPhone 13 Pro Maxã‚’ãŠä½¿ã„ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¨ã£ã¦ã€æœ€æ–°ã®AIé€šè¨³æ©Ÿèƒ½ã‚’æœ€å¤§é™ã«æ´»ç”¨ã—ã€ã‹ã¤ä½¿ç”¨æ„Ÿã‚’æãªã‚ãªã„æœ€é©ãªé¸æŠè‚¢ã¯ã€ç¾è¡Œæœ€æ–°ã®**iPhone 16 Pro Max**ã§ã™ã€‚\n\niPhone 13 Pro Maxã¯å„ªã‚ŒãŸç«¯æœ«ã§ã™ãŒã€Appleã®æœ€æ–°AIæ©Ÿèƒ½ç¾¤ã€ŒApple Intelligenceã€ã®å‹•ä½œè¦ä»¶ï¼ˆA17 Proãƒãƒƒãƒ—ä»¥ä¸Šã€ãƒ¡ãƒ¢ãƒª8GBä»¥ä¸Šï¼‰ã‚’æº€ãŸã—ã¦ã„ã¾ã›ã‚“ã€‚ã—ãŸãŒã£ã¦ã€OSã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã—ã¦ã‚‚ã€æœ€ã‚‚é‡è¦ãªAIæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ããªã„ã¨ã„ã†ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®åˆ¶ç´„ãŒã‚ã‚Šã¾ã™ã€‚\n\n---\n\n### 2. ãªãœã€ŒiPhone 16 Pro Maxã€ãªã®ã‹ï¼Ÿï¼ˆæ ¹æ‹ ã¨è©³ç´°ï¼‰\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ±‚ã‚ã‚‹ã€Œæœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã€ã‚’ã€Apple Intelligenceã«ã‚ˆã‚‹ã€Œæ–‡è„ˆã‚’ç†è§£ã—ãŸé«˜åº¦ãªç¿»è¨³ã€ã‚„ã€Œãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã€ã¨å®šç¾©ã—ãŸå ´åˆã€ä»¥ä¸‹ã®ç†ç”±ã‹ã‚‰16 Pro MaxãŒæœ€é©è§£ã¨ãªã‚Šã¾ã™ã€‚\n\n*   **Apple Intelligenceã¸ã®å®Œå…¨å¯¾å¿œ**:\n    *   **iPhone 13 Pro Max**: éå¯¾å¿œã€‚å¾“æ¥ã®ç¿»è¨³ã‚¢ãƒ—ãƒªã¯å‹•ä½œã—ã¾ã™ãŒã€ç”ŸæˆAIã‚’ç”¨ã„ãŸé«˜åº¦ãªè¦ç´„ã‚„æ–‡è„ˆç†è§£ã€ç”»åƒèªè­˜ã‚’çµ„ã¿åˆã‚ã›ãŸç¿»è¨³æ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\n    *   **iPhone 16 Pro Max**: æœ€æ–°ã®A18 Proãƒãƒƒãƒ—ã‚’æ­è¼‰ã—ã¦ãŠã‚Šã€AIå‡¦ç†ã‚’é«˜é€Ÿã‹ã¤ä½æ¶ˆè²»é›»åŠ›ã§å®Ÿè¡Œå¯èƒ½ã§ã™ã€‚\n*   **ç”»é¢ã‚µã‚¤ã‚ºã¨è¦–èªæ€§ã®ç¶­æŒãƒ»å‘ä¸Š**:\n    *   13 Pro Max (6.7ã‚¤ãƒ³ãƒ) ã‹ã‚‰ 16 Pro Max (6.9ã‚¤ãƒ³ãƒ) ã¸ã¨ç”»é¢ãŒã‚ãšã‹ã«å¤§å‹åŒ–ã—ã¦ãŠã‚Šã€ç¿»è¨³çµæœã‚„ãƒ†ã‚­ã‚¹ãƒˆã®è¦–èªæ€§ãŒå‘ä¸Šã—ã¦ã„ã¾ã™ã€‚\n    *   ãƒ™ã‚¼ãƒ«ï¼ˆæ ï¼‰ãŒç´°ããªã£ãŸãŸã‚ã€æœ¬ä½“ã‚µã‚¤ã‚ºã®å¤§å¹…ãªè‚¥å¤§åŒ–ã‚’æ„Ÿã˜ãšã«ç”»é¢é ˜åŸŸãŒåºƒãŒã£ã¦ã„ã¾ã™ã€‚\n*   **é‡é‡ã®è»½æ¸›**:\n    *   ã‚¹ãƒ†ãƒ³ãƒ¬ã‚¹ã‚¹ãƒãƒ¼ãƒ«ã®13 Pro Max (238g) ã«å¯¾ã—ã€ãƒã‚¿ãƒ‹ã‚¦ãƒ æ¡ç”¨ã®16 Pro Max (227g) ã¯ç´„11gè»½é‡åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚é•·æ™‚é–“ã®æ‰‹æŒã¡ç¿»è¨³åˆ©ç”¨ã«ãŠã„ã¦ã€ã“ã®å·®ã¯ä½“æ„Ÿä¸Šã®è² æ‹…è»½æ¸›ã«ã¤ãªãŒã‚Šã¾ã™ã€‚\n\n---\n\n### 3. é‡è¦ãªãƒªã‚¹ã‚¯è¦å› ï¼šæ—¥æœ¬èªå¯¾å¿œã®ã‚¿ã‚¤ãƒ ãƒ©ã‚°\nè³¼å…¥å‰ã«å¿…ãšèªè­˜ã—ã¦ãŠãã¹ãæ³¨æ„ç‚¹ãŒã‚ã‚Šã¾ã™ã€‚\n\n*   **æ—¥æœ¬èªå¯¾å¿œã¯ã€Œ2025å¹´ã€äºˆå®š**:\n    *   Apple Intelligenceã®æ©Ÿèƒ½è‡ªä½“ã¯ç±³å›½è‹±èªã‹ã‚‰é †æ¬¡ãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã¦ãŠã‚Šã€**æ—¥æœ¬èªã¸ã®å¯¾å¿œã¯2025å¹´ä¸­**ã¨ç™ºè¡¨ã•ã‚Œã¦ã„ã¾ã™ã€‚\n    *   ã—ãŸãŒã£ã¦ã€è³¼å…¥ç›´å¾Œã®æ™‚ç‚¹ã§ã¯ã€AIé€šè¨³æ©Ÿèƒ½ã¯ä¸»ã«è‹±èªï¼ˆå¯¾è‹±èªï¼‰ã§ã®åˆ©ç”¨ãŒä¸­å¿ƒã¨ãªã‚Šã€æ—¥æœ¬èªã‚’å«ã‚€é«˜åº¦ãªAIæ©Ÿèƒ½ãŒãƒ•ãƒ«æ´»ç”¨ã§ãã‚‹ã¾ã§ã«ã¯æ•°ãƒ¶æœˆã®ã‚¿ã‚¤ãƒ ãƒ©ã‚°ãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n    *   â€»å¾“æ¥ã®ã€Œç¿»è¨³ã‚¢ãƒ—ãƒªã€è‡ªä½“ã¯æ—¥æœ¬èªã§ã‚‚å³åº§ã«ä½¿ç”¨å¯èƒ½ã§ã™ã€‚\n\n---\n\n### 4. ã‚·ãƒŠãƒªã‚ªåˆ†æã¨ä»£æ›¿æ¡ˆ\n\n**ã‚·ãƒŠãƒªã‚ªAï¼šä»Šã™ãæœ€é«˜ã®ç’°å¢ƒã‚’æ•´ãˆãŸã„ï¼ˆæ¨å¥¨ï¼‰**\n*   **é¸æŠ**: **iPhone 16 Pro Max**\n*   **ç†ç”±**: å°†æ¥ã®æ—¥æœ¬èªå¯¾å¿œã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã«å‚™ãˆã¤ã¤ã€ç¾æ™‚ç‚¹ã§æœ€é«˜ã®ãƒãƒƒãƒ†ãƒªãƒ¼æŒã¡ã¨å‡¦ç†èƒ½åŠ›ã‚’ç¢ºä¿ã§ãã¾ã™ã€‚ãƒã‚¤ã‚¯æ€§èƒ½ã®å‘ä¸Šã«ã‚ˆã‚Šã€éŸ³å£°èªè­˜ã®ç²¾åº¦ã‚‚13ä¸–ä»£ã‚ˆã‚Šæ”¹å–„ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\n**ã‚·ãƒŠãƒªã‚ªBï¼šã‚³ã‚¹ãƒˆã‚’æŠ‘ãˆã¤ã¤AIæ©Ÿèƒ½ã‚’ä½¿ã„ãŸã„**\n*   **é¸æŠ**: **iPhone 16 Plus** ã¾ãŸã¯ **iPhone 15 Pro Max**\n*   **åˆ†æ**:\n    *   **16 Plus**: ç”»é¢ã‚µã‚¤ã‚ºã¯å¤§ãã„ã§ã™ãŒã€æœ›é ã‚«ãƒ¡ãƒ©ã®æ€§èƒ½ãŒè½ã¡ã€ProMotionï¼ˆ120Hzé§†å‹•ï¼‰ãŒãªã„ãŸã‚ã€13 Pro Maxã‹ã‚‰ã®ä¹—ã‚Šæ›ãˆã§ã¯ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã®æ»‘ã‚‰ã‹ã•ã«åŠ£åŒ–ã‚’æ„Ÿã˜ã‚‹ãƒªã‚¹ã‚¯ãŒé«˜ã„ã§ã™ã€‚\n    *   **15 Pro Max**: å‹è½ã¡ã§ã™ãŒApple Intelligenceã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚ãŸã ã—ã€æ–°å“å…¥æ‰‹ãŒé›£ã—ããªã‚Šã¤ã¤ã‚ã‚Šã€16 Pro Maxã¨ã®ä¾¡æ ¼å·®ã¨æ€§èƒ½å·®ï¼ˆç‰¹ã«ç†±å‡¦ç†ã¨ãƒãƒƒãƒ†ãƒªãƒ¼ï¼‰ã‚’è€ƒæ…®ã™ã‚‹ã¨ã€é•·ãä½¿ã†ä¸Šã§ã®è²»ç”¨å¯¾åŠ¹æœã¯16 Pro Maxã«åŠ£ã‚Šã¾ã™ã€‚\n\n**ã‚·ãƒŠãƒªã‚ªCï¼šæ—¥æœ¬èªå¯¾å¿œã¾ã§å¾…ã¡ãŸã„**\n*   **é¸æŠ**: **ç¾çŠ¶ç¶­æŒï¼ˆiPhone 13 Pro Maxç¶™ç¶šï¼‰**\n*   **åˆ†æ**: 2025å¹´ã®æ—¥æœ¬èªå¯¾å¿œå®Œäº†ã€ã‚ã‚‹ã„ã¯æ¬¡æœŸãƒ¢ãƒ‡ãƒ«ï¼ˆiPhone 17ã‚·ãƒªãƒ¼ã‚ºï¼‰ã®ç™ºè¡¨ã¾ã§å¾…ã¤æˆ¦ç•¥ã§ã™ã€‚ãŸã ã—ã€13 Pro Maxã®ãƒãƒƒãƒ†ãƒªãƒ¼åŠ£åŒ–ãŒé€²ã‚“ã§ã„ã‚‹å ´åˆã‚„ã€ãƒªã‚»ãƒ¼ãƒ«ãƒãƒªãƒ¥ãƒ¼ï¼ˆä¸‹å–ã‚Šä¾¡æ ¼ï¼‰ãŒä¸‹è½ã™ã‚‹ãƒªã‚¹ã‚¯ã‚’è€ƒæ…®ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n\n---\n\n### 5. ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å®¹é‡ã«ã¤ã„ã¦\n**æ¨å¥¨ï¼š512GBä»¥ä¸Šï¼ˆç¾çŠ¶ç¶­æŒï¼‰**\n\n*   **ç†ç”±**: AIãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜ã€ç¿»è¨³å±¥æ­´ã€é«˜ç”»è³ªåŒ–ã—ãŸå†™çœŸãƒ»å‹•ç”»ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚Šã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æ¶ˆè²»ã¯å¹´ã€…å¢—åŠ å‚¾å‘ã«ã‚ã‚Šã¾ã™ã€‚\n*   ç¾åœ¨512GBã‚’ãŠä½¿ã„ã§ã‚ã‚Œã°ã€256GBã¸ã®ãƒ€ã‚¦ãƒ³ã‚µã‚¤ã‚ºã¯ãƒ‡ãƒ¼ã‚¿ç§»è¡Œæ™‚ã®ãƒˆãƒ©ãƒ–ãƒ«ã‚„å°†æ¥çš„ãªå®¹é‡ä¸è¶³ã®ã‚¹ãƒˆãƒ¬ã‚¹ã«ç›´çµã™ã‚‹ãŸã‚æ¨å¥¨ã—ã¾ã›ã‚“ã€‚äºˆç®—ãŒè¨±ã›ã°1TBã‚‚æ¤œè¨ã®ä½™åœ°ãŒã‚ã‚Šã¾ã™ãŒã€512GBãŒãƒãƒ©ãƒ³ã‚¹ã®è‰¯ã„é¸æŠã§ã™ã€‚\n\n### ã¾ã¨ã‚\nã€Œæœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã€ã‚’å°†æ¥ã«ã‚ãŸã£ã¦å¿«é©ã«åˆ©ç”¨ã™ã‚‹ãŸã‚ã«ã¯ã€**iPhone 16 Pro Max (512GB)** ã¸ã®è²·ã„æ›¿ãˆãŒæœ€ã‚‚åˆç†çš„ã§ã™ã€‚ãŸã ã—ã€**ã€ŒAIæ©Ÿèƒ½ã®æ—¥æœ¬èªå®Œå…¨å¯¾å¿œã¯2025å¹´ä»¥é™ã€**ã¨ã„ã†ç‚¹ã®ã¿ã€ã‚ã‚‰ã‹ã˜ã‚ã”äº†æ‰¿ãã ã•ã„ã€‚"
                }
            ]
        },
        {
            "id": "cd65b542-af4d-412e-8460-b1203c4f397a",
            "title": "iPhoneã§æœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã‚’ä½¿ã„ãŸã„ãŒ...",
            "timestamp": "2025-11-29T22:59:54.495115",
            "messages": [
                {
                    "role": "user",
                    "content": "iPhoneã§æœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã‚’ä½¿ã„ãŸã„ãŒã€ã©ã®ãƒ¢ãƒ‡ãƒ«ãŒä¸€ç•ªãŠã™ã™ã‚ã‹ï¼Ÿä»Šiphonepromax13/512GBã‚’ä½¿ã£ã¦ã„ã‚‹"
                },
                {
                    "role": "model",
                    "content": "### 1. æ·±æ˜ã‚Šè€ƒå¯Ÿï¼šãªãœã€Œé€šè¨³æ©Ÿèƒ½ã€ã®ãŸã‚ã«è²·ã„æ›¿ãˆãŒå¿…è¦ãªã®ã‹\nç¾åœ¨ãŠä½¿ã„ã®iPhone 13 Pro Maxã¯ã€ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã¨ã—ã¦ã¯ä¾ç„¶ã¨ã—ã¦å„ªç§€ã§ã™ãŒã€**ã€ŒApple Intelligenceï¼ˆã‚¢ãƒƒãƒ—ãƒ«ãƒ»ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹ï¼‰ã€ã«å¯¾å¿œã—ã¦ã„ãªã„**ã¨ã„ã†æ±ºå®šçš„ãªåˆ¶ç´„ãŒã‚ã‚Šã¾ã™ã€‚\n\n2025å¹´ç¾åœ¨ã®ã€Œæœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã€ã¨ã¯ã€å˜ã«ç¿»è¨³ã‚¢ãƒ—ãƒªã‚’èµ·å‹•ã™ã‚‹ã“ã¨ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚OSãƒ¬ãƒ™ãƒ«ã§çµ±åˆã•ã‚ŒãŸAIãŒã€æ–‡è„ˆã‚’ç†è§£ã—ãªãŒã‚‰ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«å‡¦ç†ã‚’è¡Œã†ã€Œä½“é¨“ã€ã‚’æŒ‡ã—ã¾ã™ã€‚ç‰¹ã«iOS 19ã§å®Ÿè£…ã•ã‚ŒãŸã€ŒAirPodsé€£æºã«ã‚ˆã‚‹åŒæ™‚é€šè¨³ã€ã‚„ã€ã‚«ãƒ¡ãƒ©ã‚’ã‹ã–ã™ã ã‘ã®ã€Œãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹ã€ã¯ã€iPhone 13 Pro Maxã®ãƒãƒƒãƒ—ï¼ˆA15 Bionicï¼‰ã§ã¯å‡¦ç†èƒ½åŠ›ãŠã‚ˆã³ãƒ¡ãƒ¢ãƒªä¸è¶³ã«ã‚ˆã‚Šå‹•ä½œã—ã¾ã›ã‚“ã€‚\n\nã—ãŸãŒã£ã¦ã€æœ€æ–°ã®é€šè¨³ä½“é¨“ã‚’äº«å—ã™ã‚‹ãŸã‚ã«ã¯ã€Apple IntelligenceãŒãƒã‚¤ãƒ†ã‚£ãƒ–ã«å‹•ä½œã™ã‚‹ãƒãƒƒãƒ—ï¼ˆA17 Proä»¥é™ã€ç†æƒ³çš„ã«ã¯A19ä¸–ä»£ï¼‰ã‚’æ­è¼‰ã—ãŸãƒ¢ãƒ‡ãƒ«ã¸ã®ç§»è¡ŒãŒä¸å¯æ¬ ã§ã™ã€‚\n\n### 2. çµè«–\n**æœ€å„ªå…ˆæ¨å¥¨ï¼šiPhone 17 Pro Max**\nç¾åœ¨Pro Maxãƒ¢ãƒ‡ãƒ«ã‚’ãŠä½¿ã„ã§ã‚ã‚Œã°ã€ç”»é¢ã‚µã‚¤ã‚ºã¨ãƒãƒƒãƒ†ãƒªãƒ¼æŒã¡ã‚’ç¶­æŒã—ã¤ã¤ã€æœ€é«˜ã®AIå‡¦ç†èƒ½åŠ›ã‚’æŒã¤**iPhone 17 Pro Max**ãŒæœ€é©è§£ã§ã™ã€‚A19 Proãƒãƒƒãƒ—ã«ã‚ˆã‚Šã€ä¼šè©±ã®ãƒ©ã‚°ï¼ˆé…å»¶ï¼‰ãŒã»ã¼ã‚¼ãƒ­ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€šè¨³ãŒå¯èƒ½ã§ã€æœ€ã‚‚ã‚¹ãƒˆãƒ¬ã‚¹ã®ãªã„ç¿»è¨³ä½“é¨“ãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚\n\n**æºå¸¯æ€§é‡è¦–ã®åˆ¥è§£ï¼šiPhone Air**\nã‚‚ã—13 Pro Maxã®ã€Œé‡ã•ã€ã«è² æ‹…ã‚’æ„Ÿã˜ã¦ã„ã‚‹ãªã‚‰ã€2025å¹´ç§‹ç™ºå£²ã®**iPhone Air**ãŒå¼·åŠ›ãªé¸æŠè‚¢ã§ã™ã€‚è–„å‹è»½é‡ãªãŒã‚‰æœ€æ–°ã®A19ãƒãƒƒãƒ—ã‚’æ­è¼‰ã—ã¦ãŠã‚Šã€æµ·å¤–æ—…è¡Œæ™‚ãªã©ã®æŒã¡æ­©ãã‚„ã™ã•ã¨é«˜åº¦ãªé€šè¨³æ©Ÿèƒ½ã‚’ä¸¡ç«‹ã§ãã¾ã™ã€‚\n\n### 3. ç¾åœ¨ã®çŠ¶æ³ï¼šiPhone 13 Pro Maxã¨ã®æ±ºå®šçš„ãªå·®\nç¾åœ¨ãŠä½¿ã„ã®ãƒ¢ãƒ‡ãƒ«ã¨ã€æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ã®é–“ã«ã¯ã€ŒAIãŒå‹•ãã‹å¦ã‹ã€ã¨ã„ã†è¶Šãˆã‚‰ã‚Œãªã„å£ãŒå­˜åœ¨ã—ã¾ã™ã€‚\n\n| ç‰¹å¾´ | iPhone 13 Pro Max (ç¾åœ¨) | iPhone 17 Pro Max (æ¨å¥¨) |\n| :--- | :--- | :--- |\n| **Apple Intelligence** | **éå¯¾å¿œ** | **å®Œå…¨å¯¾å¿œ** |\n| **é€šè¨³ã®å‡¦ç†** | ã‚¯ãƒ©ã‚¦ãƒ‰ä¾å­˜ï¼ˆé€šä¿¡ç’°å¢ƒã«å·¦å³ã•ã‚Œã‚‹ï¼‰ | **ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹é«˜é€Ÿå‡¦ç†**ï¼ˆé€šä¿¡ãªã—ã§ã‚‚é«˜é€Ÿï¼‰ |\n| **ä¼šè©±ã®è‡ªç„¶ã•** | ç›´è¨³èª¿ã«ãªã‚ŠãŒã¡ | æ–‡è„ˆã‚’ç†è§£ã—ãŸè‡ªç„¶ãªæ„è¨³ |\n| **AirPodsé€£æº** | éŸ³å£°ã‚’èãã ã‘ | **åŒæ™‚é€šè¨³ä½“é¨“**ï¼ˆç›¸æ‰‹ã®è¨€è‘‰ãŒç¿»è¨³ã•ã‚Œã¦èã“ãˆã‚‹ï¼‰ |\n| **ã‚«ãƒ¡ãƒ©ç¿»è¨³** | å†™çœŸã‚’æ’®ã£ã¦ç¿»è¨³ | ã‹ã–ã™ã ã‘ã§ç¬æ™‚ã«ç¿»è¨³ãƒ»è¦ç´„ |\n\n### 4. 2å¹´å¾Œã®ã‚·ãƒŠãƒªã‚ªåˆ†è§£ï¼ˆ2027å¹´ã«å‘ã‘ã¦ï¼‰\n**ãƒ™ãƒ¼ã‚¹ã‚·ãƒŠãƒªã‚ªï¼ˆé«˜ç¢ºç‡ï¼‰**\n*   é€šè¨³æ©Ÿèƒ½ã¯ã•ã‚‰ã«ã€Œã‚¤ãƒ³ãƒ•ãƒ©åŒ–ã€ã—ã€é›»è©±ã‚„Webä¼šè­°ã ã‘ã§ãªãã€å¯¾é¢ä¼šè©±ã§ã‚‚ã‚¹ãƒãƒ›ã‚’æ„è­˜ã•ã›ãªã„UIï¼ˆã‚¦ã‚§ã‚¢ãƒ©ãƒ–ãƒ«é€£æºãªã©ï¼‰ãŒæ¨™æº–ã«ãªã‚Šã¾ã™ã€‚iPhone 17 Pro Maxã®å‡¦ç†èƒ½åŠ›ã§ã‚ã‚Œã°ã€å‘ã“ã†3ã€œ4å¹´ã¯ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã®ä½“é¨“ã‚’ç¶­æŒã§ãã¾ã™ã€‚\n\n**å¼·æ°—ã‚·ãƒŠãƒªã‚ªï¼ˆAIã®é€²åŒ–åŠ é€Ÿï¼‰**\n*   iOSã®ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã«ã‚ˆã‚Šã€å°‚é–€ç”¨èªã‚„æ–¹è¨€ã®ç¿»è¨³ç²¾åº¦ãŒé£›èºçš„ã«å‘ä¸Šã€‚ãƒ“ã‚¸ãƒã‚¹äº¤æ¸‰ã‚„åŒ»ç™‚ç¾å ´ãƒ¬ãƒ™ãƒ«ã®é€šè¨³ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚ã“ã®å ´åˆã€A19 Proãƒãƒƒãƒ—ã®ä½™è£•ã‚ã‚‹å‡¦ç†èƒ½åŠ›ãŒå¤§ããªã‚¢ãƒ‰ãƒãƒ³ãƒ†ãƒ¼ã‚¸ã¨ãªã‚Šã¾ã™ã€‚\n\n**å¼±æ°—ã‚·ãƒŠãƒªã‚ªï¼ˆãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®é™³è…åŒ–ï¼‰**\n*   AIãƒ¢ãƒ‡ãƒ«ãŒå·¨å¤§åŒ–ã—ã€ã‚¯ãƒ©ã‚¦ãƒ‰å‡¦ç†ã¸ã®å›å¸°ãŒé€²ã‚€å¯èƒ½æ€§ã€‚ãŸã ã—ã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼é‡è¦–ã®Appleã¯ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹å‡¦ç†ã‚’åŸºæœ¬ã¨ã™ã‚‹ãŸã‚ã€ãƒ­ãƒ¼ã‚«ãƒ«æ€§èƒ½ãŒé«˜ã„ãƒ¢ãƒ‡ãƒ«ã‚’æŒã£ã¦ã„ã‚‹ã“ã¨ã®å„ªä½æ€§ã¯å¤‰ã‚ã‚Šã¾ã›ã‚“ã€‚\n\n### 5. ä¸»ãªãƒ—ãƒ©ã‚¹è¦å› ãƒ»ãƒã‚¤ãƒŠã‚¹è¦å› \n**ãƒ—ãƒ©ã‚¹è¦å› **\n*   **æ—¥æœ¬èªå¯¾å¿œå®Œäº†**: 2025å¹´4æœˆã‚ˆã‚ŠApple IntelligenceãŒæ—¥æœ¬èªã«å®Œå…¨å¯¾å¿œã—ã¦ãŠã‚Šã€ä»Šã™ããƒ•ãƒ«æ©Ÿèƒ½ã‚’ä½¿ãˆã¾ã™ã€‚\n*   **ä¸‹å–ã‚Šä¾¡å€¤**: iPhone 13 Pro Max 512GBã¯ã€çŠ¶æ…‹ãŒè‰¯ã‘ã‚Œã°ä¾ç„¶ã¨ã—ã¦é«˜ã„ä¸‹å–ã‚Šé¡ãŒæœŸå¾…ã§ãã€ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ã‚³ã‚¹ãƒˆã‚’åœ§ç¸®ã§ãã¾ã™ã€‚\n\n**ãƒã‚¤ãƒŠã‚¹è¦å› **\n*   **å‘¨è¾ºæ©Ÿå™¨ã‚³ã‚¹ãƒˆ**: æœ€é«˜ã®ä½“é¨“ï¼ˆåŒæ™‚é€šè¨³ï¼‰ã‚’å¾—ã‚‹ã«ã¯ã€æœ€æ–°ã®AirPods Proï¼ˆç¬¬3ä¸–ä»£ç­‰ï¼‰ãŒå¿…è¦ã«ãªã‚‹å¯èƒ½æ€§ãŒé«˜ãã€ç·å‡ºè²»ãŒå¢—ãˆã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n\n### 6. ã“ã®äºˆæ¸¬ã‚’ã©ã†ä½¿ã†ã¹ãã‹\nã€Œæµ·å¤–æ—…è¡Œã§ã®ä¸å®‰ã‚’ãªãã—ãŸã„ã€ã€Œãƒ“ã‚¸ãƒã‚¹ã§è‹±èªã®ä¼šè­°ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«ç†è§£ã—ãŸã„ã€ã¨ã„ã†ãƒ‹ãƒ¼ã‚ºãŒæ˜ç¢ºã§ã‚ã‚Œã°ã€**ä»Šã™ãiPhone 17 Pro Maxã¸è²·ã„æ›¿ãˆã‚‹ã¹ã**ã§ã™ã€‚\n\niPhone 13 Pro Maxã§ã®ç¿»è¨³ã¯ã€Œãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã†ã€æ„Ÿè¦šã§ã™ãŒã€iPhone 17 Pro Maxã§ã®ç¿»è¨³ã¯ã€Œè¨€èªã®å£ãŒãªããªã‚‹ã€æ„Ÿè¦šã«è¿‘ã„ã§ã™ã€‚ç‰¹ã«512GBãƒ¢ãƒ‡ãƒ«ã‚’ãŠä½¿ã„ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã§ã‚ã‚Œã°ã€ãƒ­ãƒ¼ã‚«ãƒ«ã«ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã‚„ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã™ã‚‹å®¹é‡ã®é‡è¦æ€§ã‚‚ç†è§£ã•ã‚Œã¦ã„ã‚‹ã¯ãšã§ã™ã®ã§ã€åŒã˜å®¹é‡ã¾ãŸã¯ãã‚Œä»¥ä¸Šã§ã®ç§»è¡Œã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚"
                }
            ]
        },
        {
            "id": "28d39fb5-2373-476f-8015-e7f6e9b88d24",
            "title": "iPhoneã§æœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã‚’ä½¿ã„ãŸã„ãŒ...",
            "timestamp": "2025-11-29T22:54:56.845271",
            "messages": [
                {
                    "role": "user",
                    "content": "iPhoneã§æœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã‚’ä½¿ã„ãŸã„ãŒã€ã©ã®ãƒ¢ãƒ‡ãƒ«ãŒä¸€ç•ªãŠã™ã™ã‚ã‹ï¼Ÿä»Šiphonepromax13/512GBã‚’ä½¿ã£ã¦ã„ã‚‹"
                },
                {
                    "role": "model",
                    "content": "### 1. çµè«–\n**æ¨å¥¨ï¼šiPhone 16 Pro Maxï¼ˆ2024å¹´ç§‹ç™ºå£²äºˆå®šï¼‰ã‚’å¾…ã¤ã®ãŒæœ€å–„**\n**æ¬¡ç‚¹ï¼ˆä»Šã™ãè³¼å…¥ï¼‰ï¼šiPhone 15 Pro Max (512GB)**\n\nç¾åœ¨iPhone 13 Pro Maxã‚’ãŠä½¿ã„ã®å ´åˆã€**iPhone 15 Pro Max**ãŒã€Œæœ€æ–°ã®AIé€šè¨³æ©Ÿèƒ½ï¼ˆApple Intelligenceï¼‰ã€ã«å¯¾å¿œã™ã‚‹ç¾è¡Œå”¯ä¸€ã®é¸æŠè‚¢ã§ã™ã€‚ã—ã‹ã—ã€**ã€Œæ—¥æœ¬èªå¯¾å¿œã®æ™‚æœŸã€**ã¨ã„ã†é‡å¤§ãªãƒªã‚¹ã‚¯è¦å› ãŒã‚ã‚‹ãŸã‚ã€æ€¥ã„ã§è²·ã„æ›¿ãˆã‚‹ã‚ˆã‚Šã‚‚ã€æ¬¡æœŸãƒ¢ãƒ‡ãƒ«ï¼ˆ16ã‚·ãƒªãƒ¼ã‚ºï¼‰ã¨æ—¥æœ¬èªå¯¾å¿œã®çŠ¶æ³ã‚’è¦‹æ¥µã‚ã‚‹ã“ã¨ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚\n\n### 2. é‡è¦ãªãƒªã‚¹ã‚¯è¦å› ï¼šæ—¥æœ¬èªå¯¾å¿œã®ã‚¿ã‚¤ãƒ ãƒ©ã‚°\næ©Ÿç¨®é¸ã³ã®å‰ã«ã€æœ€ã‚‚é‡è¦ãªäº‹å®Ÿã‚’ãŠä¼ãˆã—ã¾ã™ã€‚\n*   **æ©Ÿèƒ½ã®æä¾›æ™‚æœŸ**: Apple Intelligenceï¼ˆæœ€æ–°AIæ©Ÿèƒ½ï¼‰ã¯2024å¹´ç§‹ã«ç±³å›½è‹±èªã‹ã‚‰é–‹å§‹ã•ã‚Œã¾ã™ã€‚\n*   **æ—¥æœ¬èªå¯¾å¿œ**: **2025å¹´ä»¥é™**ã«ãªã‚‹è¦‹è¾¼ã¿ã§ã™ã€‚\n*   **æ„å‘³ã™ã‚‹ã“ã¨**: ä»Šã™ãiPhone 15 Pro Maxã‚’è³¼å…¥ã—ã¦ã‚‚ã€**æ—¥æœ¬èªã§ã®æœ€æ–°AIé€šè¨³æ©Ÿèƒ½ã¯ã™ãã«ã¯ä½¿ãˆã¾ã›ã‚“**ã€‚æ—¢å­˜ã®ã€Œç¿»è¨³ã‚¢ãƒ—ãƒªã€ã¯ç¾åœ¨ã®iPhone 13 Pro Maxã§ã‚‚åˆ©ç”¨å¯èƒ½ã§ã™ã€‚ã—ãŸãŒã£ã¦ã€ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã ã‘å…ˆã«æ›´æ–°ã—ã¦ã‚‚ã€ç›®çš„ã®æ©Ÿèƒ½ãŒä½¿ãˆã‚‹ã‚ˆã†ã«ãªã‚‹ã¾ã§ã€Œå¾…ã¡ã€ã®çŠ¶æ…‹ãŒç™ºç”Ÿã—ã¾ã™ã€‚\n\n### 3. ãƒ¢ãƒ‡ãƒ«é¸å®šã®æ ¹æ‹ ã¨åˆ†æ\n\n#### ãªãœã€ŒPro Maxã€ä¸€æŠãªã®ã‹\niPhone 13 Pro Maxãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ€ã‚‚é¿ã‘ã‚‹ã¹ãã¯ã€**ã€Œãƒãƒƒãƒ†ãƒªãƒ¼æŒã¡ã€ã¨ã€Œç”»é¢ã‚µã‚¤ã‚ºã€ã®ãƒ€ã‚¦ãƒ³ã‚°ãƒ¬ãƒ¼ãƒ‰**ã§ã™ã€‚\n*   **iPhone 15 Proï¼ˆ6.1ã‚¤ãƒ³ãƒï¼‰ã‚’é¸ã‚“ã å ´åˆ**: è»½ããªã‚Šã¾ã™ãŒã€ãƒãƒƒãƒ†ãƒªãƒ¼é§†å‹•æ™‚é–“ãŒä½“æ„Ÿã§çŸ­ããªã‚Šã€ç¿»è¨³ç”»é¢ã®è¦–èªæ€§ã‚‚ä¸‹ãŒã‚Šã¾ã™ã€‚13 Pro Maxã®ã‚¿ãƒ•ã•ã«æ…£ã‚ŒãŸèº«ä½“ã«ã¯ã‚¹ãƒˆãƒ¬ã‚¹ã¨ãªã‚‹ã§ã—ã‚‡ã†ã€‚\n*   **iPhone 15 Pro Maxï¼ˆ6.7ã‚¤ãƒ³ãƒï¼‰**: ãƒã‚¿ãƒ³ç´ ææ¡ç”¨ã«ã‚ˆã‚Šã€13 Pro Maxï¼ˆ238gï¼‰ã‹ã‚‰15 Pro Maxï¼ˆ221gï¼‰ã¸ã¨**ç´„17gè»½é‡åŒ–**ã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚µã‚¤ã‚ºæ„Ÿã‚’å¤‰ãˆãšã«è»½ããªã‚Šã€ã‹ã¤AIå¯¾å¿œãƒãƒƒãƒ—ï¼ˆA17 Proï¼‰ã‚’æ­è¼‰ã—ã¦ã„ã‚‹ãŸã‚ã€ç§»è¡Œå…ˆã¨ã—ã¦ç†æƒ³çš„ã§ã™ã€‚\n\n#### iPhone 16 Pro Maxï¼ˆå¾…æ©Ÿï¼‰ã‚’æ¨ã™ç†ç”±\n*   **AIã¸ã®æœ€é©åŒ–**: æ¬¡æœŸA18ãƒãƒƒãƒ—ï¼ˆä»®ç§°ï¼‰ã¯ã€AIå‡¦ç†èƒ½åŠ›ï¼ˆNeural Engineï¼‰ãŒã•ã‚‰ã«å¼·åŒ–ã•ã‚Œã‚‹ã¨äºˆæ¸¬ã•ã‚Œã¾ã™ã€‚é€šè¨³æ©Ÿèƒ½ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚„ç²¾åº¦ã«ç›´çµã—ã¾ã™ã€‚\n*   **ãƒã‚¤ã‚¯ãƒ»æ”¾ç†±æ€§èƒ½**: éŸ³å£°èªè­˜ã®ç²¾åº¦å‘ä¸Šã‚„ã€AIå‡¦ç†æ™‚ã®ç™ºç†±å¯¾ç­–ãŒå¼·åŒ–ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n*   **ã‚¿ã‚¤ãƒŸãƒ³ã‚°**: æ—¥æœ¬èªå¯¾å¿œãŒ2025å¹´ä»¥é™ã§ã‚ã‚Œã°ã€2024å¹´ç§‹ç™ºå£²ã®16 Pro Maxã‚’è³¼å…¥ã—ã¦ã‚‚ã€æ©Ÿèƒ½è§£ç¦ã¾ã§ã®å¾…ã¡æ™‚é–“ã¯çŸ­ãã¦æ¸ˆã¿ã¾ã™ã€‚\n\n### 4. ã‚·ãƒŠãƒªã‚ªåˆ¥ã‚¢ãƒ‰ãƒã‚¤ã‚¹\n\n**ã‚·ãƒŠãƒªã‚ªAï¼šè‹±èªã§ã®é€šè¨³ãƒ»ãƒ“ã‚¸ãƒã‚¹åˆ©ç”¨ãŒä»Šã™ãå¿…è¦**\n*   **åˆ¤æ–­**: **iPhone 15 Pro Max (512GB)** ã‚’å³è³¼å…¥ã—ã¦ãã ã•ã„ã€‚\n*   **ç†ç”±**: ç±³å›½è‹±èªã§ã®Apple Intelligenceæ©Ÿèƒ½ã¯2024å¹´ç§‹ã‹ã‚‰åˆ©ç”¨å¯èƒ½ã§ã™ã€‚è‹±èªåœã¸ã®å‡ºå¼µã‚„é§åœ¨ãŒã‚ã‚‹ãªã‚‰ã€å…ˆè¡Œã—ã¦æ©æµã‚’å—ã‘ã‚‰ã‚Œã¾ã™ã€‚USB-Cå¯¾å¿œã«ã‚ˆã‚Šã€å‘¨è¾ºæ©Ÿå™¨ã®åˆ©ä¾¿æ€§ã‚‚å‘ä¸Šã—ã¾ã™ã€‚\n\n**ã‚·ãƒŠãƒªã‚ªBï¼šæ—¥æœ¬èªâ‡”å¤–å›½èªã®é€šè¨³ãŒãƒ¡ã‚¤ãƒ³**\n*   **åˆ¤æ–­**: **iPhone 13 Pro Maxã‚’ç¶­æŒã—ã€iPhone 16 Pro Maxã®ç™ºå£²ï¼ˆç§‹ï¼‰ã¾ã§å¾…æ©Ÿ**ã—ã¦ãã ã•ã„ã€‚\n*   **ç†ç”±**: ä»Šè²·ã„æ›¿ãˆã¦ã‚‚ã€è‚å¿ƒã®AIæ©Ÿèƒ½ãŒæ—¥æœ¬èªã§ä½¿ãˆãªã„æœŸé–“ãŒç¶šãã¾ã™ã€‚13 Pro Maxã¯ä¾ç„¶ã¨ã—ã¦é«˜æ€§èƒ½ã§ã‚ã‚Šã€iOS 18ã®æ¨™æº–çš„ãªç¿»è¨³ã‚¢ãƒ—ãƒªã®ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã¯å—ã‘ã‚‰ã‚Œã¾ã™ã€‚ç„¦ã£ã¦è²·ã„æ›¿ãˆã‚‹ã‚³ã‚¹ãƒˆãƒ¡ãƒªãƒƒãƒˆãŒè–„ã„ã§ã™ã€‚\n\n### 5. ã¾ã¨ã‚\nã€Œæœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã€ã‚’ãƒ•ãƒ«æ´»ç”¨ã™ã‚‹ã«ã¯ã€**ã€Œãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ï¼ˆA17 Proä»¥é™ï¼‰ã€**ã¨**ã€Œè¨€èªå¯¾å¿œï¼ˆæ—¥æœ¬èªï¼‰ã€**ã®2ã¤ã®æ¡ä»¶ãŒæƒã†å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n\n*   **ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢**: iPhone 15 Pro Maxã§ã‚¯ãƒªã‚¢å¯èƒ½ã€‚\n*   **è¨€èªå¯¾å¿œ**: ã¾ã ã‚¯ãƒªã‚¢ã§ãã¦ã„ã¾ã›ã‚“ï¼ˆ2025å¹´ä»¥é™ï¼‰ã€‚\n\nã—ãŸãŒã£ã¦ã€**ã€ŒiPhone 16 Pro Maxã®ç™ºå£²ã‚’å¾…ã¡ã¤ã¤ã€æ—¥æœ¬èªå¯¾å¿œã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ³¨è¦–ã™ã‚‹ã€**ã®ãŒã€13 Pro Maxãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¨ã£ã¦æœ€ã‚‚è³¢æ˜ã§æã®ãªã„æˆ¦ç•¥ã§ã™ã€‚\n\n**æƒ…å ±æº**:\n*   Apple WWDC24 Keynote (Apple Intelligenceã®å¯¾å¿œæ©Ÿç¨®ãƒ»è¨€èªå±•é–‹ã«ã¤ã„ã¦)\n*   iPhone 15 Pro/Max Technical Specifications (Apple)"
                }
            ]
        },
        {
            "id": "858e36e6-ce62-4c02-8756-c254758a82b9",
            "title": "iPhoneã§æœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã‚’ä½¿ã„ãŸã„ãŒ...",
            "timestamp": "2025-11-29T22:54:19.406138",
            "messages": [
                {
                    "role": "user",
                    "content": "iPhoneã§æœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã‚’ä½¿ã„ãŸã„ãŒã€ã©ã®ãƒ¢ãƒ‡ãƒ«ãŒä¸€ç•ªãŠã™ã™ã‚ã‹ï¼Ÿä»Šiphonepromax13/512GBã‚’ä½¿ã£ã¦ã„ã‚‹"
                },
                {
                    "role": "model",
                    "content": "### 1. æ·±æ˜ã‚Šè€ƒå¯Ÿï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n\n**Q1. A19ãƒãƒƒãƒ—ï¼ˆiPhone 17ï¼‰ã¨æ—§ãƒ¢ãƒ‡ãƒ«ï¼ˆ15/16ï¼‰ã§ç¿»è¨³ã«ä½“æ„Ÿå·®ã¯ã‚ã‚‹ã‹ï¼Ÿ**\nã‚ã‚Šã¾ã™ã€‚ç‰¹ã«ã€Œãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ç¿»è¨³ã€ã«ãŠã„ã¦é¡•è‘—ã§ã™ã€‚A19ãƒãƒƒãƒ—ã®å¼·åŒ–ã•ã‚ŒãŸNeural Engineã¯ã€ä¼šè©±ã®ã€Œé–“ã€ã‚’æ¤œçŸ¥ã™ã‚‹é€Ÿåº¦ã‚„ã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ç’°å¢ƒã§ã®ç¿»è¨³ç”Ÿæˆé€Ÿåº¦ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚iPhone 15 Proç­‰ã§ã‚‚å‹•ä½œã¯ã—ã¾ã™ãŒã€ä¼šè©±ã®ãƒ†ãƒ³ãƒãŒé€Ÿã„å ´åˆã€å‡¦ç†å¾…ã¡ã®ãƒ©ã‚°ãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n\n**Q2. Apple Intelligenceã®æ—¥æœ¬èªå¯¾å¿œã«é…ã‚Œã‚„æ©Ÿèƒ½åˆ¶é™ã®ãƒªã‚¹ã‚¯ã¯ã‚ã‚‹ã‹ï¼Ÿ**\né«˜ã„ç¢ºç‡ã§å­˜åœ¨ã—ã¾ã™ã€‚Appleã®AIæ©Ÿèƒ½ã¯è‹±èªåœã‹ã‚‰å…ˆè¡Œãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã‚‹å‚¾å‘ãŒã‚ã‚Šã€æ—¥æœ¬èªç‰¹æœ‰ã®ã€Œæ•¬èªã®ä½¿ã„åˆ†ã‘ã€ã‚„ã€Œä¸»èªçœç•¥ã®è£œå®Œã€ã«ãŠã„ã¦ã€åˆæœŸæ®µéšã§ã¯è‹±èªã»ã©ã®ç²¾åº¦ãŒå‡ºãªã„ã€ã‚ã‚‹ã„ã¯ä¸€éƒ¨æ©Ÿèƒ½ï¼ˆé«˜åº¦ãªè¦ç´„ãªã©ï¼‰ã®å®Ÿè£…ãŒæ•°ãƒ¶æœˆé…ã‚Œã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚\n\n**Q3. Google Pixelã®ç¿»è¨³æ©Ÿèƒ½ã¨æ¯”è¼ƒã—ã¦åŠ£ã‚‹ç‚¹ã¯ï¼Ÿ**\nã€Œå¯¾å¿œè¨€èªæ•°ã€ã¨ã€Œãƒ‡ãƒ¼ã‚¿è“„ç©é‡ã€ã§åŠ£ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚Googleã¯é•·å¹´ç¿»è¨³ãƒ‡ãƒ¼ã‚¿ã‚’è“„ç©ã—ã¦ãŠã‚Šã€ãƒã‚¤ãƒŠãƒ¼è¨€èªã®å¯¾å¿œã‚„å£èªè¡¨ç¾ã®å¼·ã•ãŒã‚ã‚Šã¾ã™ã€‚ä¸€æ–¹ã€Appleã¯ãƒ‡ãƒã‚¤ã‚¹å†…å‡¦ç†ï¼ˆãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼é‡è¦–ï¼‰ã¨AirPodsã¨ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢é€£æºã«ã‚ˆã‚‹UXï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ï¼‰ã§å·®åˆ¥åŒ–ã‚’å›³ã£ã¦ã„ã¾ã™ã€‚\n\n**Q4. AirPods Proé€£æºã¯é¨’éŸ³ä¸‹ã§ã‚‚å®Ÿç”¨çš„ã‹ï¼Ÿ**\nå®Ÿç”¨çš„ã§ã™ãŒé™ç•Œã¯ã‚ã‚Šã¾ã™ã€‚æœ€æ–°ã®AirPods Proã®ã€Œå£°ã‚’åˆ†é›¢ã€æ©Ÿèƒ½ã¨ãƒã‚¤ã‚ºã‚­ãƒ£ãƒ³ã‚»ãƒªãƒ³ã‚°ã¯å¼·åŠ›ã§ã™ãŒã€é§…ã®ãƒ›ãƒ¼ãƒ ã‚„æ··é›‘ã—ãŸå±…é…’å±‹ãªã©ã€å‘¨å›²ã®ä¼šè©±ãƒ¬ãƒ™ãƒ«ãŒé«˜ã„å ´æ‰€ã§ã¯ã€ç¿»è¨³å¯¾è±¡ã®å£°ã‚’æ­£ç¢ºã«æ‹¾ã„ãã‚Œãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚é™ã‹ãªã‚«ãƒ•ã‚§ã‚„ä¼šè­°å®¤ãƒ¬ãƒ™ãƒ«ã§ã‚ã‚Œã°éå¸¸ã«æœ‰åŠ¹ã§ã™ã€‚\n\n**Q5. ãƒãƒƒãƒ†ãƒªãƒ¼æ¶ˆè²»ã¨ã‚¹ãƒãƒ›é›†ç´„ã®ãƒªã‚¹ã‚¯ã¯ï¼Ÿ**\né€šè¨³æ©Ÿèƒ½ï¼ˆéŸ³å£°èªè­˜ï¼‹AIå‡¦ç†ï¼‹é€šä¿¡ï¼‰ã¯ãƒãƒƒãƒ†ãƒªãƒ¼ã‚’æ¿€ã—ãæ¶ˆè€—ã—ã¾ã™ã€‚iPhone 17 Pro Maxã¯ãƒãƒƒãƒ†ãƒªãƒ¼æŒã¡ãŒè‰¯ã„ã§ã™ãŒã€æ—…è¡Œä¸­ã«åœ°å›³ã‚„ã‚«ãƒ¡ãƒ©ã¨ä½µç”¨ã™ã‚‹ã¨1æ—¥æŒãŸãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å°‚ç”¨æ©Ÿï¼ˆãƒã‚±ãƒˆãƒ¼ã‚¯ç­‰ï¼‰ã‚’æŒãŸãšã‚¹ãƒãƒ›ã«é›†ç´„ã™ã‚‹å ´åˆã¯ã€MagSafeå¯¾å¿œã®ãƒ¢ãƒã‚¤ãƒ«ãƒãƒƒãƒ†ãƒªãƒ¼æºè¡ŒãŒå¿…é ˆã§ã™ã€‚\n\n---\n\n### 2. çµè«–\n**iPhone 17 Pro Max (512GBã¾ãŸã¯1TB)** ãŒå”¯ä¸€ã‹ã¤æœ€è‰¯ã®é¸æŠè‚¢ã§ã™ã€‚\n\nç¾åœ¨ãŠä½¿ã„ã®iPhone 13 Pro Maxã¯ã€Appleã®æœ€æ–°AIé€šè¨³æ©Ÿèƒ½ã®è¦ä»¶ã‚’æº€ãŸã—ã¦ã„ã¾ã›ã‚“ã€‚æœ€æ–°ã®é€šè¨³ä½“é¨“ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ç¿»è¨³ã€AirPodsé€£æºï¼‰ã‚’äº«å—ã™ã‚‹ã«ã¯è²·ã„æ›¿ãˆãŒå¿…é ˆã§ã™ã€‚ç‰¹ã«ã€Œç”»é¢ã‚µã‚¤ã‚ºã€ã¨ã€Œãƒãƒƒãƒ†ãƒªãƒ¼æŒã¡ã€ã‚’é‡è¦–ã•ã‚Œã‚‹ç¾åœ¨ã®åˆ©ç”¨ã‚¹ã‚¿ã‚¤ãƒ«ã‚’ç¶­æŒã—ã¤ã¤ã€AIå‡¦ç†ã«ã‚ˆã‚‹ç¿»è¨³ãƒ©ã‚°ã‚’æœ€å°é™ã«æŠ‘ãˆã‚‹ãŸã‚ã«ã¯ã€æœ€æ–°ã®æœ€ä¸Šä½ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹17 Pro MaxãŒæœ€é©è§£ã¨ãªã‚Šã¾ã™ã€‚\n\n### 3. ç¾åœ¨ã®çŠ¶æ³\n*   **ãŠä½¿ã„ã®ãƒ¢ãƒ‡ãƒ«**: iPhone 13 Pro Maxã¯ã€ŒApple Intelligenceã€éå¯¾å¿œã®ãŸã‚ã€OSã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã—ã¦ã‚‚æœ€æ–°ã®AIé€šè¨³æ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\n*   **æŠ€è¡“çš„è¦ä»¶**: é«˜åº¦ãªAIç¿»è¨³ã«ã¯ã€iPhone 15 Proä»¥é™ã«æ­è¼‰ã•ã‚ŒãŸé«˜æ€§èƒ½ãƒãƒƒãƒ—ï¼ˆA17 Proä»¥ä¸Šï¼‰ãŒå¿…è¦ã§ã™ã€‚\n*   **æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ã®å„ªä½æ€§**: iPhone 17 Pro Maxã«æ­è¼‰ã•ã‚Œã‚‹A19 Proãƒãƒƒãƒ—ã¨12GBãƒ¡ãƒ¢ãƒªã¯ã€ç¿»è¨³å‡¦ç†ã‚’ãƒ‡ãƒã‚¤ã‚¹å†…ã§é«˜é€Ÿã«è¡Œã†ãŸã‚ã«è¨­è¨ˆã•ã‚Œã¦ãŠã‚Šã€13 Pro Maxã¨æ¯”è¼ƒã—ã¦å‡¦ç†èƒ½åŠ›ãŒé£›èºçš„ã«å‘ä¸Šã—ã¦ã„ã¾ã™ã€‚\n\n### 4. 2å¹´å¾Œã®ã‚·ãƒŠãƒªã‚ªåˆ†è§£\n\n| ã‚·ãƒŠãƒªã‚ª | æƒ³å®šã•ã‚Œã‚‹çŠ¶æ³ |\n| :--- | :--- |\n| **ãƒ™ãƒ¼ã‚¹ã‚·ãƒŠãƒªã‚ª**<br>ï¼ˆå¯èƒ½æ€§ï¼šé«˜ï¼‰ | **ã€Œå®Ÿç”¨çš„ãªé€šè¨³ãƒ„ãƒ¼ãƒ«ã€ã¨ã—ã¦å®šç€**<br>æ—¥æœ¬èªå¯¾å¿œãŒé€²ã¿ã€æµ·å¤–æ—…è¡Œã§ã®æ³¨æ–‡ã‚„é“æ¡ˆå†…ã€æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«ã§ã‚ã‚Œã°ã‚¹ãƒˆãƒ¬ã‚¹ãªãåˆ©ç”¨å¯èƒ½ã«ãªã‚‹ã€‚AirPodsé€£æºã«ã‚ˆã‚Šã€ã‚¹ãƒãƒ›ã‚’å–ã‚Šå‡ºã•ãšã«ç¿»è¨³ã‚’èãã‚¹ã‚¿ã‚¤ãƒ«ãŒæ™®åŠã—å§‹ã‚ã‚‹ã€‚ |\n| **å¼·æ°—ã‚·ãƒŠãƒªã‚ª**<br>ï¼ˆå¯èƒ½æ€§ï¼šä¸­ï¼‰ | **ã€Œã»ã‚“ã‚„ãã‚³ãƒ³ãƒ‹ãƒ£ã‚¯ã€ã«è¿‘ã„ä½“é¨“**<br>AIã®æ–‡è„ˆç†è§£ãŒé€²åŒ–ã—ã€ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«ã®è¤‡é›‘ãªä¼šè©±ã‚‚é…å»¶ãªãç¿»è¨³å¯èƒ½ã«ã€‚ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ç¿»è¨³ã®ç²¾åº¦ãŒåŠ‡çš„ã«å‘ä¸Šã—ã€é›»æ³¢ã®ãªã„å ´æ‰€ã§ã‚‚å®Œç’§ã«å‹•ä½œã™ã‚‹ã€‚ |\n| **å¼±æ°—ã‚·ãƒŠãƒªã‚ª**<br>ï¼ˆå¯èƒ½æ€§ï¼šä½ï¼‰ | **ã€ŒGoogleç¿»è¨³ã‚¢ãƒ—ãƒªã¨å¤§å·®ãªã—ã€**<br>æ—¥æœ¬èªç‰¹æœ‰ã®ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ç†è§£ã«è‹¦æˆ¦ã—ã€ç¿»è¨³ç²¾åº¦ãŒé ­æ‰“ã¡ã«ãªã‚‹ã€‚ãƒãƒƒãƒ†ãƒªãƒ¼æ¶ˆè²»ãŒæ¿€ã—ã™ãã¦ã€çµå±€ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã§ã®ç¿»è¨³ãŒãƒ¡ã‚¤ãƒ³ã¨ãªã‚Šã€å°‚ç”¨æ©Ÿï¼ˆãƒã‚±ãƒˆãƒ¼ã‚¯ç­‰ï¼‰ã®å„ªä½æ€§ãŒå´©ã‚Œãªã„ã€‚ |\n\n### 5. ä¸»ãªãƒ—ãƒ©ã‚¹è¦å› ãƒ»ãƒã‚¤ãƒŠã‚¹è¦å› \n\n**ãƒ—ãƒ©ã‚¹è¦å› **\n*   **ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ é€£æº**: AirPods Proï¼ˆç¬¬3ä¸–ä»£ç­‰ï¼‰ã¨ã®é€£æºã§ã€è€³å…ƒã§ç¿»è¨³éŸ³å£°ã‚’èã‘ã‚‹ã€Œãƒãƒ³ã‚ºãƒ•ãƒªãƒ¼é€šè¨³ã€ã¯Appleç‹¬è‡ªã®å¼·ã¿ã€‚\n*   **ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢é€²åŒ–**: USB-Cå¯¾å¿œã«ã‚ˆã‚‹å……é›»ç’°å¢ƒã®æ”¹å–„ã¨ã€ãƒã‚¿ãƒ³/ã‚¢ãƒ«ãƒŸç´ æã«ã‚ˆã‚‹è»½é‡åŒ–ã§ã€æŒã¡é‹ã³ã®è² æ‹…ãŒæ¸›ã‚‹ã€‚\n*   **ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹å‡¦ç†**: é€šä¿¡ç’°å¢ƒãŒæ‚ªã„å ´æ‰€ã§ã‚‚ã€ã‚ã‚‹ç¨‹åº¦ã®ç¿»è¨³æ©Ÿèƒ½ãŒä½¿ãˆã‚‹ï¼ˆãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã‚‚ä¿è­·ã•ã‚Œã‚‹ï¼‰ã€‚\n\n**ãƒã‚¤ãƒŠã‚¹è¦å› **\n*   **ã‚³ã‚¹ãƒˆ**: æœ€æ–°ã®Pro Maxãƒ¢ãƒ‡ãƒ«ï¼ˆç‰¹ã«å¤§å®¹é‡ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ï¼‰ã¯éå¸¸ã«é«˜é¡ã«ãªã‚‹ã€‚\n*   **æ—¥æœ¬èªå¯¾å¿œã®ã‚¿ã‚¤ãƒ ãƒ©ã‚°**: è‹±èªåœã®æ©Ÿèƒ½æä¾›ã«æ¯”ã¹ã€æ—¥æœ¬èªç‰ˆã®ãƒ•ãƒ«æ©Ÿèƒ½å®Ÿè£…ãŒé…ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚\n\n### 6. ã“ã®äºˆæ¸¬ã‚’ã©ã†ä½¿ã†ã¹ãã‹\n*   **è²·ã„æ›¿ãˆã®åˆ¤æ–­**: ã€Œé€šè¨³æ©Ÿèƒ½ã‚’ä½¿ã„ãŸã„ã€ã¨ã„ã†ãƒ‹ãƒ¼ã‚ºãŒæ˜ç¢ºã§ã‚ã‚Œã°ã€iPhone 13 Pro Maxã‹ã‚‰ã®è²·ã„æ›¿ãˆã¯å¿…é ˆã§ã™ã€‚iPhone 15/16 Proã§ã‚‚æ©Ÿèƒ½ã¯ä½¿ãˆã¾ã™ãŒã€é•·ãå¿«é©ã«ä½¿ã†ãªã‚‰å‡¦ç†èƒ½åŠ›ã«ä½™è£•ã®ã‚ã‚‹17 Pro Maxã‚’æ¨å¥¨ã—ã¾ã™ã€‚\n*   **ãƒªã‚¹ã‚¯ç®¡ç†**: æµ·å¤–æ—…è¡Œãªã©ã§ã‚¬ãƒƒãƒ„ãƒªä½¿ã†äºˆå®šãŒã‚ã‚‹å ´åˆã¯ã€iPhoneã ã‘ã«é ¼ã‚‰ãšã€ãƒ¢ãƒã‚¤ãƒ«ãƒãƒƒãƒ†ãƒªãƒ¼ã‚’å¿…ãšç”¨æ„ã—ã¦ãã ã•ã„ã€‚ã¾ãŸã€è³¼å…¥ç›´å¾Œã¯æ—¥æœ¬èªå¯¾å¿œçŠ¶æ³ã‚’ç¢ºèªã—ã€é‡è¦ãªå ´é¢ã§ã¯å¿µã®ãŸã‚Googleç¿»è¨³ã‚¢ãƒ—ãƒªãªã©ã‚‚ä½µç”¨ã™ã‚‹æº–å‚™ã‚’ã—ã¦ãŠãã¨å®‰å¿ƒã§ã™ã€‚"
                }
            ]
        },
        {
            "id": "87606892-b250-489e-acb2-38728ae44ea5",
            "title": "iPhoneã§æœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã‚’ä½¿ã„ãŸã„ãŒ...",
            "timestamp": "2025-11-29T22:54:04.357789",
            "messages": [
                {
                    "role": "user",
                    "content": "iPhoneã§æœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã‚’ä½¿ã„ãŸã„ãŒã€ã©ã®ãƒ¢ãƒ‡ãƒ«ãŒä¸€ç•ªãŠã™ã™ã‚ã‹ï¼Ÿä»Šiphonepromax13/512GBã‚’ä½¿ã£ã¦ã„ã‚‹"
                },
                {
                    "role": "model",
                    "content": "### 1. æ·±æ˜ã‚Šè€ƒå¯Ÿï¼šãªãœã€Œæœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã€ã«è²·ã„æ›¿ãˆãŒå¿…è¦ãªã®ã‹\n\nã€Œæœ€æ–°ã®é€šè¨³æ©Ÿèƒ½ã€ã‚’ä½¿ã„ãŸã„ã¨ã„ã†è¦æœ›ã«å¯¾ã—ã€å˜ã«ç¿»è¨³ã‚¢ãƒ—ãƒªãŒå‹•ãã‹ã©ã†ã‹ã§ã¯ãªãã€**ã€Œä¼šè©±ã®é–‹å§‹é€Ÿåº¦ã€ã¨ã€Œæ–‡è„ˆç†è§£åŠ›ã€**ã®2ç‚¹ãŒæ±ºå®šçš„ãªé•ã„ã¨ãªã‚Šã¾ã™ã€‚\n\nç¾åœ¨ãŠä½¿ã„ã®iPhone 13 Pro Maxã¨ã€æœ€æ–°æ©Ÿç¨®ã«ãŠã‘ã‚‹é€šè¨³ä½“é¨“ã«ã¯ä»¥ä¸‹ã®æ§‹é€ çš„ãªã‚®ãƒ£ãƒƒãƒ—ãŒå­˜åœ¨ã—ã¾ã™ã€‚\n\n*   **AIã®é ­è„³ï¼ˆApple Intelligenceï¼‰**: æœ€æ–°ã®iOSã§ã¯ã€å˜èªã‚’ç½®ãæ›ãˆã‚‹ã ã‘ã§ãªãã€AIãŒæ–‡è„ˆã‚’ç†è§£ã—ã¦ç¿»è¨³ã—ãŸã‚Šã€é€šè©±å†…å®¹ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§éŒ²éŸ³ãƒ»ç¿»è¨³ãƒ»è¦ç´„ã™ã‚‹æ©Ÿèƒ½ãŒè¿½åŠ ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã¯é«˜åº¦ãªå‡¦ç†èƒ½åŠ›ã‚’æŒã¤ãƒãƒƒãƒ—ï¼ˆA17 Proä»¥é™ï¼‰ãŒå¿…é ˆã§ã‚ã‚Šã€iPhone 13 Pro Maxã®ãƒãƒƒãƒ—ï¼ˆA15ï¼‰ã§ã¯å‹•ä½œã—ã¾ã›ã‚“ã€‚\n*   **ç‰©ç†çš„ãªå³å¿œæ€§ï¼ˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³ãƒ»ã‚«ãƒ¡ãƒ©ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ï¼‰**: \n    *   **è´è¦šçš„ç¿»è¨³**: ãƒã‚±ãƒƒãƒˆã‹ã‚‰å–ã‚Šå‡ºã—ãªãŒã‚‰ãƒœã‚¿ãƒ³ã‚’é•·æŠ¼ã—ã™ã‚‹ã ã‘ã§ç¿»è¨³ãƒ¢ãƒ¼ãƒ‰ã«å…¥ã‚‹ï¼ˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³ï¼‰ã€‚\n    *   **è¦–è¦šçš„ç¿»è¨³**: è¡—ä¸­ã®çœ‹æ¿ã‚„ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã«ã‚«ãƒ¡ãƒ©ã‚’å‘ã‘ã‚‹ã ã‘ã§ã€ãƒœã‚¿ãƒ³æ“ä½œä¸€ã¤ã§ç¿»è¨³ãƒ»æƒ…å ±æ¤œç´¢ã‚’è¡Œã†ï¼ˆVisual Intelligenceï¼‰ã€‚\n    *   ã“ã‚Œã‚‰ã¯ã‚¢ãƒ—ãƒªã‚’æ¢ã—ã¦ã‚¿ãƒƒãƒ—ã™ã‚‹æ‰‹é–“ã‚’çœãã€ä¼šè©±ã®ãƒ†ãƒ³ãƒã‚’æãªã‚ãªã„ãŸã‚ã«é‡è¦ã§ã™ãŒã€13 Pro Maxã«ã¯ã“ã‚Œã‚‰ã®ç‰©ç†ãƒœã‚¿ãƒ³ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚\n\nã—ãŸãŒã£ã¦ã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ï¼ˆAIï¼‰ã¨ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ï¼ˆå°‚ç”¨ãƒœã‚¿ãƒ³ï¼‰ã®ä¸¡é¢ã§ã€Œæœ€æ–°ã€ã‚’äº«å—ã™ã‚‹ã«ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®é¸å®šãŒéå¸¸ã«é‡è¦ã«ãªã‚Šã¾ã™ã€‚\n\n---\n\n### 2. çµè«–\n\n**æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ï¼šiPhone 16 Pro Maxï¼ˆ512GBä»¥ä¸Šï¼‰**\n\nç¾åœ¨iPhone 13 Pro Maxã‚’ãŠä½¿ã„ã®ã‚ãªãŸã«ã¨ã£ã¦ã€ç”»é¢ã‚µã‚¤ã‚ºã‚„ãƒãƒƒãƒ†ãƒªãƒ¼æŒã¡ã®åˆ©ä¾¿æ€§ã‚’æãªã‚ãšã€ã‹ã¤ã€ŒApple Intelligenceã€ã€Œã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³ã€ã€Œã‚«ãƒ¡ãƒ©ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ï¼ˆVisual Intelligenceï¼‰ã€ã¨ã„ã†**3ã¤ã®æœ€æ–°é€šè¨³è¦ç´ ã‚’ã™ã¹ã¦ç¶²ç¾…ã—ã¦ã„ã‚‹å”¯ä¸€ã®é¸æŠè‚¢**ã§ã™ã€‚\n\n---\n\n### 3. ç¾åœ¨ã®çŠ¶æ³ï¼šiPhone 13 Pro Maxã¨ã®æ±ºå®šçš„ãªå·®\n\nç¾åœ¨ãŠä½¿ã„ã®ãƒ¢ãƒ‡ãƒ«ã¨æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€é€šè¨³ãƒ»ç¿»è¨³ä½“é¨“ã«ãŠã„ã¦ä»¥ä¸‹ã®å…·ä½“çš„ãªå·®ãŒç”Ÿã˜ã¾ã™ã€‚\n\n| æ©Ÿèƒ½ | iPhone 13 Pro Max (ç¾åœ¨) | iPhone 16 Pro Max (æ¨å¥¨) | ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ã®é•ã„ |\n| :--- | :--- | :--- | :--- |\n| **å¯¾é¢é€šè¨³ã®èµ·å‹•** | ç”»é¢ãƒ­ãƒƒã‚¯è§£é™¤ â†’ ã‚¢ãƒ—ãƒªã‚’æ¢ã—ã¦èµ·å‹• | **ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³é•·æŠ¼ã—** | ãƒ­ãƒƒã‚¯è§£é™¤ä¸è¦ã§ã€ç›¸æ‰‹ã‚’å¾…ãŸã›ãšã«å³åº§ã«ç¿»è¨³ã‚’é–‹å§‹ã§ãã¾ã™ã€‚ |\n| **çœ‹æ¿ãƒ»ãƒ¡ãƒ‹ãƒ¥ãƒ¼ç¿»è¨³** | ã‚«ãƒ¡ãƒ©ã‚¢ãƒ—ãƒªèµ·å‹• â†’ ç¿»è¨³ãƒ¢ãƒ¼ãƒ‰é¸æŠ | **ã‚«ãƒ¡ãƒ©ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒœã‚¿ãƒ³** | å´é¢ã®ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ã‹ã–ã™ã ã‘ã§ã€AIãŒåº—åã‚„ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’èªè­˜ãƒ»ç¿»è¨³ã—ã¾ã™ï¼ˆVisual Intelligenceï¼‰ã€‚ |\n| **é€šè©±ãƒ»éŸ³å£°ãƒ¡ãƒ¢** | å¤–éƒ¨ã‚¢ãƒ—ãƒªãŒå¿…è¦ | **æ¨™æº–å¯¾å¿œ (Apple Intelligence)** | é€šè©±å†…å®¹ã‚’éŒ²éŸ³ã—ã€è‡ªå‹•ã§æ–‡å­—èµ·ã“ã—ãƒ»ç¿»è¨³ãƒ»è¦ç´„ã¾ã§å®Œäº†ã—ã¾ã™ã€‚ |\n| **å‡¦ç†ãƒãƒƒãƒ—** | A15 Bionic | **A18 Pro** | ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ç¿»è¨³ã®é€Ÿåº¦ã¨ç²¾åº¦ã€AIå‡¦ç†ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒåœ§å€’çš„ã«é«˜é€Ÿã§ã™ã€‚ |\n\n---\n\n### 4. 2å¹´å¾Œã®ã‚·ãƒŠãƒªã‚ªåˆ†è§£\n\nè³¼å…¥å¾Œ2å¹´é–“ï¼ˆ2025å¹´ã€œ2027å¹´ï¼‰ã‚’è¦‹æ®ãˆãŸå ´åˆã€é€šè¨³æ©Ÿèƒ½ã¯ã©ã†é€²åŒ–ã—ã€ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ã©ã†å½¹ç«‹ã¤ã‹äºˆæ¸¬ã—ã¾ã™ã€‚\n\n*   **ãƒ™ãƒ¼ã‚¹ã‚·ãƒŠãƒªã‚ªï¼ˆé«˜ç¢ºç‡ï¼‰**\n    *   iOSã®ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã«ã‚ˆã‚Šã€Apple Intelligenceã®æ—¥æœ¬èªå¯¾å¿œç²¾åº¦ãŒã•ã‚‰ã«å‘ä¸Šã€‚\n    *   ãƒ­ãƒ¼ã‚«ãƒ«ï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³ï¼‰ã§ã®ç¿»è¨³èƒ½åŠ›ãŒå¼·åŒ–ã•ã‚Œã€æµ·å¤–æ—…è¡Œæ™‚ã®é€šä¿¡åœå¤–ã§ã‚‚A18 Proãƒãƒƒãƒ—ã®ãƒ‘ãƒ¯ãƒ¼ã§é«˜é€Ÿãªé€šè¨³ãŒå¯èƒ½ã«ãªã‚‹ã€‚\n*   **å¼·æ°—ã‚·ãƒŠãƒªã‚ªï¼ˆæœŸå¾…å€¤ï¼‰**\n    *   ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£è£½ã‚¢ãƒ—ãƒªï¼ˆZoomã‚„Teamsãªã©ï¼‰ã§ã‚‚ã€iPhoneæœ¬ä½“ã®AIãƒãƒƒãƒ—ã‚’æ´»ç”¨ã—ãŸãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åŒæ™‚é€šè¨³æ©Ÿèƒ½ãŒè§£æ”¾ã•ã‚Œã‚‹ã€‚\n    *   ã€Œè‡ªåˆ†ã®å£°ã‚’ä»–è¨€èªã«å¤‰æ›ã—ã¦ç™ºè©±ã•ã›ã‚‹ã€æ©Ÿèƒ½ï¼ˆãƒ‘ãƒ¼ã‚½ãƒŠãƒ«ãƒœã‚¤ã‚¹ç¿»è¨³ï¼‰ã®å®Ÿç”¨åŒ–ãŒé€²ã¿ã€ãƒ“ã‚¸ãƒã‚¹ã‚·ãƒ¼ãƒ³ã§ã®åˆ©ç”¨ä¾¡å€¤ãŒé£›èºçš„ã«é«˜ã¾ã‚‹ã€‚\n*   **å¼±æ°—ã‚·ãƒŠãƒªã‚ªï¼ˆãƒªã‚¹ã‚¯ï¼‰**\n    *   é«˜åº¦ãªAIæ©Ÿèƒ½ã®ä¸€éƒ¨ãŒã‚¯ãƒ©ã‚¦ãƒ‰å‡¦ç†ä¾å­˜ã¨ãªã‚Šã€é€šä¿¡ç’°å¢ƒãŒæ‚ªã„å ´æ‰€ã§ã¯ã€Œæœ€æ–°æ©Ÿèƒ½ã€ã®æ©æµãŒè–„ã‚Œã‚‹ï¼ˆãŸã ã—ã€åŸºæœ¬çš„ãªç¿»è¨³ã¯ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹ã§å‹•ä½œï¼‰ã€‚\n\n---\n\n### 5. ä¸»ãªãƒ—ãƒ©ã‚¹è¦å› ãƒ»ãƒã‚¤ãƒŠã‚¹è¦å› \n\n**ãƒ—ãƒ©ã‚¹è¦å› **\n*   **ç”»é¢ã‚µã‚¤ã‚º**: 13 Pro Max (6.7ã‚¤ãƒ³ãƒ) ã‹ã‚‰ 16 Pro Max (6.9ã‚¤ãƒ³ãƒ) ã¸ã‚ãšã‹ã«å¤§å‹åŒ–ã—ã¦ãŠã‚Šã€ç¿»è¨³çµæœã®ãƒ†ã‚­ã‚¹ãƒˆã‚„ã€ã‚«ãƒ¡ãƒ©ç¿»è¨³æ™‚ã®è¦–èªæ€§ãŒå‘ä¸Šã—ã¦ã„ã¾ã™ã€‚\n*   **ãƒã‚¤ã‚¯æ€§èƒ½**: éŸ³å£°èªè­˜ã®ç²¾åº¦ã«ç›´çµã™ã‚‹ãƒã‚¤ã‚¯æ€§èƒ½ã¨ãƒã‚¤ã‚ºã‚­ãƒ£ãƒ³ã‚»ãƒªãƒ³ã‚°å‡¦ç†ãŒé€²åŒ–ã—ã¦ãŠã‚Šã€é¨’ãŒã—ã„è¡—ä¸­ã§ã®é€šè¨³ç²¾åº¦ãŒä¸ŠãŒã‚Šã¾ã™ã€‚\n*   **ãƒãƒƒãƒ†ãƒªãƒ¼**: AIå‡¦ç†ã¯é›»åŠ›ã‚’æ¶ˆè²»ã—ã¾ã™ãŒã€16 Pro Maxã¯iPhoneå²ä¸Šæœ€é•·ã®ãƒãƒƒãƒ†ãƒªãƒ¼é§†å‹•æ™‚é–“ã‚’èª‡ã‚Šã€é•·æ™‚é–“ã®é€šè¨³åˆ©ç”¨ã«è€ãˆã‚‰ã‚Œã¾ã™ã€‚\n\n**ãƒã‚¤ãƒŠã‚¹è¦å› **\n*   **ã‚µã‚¤ã‚ºã¨é‡é‡**: ç”»é¢ãŒå¤§ãããªã£ãŸåˆ†ã€ç‰‡æ‰‹ã§ã®æ“ä½œæ„Ÿï¼ˆç‰¹ã«ã‚«ãƒ¡ãƒ©ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒœã‚¿ãƒ³ã®ä½ç½®ï¼‰ã«æ…£ã‚ŒãŒå¿…è¦ãªå ´åˆãŒã‚ã‚Šã¾ã™ã€‚\n*   **ã‚³ã‚¹ãƒˆ**: é«˜æ€§èƒ½åŒ–ã«ä¼´ã„ç«¯æœ«ä¾¡æ ¼ãŒé«˜é¡ã§ã™ã€‚ãŸã ã—ã€13 Pro Maxã®ä¸‹å–ã‚Šä¾¡æ ¼ã¯ã¾ã æ¯”è¼ƒçš„é«˜å€¤ãŒæœŸå¾…ã§ãã¾ã™ã€‚\n\n---\n\n### 6. ã“ã®äºˆæ¸¬ã‚’ã©ã†ä½¿ã†ã¹ãã‹\n\n*   **ã€Œé€šè¨³ã€ã‚’é‡è¦–ã™ã‚‹ãªã‚‰å³è²·ã„æ›¿ãˆ**:\n    æµ·å¤–å‡ºå¼µã€æ—…è¡Œã€èªå­¦å­¦ç¿’ãªã©ã§ã€Œã‚¹ãƒ ãƒ¼ã‚ºãªä¼šè©±ã€ã‚’æœ€å„ªå…ˆã™ã‚‹ãªã‚‰ã€**iPhone 16 Pro Max**ã¸ã®è²·ã„æ›¿ãˆã¯æŠ•è³‡å¯¾åŠ¹æœãŒé«˜ã„ã§ã™ã€‚ç‰¹ã«ã€Œã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³ã€ã¨ã€Œã‚«ãƒ¡ãƒ©ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã€ã«ã‚ˆã‚‹ç‰©ç†çš„ãªã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆã¯ã€ä¸€åº¦ä½¿ã†ã¨æˆ»ã‚Œãªã„åˆ©ä¾¿æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n*   **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®é¸æŠ**:\n    ç¾åœ¨512GBã‚’ãŠä½¿ã„ã¨ã®ã“ã¨ã§ã™ãŒã€ä»Šå¾ŒAIãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜ã‚„ã€ç¿»è¨³å±¥æ­´ãƒ»éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®è“„ç©ãŒå¢—ãˆã‚‹ã“ã¨ã‚’è€ƒæ…®ã™ã‚‹ã¨ã€**ä»Šå›ã‚‚512GBã€ã‚ã‚‹ã„ã¯1TB**ã‚’é¸æŠã™ã‚‹ã“ã¨ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚å®¹é‡ä¸è¶³ã§AIæ©Ÿèƒ½ãŒåˆ¶é™ã•ã‚Œã‚‹ãƒªã‚¹ã‚¯ã‚’æ’é™¤ã™ã‚‹ãŸã‚ã§ã™ã€‚\n*   **15 Pro Maxã¯é¿ã‘ã‚‹ã¹ã**:\n    ä¸­å¤ã®iPhone 15 Pro Maxã‚‚AIå¯¾å¿œã§ã™ãŒã€ã€Œã‚«ãƒ¡ãƒ©ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ï¼ˆVisual Intelligenceï¼‰ã€ãŒéæ­è¼‰ã§ã™ã€‚è¦–è¦šçš„ãªç¿»è¨³æ©Ÿèƒ½ã‚’é‡è¦–ã™ã‚‹ãªã‚‰ã€16ã‚·ãƒªãƒ¼ã‚ºã‚’é¸ã¶ã¹ãã§ã™ã€‚"
                }
            ]
        },
        {
            "id": "b52f4f61-03ff-40db-b186-792b6a4de483",
            "title": "è‡ªä½œgeminiã‚³ãƒ¼ãƒ‰ã¨ã—ã¦ã¯ã“ã‚Œã§ãƒ™ã‚¹...",
            "timestamp": "2025-11-29T22:48:11.327134",
            "messages": [
                {
                    "role": "user",
                    "content": "è‡ªä½œgeminiã‚³ãƒ¼ãƒ‰ã¨ã—ã¦ã¯ã“ã‚Œã§ãƒ™ã‚¹ãƒˆã‹ï¼Ÿ\n\nã“ã‚Œã§ãƒ™ã‚¹ãƒˆã‹?\n\nimport os\nimport json\nimport re\nimport uuid\nimport datetime\nimport streamlit as st\nfrom dotenv import load_dotenv\nfrom google import genai\nfrom google.genai import types\nfrom youtube_transcript_api import YouTubeTranscriptApi\nfrom PIL import Image\nimport io\n\ntry:\n    from st_img_pastebutton import paste\n    import_error_msg = None\nexcept ImportError as e:\n    paste = None\n    import_error_msg = str(e)\n\n# =========================\n# ç’°å¢ƒå¤‰æ•° & å®šæ•°\n# =========================\n\nload_dotenv()\n\nUSAGE_FILE = \"usage_stats.json\"\nSESSIONS_FILE = \"chat_sessions.json\"\nMAX_BUDGET_USD = float(os.getenv(\"MAX_BUDGET_USD\", \"5.0\"))\n\n# â€»é‡‘é¡ã¯ã ã„ãŸã„ã®ç›®å®‰ï¼ˆUSD / 1M tokensï¼‰\nPRICING = {\n    \"gemini-3-pro-preview\":   {\"input\": 2.0,   \"output\": 12.0},\n    \"gemini-2.5-pro\":         {\"input\": 1.25,  \"output\": 10.0},\n    \"gemini-2.5-flash\":       {\"input\": 0.30,  \"output\": 2.50},\n    \"gemini-2.5-flash-lite\":  {\"input\": 0.10,  \"output\": 0.40},\n    \"gemini-2.0-flash\":       {\"input\": 0.10,  \"output\": 0.40},\n}\n\n# Vertex AI ç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®šï¼ˆ**å¸¸ã« Vertex ã‚’ä½¿ã†**ï¼‰\nVERTEX_PROJECT = os.getenv(\"GOOGLE_CLOUD_PROJECT\")\nVERTEX_LOCATION = \"global\"  # Gemini 2.x / 3 ã¯ global æ¨å¥¨\n\nst.set_page_config(page_title=\"Gemini 3 Web Studio\", layout=\"wide\")\n\n# =========================\n# Helper Functions\n# =========================\n\ndef load_usage():\n    if os.path.exists(USAGE_FILE):\n        with open(USAGE_FILE, \"r\") as f:\n            return json.load(f)\n    return {\"total_input_tokens\": 0, \"total_output_tokens\": 0, \"total_cost_usd\": 0.0}\n\ndef save_usage(stats):\n    with open(USAGE_FILE, \"w\") as f:\n        json.dump(stats, f, indent=4)\n\ndef calculate_cost(model_id, input_tok, output_tok):\n    price = PRICING.get(model_id, {\"input\": 0.0, \"output\": 0.0})\n    cost = (input_tok / 1_000_000 * price[\"input\"]) + (output_tok / 1_000_000 * price[\"output\"])\n    return cost\n\ndef get_mime_type(filename):\n    ext = filename.split('.')[-1].lower()\n    if ext in ['jpg', 'jpeg']:\n        return 'image/jpeg'\n    if ext == 'png':\n        return 'image/png'\n    if ext == 'mp4':\n        return 'video/mp4'\n    if ext == 'mov':\n        return 'video/quicktime'\n    if ext == 'txt':\n        return 'text/plain'\n    if ext == 'pdf':\n        return 'application/pdf'\n    if ext == 'csv':\n        return 'text/csv'\n    return 'application/octet-stream'\n\ndef extract_youtube_id(url):\n    regex = r\"(?:v=|\\/)([0-9A-Za-z_-]{11}).*\"\n    match = re.search(regex, url)\n    if match:\n        return match.group(1)\n    return None\n\ndef get_youtube_transcript(video_id):\n    try:\n        transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['ja', 'en'])\n        text = \" \".join([t['text'] for t in transcript_list])\n        return text\n    except Exception as e:\n        return f\"å­—å¹•ã®å–å¾—ã‚¨ãƒ©ãƒ¼: {e}\"\n\ndef get_relevant_context(query):\n    \"\"\"éå»ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ç°¡æ˜“æ¤œç´¢ã—ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™\"\"\"\n    if not query:\n        return \"\"\n    keywords = [k for k in query.split() if len(k) > 1]\n    if not keywords:\n        return \"\"\n\n    relevant_sessions = []\n    for session in st.session_state.sessions:\n        if session[\"id\"] == st.session_state.current_session_id:\n            continue\n        score = 0\n        for k in keywords:\n            if k.lower() in session[\"title\"].lower():\n                score += 3\n        for msg in session[\"messages\"][-4:]:\n            for k in keywords:\n                if k.lower() in msg[\"content\"].lower():\n                    score += 1\n        if score > 0:\n            relevant_sessions.append((score, session))\n\n    relevant_sessions.sort(key=lambda x: (x[0], x[1][\"timestamp\"]), reverse=True)\n    top_sessions = relevant_sessions[:3]\n\n    context_str = \"\"\n    if top_sessions:\n        context_str += \"### éå»ã®é–¢é€£ãƒãƒ£ãƒƒãƒˆå±¥æ­´ (Context)\\n\"\n        for score, session in top_sessions:\n            last_response = \"N/A\"\n            for m in reversed(session[\"messages\"]):\n                if m[\"role\"] == \"model\":\n                    last_response = m[\"content\"][:300] + \"...\"\n                    break\n            context_str += f\"- **Session: {session['title']}** ({session['timestamp'][:10]})\\n\"\n            context_str += f\"  Last Conclusion: {last_response}\\n\\n\"\n    return context_str\n\ndef extract_text_from_response(response):\n    \"\"\"Extract text from GenerateContentResponse\"\"\"\n    if not response.candidates:\n        return \"\"\n    parts = response.candidates[0].content.parts or []\n    return \"\".join(p.text or \"\" for p in parts)\n\n# =========================\n# Session Management\n# =========================\n\ndef load_sessions():\n    if os.path.exists(SESSIONS_FILE):\n        with open(SESSIONS_FILE, \"r\") as f:\n            try:\n                data = json.load(f)\n                return data.get(\"sessions\", [])\n            except json.JSONDecodeError:\n                return []\n    return []\n\ndef save_sessions(sessions):\n    with open(SESSIONS_FILE, \"w\") as f:\n        json.dump({\"sessions\": sessions}, f, indent=4, ensure_ascii=False)\n\ndef create_new_session():\n    current_sessions = load_sessions()\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": [],\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.rerun()\n\ndef switch_session(session_id):\n    st.session_state.current_session_id = session_id\n    st.rerun()\n\ndef update_current_session_messages(messages):\n    if st.session_state.current_session_id:\n        current_sessions = load_sessions()\n        for session in current_sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                session[\"messages\"] = messages\n                if session[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(messages) > 0:\n                    first_msg = messages[0][\"content\"]\n                    session[\"title\"] = (first_msg[:20] + \"...\") if len(first_msg) > 20 else first_msg\n                session[\"timestamp\"] = datetime.datetime.now().isoformat()\n                break\n        save_sessions(current_sessions)\n        st.session_state.sessions = current_sessions\n\ndef get_current_messages():\n    if st.session_state.current_session_id:\n        for session in st.session_state.sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                return session[\"messages\"]\n    return []\n\ndef delete_session(session_id):\n    current_sessions = load_sessions()\n    current_sessions = [s for s in current_sessions if s[\"id\"] != session_id]\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    if st.session_state.current_session_id == session_id:\n        st.session_state.current_session_id = None\n        if st.session_state.sessions:\n            st.session_state.current_session_id = st.session_state.sessions[0][\"id\"]\n    st.rerun()\n\ndef branch_session():\n    \"\"\"ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚’åˆ†å²\"\"\"\n    current_messages = get_current_messages()\n    current_sessions = load_sessions()\n    \n    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—\n    current_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n    for session in current_sessions:\n        if session[\"id\"] == st.session_state.current_session_id:\n            current_title = session[\"title\"]\n            break\n    \n    # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": f\"{current_title} (åˆ†å²)\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": current_messages.copy(),  # ç¾åœ¨ã®å±¥æ­´ã‚’ã‚³ãƒ”ãƒ¼\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    \n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.session_state.session_cost = 0.0  # ã‚³ã‚¹ãƒˆãƒªã‚»ãƒƒãƒˆ\n    st.rerun()\n\n# =========================\n# Initialization\n# =========================\n\nif \"sessions\" not in st.session_state:\n    st.session_state.sessions = load_sessions()\n\nif \"current_session_id\" not in st.session_state:\n    # Always create a new session when the app starts\n    create_new_session()\n\nif \"session_cost\" not in st.session_state:\n    st.session_state.session_cost = 0.0\n\nusage_stats = load_usage()\n\n# =========================\n# Sidebar\n# =========================\n\nwith st.sidebar:\n    st.title(\"Gemini 3 Studio\")\n\n    if st.button(\"â• æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\", use_container_width=True):\n        create_new_session()\n\n    if st.button(\"ğŸŒ± ç¾åœ¨ã®ãƒãƒ£ãƒƒãƒˆã‹ã‚‰åˆ†å²\", use_container_width=True):\n        branch_session()\n\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    current_messages = get_current_messages()\n    if current_messages:\n        export_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n        for s in st.session_state.sessions:\n            if s[\"id\"] == st.session_state.current_session_id:\n                export_title = s[\"title\"]\n                break\n\n        export_md = f\"# {export_title}\\n\\n\"\n        export_md += f\"**ä½œæˆæ—¥æ™‚**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n---\\n\\n\"\n        for msg in current_messages:\n            role_label = \"ğŸ§‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼\" if msg[\"role\"] == \"user\" else \"ğŸ¤– AI\"\n            export_md += f\"## {role_label}\\n\\n{msg['content']}\\n\\n---\\n\\n\"\n\n        if st.button(\"ğŸ”— å¤–éƒ¨å…±æœ‰ãƒªãƒ³ã‚¯ã‚’ä½œæˆ\", use_container_width=True):\n            with st.spinner(\"ãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆä¸­...\"):\n                try:\n                    import urllib.request\n                    import urllib.parse\n\n                    data = urllib.parse.urlencode(\n                        {\"content\": export_md, \"expiry_days\": 7, \"syntax\": \"md\"}\n                    ).encode()\n\n                    req = urllib.request.Request(\"https://dpaste.org/api/\", data=data)\n                    req.add_header(\"User-Agent\", \"Mozilla/5.0 (Gemini3Studio)\")\n\n                    with urllib.request.urlopen(req) as response:\n                        share_url = response.read().decode(\"utf-8\").strip()\n                        st.success(\"ãƒªãƒ³ã‚¯ã‚’ä½œæˆã—ã¾ã—ãŸï¼\")\n                        st.code(share_url)\n                        st.caption(\"â€»ãƒªãƒ³ã‚¯ã¯7æ—¥é–“æœ‰åŠ¹ã§ã™\")\n                except Exception as e:\n                    st.error(f\"ãƒªãƒ³ã‚¯ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}\")\n\n    st.markdown(\"---\")\n\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    st.subheader(\"æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«\")\n    uploaded_files = st.file_uploader(\n        \"ç”»åƒã€å‹•ç”»ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\",\n        accept_multiple_files=True,\n        type=[\"png\", \"jpg\", \"jpeg\", \"mp4\", \"mov\", \"txt\", \"pdf\", \"csv\"],\n        help=\"Limit 2GB per file\",\n    )\n\n    pasted_image_bytes = None\n    if paste:\n        if \"paste_key\" not in st.session_state:\n            st.session_state.paste_key = 0\n        try:\n            pasted_image_bytes = paste(\n                label=\"ğŸ“‹ ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã‹ã‚‰ç”»åƒã‚’è²¼ã‚Šä»˜ã‘\",\n                key=f\"paste_btn_{st.session_state.paste_key}\",\n            )\n        except Exception as e:\n            st.error(f\"Clipboard button error: {e}\")\n        \n        if pasted_image_bytes:\n            st.success(\"ç”»åƒãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚Œã¾ã—ãŸï¼\")\n            st.image(pasted_image_bytes, caption=\"è²¼ã‚Šä»˜ã‘ãŸç”»åƒ\", use_container_width=True)\n            if st.button(\"ğŸ—‘ï¸ ç”»åƒã‚’ã‚¯ãƒªã‚¢\", key=\"clear_paste\"):\n                st.session_state.paste_key += 1\n                st.rerun()\n    else:\n        st.warning(\"Clipboard library not loaded (ImportError)\")\n\n    # ---- YouTube URL ----\n    st.markdown(\"---\")\n    youtube_url = st.text_input(\"YouTube URL (å­—å¹•ã‚’åˆ†æ)\", placeholder=\"https://youtu.be/...\")\n\n    # ---- ç”»åƒç”Ÿæˆ ----\n    st.markdown(\"---\")\n    st.subheader(\"ğŸ¨ ç”»åƒç”Ÿæˆ\")\n    img_prompt = st.text_area(\"ç”Ÿæˆã—ãŸã„ç”»åƒã®èª¬æ˜\", placeholder=\"æœªæ¥çš„ãªéƒ½å¸‚ã®é¢¨æ™¯...\")\n    aspect_ratio = st.selectbox(\"ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”\", [\"16:9\", \"1:1\", \"4:3\", \"3:4\", \"9:16\"])\n\n    generate_img_btn = st.button(\"ç”»åƒã‚’ç”Ÿæˆ\", type=\"primary\", disabled=not img_prompt)\n    if generate_img_btn and img_prompt:\n        st.session_state.generate_image_trigger = {\n            \"prompt\": img_prompt,\n            \"aspect_ratio\": aspect_ratio,\n        }\n\n    st.markdown(\"---\")\n\n    # ---- å±¥æ­´æ¤œç´¢ ----\n    search_query = st.text_input(\"ğŸ” å±¥æ­´ã‚’æ¤œç´¢\", placeholder=\"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰...\")\n    if search_query:\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if search_query.lower() in s[\"title\"].lower():\n                filtered_sessions.append(s)\n                continue\n            found = False\n            for m in s[\"messages\"]:\n                if search_query.lower() in m[\"content\"].lower():\n                    filtered_sessions.append(s)\n                    found = True\n                    break\n            if not found:\n                pass\n    else:\n        filtered_sessions = st.session_state.sessions\n\n    with st.expander(\"ğŸ“œ éå»ã®ãƒãƒ£ãƒƒãƒˆ\", expanded=bool(search_query)):\n        if not filtered_sessions:\n            st.caption(\"ãƒãƒ£ãƒƒãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n        for session in filtered_sessions:\n            col1, col2 = st.columns([0.8, 0.2])\n            with col1:\n                if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                    switch_session(session[\"id\"])\n            with col2:\n                if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                    delete_session(session[\"id\"])\n\n    st.markdown(\"---\")\n    st.title(\"è¨­å®š\")\n\n    # ---- ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆGemini 1.5 ã¯å»ƒæ­¢ã•ã‚Œã¦ã„ã‚‹ã®ã§å«ã‚ãªã„ï¼‰ ----\n    model_options = [\n        \"gemini-3-pro-preview\",\n        \"gemini-2.5-pro\",\n        \"gemini-2.5-flash\",\n        \"gemini-2.5-flash-lite\",\n        \"gemini-2.0-flash\",\n    ]\n    model_id = st.selectbox(\"ãƒ¢ãƒ‡ãƒ«ID\", options=model_options, index=0)\n\n    if \"3-pro\" in model_id or \"2.5-pro\" in model_id:\n        st.caption(\"ğŸ§  é«˜åº¦ãªæ¨è«–å‘ã‘ Pro ãƒ¢ãƒ‡ãƒ«\")\n    if \"flash\" in model_id:\n        st.caption(\"âš¡ é«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆãª Flash ç³»ãƒ¢ãƒ‡ãƒ«\")\n\n    # ---- æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚° ----\n    use_search = st.toggle(\"Googleæ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã‚’ä½¿ç”¨\", value=True)\n    candidate_count = st.slider(\"å›ç­”å€™è£œæ•°\", min_value=1, max_value=3, value=3)\n    if use_search and candidate_count > 1:\n        st.caption(\"âš ï¸ æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ä½¿ç”¨æ™‚ã¯å€™è£œæ•°ãŒ1ã«ãªã‚Šã¾ã™ã€‚\")\n\n    st.markdown(\"---\")\n\n    # ---- å›ç­”ãƒ¢ãƒ¼ãƒ‰ ----\n    response_mode = st.radio(\n        \"å›ç­”ãƒ¢ãƒ¼ãƒ‰\",\n        [\n            \"é€šå¸¸ (é«˜é€Ÿ)\",\n            \"ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n            \"ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n            \"ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n            \"ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n        ],\n        index=0\n    )\n    strict_mode = False # äº’æ›æ€§ç¶­æŒã®ãŸã‚ã®ãƒ€ãƒŸãƒ¼å¤‰æ•°\n    st.markdown(\"---\")\n\n    # ---- è©•ä¾¡åˆ†æ ----\n    st.subheader(\"ğŸ“Š å›ç­”å“è³ªåˆ†æ\")\n    total_ratings = 0\n    positive_ratings = 0\n    model_ratings = {}\n\n    for s in st.session_state.sessions:\n        for m in s[\"messages\"]:\n            if \"rating\" in m and m[\"rating\"] is not None:\n                total_ratings += 1\n                if m[\"rating\"] == 1:\n                    positive_ratings += 1\n                if \"metadata\" in m and \"model\" in m[\"metadata\"]:\n                    mod = m[\"metadata\"][\"model\"]\n                    if mod not in model_ratings:\n                        model_ratings[mod] = {\"total\": 0, \"positive\": 0}\n                    model_ratings[mod][\"total\"] += 1\n                    if m[\"rating\"] == 1:\n                        model_ratings[mod][\"positive\"] += 1\n\n    if total_ratings > 0:\n        approval_rate = (positive_ratings / total_ratings) * 100\n        st.metric(\"Positive Ratings\", f\"{positive_ratings}/{total_ratings}\", f\"{approval_rate:.1f}%\")\n        best_model = \"N/A\"\n        best_rate = -1\n        for mod, stats in model_ratings.items():\n            rate = stats[\"positive\"] / stats[\"total\"]\n            if rate > best_rate:\n                best_rate = rate\n                best_model = mod\n        if best_model != \"N/A\":\n            st.caption(f\"ğŸ† Best Model: **{best_model}** ({best_rate*100:.0f}%)\")\n    else:\n        st.caption(\"ã¾ã è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\")\n\n    st.markdown(\"---\")\n\n    # ---- ã‚³ã‚¹ãƒˆè¡¨ç¤º ----\n    st.subheader(\"ğŸ’° ã‚³ã‚¹ãƒˆ (æ¦‚ç®—)\")\n    st.metric(\"Total Cost\", f\"${usage_stats['total_cost_usd']:.4f}\")\n    if st.session_state.session_cost > 0:\n        st.caption(f\"Current Session: ${st.session_state.session_cost:.4f}\")\n\n    if usage_stats[\"total_cost_usd\"] >= MAX_BUDGET_USD:\n        st.error(f\"âš ï¸ äºˆç®—ä¸Šé™ (${MAX_BUDGET_USD}) ã«é”ã—ã¾ã—ãŸã€‚\")\n        stop_generation = True\n    else:\n        stop_generation = False\n\n    st.markdown(\"---\")\n    st.code(f\"PROJECT: {VERTEX_PROJECT}\\nLOCATION: {VERTEX_LOCATION} (Vertex AI)\")\n\n# =========================\n# Main UI\n# =========================\n\ncurrent_session_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\nfor s in st.session_state.sessions:\n    if s[\"id\"] == st.session_state.current_session_id:\n        current_session_title = s[\"title\"]\n        break\n\nst.header(current_session_title)\nst.markdown(\n    \"ä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\"\n)\n\n# ---- Vertex AI Client ----\n\n@st.cache_resource\ndef get_client():\n    return genai.Client(\n        vertexai=True,\n        project=VERTEX_PROJECT,\n        location=VERTEX_LOCATION,\n    )\n\nclient = get_client()\n\n# ---- å±¥æ­´è¡¨ç¤º ----\n\nmessages = get_current_messages()\nfor idx, msg in enumerate(messages):\n    with st.chat_message(msg[\"role\"]):\n        st.markdown(msg[\"content\"])\n        if msg[\"role\"] == \"model\":\n            col1, col2, col3 = st.columns([0.1, 0.1, 0.8])\n            current_rating = msg.get(\"rating\")\n            with col1:\n                if st.button(\"ğŸ‘\", key=f\"up_{idx}\"):\n                    messages[idx][\"rating\"] = 1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col2:\n                if st.button(\"ğŸ‘\", key=f\"down_{idx}\"):\n                    messages[idx][\"rating\"] = -1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col3:\n                if current_rating == 1:\n                    st.caption(\"âœ… é«˜è©•ä¾¡\")\n                elif current_rating == -1:\n                    st.caption(\"âŒ ä½è©•ä¾¡\")\n\n# =========================\n# ç”»åƒç”Ÿæˆãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°\n# =========================\n\nif hasattr(st.session_state, \"generate_image_trigger\") and st.session_state.generate_image_trigger:\n    img_data = st.session_state.generate_image_trigger\n    del st.session_state.generate_image_trigger\n\n    with st.chat_message(\"user\"):\n        st.markdown(f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\")\n        st.caption(f\"ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”: {img_data['aspect_ratio']}\")\n\n    messages.append({\"role\": \"user\", \"content\": f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\"})\n    update_current_session_messages(messages)\n\n    with st.chat_message(\"assistant\"):\n        with st.status(\"ç”»åƒã‚’ç”Ÿæˆä¸­...\", expanded=True) as status:\n            try:\n                config = types.GenerateContentConfig(\n                    response_modalities=[\"IMAGE\"],\n                    image_config=types.ImageConfig(\n                        aspect_ratio=img_data[\"aspect_ratio\"]\n                    ),\n                )\n                status.write(\"Gemini 3 Pro Imageã§ç”Ÿæˆä¸­...\")\n                response = client.models.generate_content(\n                    model=\"gemini-3-pro-image-preview\",\n                    contents=img_data[\"prompt\"],\n                    config=config,\n                )\n\n                generated_image = None\n\n                # ç”»åƒã‚’å–ã‚Šå‡ºã™\n                if getattr(response, \"candidates\", None):\n                    for candidate in response.candidates:\n                        if getattr(candidate, \"content\", None) and candidate.content.parts:\n                            for part in candidate.content.parts:\n                                if getattr(part, \"inline_data\", None):\n                                    try:\n                                        generated_image = part.as_image()\n                                    except AttributeError:\n                                        image_bytes_raw = part.inline_data.data\n                                        generated_image = Image.open(io.BytesIO(image_bytes_raw))\n                                    break\n                        if generated_image is not None:\n                            break\n\n                if generated_image is not None:\n                    st.image(generated_image, caption=img_data[\"prompt\"])\n                    buf = io.BytesIO()\n                    generated_image.save(buf, format=\"PNG\")\n                    image_bytes = buf.getvalue()\n                    st.download_button(\n                        label=\"ğŸ’¾ ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\",\n                        data=image_bytes,\n                        file_name=f\"generated_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png\",\n                        mime=\"image/png\",\n                    )\n                    messages.append(\n                        {\"role\": \"model\", \"content\": f\"âœ… ç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {img_data['prompt']}\"}\n                    )\n                    update_current_session_messages(messages)\n                    status.update(label=\"âœ… ç”»åƒç”Ÿæˆå®Œäº†\", state=\"complete\")\n                else:\n                    st.error(\"ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")\n                    status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n\n            except Exception as e:\n                status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n                st.error(f\"ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}\")\n\n# =========================\n# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›\n# =========================\n\nprompt = st.chat_input(\"ä½•ã‹èã„ã¦ãã ã•ã„...\", disabled=stop_generation)\n\nif prompt:\n    if stop_generation:\n        st.error(\"äºˆç®—ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚\")\n    else:\n        # ---- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€è¡¨ç¤º ----\n        with st.chat_message(\"user\"):\n            st.markdown(prompt)\n            if uploaded_files:\n                for uf in uploaded_files:\n                    st.caption(f\"ğŸ“ æ·»ä»˜: {uf.name}\")\n            if youtube_url:\n                st.caption(f\"ğŸ“º YouTube: {youtube_url}\")\n            if pasted_image_bytes:\n                st.caption(\"ğŸ“‹ ç”»åƒãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚Œã¾ã—ãŸ\")\n\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        update_current_session_messages(messages)\n\n        # ---- ãƒ¢ãƒ‡ãƒ«å¿œç­” ----\n        with st.chat_message(\"assistant\"):\n            status_container = st.status(\"æ€è€ƒä¸­...\", expanded=True)\n            try:\n                # ä¼šè©±å±¥æ­´\n                model_history = []\n                for msg in messages[:-1]:\n                    model_history.append(\n                        types.Content(\n                            role=msg[\"role\"],\n                            parts=[types.Part.from_text(text=msg[\"content\"])],\n                        )\n                    )\n\n                # ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³\n                current_parts = [types.Part.from_text(text=prompt)]\n\n                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«\n                for uploaded_file in uploaded_files or []:\n                    try:\n                        mime_type = get_mime_type(uploaded_file.name)\n                        bytes_data = uploaded_file.getvalue()\n                        part = types.Part.from_bytes(data=bytes_data, mime_type=mime_type)\n                        current_parts.append(part)\n                        status_container.write(f\"ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™å®Œäº†: {uploaded_file.name}\")\n                    except Exception as e:\n                        status_container.error(\n                            f\"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {uploaded_file.name} - {e}\"\n                        )\n\n                # è²¼ã‚Šä»˜ã‘ç”»åƒ\n                if pasted_image_bytes:\n                    import base64\n\n                    status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã‚’å‡¦ç†ä¸­...\")\n                    try:\n                        if isinstance(pasted_image_bytes, str):\n                            if pasted_image_bytes.startswith(\"data:\"):\n                                base64_str = pasted_image_bytes.split(\",\", 1)[1]\n                                image_bytes_decoded = base64.b64decode(base64_str)\n                            else:\n                                image_bytes_decoded = base64.b64decode(pasted_image_bytes)\n                        else:\n                            image_bytes_decoded = pasted_image_bytes\n                        part = types.Part.from_bytes(\n                            data=image_bytes_decoded, mime_type=\"image/png\"\n                        )\n                        current_parts.append(part)\n                        status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®æº–å‚™å®Œäº†\")\n                    except Exception as e:\n                        status_container.error(f\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n\n                # YouTube å­—å¹•\n                if youtube_url:\n                    vid_id = extract_youtube_id(youtube_url)\n                    if vid_id:\n                        status_container.write(\"YouTubeã®å­—å¹•ã‚’å–å¾—ä¸­...\")\n                        transcript_text = get_youtube_transcript(vid_id)\n                        current_parts.append(\n                            types.Part.from_text(text=f\"YouTube Transcript:\\n{transcript_text}\")\n                        )\n                    else:\n                        status_container.write(\"ç„¡åŠ¹ãªYouTube URLã§ã™ã€‚\")\n\n                contents_for_model = model_history + [\n                    types.Content(role=\"user\", parts=current_parts)\n                ]\n\n                # ---- Tool / Config ----\n                tools = []\n                final_candidate_count = candidate_count\n                if use_search:\n                    tools.append(types.Tool(google_search=types.GoogleSearch()))\n                    final_candidate_count = 1\n\n                # â˜… System Instruction ã®æ”¹å–„: ãƒ¡ã‚¿ç™ºè¨€ç¦æ­¢ã¨ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªæŒ¯ã‚‹èˆã„ã‚’æŒ‡ç¤º\n                base_system_instruction = (\n                    \"ã‚ãªãŸã¯é«˜åº¦ãªçŸ¥æ€§ã‚’æŒã¤å°‚é–€çš„ãªãƒªã‚µãƒ¼ãƒãƒ»ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\\n\"\n                    \"ä»¥ä¸‹ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’å³å®ˆã—ã¦ãã ã•ã„ï¼š\\n\"\n                    \"1. **ãƒ¡ã‚¿ç™ºè¨€ã®ç¦æ­¢**: ã€Œç§ã¯AIã§ã™ã€ã€Œä¸–ç•Œæœ€é«˜å³°ã®ï½ã¨ã—ã¦ã€ãªã©ã®è‡ªå·±è¨€åŠã‚„å‰ç½®ãã¯ä¸€åˆ‡è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚\\n\"\n                    \"2. **æ„å›³ã®æ±²ã¿å–ã‚Š**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã®èƒŒå¾Œã«ã‚ã‚‹æ„å›³ï¼ˆæ–‡è„ˆã€æš—é»™ã®å‰æï¼‰ã‚’æ¨æ¸¬ã—ã€è¨€è‘‰é€šã‚Šã§ã¯ãªãã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ¬å½“ã«çŸ¥ã‚ŠãŸã„ã“ã¨ã€ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n\"\n                    \"3. **æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”**: çµè«–ã‚’å…ˆã«è¿°ã¹ã€ãã®å¾Œã«è©³ç´°ãªæ ¹æ‹ ã€ã‚·ãƒŠãƒªã‚ªåˆ†æã€ãƒªã‚¹ã‚¯è¦å› ã‚’è«–ç†çš„ã«å±•é–‹ã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"4. **å®¢è¦³æ€§**: äºˆæ¸¬ã‚’è¡Œã†å ´åˆã¯ã€æ–­å®šã‚’é¿ã‘ã€è¤‡æ•°ã®ã‚·ãƒŠãƒªã‚ªï¼ˆæ¥½è¦³ã€æ‚²è¦³ã€ä¸­ç«‹ï¼‰ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"5. **å¼•ç”¨**: æ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸå ´åˆã¯ã€å¿…ãšæƒ…å ±æºã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚\"\n                )\n\n                final_answer = \"\"\n                grounding_metadata = None\n                \n                # =========================\n                # ãƒ¢ãƒ¼ãƒ‰è¨­å®šã®è§£æ\n                # =========================\n                enable_research = True  # å…¨ãƒ¢ãƒ¼ãƒ‰ã§ãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œ\n                enable_meta = \"ãƒ¡ã‚¿\" in response_mode or \"MAX\" in response_mode\n                enable_strict = \"é¬¼è»æ›¹\" in response_mode or \"MAX\" in response_mode\n\n                # =========================\n                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (é«˜é€Ÿ / é¬¼è»æ›¹)\n                # =========================\n                if not enable_research:\n                    config = types.GenerateContentConfig(\n                        temperature=0.7,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=base_system_instruction,\n                    )\n                    \n                    status_container.write(\"å›ç­”ç”Ÿæˆä¸­...\")\n                    response = client.models.generate_content(\n                        model=model_id,\n                        contents=contents_for_model,\n                        config=config,\n                    )\n                    \n                    final_answer = extract_text_from_response(response)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®—\n                    if response.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            response.usage_metadata.prompt_token_count,\n                            response.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += response.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += response.usage_metadata.candidates_token_count\n\n                    # é¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ (é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ç‰ˆ)\n                    if enable_strict:\n                        status_container.write(\"ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        reviewer_instruction = base_system_instruction + \"\"\"\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n                        review_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\nåˆç‰ˆå›ç­”:\\n{final_answer}\\n\\nãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\")])]\n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=types.GenerateContentConfig(temperature=0.1, candidate_count=1, system_instruction=reviewer_instruction)\n                        )\n                        final_answer = extract_text_from_response(review_resp)\n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        \n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(model_id, review_resp.usage_metadata.prompt_token_count, review_resp.usage_metadata.candidates_token_count)\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n\n                # =========================\n                # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰\n                # =========================\n                else:\n                    # =========================\n                    # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰: å¤šæ®µéšã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ \n                    # =========================\n                    \n                    # --- Phase 1: ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 1: ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    research_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒªã‚µãƒ¼ãƒå°‚ä»»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚æœ€çµ‚å›ç­”ã¯æ›¸ã‹ãšã€äº‹å®Ÿåé›†ã«é›†ä¸­ã™ã‚‹ã“ã¨ã€‚\n\n**èª¿æŸ»è¦³ç‚¹**:\n- è³ªå•ã«é–¢é€£ã™ã‚‹æœ€æ–°ã®äº‹å®Ÿãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ»çµ±è¨ˆ\n- å…¬å¼æƒ…å ±ã‚„ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã‹ã‚‰ã®å¼•ç”¨\n- é–¢é€£ã™ã‚‹èƒŒæ™¯æƒ…å ±ã‚„æ–‡è„ˆ\n- ç«¶åˆãƒ»ä»£æ›¿æ¡ˆãƒ»æ¯”è¼ƒå¯¾è±¡ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n- ãƒªã‚¹ã‚¯ãƒ»åˆ¶ç´„ãƒ»æ³¨æ„ç‚¹ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n- å‚è€ƒã«ã—ãŸä¸»è¦ãªæƒ…å ±æºã®URL\n\n**é‡è¦**: \n- çµè«–ã‚„æ¨å¥¨ã¯æ›¸ã‹ãšã€å¾Œå·¥ç¨‹ãŒåˆ¤æ–­ã§ãã‚‹èª¿æŸ»ãƒ¡ãƒ¢ã«é›†ä¸­ã™ã‚‹ã“ã¨\n- æœ€æ–°ã®æƒ…å ±ã‚’å„ªå…ˆçš„ã«æ¤œç´¢ã™ã‚‹ã“ã¨\n- æ¤œç´¢çµæœã‚’å¿…ãšæ´»ç”¨ã—ã€æƒ…å ±æºã‚’æ˜è¨˜ã™ã‚‹ã“ã¨\n\"\"\"\n\n                    # éå»ã®é–¢é€£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—\n                    past_context = get_relevant_context(prompt)\n                    \n                    # ãƒªã‚µãƒ¼ãƒç”¨ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ§‹ç¯‰\n                    research_parts = [types.Part(text=f\"ã“ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š\\n{prompt}\")]\n                    \n                    if past_context:\n                        research_parts.insert(0, types.Part(text=\"ä»¥ä¸‹ã¯éå»ã®é–¢é€£ãƒãƒ£ãƒƒãƒˆã‹ã‚‰æŠ½å‡ºã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã™ï¼š\\n\\n\" + past_context))\n                    \n                    research_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=research_parts)\n                    ]\n                    \n                    research_config = types.GenerateContentConfig(\n                        temperature=0.2,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=research_instruction,\n                    )\n                    \n                    research_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=research_contents,\n                        config=research_config,\n                    )\n                    \n                    research_text = extract_text_from_response(research_resp)\n                    \n                    # ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºã®ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ±ã‚’ä¿å­˜\n                    if research_resp.candidates and research_resp.candidates[0].grounding_metadata:\n                        grounding_metadata = research_resp.candidates[0].grounding_metadata\n                    \n                    status_container.write(\"âœ“ ãƒªã‚µãƒ¼ãƒå®Œäº†\")\n                    with status_container.expander(\"åé›†ã—ãŸèª¿æŸ»ãƒ¡ãƒ¢\", expanded=False):\n                        st.markdown(research_text)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1)\n                    if research_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            research_resp.usage_metadata.prompt_token_count,\n                            research_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += research_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += research_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 1.5: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    questions_text = \"\"\n                    if enable_meta:\n                        status_container.write(\"Phase 1.5: ãƒ¡ã‚¿è³ªå•ç”Ÿæˆä¸­...\")\n                        \n                        question_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ç›®çš„**: \nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•ã¨èª¿æŸ»ãƒ¡ãƒ¢ã‚’è¸ã¾ãˆã¦ã€ã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±ãç†è§£ã™ã‚‹ãŸã‚ã®ã€Œé‹­ã„ã‚µãƒ–è³ªå•ã€ã‚’ä½œæˆã™ã‚‹ã“ã¨ã€‚\n\n**ãƒ«ãƒ¼ãƒ«**:\n- æœ€å¤§5å€‹ã¾ã§\n- å„è³ªå•ã¯1-2è¡Œã§å…·ä½“çš„ã‹ã¤é‹­ã\n- ä»¥ä¸‹ã®è¦³ç‚¹ã‚’æ„è­˜:\n  1. å‰æãŒå´©ã‚Œã‚‹å¯èƒ½æ€§ã¯ã©ã“ã‹ï¼Ÿ\n  2. å¼·æ°—/å¼±æ°—ã‚·ãƒŠãƒªã‚ªã®åˆ†å²ç‚¹ã¯ä½•ã‹ï¼Ÿ\n  3. ç«¶åˆãƒ»æŠ€è¡“ãƒ»è¦åˆ¶ã®ä¸ç¢ºå®Ÿæ€§ã¯ï¼Ÿ\n  4. ã€Œäºˆæ¸¬ãŒå¤–ã‚Œã‚‹ã¨ã—ãŸã‚‰ã©ã‚“ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ï¼Ÿã€\n\n**å‡ºåŠ›**: ç®‡æ¡æ›¸ãï¼ˆQ1, Q2...ï¼‰ã®ã¿\n\"\"\"\n\n                        question_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•:\\n{prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\nã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±æ˜ã‚Šã™ã‚‹ãŸã‚ã®é‡è¦ãªã‚µãƒ–è³ªå•ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\")])]\n                        \n                        question_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=question_contents,\n                            config=types.GenerateContentConfig(\n                                temperature=0.4,\n                                candidate_count=1,\n                                system_instruction=question_instruction,\n                            )\n                        )\n                        \n                        questions_text = extract_text_from_response(question_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¡ã‚¿è³ªå•ç”Ÿæˆå®Œäº†\")\n                        with status_container.expander(\"ç”Ÿæˆã•ã‚ŒãŸãƒ¡ã‚¿è³ªå•\", expanded=False):\n                            st.markdown(questions_text)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1.5)\n                        if question_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                question_resp.usage_metadata.prompt_token_count,\n                                question_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += question_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += question_resp.usage_metadata.candidates_token_count\n\n                    # --- Phase 2: çµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 2: çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    deep_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã¨ãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ã‚’æ ¹æ‹ ã¨ã—ã¦ã€ä»¥ä¸‹ã®æ§‹æˆã§å›ç­”ï¼š\n1. **æ·±æ˜ã‚Šè€ƒå¯Ÿ**ï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n2. **çµè«–**ï¼ˆ2-3è¡Œï¼‰\n3. **ç¾åœ¨ã®çŠ¶æ³**ï¼ˆæ•°å­—ãƒ»äº‹å®Ÿãƒ™ãƒ¼ã‚¹ï¼‰\n4. **2å¹´å¾Œã®ã‚·ãƒŠãƒªã‚ªåˆ†è§£**ï¼ˆãƒ™ãƒ¼ã‚¹ï¼å¼·æ°—ï¼å¼±æ°—ï¼‰\n5. **ä¸»ãªãƒ—ãƒ©ã‚¹è¦å› ãƒ»ãƒã‚¤ãƒŠã‚¹è¦å› **\n6. **ã“ã®äºˆæ¸¬ã‚’ã©ã†ä½¿ã†ã¹ãã‹**ï¼ˆãƒªã‚¹ã‚¯è¨±å®¹åº¦ã¸ã®ç¤ºå”†ï¼‰\n\n**é‡è¦**: æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n\"\"\"\n                    synthesis_prompt_text = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if enable_meta and questions_text:\n                        synthesis_prompt_text += f\"==== ãƒ¡ã‚¿è³ªå•ä¸€è¦§ ====\\n{questions_text}\\n==== ãƒ¡ã‚¿è³ªå•ã“ã“ã¾ã§ ====\\n\\næŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n2. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»ã‚·ãƒŠãƒªã‚ªåˆ†è§£ãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    else:\n                        synthesis_prompt_text += \"ä¸Šè¨˜ãƒ¡ãƒ¢ã‚’æ ¹æ‹ ã«ã€æœ€çµ‚å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\"\n\n                    synthesis_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=[\n                            types.Part(text=synthesis_prompt_text)\n                        ])\n                    ]\n                    \n                    synthesis_config = types.GenerateContentConfig(\n                        temperature=0.3,\n                        candidate_count=1,\n                        tools=[],  # çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºã§ã¯æ¤œç´¢OFF\n                        system_instruction=deep_instruction,\n                    )\n                    \n                    synthesis_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=synthesis_contents,\n                        config=synthesis_config,\n                    )\n                    \n                    draft_answer = extract_text_from_response(synthesis_resp)\n                    \n                    status_container.write(\"âœ“ çµ±åˆå®Œäº†\")\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 2)\n                    if synthesis_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            synthesis_resp.usage_metadata.prompt_token_count,\n                            synthesis_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += synthesis_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += synthesis_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    if enable_strict:\n                        status_container.write(\"Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        \n                        reviewer_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™ï¼š\n- äº‹å®Ÿã¨æ¨æ¸¬ã‚’æ˜ç¢ºã«åˆ†ã‘ã‚‹\n- éåº¦ã«è‡ªä¿¡ã®ã‚ã‚‹æ–­å®šã‚’å¼±ã‚ã‚‹\n- æ•°å­—ã‚„å›ºæœ‰åè©ãŒèª¿æŸ»ãƒ¡ãƒ¢ã¨çŸ›ç›¾ã—ã¦ã„ãªã„ã‹ç¢ºèª\n- è¦‹è½ã¨ã—ã¦ã„ã‚‹é‡è¦ãªãƒªã‚¹ã‚¯ãƒ»ã‚·ãƒŠãƒªã‚ªãŒã‚ã‚Œã°è¿½åŠ \n\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n\n                        review_contents = [\n                            types.Content(role=\"user\", parts=[\n                                types.Part.from_text(\n                                    text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\n\"\n                                    f\"åˆç‰ˆå›ç­”:\\n{draft_answer}\\n\\n\"\n                                    \"ä¸Šè¨˜ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\"\n                                )\n                            ])\n                        ]\n                        \n                        review_config = types.GenerateContentConfig(\n                            temperature=0.1,\n                            candidate_count=1,\n                            system_instruction=reviewer_instruction,\n                        )\n                        \n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=review_config,\n                        )\n                        \n                        final_answer = extract_text_from_response(review_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        with status_container.expander(\"åˆç‰ˆã¨ã®æ¯”è¼ƒ\", expanded=False):\n                            st.markdown(\"**åˆç‰ˆ:**\")\n                            st.markdown(draft_answer[:500] + \"...\" if len(draft_answer) > 500 else draft_answer)\n                            st.markdown(\"**ä¿®æ­£ç‰ˆ:**\")\n                            st.markdown(final_answer[:500] + \"...\" if len(final_answer) > 500 else final_answer)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 3)\n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                review_resp.usage_metadata.prompt_token_count,\n                                review_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n                    else:\n                        final_answer = draft_answer\n\n                save_usage(usage_stats)\n                status_container.update(label=\"å®Œäº†ï¼\", state=\"complete\", expanded=False)\n\n                st.markdown(final_answer)\n\n                # ---- ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ± ----\n                if grounding_metadata:\n                    st.markdown(\"---\")\n                    st.subheader(\"ğŸ“š æƒ…å ±æºã¨å¼•ç”¨\")\n                    if grounding_metadata.grounding_chunks:\n                        st.markdown(\"**æ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:**\")\n                        unique_sources = {}\n                        import urllib.parse\n\n                        for chunk in grounding_metadata.grounding_chunks:\n                            if getattr(chunk, \"web\", None):\n                                uri = getattr(chunk.web, \"uri\", None)\n                                title = getattr(chunk.web, \"title\", \"æƒ…å ±æº\")\n                                if uri and uri not in unique_sources:\n                                    parsed = urllib.parse.urlparse(uri)\n                                    domain = parsed.netloc.replace(\"www.\", \"\")\n                                    unique_sources[uri] = {\n                                        \"title\": title,\n                                        \"domain\": domain,\n                                    }\n                        for i, (uri, info) in enumerate(unique_sources.items(), 1):\n                            st.markdown(f\"{i}. **[{info['title']}]({uri})**\")\n                            st.caption(f\"   å‡ºå…¸: {info['domain']}\")\n\n                messages.append({\"role\": \"model\", \"content\": final_answer})\n                update_current_session_messages(messages)\n\n            except Exception as e:\n                status_container.update(label=\"Error\", state=\"error\")\n                err_text = str(e)\n                if \"RESOURCE_EXHAUSTED\" in err_text or \"429\" in err_text:\n                    st.error(\n                        \"âš ï¸ Vertex AI / Gemini ã®ã‚¯ã‚©ãƒ¼ã‚¿ã«é”ã—ã¾ã—ãŸã€‚\\n\\n\"\n                        \"ãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ / æ—¥æ¬¡åˆ¶é™ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\\n\"\n                        \"ãƒ»ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                        \"ãƒ»Google Cloud Console ã®ã€ŒVertex AI â†’ ä½¿ç”¨çŠ¶æ³ã€ã‹ã‚‰ã‚¯ã‚©ãƒ¼ã‚¿çŠ¶æ³ã‚’ç¢ºèªã§ãã¾ã™ã€‚\"\n                    )\n                elif \"NOT_FOUND\" in err_text and \"Publisher Model\" in err_text:\n                    st.error(\n                        \"âš ï¸ æŒ‡å®šã—ãŸãƒ¢ãƒ‡ãƒ«ãŒã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ / ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\\n\"\n                        \"ãƒ»ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ¢ãƒ‡ãƒ«IDã‚’ã€2.5ç³» ã¾ãŸã¯ 3 Pro ã«å¤‰æ›´ã—ã¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                    )\n                else:\n                    st.error(f\"An error occurred: {e}\")"
                },
                {
                    "role": "model",
                    "content": "ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: è‡ªä½œgeminiã‚³ãƒ¼ãƒ‰ã¨ã—ã¦ã¯ã“ã‚Œã§ãƒ™ã‚¹ãƒˆã‹ï¼Ÿ\n\nä¿®æ­£ç‰ˆå›ç­”:\n\n### 1. çµè«–\n\n**ã€Œã„ã„ãˆã€ãƒ™ã‚¹ãƒˆã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã¨ã—ã¦ã¯ã€é«˜æ©Ÿèƒ½ã€ã§ã™ãŒã€ãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒªã¨ã—ã¦ã®ã€åŸºæœ¬æ§‹é€ ã€ã«è‡´å‘½çš„ãªæ¬ é™¥ãŒã‚ã‚Šã¾ã™ã€‚ã€**\n\nç¾çŠ¶ã®ã‚³ãƒ¼ãƒ‰ã¯ã€æœ€æ–°ã®SDKã‚„ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ©Ÿèƒ½ã‚’è©°ã‚è¾¼ã‚“ã ã€Œæ©Ÿèƒ½ã®ã‚·ãƒ§ãƒ¼ã‚±ãƒ¼ã‚¹ã€ã¨ã—ã¦ã¯å„ªç§€ã§ã™ã€‚ã—ã‹ã—ã€**ã€Œãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã§ç”»åƒãŒèªè­˜ã•ã‚Œãªããªã‚‹ãƒã‚°ï¼ˆä»•æ§˜æ¼ã‚Œï¼‰ã€**ã‚„**ã€Œã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ¬ å¦‚ã«ã‚ˆã‚‹UXã®æ‚ªã•ã€**ãŒã‚ã‚Šã€å®Ÿç”¨ãƒ„ãƒ¼ãƒ«ã¨ã—ã¦ã¯æœªå®Œæˆã§ã™ã€‚\n\n---\n\n### 2. é¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼šè¦‹è½ã¨ã•ã‚Œã¦ã„ã‚‹é‡å¤§ãªæ¬ é™¥\n\nã‚³ãƒ¼ãƒ‰ã‚’è©³ç´°ã«åˆ†æã—ãŸçµæœã€åˆç‰ˆå›ç­”ã§è¦‹è½ã¨ã•ã‚Œã¦ã„ãŸ**æ§‹é€ çš„ãªãƒã‚°**ã¨**ãƒªã‚¹ã‚¯**ã‚’æŒ‡æ‘˜ã—ã¾ã™ã€‚\n\n#### âŒ 1. ç”»åƒãŒã€Œè¨˜æ†¶ã€ã«æ®‹ã‚‰ãªã„ï¼ˆè‡´å‘½çš„ï¼‰\nã‚³ãƒ¼ãƒ‰ã®ä»¥ä¸‹ã®éƒ¨åˆ†ã«é‡å¤§ãªä»•æ§˜æ¼ã‚ŒãŒã‚ã‚Šã¾ã™ã€‚\n- **ç¾çŠ¶**: ç”»åƒã‚„ãƒ•ã‚¡ã‚¤ãƒ«ã¯ `current_parts` ã«è¿½åŠ ã•ã‚Œã€ãã®å ´ã®APIã‚³ãƒ¼ãƒ«ã«ã¯ä½¿ã‚ã‚Œã¾ã™ãŒã€`messages` ãƒªã‚¹ãƒˆï¼ˆå±¥æ­´ä¿å­˜ç”¨ï¼‰ã«ã¯ `prompt`ï¼ˆãƒ†ã‚­ã‚¹ãƒˆï¼‰ã—ã‹ä¿å­˜ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n- **çµæœ**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸå¾Œã€æ¬¡ã®ã‚¿ãƒ¼ãƒ³ã§ã€Œã“ã®ç”»åƒã«ã¤ã„ã¦ã‚‚ã£ã¨è©³ã—ãã€ã¨èã„ã¦ã‚‚ã€**AIã¯éå»ã®ç”»åƒã‚’å‚ç…§ã§ãã¾ã›ã‚“**ï¼ˆå±¥æ­´ã«å«ã¾ã‚Œã¦ã„ãªã„ãŸã‚ï¼‰ã€‚\n- **ä¿®æ­£**: ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’Base64æ–‡å­—åˆ—ã¨ã—ã¦ `messages` ã«ä¿å­˜ã™ã‚‹ã‹ã€Googleã®File APIã‚’ä½¿ç”¨ã—ã¦URIã‚’ç®¡ç†ã—ã€å±¥æ­´æ§‹ç¯‰æ™‚ã«å†åˆ©ç”¨ã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ãŒå¿…é ˆã§ã™ã€‚\n\n#### âŒ 2. `Gemini 3` ã¯ç¾æ™‚ç‚¹ã§å­˜åœ¨ã—ãªã„ï¼ˆå¹»è¦šãƒªã‚¹ã‚¯ï¼‰\n- ã‚³ãƒ¼ãƒ‰å†…ã« `gemini-3-pro-preview` ã‚„ `gemini-2.5` ã¨ã„ã†ãƒ¢ãƒ‡ãƒ«IDãŒã‚ã‚Šã¾ã™ãŒã€ã“ã‚Œã‚‰ã¯ç¾æ™‚ç‚¹ï¼ˆ2024-2025å¹´æƒ³å®šï¼‰ã®å…¬é–‹ãƒ¢ãƒ‡ãƒ«ã§ã¯ã‚ã‚Šã¾ã›ã‚“ï¼ˆæœ€æ–°ã¯ `gemini-1.5-pro` ã‚„ `gemini-2.0-flash`ï¼‰ã€‚\n- **ãƒªã‚¹ã‚¯**: å­˜åœ¨ã—ãªã„ãƒ¢ãƒ‡ãƒ«IDã‚’æŒ‡å®šã™ã‚‹ã¨ `404 Not Found` ã‚¨ãƒ©ãƒ¼ã§å³æ­»ã—ã¾ã™ã€‚å®Ÿåœ¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«IDï¼ˆä¾‹: `gemini-1.5-pro-002`ï¼‰ã«æ›¸ãæ›ãˆã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n\n#### âŒ 3. ãƒ­ãƒ¼ã‚«ãƒ«JSONä¿å­˜ã®é™ç•Œ\n- `chat_sessions.json` ã¸ã®ä¿å­˜ã¯ã€ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œãªã‚‰å‹•ãã¾ã™ãŒã€Streamlit Cloudã‚„Cloud Runã«ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã¨ã€**å†èµ·å‹•ã®ãŸã³ã«å±¥æ­´ãŒå…¨æ¶ˆå»**ã•ã‚Œã¾ã™ï¼ˆã‚³ãƒ³ãƒ†ãƒŠã®ä»•æ§˜ï¼‰ã€‚\n- **ä¿®æ­£**: æœ¬æ ¼çš„ã«ä½¿ã†ãªã‚‰ã€SQLiteã‚„Firestoreãªã©ã®å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®æ¥ç¶šãŒå¿…è¦ã§ã™ã€‚\n\n#### âŒ 4. ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãªã—ã®UX\n- åˆç‰ˆã®æŒ‡æ‘˜é€šã‚Šã€`generate_content_stream` ã‚’ä½¿ã£ã¦ã„ãªã„ãŸã‚ã€é•·æ–‡ç”Ÿæˆæ™‚ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯æ•°åç§’é–“ã€Œãƒ•ãƒªãƒ¼ã‚ºã—ãŸç”»é¢ã€ã‚’è¦‹ç¶šã‘ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ã“ã‚Œã¯ãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒªã¨ã—ã¦è‡´å‘½çš„ã§ã™ã€‚\n\n---\n\n### 3. ç¾åœ¨ã®çŠ¶æ³ã¨ã‚·ãƒŠãƒªã‚ªåˆ†æ\n\n*   **ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: ã€Œæ©Ÿèƒ½ã¦ã‚“ã“ç››ã‚Šã®å®Ÿé¨“å®¤ã€ã€‚å€‹ã€…ã®æ©Ÿèƒ½ï¼ˆæ¤œç´¢ã€YouTubeå­—å¹•ã€ç”»åƒç”Ÿæˆï¼‰ã¯å‹•ããŒã€ãã‚Œã‚‰ã‚’ç¹‹ãã€Œä¼šè©±ã®æ–‡è„ˆç¶­æŒã€ãŒä¸å®Œå…¨ã€‚\n*   **ã‚³ã‚¹ãƒˆè©•ä¾¡**: ç”»åƒãŒå±¥æ­´ã«æ®‹ã‚‰ãªã„ãŸã‚ã€é€†èª¬çš„ã«ã‚³ã‚¹ãƒˆã¯å®‰ãæ¸ˆã¿ã¾ã™ãŒã€æ©Ÿèƒ½è¦ä»¶ã‚’æº€ãŸã—ã¦ã„ã¾ã›ã‚“ã€‚ç”»åƒã‚’æ­£ã—ãå±¥æ­´ã«å«ã‚ãŸå ´åˆã€Gemini Proã®ç”»åƒå…¥åŠ›ã‚³ã‚¹ãƒˆã«ã‚ˆã‚Šäºˆç®—ï¼ˆ$5.0ï¼‰ã¯ä¸€ç¬ã§æº¶ã‘ã¾ã™ã€‚\n\n#### 2å¹´å¾Œã®ã‚·ãƒŠãƒªã‚ªåˆ†è§£\n*   **æ¥½è¦³ã‚·ãƒŠãƒªã‚ªï¼ˆä¿®æ­£å¾Œï¼‰**:\n    *   ç”»åƒå±¥æ­´ã®ç®¡ç†ï¼ˆFile APIåˆ©ç”¨ï¼‰ã¨ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚’å®Ÿè£…ã—ã€è‡ªåˆ†å°‚ç”¨ã®ã€Œæœ€å¼·ãƒªã‚µãƒ¼ãƒã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€ã¨ã—ã¦å®šç€ã€‚Googleå…¬å¼UIã‚ˆã‚Šã‚‚æŸ”è»Ÿãªè¨­å®šï¼ˆSafety Filterè§£é™¤ãªã©ï¼‰ã§é‡å®ã™ã‚‹ã€‚\n*   **æ‚²è¦³ã‚·ãƒŠãƒªã‚ªï¼ˆç¾çŠ¶ç¶­æŒï¼‰**:\n    *   ã€Œã•ã£ãã®ç”»åƒã€ãŒé€šã˜ãªã„ã“ã¨ã«ã‚¹ãƒˆãƒ¬ã‚¹ã‚’æ„Ÿã˜ã¦ä½¿ã‚ãªããªã‚‹ã€‚ã¾ãŸã€Vertex AIã®èªè¨¼å‘¨ã‚Šã‚„ã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ã®ã‚¨ãƒ©ãƒ¼å‡¦ç†ãŒãªã„ãŸã‚ã€ã„ã–ã¨ã„ã†æ™‚ã«å‹•ã‹ãšä¿¡é ¼ã‚’å¤±ã†ã€‚\n\n---\n\n### 4. ä¿®æ­£ã®ãŸã‚ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ï¼ˆå„ªå…ˆåº¦é †ï¼‰\n\nã“ã®ã‚³ãƒ¼ãƒ‰ã‚’ã€Œãƒ™ã‚¹ãƒˆã€ã«è¿‘ã¥ã‘ã‚‹ãŸã‚ã®å…·ä½“çš„ãªä¿®æ­£æ‰‹é †ã§ã™ã€‚\n\n1.  **ã€Mustã€‘ç”»åƒå±¥æ­´ã®å®Ÿè£…**\n    *   ç”»åƒã‚’ `messages` ã«ä¿å­˜ã™ã‚‹ä»•çµ„ã¿ã‚’ä½œã‚‹ã‹ã€ä¸€æ™‚çš„ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®æƒ…å ±ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿æŒã—ã€`model_history` æ§‹ç¯‰æ™‚ã«å†æ·»ä»˜ã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚\n    *   *æ¨å¥¨*: ã‚³ã‚¹ãƒˆå‰Šæ¸›ã®ãŸã‚ã€ç”»åƒã¯ã€Œç›´è¿‘ã®1ã‚¿ãƒ¼ãƒ³ã®ã¿ã€ä¿æŒã™ã‚‹ä»•æ§˜ã«ã™ã‚‹ã®ãŒç¾å®Ÿçš„ã§ã™ã€‚\n\n2.  **ã€Mustã€‘ãƒ¢ãƒ‡ãƒ«IDã®é©æ­£åŒ–**\n    *   å®Ÿåœ¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«IDï¼ˆ`gemini-1.5-pro`, `gemini-2.0-flash-exp` ç­‰ï¼‰ã«å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚\n\n3.  **ã€Mustã€‘ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œ**\n    *   `client.models.generate_content` ã‚’ `generate_content_stream` ã«å¤‰æ›´ã—ã€`st.write_stream` ç­‰ã§é€æ¬¡è¡¨ç¤ºã™ã‚‹ã‚ˆã†ã«æ›¸ãæ›ãˆã¦ãã ã•ã„ã€‚\n\n4.  **ã€Shouldã€‘ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–**\n    *   `try-except` ãƒ–ãƒ­ãƒƒã‚¯ã‚’å¼·åŒ–ã—ã€ç‰¹ã« `429 Resource Exhausted`ï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼‰æ™‚ã®ãƒªãƒˆãƒ©ã‚¤å‡¦ç†ï¼ˆ`tenacity` ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæ¨å¥¨ï¼‰ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚\n\n### ç·è©•\n**ã€Œã‚³ãƒ¼ãƒ‰ã®éƒ¨å“ã¯æƒã£ã¦ã„ã¾ã™ãŒã€çµ„ã¿ç«‹ã¦æ–¹ã«ç©´ãŒã‚ã‚Šã¾ã™ã€‚ç‰¹ã«ã€ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã§ã®ç”»åƒã®æ‰±ã„ã€ã¯ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®æ€¥æ‰€ã§ã™ã€‚ã“ã“ã‚’ç›´ã›ã°ã€éå¸¸ã«å¼·åŠ›ãªãƒ„ãƒ¼ãƒ«ã«ãªã‚Šã¾ã™ã€‚ã€**"
                }
            ]
        },
        {
            "id": "b2b26260-e49c-42f0-9af7-1193d7c23a39",
            "title": "è‡ªä½œgeminiã‚³ãƒ¼ãƒ‰ã¨ã—ã¦ã¯ã“ã‚Œã§ãƒ™ã‚¹...",
            "timestamp": "2025-11-29T22:47:42.723107",
            "messages": [
                {
                    "role": "user",
                    "content": "è‡ªä½œgeminiã‚³ãƒ¼ãƒ‰ã¨ã—ã¦ã¯ã“ã‚Œã§ãƒ™ã‚¹ãƒˆã‹ï¼Ÿ\n\nã“ã‚Œã§ãƒ™ã‚¹ãƒˆã‹?\n\nimport os\nimport json\nimport re\nimport uuid\nimport datetime\nimport streamlit as st\nfrom dotenv import load_dotenv\nfrom google import genai\nfrom google.genai import types\nfrom youtube_transcript_api import YouTubeTranscriptApi\nfrom PIL import Image\nimport io\n\ntry:\n    from st_img_pastebutton import paste\n    import_error_msg = None\nexcept ImportError as e:\n    paste = None\n    import_error_msg = str(e)\n\n# =========================\n# ç’°å¢ƒå¤‰æ•° & å®šæ•°\n# =========================\n\nload_dotenv()\n\nUSAGE_FILE = \"usage_stats.json\"\nSESSIONS_FILE = \"chat_sessions.json\"\nMAX_BUDGET_USD = float(os.getenv(\"MAX_BUDGET_USD\", \"5.0\"))\n\n# â€»é‡‘é¡ã¯ã ã„ãŸã„ã®ç›®å®‰ï¼ˆUSD / 1M tokensï¼‰\nPRICING = {\n    \"gemini-3-pro-preview\":   {\"input\": 2.0,   \"output\": 12.0},\n    \"gemini-2.5-pro\":         {\"input\": 1.25,  \"output\": 10.0},\n    \"gemini-2.5-flash\":       {\"input\": 0.30,  \"output\": 2.50},\n    \"gemini-2.5-flash-lite\":  {\"input\": 0.10,  \"output\": 0.40},\n    \"gemini-2.0-flash\":       {\"input\": 0.10,  \"output\": 0.40},\n}\n\n# Vertex AI ç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®šï¼ˆ**å¸¸ã« Vertex ã‚’ä½¿ã†**ï¼‰\nVERTEX_PROJECT = os.getenv(\"GOOGLE_CLOUD_PROJECT\")\nVERTEX_LOCATION = \"global\"  # Gemini 2.x / 3 ã¯ global æ¨å¥¨\n\nst.set_page_config(page_title=\"Gemini 3 Web Studio\", layout=\"wide\")\n\n# =========================\n# Helper Functions\n# =========================\n\ndef load_usage():\n    if os.path.exists(USAGE_FILE):\n        with open(USAGE_FILE, \"r\") as f:\n            return json.load(f)\n    return {\"total_input_tokens\": 0, \"total_output_tokens\": 0, \"total_cost_usd\": 0.0}\n\ndef save_usage(stats):\n    with open(USAGE_FILE, \"w\") as f:\n        json.dump(stats, f, indent=4)\n\ndef calculate_cost(model_id, input_tok, output_tok):\n    price = PRICING.get(model_id, {\"input\": 0.0, \"output\": 0.0})\n    cost = (input_tok / 1_000_000 * price[\"input\"]) + (output_tok / 1_000_000 * price[\"output\"])\n    return cost\n\ndef get_mime_type(filename):\n    ext = filename.split('.')[-1].lower()\n    if ext in ['jpg', 'jpeg']:\n        return 'image/jpeg'\n    if ext == 'png':\n        return 'image/png'\n    if ext == 'mp4':\n        return 'video/mp4'\n    if ext == 'mov':\n        return 'video/quicktime'\n    if ext == 'txt':\n        return 'text/plain'\n    if ext == 'pdf':\n        return 'application/pdf'\n    if ext == 'csv':\n        return 'text/csv'\n    return 'application/octet-stream'\n\ndef extract_youtube_id(url):\n    regex = r\"(?:v=|\\/)([0-9A-Za-z_-]{11}).*\"\n    match = re.search(regex, url)\n    if match:\n        return match.group(1)\n    return None\n\ndef get_youtube_transcript(video_id):\n    try:\n        transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['ja', 'en'])\n        text = \" \".join([t['text'] for t in transcript_list])\n        return text\n    except Exception as e:\n        return f\"å­—å¹•ã®å–å¾—ã‚¨ãƒ©ãƒ¼: {e}\"\n\ndef get_relevant_context(query):\n    \"\"\"éå»ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ç°¡æ˜“æ¤œç´¢ã—ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™\"\"\"\n    if not query:\n        return \"\"\n    keywords = [k for k in query.split() if len(k) > 1]\n    if not keywords:\n        return \"\"\n\n    relevant_sessions = []\n    for session in st.session_state.sessions:\n        if session[\"id\"] == st.session_state.current_session_id:\n            continue\n        score = 0\n        for k in keywords:\n            if k.lower() in session[\"title\"].lower():\n                score += 3\n        for msg in session[\"messages\"][-4:]:\n            for k in keywords:\n                if k.lower() in msg[\"content\"].lower():\n                    score += 1\n        if score > 0:\n            relevant_sessions.append((score, session))\n\n    relevant_sessions.sort(key=lambda x: (x[0], x[1][\"timestamp\"]), reverse=True)\n    top_sessions = relevant_sessions[:3]\n\n    context_str = \"\"\n    if top_sessions:\n        context_str += \"### éå»ã®é–¢é€£ãƒãƒ£ãƒƒãƒˆå±¥æ­´ (Context)\\n\"\n        for score, session in top_sessions:\n            last_response = \"N/A\"\n            for m in reversed(session[\"messages\"]):\n                if m[\"role\"] == \"model\":\n                    last_response = m[\"content\"][:300] + \"...\"\n                    break\n            context_str += f\"- **Session: {session['title']}** ({session['timestamp'][:10]})\\n\"\n            context_str += f\"  Last Conclusion: {last_response}\\n\\n\"\n    return context_str\n\ndef extract_text_from_response(response):\n    \"\"\"Extract text from GenerateContentResponse\"\"\"\n    if not response.candidates:\n        return \"\"\n    parts = response.candidates[0].content.parts or []\n    return \"\".join(p.text or \"\" for p in parts)\n\n# =========================\n# Session Management\n# =========================\n\ndef load_sessions():\n    if os.path.exists(SESSIONS_FILE):\n        with open(SESSIONS_FILE, \"r\") as f:\n            try:\n                data = json.load(f)\n                return data.get(\"sessions\", [])\n            except json.JSONDecodeError:\n                return []\n    return []\n\ndef save_sessions(sessions):\n    with open(SESSIONS_FILE, \"w\") as f:\n        json.dump({\"sessions\": sessions}, f, indent=4, ensure_ascii=False)\n\ndef create_new_session():\n    current_sessions = load_sessions()\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": [],\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.rerun()\n\ndef switch_session(session_id):\n    st.session_state.current_session_id = session_id\n    st.rerun()\n\ndef update_current_session_messages(messages):\n    if st.session_state.current_session_id:\n        current_sessions = load_sessions()\n        for session in current_sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                session[\"messages\"] = messages\n                if session[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(messages) > 0:\n                    first_msg = messages[0][\"content\"]\n                    session[\"title\"] = (first_msg[:20] + \"...\") if len(first_msg) > 20 else first_msg\n                session[\"timestamp\"] = datetime.datetime.now().isoformat()\n                break\n        save_sessions(current_sessions)\n        st.session_state.sessions = current_sessions\n\ndef get_current_messages():\n    if st.session_state.current_session_id:\n        for session in st.session_state.sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                return session[\"messages\"]\n    return []\n\ndef delete_session(session_id):\n    current_sessions = load_sessions()\n    current_sessions = [s for s in current_sessions if s[\"id\"] != session_id]\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    if st.session_state.current_session_id == session_id:\n        st.session_state.current_session_id = None\n        if st.session_state.sessions:\n            st.session_state.current_session_id = st.session_state.sessions[0][\"id\"]\n    st.rerun()\n\ndef branch_session():\n    \"\"\"ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚’åˆ†å²\"\"\"\n    current_messages = get_current_messages()\n    current_sessions = load_sessions()\n    \n    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—\n    current_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n    for session in current_sessions:\n        if session[\"id\"] == st.session_state.current_session_id:\n            current_title = session[\"title\"]\n            break\n    \n    # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": f\"{current_title} (åˆ†å²)\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": current_messages.copy(),  # ç¾åœ¨ã®å±¥æ­´ã‚’ã‚³ãƒ”ãƒ¼\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    \n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.session_state.session_cost = 0.0  # ã‚³ã‚¹ãƒˆãƒªã‚»ãƒƒãƒˆ\n    st.rerun()\n\n# =========================\n# Initialization\n# =========================\n\nif \"sessions\" not in st.session_state:\n    st.session_state.sessions = load_sessions()\n\nif \"current_session_id\" not in st.session_state:\n    # Always create a new session when the app starts\n    create_new_session()\n\nif \"session_cost\" not in st.session_state:\n    st.session_state.session_cost = 0.0\n\nusage_stats = load_usage()\n\n# =========================\n# Sidebar\n# =========================\n\nwith st.sidebar:\n    st.title(\"Gemini 3 Studio\")\n\n    if st.button(\"â• æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\", use_container_width=True):\n        create_new_session()\n\n    if st.button(\"ğŸŒ± ç¾åœ¨ã®ãƒãƒ£ãƒƒãƒˆã‹ã‚‰åˆ†å²\", use_container_width=True):\n        branch_session()\n\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    current_messages = get_current_messages()\n    if current_messages:\n        export_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n        for s in st.session_state.sessions:\n            if s[\"id\"] == st.session_state.current_session_id:\n                export_title = s[\"title\"]\n                break\n\n        export_md = f\"# {export_title}\\n\\n\"\n        export_md += f\"**ä½œæˆæ—¥æ™‚**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n---\\n\\n\"\n        for msg in current_messages:\n            role_label = \"ğŸ§‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼\" if msg[\"role\"] == \"user\" else \"ğŸ¤– AI\"\n            export_md += f\"## {role_label}\\n\\n{msg['content']}\\n\\n---\\n\\n\"\n\n        if st.button(\"ğŸ”— å¤–éƒ¨å…±æœ‰ãƒªãƒ³ã‚¯ã‚’ä½œæˆ\", use_container_width=True):\n            with st.spinner(\"ãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆä¸­...\"):\n                try:\n                    import urllib.request\n                    import urllib.parse\n\n                    data = urllib.parse.urlencode(\n                        {\"content\": export_md, \"expiry_days\": 7, \"syntax\": \"md\"}\n                    ).encode()\n\n                    req = urllib.request.Request(\"https://dpaste.org/api/\", data=data)\n                    req.add_header(\"User-Agent\", \"Mozilla/5.0 (Gemini3Studio)\")\n\n                    with urllib.request.urlopen(req) as response:\n                        share_url = response.read().decode(\"utf-8\").strip()\n                        st.success(\"ãƒªãƒ³ã‚¯ã‚’ä½œæˆã—ã¾ã—ãŸï¼\")\n                        st.code(share_url)\n                        st.caption(\"â€»ãƒªãƒ³ã‚¯ã¯7æ—¥é–“æœ‰åŠ¹ã§ã™\")\n                except Exception as e:\n                    st.error(f\"ãƒªãƒ³ã‚¯ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}\")\n\n    st.markdown(\"---\")\n\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    st.subheader(\"æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«\")\n    uploaded_files = st.file_uploader(\n        \"ç”»åƒã€å‹•ç”»ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\",\n        accept_multiple_files=True,\n        type=[\"png\", \"jpg\", \"jpeg\", \"mp4\", \"mov\", \"txt\", \"pdf\", \"csv\"],\n        help=\"Limit 2GB per file\",\n    )\n\n    pasted_image_bytes = None\n    if paste:\n        if \"paste_key\" not in st.session_state:\n            st.session_state.paste_key = 0\n        try:\n            pasted_image_bytes = paste(\n                label=\"ğŸ“‹ ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã‹ã‚‰ç”»åƒã‚’è²¼ã‚Šä»˜ã‘\",\n                key=f\"paste_btn_{st.session_state.paste_key}\",\n            )\n        except Exception as e:\n            st.error(f\"Clipboard button error: {e}\")\n        \n        if pasted_image_bytes:\n            st.success(\"ç”»åƒãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚Œã¾ã—ãŸï¼\")\n            st.image(pasted_image_bytes, caption=\"è²¼ã‚Šä»˜ã‘ãŸç”»åƒ\", use_container_width=True)\n            if st.button(\"ğŸ—‘ï¸ ç”»åƒã‚’ã‚¯ãƒªã‚¢\", key=\"clear_paste\"):\n                st.session_state.paste_key += 1\n                st.rerun()\n    else:\n        st.warning(\"Clipboard library not loaded (ImportError)\")\n\n    # ---- YouTube URL ----\n    st.markdown(\"---\")\n    youtube_url = st.text_input(\"YouTube URL (å­—å¹•ã‚’åˆ†æ)\", placeholder=\"https://youtu.be/...\")\n\n    # ---- ç”»åƒç”Ÿæˆ ----\n    st.markdown(\"---\")\n    st.subheader(\"ğŸ¨ ç”»åƒç”Ÿæˆ\")\n    img_prompt = st.text_area(\"ç”Ÿæˆã—ãŸã„ç”»åƒã®èª¬æ˜\", placeholder=\"æœªæ¥çš„ãªéƒ½å¸‚ã®é¢¨æ™¯...\")\n    aspect_ratio = st.selectbox(\"ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”\", [\"16:9\", \"1:1\", \"4:3\", \"3:4\", \"9:16\"])\n\n    generate_img_btn = st.button(\"ç”»åƒã‚’ç”Ÿæˆ\", type=\"primary\", disabled=not img_prompt)\n    if generate_img_btn and img_prompt:\n        st.session_state.generate_image_trigger = {\n            \"prompt\": img_prompt,\n            \"aspect_ratio\": aspect_ratio,\n        }\n\n    st.markdown(\"---\")\n\n    # ---- å±¥æ­´æ¤œç´¢ ----\n    search_query = st.text_input(\"ğŸ” å±¥æ­´ã‚’æ¤œç´¢\", placeholder=\"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰...\")\n    if search_query:\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if search_query.lower() in s[\"title\"].lower():\n                filtered_sessions.append(s)\n                continue\n            found = False\n            for m in s[\"messages\"]:\n                if search_query.lower() in m[\"content\"].lower():\n                    filtered_sessions.append(s)\n                    found = True\n                    break\n            if not found:\n                pass\n    else:\n        filtered_sessions = st.session_state.sessions\n\n    with st.expander(\"ğŸ“œ éå»ã®ãƒãƒ£ãƒƒãƒˆ\", expanded=bool(search_query)):\n        if not filtered_sessions:\n            st.caption(\"ãƒãƒ£ãƒƒãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n        for session in filtered_sessions:\n            col1, col2 = st.columns([0.8, 0.2])\n            with col1:\n                if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                    switch_session(session[\"id\"])\n            with col2:\n                if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                    delete_session(session[\"id\"])\n\n    st.markdown(\"---\")\n    st.title(\"è¨­å®š\")\n\n    # ---- ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆGemini 1.5 ã¯å»ƒæ­¢ã•ã‚Œã¦ã„ã‚‹ã®ã§å«ã‚ãªã„ï¼‰ ----\n    model_options = [\n        \"gemini-3-pro-preview\",\n        \"gemini-2.5-pro\",\n        \"gemini-2.5-flash\",\n        \"gemini-2.5-flash-lite\",\n        \"gemini-2.0-flash\",\n    ]\n    model_id = st.selectbox(\"ãƒ¢ãƒ‡ãƒ«ID\", options=model_options, index=0)\n\n    if \"3-pro\" in model_id or \"2.5-pro\" in model_id:\n        st.caption(\"ğŸ§  é«˜åº¦ãªæ¨è«–å‘ã‘ Pro ãƒ¢ãƒ‡ãƒ«\")\n    if \"flash\" in model_id:\n        st.caption(\"âš¡ é«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆãª Flash ç³»ãƒ¢ãƒ‡ãƒ«\")\n\n    # ---- æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚° ----\n    use_search = st.toggle(\"Googleæ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã‚’ä½¿ç”¨\", value=True)\n    candidate_count = st.slider(\"å›ç­”å€™è£œæ•°\", min_value=1, max_value=3, value=3)\n    if use_search and candidate_count > 1:\n        st.caption(\"âš ï¸ æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ä½¿ç”¨æ™‚ã¯å€™è£œæ•°ãŒ1ã«ãªã‚Šã¾ã™ã€‚\")\n\n    st.markdown(\"---\")\n\n    # ---- å›ç­”ãƒ¢ãƒ¼ãƒ‰ ----\n    response_mode = st.radio(\n        \"å›ç­”ãƒ¢ãƒ¼ãƒ‰\",\n        [\n            \"é€šå¸¸ (é«˜é€Ÿ)\",\n            \"ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n            \"ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n            \"ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n            \"ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n        ],\n        index=0\n    )\n    strict_mode = False # äº’æ›æ€§ç¶­æŒã®ãŸã‚ã®ãƒ€ãƒŸãƒ¼å¤‰æ•°\n    st.markdown(\"---\")\n\n    # ---- è©•ä¾¡åˆ†æ ----\n    st.subheader(\"ğŸ“Š å›ç­”å“è³ªåˆ†æ\")\n    total_ratings = 0\n    positive_ratings = 0\n    model_ratings = {}\n\n    for s in st.session_state.sessions:\n        for m in s[\"messages\"]:\n            if \"rating\" in m and m[\"rating\"] is not None:\n                total_ratings += 1\n                if m[\"rating\"] == 1:\n                    positive_ratings += 1\n                if \"metadata\" in m and \"model\" in m[\"metadata\"]:\n                    mod = m[\"metadata\"][\"model\"]\n                    if mod not in model_ratings:\n                        model_ratings[mod] = {\"total\": 0, \"positive\": 0}\n                    model_ratings[mod][\"total\"] += 1\n                    if m[\"rating\"] == 1:\n                        model_ratings[mod][\"positive\"] += 1\n\n    if total_ratings > 0:\n        approval_rate = (positive_ratings / total_ratings) * 100\n        st.metric(\"Positive Ratings\", f\"{positive_ratings}/{total_ratings}\", f\"{approval_rate:.1f}%\")\n        best_model = \"N/A\"\n        best_rate = -1\n        for mod, stats in model_ratings.items():\n            rate = stats[\"positive\"] / stats[\"total\"]\n            if rate > best_rate:\n                best_rate = rate\n                best_model = mod\n        if best_model != \"N/A\":\n            st.caption(f\"ğŸ† Best Model: **{best_model}** ({best_rate*100:.0f}%)\")\n    else:\n        st.caption(\"ã¾ã è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\")\n\n    st.markdown(\"---\")\n\n    # ---- ã‚³ã‚¹ãƒˆè¡¨ç¤º ----\n    st.subheader(\"ğŸ’° ã‚³ã‚¹ãƒˆ (æ¦‚ç®—)\")\n    st.metric(\"Total Cost\", f\"${usage_stats['total_cost_usd']:.4f}\")\n    if st.session_state.session_cost > 0:\n        st.caption(f\"Current Session: ${st.session_state.session_cost:.4f}\")\n\n    if usage_stats[\"total_cost_usd\"] >= MAX_BUDGET_USD:\n        st.error(f\"âš ï¸ äºˆç®—ä¸Šé™ (${MAX_BUDGET_USD}) ã«é”ã—ã¾ã—ãŸã€‚\")\n        stop_generation = True\n    else:\n        stop_generation = False\n\n    st.markdown(\"---\")\n    st.code(f\"PROJECT: {VERTEX_PROJECT}\\nLOCATION: {VERTEX_LOCATION} (Vertex AI)\")\n\n# =========================\n# Main UI\n# =========================\n\ncurrent_session_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\nfor s in st.session_state.sessions:\n    if s[\"id\"] == st.session_state.current_session_id:\n        current_session_title = s[\"title\"]\n        break\n\nst.header(current_session_title)\nst.markdown(\n    \"ä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\"\n)\n\n# ---- Vertex AI Client ----\n\n@st.cache_resource\ndef get_client():\n    return genai.Client(\n        vertexai=True,\n        project=VERTEX_PROJECT,\n        location=VERTEX_LOCATION,\n    )\n\nclient = get_client()\n\n# ---- å±¥æ­´è¡¨ç¤º ----\n\nmessages = get_current_messages()\nfor idx, msg in enumerate(messages):\n    with st.chat_message(msg[\"role\"]):\n        st.markdown(msg[\"content\"])\n        if msg[\"role\"] == \"model\":\n            col1, col2, col3 = st.columns([0.1, 0.1, 0.8])\n            current_rating = msg.get(\"rating\")\n            with col1:\n                if st.button(\"ğŸ‘\", key=f\"up_{idx}\"):\n                    messages[idx][\"rating\"] = 1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col2:\n                if st.button(\"ğŸ‘\", key=f\"down_{idx}\"):\n                    messages[idx][\"rating\"] = -1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col3:\n                if current_rating == 1:\n                    st.caption(\"âœ… é«˜è©•ä¾¡\")\n                elif current_rating == -1:\n                    st.caption(\"âŒ ä½è©•ä¾¡\")\n\n# =========================\n# ç”»åƒç”Ÿæˆãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°\n# =========================\n\nif hasattr(st.session_state, \"generate_image_trigger\") and st.session_state.generate_image_trigger:\n    img_data = st.session_state.generate_image_trigger\n    del st.session_state.generate_image_trigger\n\n    with st.chat_message(\"user\"):\n        st.markdown(f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\")\n        st.caption(f\"ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”: {img_data['aspect_ratio']}\")\n\n    messages.append({\"role\": \"user\", \"content\": f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\"})\n    update_current_session_messages(messages)\n\n    with st.chat_message(\"assistant\"):\n        with st.status(\"ç”»åƒã‚’ç”Ÿæˆä¸­...\", expanded=True) as status:\n            try:\n                config = types.GenerateContentConfig(\n                    response_modalities=[\"IMAGE\"],\n                    image_config=types.ImageConfig(\n                        aspect_ratio=img_data[\"aspect_ratio\"]\n                    ),\n                )\n                status.write(\"Gemini 3 Pro Imageã§ç”Ÿæˆä¸­...\")\n                response = client.models.generate_content(\n                    model=\"gemini-3-pro-image-preview\",\n                    contents=img_data[\"prompt\"],\n                    config=config,\n                )\n\n                generated_image = None\n\n                # ç”»åƒã‚’å–ã‚Šå‡ºã™\n                if getattr(response, \"candidates\", None):\n                    for candidate in response.candidates:\n                        if getattr(candidate, \"content\", None) and candidate.content.parts:\n                            for part in candidate.content.parts:\n                                if getattr(part, \"inline_data\", None):\n                                    try:\n                                        generated_image = part.as_image()\n                                    except AttributeError:\n                                        image_bytes_raw = part.inline_data.data\n                                        generated_image = Image.open(io.BytesIO(image_bytes_raw))\n                                    break\n                        if generated_image is not None:\n                            break\n\n                if generated_image is not None:\n                    st.image(generated_image, caption=img_data[\"prompt\"])\n                    buf = io.BytesIO()\n                    generated_image.save(buf, format=\"PNG\")\n                    image_bytes = buf.getvalue()\n                    st.download_button(\n                        label=\"ğŸ’¾ ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\",\n                        data=image_bytes,\n                        file_name=f\"generated_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png\",\n                        mime=\"image/png\",\n                    )\n                    messages.append(\n                        {\"role\": \"model\", \"content\": f\"âœ… ç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {img_data['prompt']}\"}\n                    )\n                    update_current_session_messages(messages)\n                    status.update(label=\"âœ… ç”»åƒç”Ÿæˆå®Œäº†\", state=\"complete\")\n                else:\n                    st.error(\"ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")\n                    status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n\n            except Exception as e:\n                status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n                st.error(f\"ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}\")\n\n# =========================\n# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›\n# =========================\n\nprompt = st.chat_input(\"ä½•ã‹èã„ã¦ãã ã•ã„...\", disabled=stop_generation)\n\nif prompt:\n    if stop_generation:\n        st.error(\"äºˆç®—ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚\")\n    else:\n        # ---- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€è¡¨ç¤º ----\n        with st.chat_message(\"user\"):\n            st.markdown(prompt)\n            if uploaded_files:\n                for uf in uploaded_files:\n                    st.caption(f\"ğŸ“ æ·»ä»˜: {uf.name}\")\n            if youtube_url:\n                st.caption(f\"ğŸ“º YouTube: {youtube_url}\")\n            if pasted_image_bytes:\n                st.caption(\"ğŸ“‹ ç”»åƒãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚Œã¾ã—ãŸ\")\n\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        update_current_session_messages(messages)\n\n        # ---- ãƒ¢ãƒ‡ãƒ«å¿œç­” ----\n        with st.chat_message(\"assistant\"):\n            status_container = st.status(\"æ€è€ƒä¸­...\", expanded=True)\n            try:\n                # ä¼šè©±å±¥æ­´\n                model_history = []\n                for msg in messages[:-1]:\n                    model_history.append(\n                        types.Content(\n                            role=msg[\"role\"],\n                            parts=[types.Part.from_text(text=msg[\"content\"])],\n                        )\n                    )\n\n                # ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³\n                current_parts = [types.Part.from_text(text=prompt)]\n\n                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«\n                for uploaded_file in uploaded_files or []:\n                    try:\n                        mime_type = get_mime_type(uploaded_file.name)\n                        bytes_data = uploaded_file.getvalue()\n                        part = types.Part.from_bytes(data=bytes_data, mime_type=mime_type)\n                        current_parts.append(part)\n                        status_container.write(f\"ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™å®Œäº†: {uploaded_file.name}\")\n                    except Exception as e:\n                        status_container.error(\n                            f\"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {uploaded_file.name} - {e}\"\n                        )\n\n                # è²¼ã‚Šä»˜ã‘ç”»åƒ\n                if pasted_image_bytes:\n                    import base64\n\n                    status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã‚’å‡¦ç†ä¸­...\")\n                    try:\n                        if isinstance(pasted_image_bytes, str):\n                            if pasted_image_bytes.startswith(\"data:\"):\n                                base64_str = pasted_image_bytes.split(\",\", 1)[1]\n                                image_bytes_decoded = base64.b64decode(base64_str)\n                            else:\n                                image_bytes_decoded = base64.b64decode(pasted_image_bytes)\n                        else:\n                            image_bytes_decoded = pasted_image_bytes\n                        part = types.Part.from_bytes(\n                            data=image_bytes_decoded, mime_type=\"image/png\"\n                        )\n                        current_parts.append(part)\n                        status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®æº–å‚™å®Œäº†\")\n                    except Exception as e:\n                        status_container.error(f\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n\n                # YouTube å­—å¹•\n                if youtube_url:\n                    vid_id = extract_youtube_id(youtube_url)\n                    if vid_id:\n                        status_container.write(\"YouTubeã®å­—å¹•ã‚’å–å¾—ä¸­...\")\n                        transcript_text = get_youtube_transcript(vid_id)\n                        current_parts.append(\n                            types.Part.from_text(text=f\"YouTube Transcript:\\n{transcript_text}\")\n                        )\n                    else:\n                        status_container.write(\"ç„¡åŠ¹ãªYouTube URLã§ã™ã€‚\")\n\n                contents_for_model = model_history + [\n                    types.Content(role=\"user\", parts=current_parts)\n                ]\n\n                # ---- Tool / Config ----\n                tools = []\n                final_candidate_count = candidate_count\n                if use_search:\n                    tools.append(types.Tool(google_search=types.GoogleSearch()))\n                    final_candidate_count = 1\n\n                # â˜… System Instruction ã®æ”¹å–„: ãƒ¡ã‚¿ç™ºè¨€ç¦æ­¢ã¨ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªæŒ¯ã‚‹èˆã„ã‚’æŒ‡ç¤º\n                base_system_instruction = (\n                    \"ã‚ãªãŸã¯é«˜åº¦ãªçŸ¥æ€§ã‚’æŒã¤å°‚é–€çš„ãªãƒªã‚µãƒ¼ãƒãƒ»ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\\n\"\n                    \"ä»¥ä¸‹ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’å³å®ˆã—ã¦ãã ã•ã„ï¼š\\n\"\n                    \"1. **ãƒ¡ã‚¿ç™ºè¨€ã®ç¦æ­¢**: ã€Œç§ã¯AIã§ã™ã€ã€Œä¸–ç•Œæœ€é«˜å³°ã®ï½ã¨ã—ã¦ã€ãªã©ã®è‡ªå·±è¨€åŠã‚„å‰ç½®ãã¯ä¸€åˆ‡è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚\\n\"\n                    \"2. **æ„å›³ã®æ±²ã¿å–ã‚Š**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã®èƒŒå¾Œã«ã‚ã‚‹æ„å›³ï¼ˆæ–‡è„ˆã€æš—é»™ã®å‰æï¼‰ã‚’æ¨æ¸¬ã—ã€è¨€è‘‰é€šã‚Šã§ã¯ãªãã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ¬å½“ã«çŸ¥ã‚ŠãŸã„ã“ã¨ã€ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n\"\n                    \"3. **æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”**: çµè«–ã‚’å…ˆã«è¿°ã¹ã€ãã®å¾Œã«è©³ç´°ãªæ ¹æ‹ ã€ã‚·ãƒŠãƒªã‚ªåˆ†æã€ãƒªã‚¹ã‚¯è¦å› ã‚’è«–ç†çš„ã«å±•é–‹ã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"4. **å®¢è¦³æ€§**: äºˆæ¸¬ã‚’è¡Œã†å ´åˆã¯ã€æ–­å®šã‚’é¿ã‘ã€è¤‡æ•°ã®ã‚·ãƒŠãƒªã‚ªï¼ˆæ¥½è¦³ã€æ‚²è¦³ã€ä¸­ç«‹ï¼‰ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"5. **å¼•ç”¨**: æ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸå ´åˆã¯ã€å¿…ãšæƒ…å ±æºã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚\"\n                )\n\n                final_answer = \"\"\n                grounding_metadata = None\n                \n                # =========================\n                # ãƒ¢ãƒ¼ãƒ‰è¨­å®šã®è§£æ\n                # =========================\n                enable_research = True  # å…¨ãƒ¢ãƒ¼ãƒ‰ã§ãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œ\n                enable_meta = \"ãƒ¡ã‚¿\" in response_mode or \"MAX\" in response_mode\n                enable_strict = \"é¬¼è»æ›¹\" in response_mode or \"MAX\" in response_mode\n\n                # =========================\n                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (é«˜é€Ÿ / é¬¼è»æ›¹)\n                # =========================\n                if not enable_research:\n                    config = types.GenerateContentConfig(\n                        temperature=0.7,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=base_system_instruction,\n                    )\n                    \n                    status_container.write(\"å›ç­”ç”Ÿæˆä¸­...\")\n                    response = client.models.generate_content(\n                        model=model_id,\n                        contents=contents_for_model,\n                        config=config,\n                    )\n                    \n                    final_answer = extract_text_from_response(response)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®—\n                    if response.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            response.usage_metadata.prompt_token_count,\n                            response.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += response.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += response.usage_metadata.candidates_token_count\n\n                    # é¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ (é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ç‰ˆ)\n                    if enable_strict:\n                        status_container.write(\"ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        reviewer_instruction = base_system_instruction + \"\"\"\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n                        review_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\nåˆç‰ˆå›ç­”:\\n{final_answer}\\n\\nãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\")])]\n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=types.GenerateContentConfig(temperature=0.1, candidate_count=1, system_instruction=reviewer_instruction)\n                        )\n                        final_answer = extract_text_from_response(review_resp)\n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        \n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(model_id, review_resp.usage_metadata.prompt_token_count, review_resp.usage_metadata.candidates_token_count)\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n\n                # =========================\n                # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰\n                # =========================\n                else:\n                    # =========================\n                    # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰: å¤šæ®µéšã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ \n                    # =========================\n                    \n                    # --- Phase 1: ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 1: ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    research_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒªã‚µãƒ¼ãƒå°‚ä»»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚æœ€çµ‚å›ç­”ã¯æ›¸ã‹ãšã€äº‹å®Ÿåé›†ã«é›†ä¸­ã™ã‚‹ã“ã¨ã€‚\n\n**èª¿æŸ»è¦³ç‚¹**:\n- è³ªå•ã«é–¢é€£ã™ã‚‹æœ€æ–°ã®äº‹å®Ÿãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ»çµ±è¨ˆ\n- å…¬å¼æƒ…å ±ã‚„ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã‹ã‚‰ã®å¼•ç”¨\n- é–¢é€£ã™ã‚‹èƒŒæ™¯æƒ…å ±ã‚„æ–‡è„ˆ\n- ç«¶åˆãƒ»ä»£æ›¿æ¡ˆãƒ»æ¯”è¼ƒå¯¾è±¡ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n- ãƒªã‚¹ã‚¯ãƒ»åˆ¶ç´„ãƒ»æ³¨æ„ç‚¹ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n- å‚è€ƒã«ã—ãŸä¸»è¦ãªæƒ…å ±æºã®URL\n\n**é‡è¦**: \n- çµè«–ã‚„æ¨å¥¨ã¯æ›¸ã‹ãšã€å¾Œå·¥ç¨‹ãŒåˆ¤æ–­ã§ãã‚‹èª¿æŸ»ãƒ¡ãƒ¢ã«é›†ä¸­ã™ã‚‹ã“ã¨\n- æœ€æ–°ã®æƒ…å ±ã‚’å„ªå…ˆçš„ã«æ¤œç´¢ã™ã‚‹ã“ã¨\n- æ¤œç´¢çµæœã‚’å¿…ãšæ´»ç”¨ã—ã€æƒ…å ±æºã‚’æ˜è¨˜ã™ã‚‹ã“ã¨\n\"\"\"\n\n                    # éå»ã®é–¢é€£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—\n                    past_context = get_relevant_context(prompt)\n                    \n                    # ãƒªã‚µãƒ¼ãƒç”¨ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ§‹ç¯‰\n                    research_parts = [types.Part(text=f\"ã“ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š\\n{prompt}\")]\n                    \n                    if past_context:\n                        research_parts.insert(0, types.Part(text=\"ä»¥ä¸‹ã¯éå»ã®é–¢é€£ãƒãƒ£ãƒƒãƒˆã‹ã‚‰æŠ½å‡ºã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã™ï¼š\\n\\n\" + past_context))\n                    \n                    research_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=research_parts)\n                    ]\n                    \n                    research_config = types.GenerateContentConfig(\n                        temperature=0.2,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=research_instruction,\n                    )\n                    \n                    research_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=research_contents,\n                        config=research_config,\n                    )\n                    \n                    research_text = extract_text_from_response(research_resp)\n                    \n                    # ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºã®ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ±ã‚’ä¿å­˜\n                    if research_resp.candidates and research_resp.candidates[0].grounding_metadata:\n                        grounding_metadata = research_resp.candidates[0].grounding_metadata\n                    \n                    status_container.write(\"âœ“ ãƒªã‚µãƒ¼ãƒå®Œäº†\")\n                    with status_container.expander(\"åé›†ã—ãŸèª¿æŸ»ãƒ¡ãƒ¢\", expanded=False):\n                        st.markdown(research_text)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1)\n                    if research_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            research_resp.usage_metadata.prompt_token_count,\n                            research_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += research_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += research_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 1.5: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    questions_text = \"\"\n                    if enable_meta:\n                        status_container.write(\"Phase 1.5: ãƒ¡ã‚¿è³ªå•ç”Ÿæˆä¸­...\")\n                        \n                        question_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ç›®çš„**: \nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•ã¨èª¿æŸ»ãƒ¡ãƒ¢ã‚’è¸ã¾ãˆã¦ã€ã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±ãç†è§£ã™ã‚‹ãŸã‚ã®ã€Œé‹­ã„ã‚µãƒ–è³ªå•ã€ã‚’ä½œæˆã™ã‚‹ã“ã¨ã€‚\n\n**ãƒ«ãƒ¼ãƒ«**:\n- æœ€å¤§5å€‹ã¾ã§\n- å„è³ªå•ã¯1-2è¡Œã§å…·ä½“çš„ã‹ã¤é‹­ã\n- ä»¥ä¸‹ã®è¦³ç‚¹ã‚’æ„è­˜:\n  1. å‰æãŒå´©ã‚Œã‚‹å¯èƒ½æ€§ã¯ã©ã“ã‹ï¼Ÿ\n  2. å¼·æ°—/å¼±æ°—ã‚·ãƒŠãƒªã‚ªã®åˆ†å²ç‚¹ã¯ä½•ã‹ï¼Ÿ\n  3. ç«¶åˆãƒ»æŠ€è¡“ãƒ»è¦åˆ¶ã®ä¸ç¢ºå®Ÿæ€§ã¯ï¼Ÿ\n  4. ã€Œäºˆæ¸¬ãŒå¤–ã‚Œã‚‹ã¨ã—ãŸã‚‰ã©ã‚“ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ï¼Ÿã€\n\n**å‡ºåŠ›**: ç®‡æ¡æ›¸ãï¼ˆQ1, Q2...ï¼‰ã®ã¿\n\"\"\"\n\n                        question_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•:\\n{prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\nã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±æ˜ã‚Šã™ã‚‹ãŸã‚ã®é‡è¦ãªã‚µãƒ–è³ªå•ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\")])]\n                        \n                        question_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=question_contents,\n                            config=types.GenerateContentConfig(\n                                temperature=0.4,\n                                candidate_count=1,\n                                system_instruction=question_instruction,\n                            )\n                        )\n                        \n                        questions_text = extract_text_from_response(question_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¡ã‚¿è³ªå•ç”Ÿæˆå®Œäº†\")\n                        with status_container.expander(\"ç”Ÿæˆã•ã‚ŒãŸãƒ¡ã‚¿è³ªå•\", expanded=False):\n                            st.markdown(questions_text)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1.5)\n                        if question_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                question_resp.usage_metadata.prompt_token_count,\n                                question_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += question_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += question_resp.usage_metadata.candidates_token_count\n\n                    # --- Phase 2: çµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 2: çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    deep_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã¨ãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ã‚’æ ¹æ‹ ã¨ã—ã¦ã€ä»¥ä¸‹ã®æ§‹æˆã§å›ç­”ï¼š\n1. **æ·±æ˜ã‚Šè€ƒå¯Ÿ**ï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n2. **çµè«–**ï¼ˆ2-3è¡Œï¼‰\n3. **ç¾åœ¨ã®çŠ¶æ³**ï¼ˆæ•°å­—ãƒ»äº‹å®Ÿãƒ™ãƒ¼ã‚¹ï¼‰\n4. **2å¹´å¾Œã®ã‚·ãƒŠãƒªã‚ªåˆ†è§£**ï¼ˆãƒ™ãƒ¼ã‚¹ï¼å¼·æ°—ï¼å¼±æ°—ï¼‰\n5. **ä¸»ãªãƒ—ãƒ©ã‚¹è¦å› ãƒ»ãƒã‚¤ãƒŠã‚¹è¦å› **\n6. **ã“ã®äºˆæ¸¬ã‚’ã©ã†ä½¿ã†ã¹ãã‹**ï¼ˆãƒªã‚¹ã‚¯è¨±å®¹åº¦ã¸ã®ç¤ºå”†ï¼‰\n\n**é‡è¦**: æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n\"\"\"\n                    synthesis_prompt_text = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if enable_meta and questions_text:\n                        synthesis_prompt_text += f\"==== ãƒ¡ã‚¿è³ªå•ä¸€è¦§ ====\\n{questions_text}\\n==== ãƒ¡ã‚¿è³ªå•ã“ã“ã¾ã§ ====\\n\\næŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n2. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»ã‚·ãƒŠãƒªã‚ªåˆ†è§£ãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    else:\n                        synthesis_prompt_text += \"ä¸Šè¨˜ãƒ¡ãƒ¢ã‚’æ ¹æ‹ ã«ã€æœ€çµ‚å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\"\n\n                    synthesis_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=[\n                            types.Part(text=synthesis_prompt_text)\n                        ])\n                    ]\n                    \n                    synthesis_config = types.GenerateContentConfig(\n                        temperature=0.3,\n                        candidate_count=1,\n                        tools=[],  # çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºã§ã¯æ¤œç´¢OFF\n                        system_instruction=deep_instruction,\n                    )\n                    \n                    synthesis_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=synthesis_contents,\n                        config=synthesis_config,\n                    )\n                    \n                    draft_answer = extract_text_from_response(synthesis_resp)\n                    \n                    status_container.write(\"âœ“ çµ±åˆå®Œäº†\")\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 2)\n                    if synthesis_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            synthesis_resp.usage_metadata.prompt_token_count,\n                            synthesis_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += synthesis_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += synthesis_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    if enable_strict:\n                        status_container.write(\"Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        \n                        reviewer_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™ï¼š\n- äº‹å®Ÿã¨æ¨æ¸¬ã‚’æ˜ç¢ºã«åˆ†ã‘ã‚‹\n- éåº¦ã«è‡ªä¿¡ã®ã‚ã‚‹æ–­å®šã‚’å¼±ã‚ã‚‹\n- æ•°å­—ã‚„å›ºæœ‰åè©ãŒèª¿æŸ»ãƒ¡ãƒ¢ã¨çŸ›ç›¾ã—ã¦ã„ãªã„ã‹ç¢ºèª\n- è¦‹è½ã¨ã—ã¦ã„ã‚‹é‡è¦ãªãƒªã‚¹ã‚¯ãƒ»ã‚·ãƒŠãƒªã‚ªãŒã‚ã‚Œã°è¿½åŠ \n\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n\n                        review_contents = [\n                            types.Content(role=\"user\", parts=[\n                                types.Part.from_text(\n                                    text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\n\"\n                                    f\"åˆç‰ˆå›ç­”:\\n{draft_answer}\\n\\n\"\n                                    \"ä¸Šè¨˜ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\"\n                                )\n                            ])\n                        ]\n                        \n                        review_config = types.GenerateContentConfig(\n                            temperature=0.1,\n                            candidate_count=1,\n                            system_instruction=reviewer_instruction,\n                        )\n                        \n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=review_config,\n                        )\n                        \n                        final_answer = extract_text_from_response(review_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        with status_container.expander(\"åˆç‰ˆã¨ã®æ¯”è¼ƒ\", expanded=False):\n                            st.markdown(\"**åˆç‰ˆ:**\")\n                            st.markdown(draft_answer[:500] + \"...\" if len(draft_answer) > 500 else draft_answer)\n                            st.markdown(\"**ä¿®æ­£ç‰ˆ:**\")\n                            st.markdown(final_answer[:500] + \"...\" if len(final_answer) > 500 else final_answer)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 3)\n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                review_resp.usage_metadata.prompt_token_count,\n                                review_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n                    else:\n                        final_answer = draft_answer\n\n                save_usage(usage_stats)\n                status_container.update(label=\"å®Œäº†ï¼\", state=\"complete\", expanded=False)\n\n                st.markdown(final_answer)\n\n                # ---- ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ± ----\n                if grounding_metadata:\n                    st.markdown(\"---\")\n                    st.subheader(\"ğŸ“š æƒ…å ±æºã¨å¼•ç”¨\")\n                    if grounding_metadata.grounding_chunks:\n                        st.markdown(\"**æ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:**\")\n                        unique_sources = {}\n                        import urllib.parse\n\n                        for chunk in grounding_metadata.grounding_chunks:\n                            if getattr(chunk, \"web\", None):\n                                uri = getattr(chunk.web, \"uri\", None)\n                                title = getattr(chunk.web, \"title\", \"æƒ…å ±æº\")\n                                if uri and uri not in unique_sources:\n                                    parsed = urllib.parse.urlparse(uri)\n                                    domain = parsed.netloc.replace(\"www.\", \"\")\n                                    unique_sources[uri] = {\n                                        \"title\": title,\n                                        \"domain\": domain,\n                                    }\n                        for i, (uri, info) in enumerate(unique_sources.items(), 1):\n                            st.markdown(f\"{i}. **[{info['title']}]({uri})**\")\n                            st.caption(f\"   å‡ºå…¸: {info['domain']}\")\n\n                messages.append({\"role\": \"model\", \"content\": final_answer})\n                update_current_session_messages(messages)\n\n            except Exception as e:\n                status_container.update(label=\"Error\", state=\"error\")\n                err_text = str(e)\n                if \"RESOURCE_EXHAUSTED\" in err_text or \"429\" in err_text:\n                    st.error(\n                        \"âš ï¸ Vertex AI / Gemini ã®ã‚¯ã‚©ãƒ¼ã‚¿ã«é”ã—ã¾ã—ãŸã€‚\\n\\n\"\n                        \"ãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ / æ—¥æ¬¡åˆ¶é™ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\\n\"\n                        \"ãƒ»ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                        \"ãƒ»Google Cloud Console ã®ã€ŒVertex AI â†’ ä½¿ç”¨çŠ¶æ³ã€ã‹ã‚‰ã‚¯ã‚©ãƒ¼ã‚¿çŠ¶æ³ã‚’ç¢ºèªã§ãã¾ã™ã€‚\"\n                    )\n                elif \"NOT_FOUND\" in err_text and \"Publisher Model\" in err_text:\n                    st.error(\n                        \"âš ï¸ æŒ‡å®šã—ãŸãƒ¢ãƒ‡ãƒ«ãŒã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ / ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\\n\"\n                        \"ãƒ»ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ¢ãƒ‡ãƒ«IDã‚’ã€2.5ç³» ã¾ãŸã¯ 3 Pro ã«å¤‰æ›´ã—ã¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                    )\n                else:\n                    st.error(f\"An error occurred: {e}\")"
                },
                {
                    "role": "model",
                    "content": "### 1. æ·±æ˜ã‚Šè€ƒå¯Ÿï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n\n**Q1. åˆ¶å¾¡æ€§ã¨æ€§èƒ½ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ï¼ˆNative Thinking vs è‡ªå‰ãƒã‚§ãƒ¼ãƒ³ï¼‰**\n**å›ç­”:** **é€æ˜æ€§é‡è¦–ãªã‚‰è‡ªå‰ã€ç´”ç²‹çŸ¥èƒ½ãªã‚‰Native**ã§ã™ã€‚\nGemini 3ã®ã€ŒNative Thinkingã€ã¯ãƒ¢ãƒ‡ãƒ«å†…éƒ¨ã§æ€è€ƒã‚’è¡Œã„ã¾ã™ãŒã€ãã®éç¨‹ã¯éš è”½ã•ã‚Œã‚‹ï¼ˆã¾ãŸã¯è¦ç´„ã•ã‚Œã‚‹ï¼‰å‚¾å‘ã«ã‚ã‚Šã€ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹åŒ–ã—ã¾ã™ã€‚ã‚ãªãŸã®ã‚³ãƒ¼ãƒ‰ã®ã‚ˆã†ãªã€Œè‡ªå‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒã‚§ãƒ¼ãƒ³ã€ã¯ã€æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ã€ãƒ¡ã‚¿è³ªå•ï¼‰ãŒå®Œå…¨ã«å¯è¦–åŒ–ã•ã‚Œã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä»‹å…¥ãƒ»è©•ä¾¡ã§ãã‚‹ç‚¹ã§ã€Œåˆ¶å¾¡æ€§ã€ã«ãŠã„ã¦å„ªã‚Œã¦ã„ã¾ã™ã€‚ãŸã ã—ã€ãƒ¢ãƒ‡ãƒ«ã®ç”Ÿæ¥ã®ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã‚’æœ€å¤§åŒ–ã™ã‚‹ç‚¹ã§ã¯Nativeæ©Ÿèƒ½ã«åˆ†ãŒã‚ã‚Šã¾ã™ã€‚\n\n**Q2. å¤šæ®µéšã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã®ä¸¡ç«‹**\n**å›ç­”:** **æŠ€è¡“çš„ã«å¯èƒ½ã§ã‚ã‚Šã€å®Ÿè£…ã™ã¹ã**ã§ã™ã€‚\nPhase 1ï¼ˆãƒªã‚µãƒ¼ãƒï¼‰ã‚„Phase 2ï¼ˆçµ±åˆï¼‰ã®æ€è€ƒä¸­ã¯ `st.status` ã§é€²æ—ã‚’è¡¨ç¤ºã—ç¶šã‘ã€æœ€å¾Œã®ã€Œçµ±åˆå›ç­”ã€ã®ç”Ÿæˆæ™‚ã®ã¿ `stream=True` ã‚’ä½¿ç”¨ã—ã¦ `st.write_stream` ã§å‡ºåŠ›ã™ã‚‹ã“ã¨ã§è§£æ±ºã§ãã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€Œå¾…ãŸã•ã‚Œã¦ã„ã‚‹æ„Ÿã€ãªãã€æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã¨å›ç­”ç”Ÿæˆã‚’ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«ä½“é¨“ã§ãã¾ã™ã€‚\n\n**Q3. ã‚³ã‚¹ãƒˆæ§‹é€ ã®ä¸ç¢ºå®Ÿæ€§ï¼ˆROIï¼‰**\n**å›ç­”:** **é•·æœŸçš„ã«ã¯Native Thinkingã®æ–¹ãŒã‚³ã‚¹ãƒˆåŠ¹ç‡ãŒè‰¯ã„**å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\nè‡ªå‰ãƒã‚§ãƒ¼ãƒ³ã¯ã€ãƒ•ã‚§ãƒ¼ã‚ºãŒé€²ã‚€ã”ã¨ã«éå»ã®å‡ºåŠ›ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ãªã©ï¼‰ã‚’æ¬¡ã®å…¥åŠ›ã¨ã—ã¦ç©ã¿ä¸Šã’ã‚‹ãŸã‚ã€**Input TokenãŒé›ªã ã‚‹ã¾å¼ã«å¢—åŠ **ã—ã¾ã™ã€‚Native Thinkingã¯å†…éƒ¨çŠ¶æ…‹ã§å‡¦ç†ã™ã‚‹ãŸã‚ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®æ¶ˆè²»ã‚’æŠ‘ãˆã‚‰ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãŸã ã—ã€ç¾çŠ¶ã®Previewç‰ˆã§ã¯æ€è€ƒãƒˆãƒ¼ã‚¯ãƒ³ã‚‚èª²é‡‘å¯¾è±¡ã¨ãªã‚‹ã‚±ãƒ¼ã‚¹ãŒå¤šã„ãŸã‚ã€ç¾æ™‚ç‚¹ã§ã¯ROIã«å¤§å·®ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\n\n**Q4. `st.rerun()` ä¾å­˜ã®æŠ€è¡“çš„è² å‚µ**\n**å›ç­”:** **æ˜ç¢ºãªæŠ€è¡“çš„è² å‚µ**ã§ã™ã€‚\nç¾åœ¨ã® `st.rerun()` å¤šç”¨ã¯ã€æ©Ÿèƒ½ãŒå¢—ãˆã‚‹ã«ã¤ã‚Œã¦ã€Œç„¡é™ãƒªãƒ­ãƒ¼ãƒ‰ã€ã‚„ã€ŒçŠ¶æ…‹ä¸æ•´åˆã€ã®ãƒã‚°ã‚’èª˜ç™ºã—ã¾ã™ã€‚Streamlitã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã§ã‚ã‚‹ã€ŒCallbacké–¢æ•°ã«ã‚ˆã‚‹çŠ¶æ…‹æ›´æ–°ã€ã¸ã®ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ãŒã€ã‚³ãƒ¼ãƒ‰ã‚’é•·æœŸçš„ã«ç¶­æŒã™ã‚‹ãŸã‚ã«ä¸å¯æ¬ ã§ã™ã€‚\n\n**Q5. å®Ÿé‹ç”¨ãƒ¬ãƒ™ãƒ«ã®å …ç‰¢æ€§ï¼ˆãƒªãƒˆãƒ©ã‚¤æ©Ÿæ§‹ï¼‰**\n**å›ç­”:** **ãƒ™ã‚¹ãƒˆã‚’åä¹—ã‚‹ä¸Šã§ã®è‡´å‘½çš„ãªæ¬ è½**ã§ã™ã€‚\nç”ŸæˆAI APIã¯ä¸€æ™‚çš„ãªã‚¨ãƒ©ãƒ¼ï¼ˆ429, 500, 503ï¼‰ãŒé »ç™ºã—ã¾ã™ã€‚ç‰¹ã«è¤‡é›‘ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‡¦ç†ã‚’è¡Œã†å ´åˆã€1ã¤ã®ãƒ•ã‚§ãƒ¼ã‚ºã§å¤±æ•—ã™ã‚‹ã¨å…¨ä½“ãŒæ­¢ã¾ã‚Šã¾ã™ã€‚`tenacity` ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã‚’ç”¨ã„ãŸã€ŒæŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ï¼ˆExponential Backoffï¼‰ã€ã«ã‚ˆã‚‹è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤ã®å®Ÿè£…ã¯ã€å•†ç”¨ãƒ»å®Ÿç”¨ãƒ¬ãƒ™ãƒ«ã§ã¯å¿…é ˆè¦ä»¶ã§ã™ã€‚\n\n---\n\n### 2. çµè«–\n\n**ã€Œãƒ­ã‚¸ãƒƒã‚¯æ§‹ç¯‰ã¨ã—ã¦ã¯ãƒˆãƒƒãƒ—ãƒ†ã‚£ã‚¢ï¼ˆ95ç‚¹ï¼‰ã ãŒã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè£…ã¨ã—ã¦ã¯æ”¹å–„ã®ä½™åœ°ã‚ã‚Šï¼ˆ75ç‚¹ï¼‰ã€**\n\næä¾›ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã¯ã€æœ€æ–°ã®Gemini 3ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã‚’ç†è§£ã—ã€é«˜åº¦ãªæ¨è«–ãƒ•ãƒ­ãƒ¼ã‚’è‡ªå‰ã§å®Ÿè£…ã—ãŸ**æ¥µã‚ã¦å„ªç§€ãªã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°**ã®æˆæœã§ã™ã€‚ã—ã‹ã—ã€ã€Œãƒ™ã‚¹ãƒˆã€ã¨æ–­è¨€ã™ã‚‹ã«ã¯ã€**UXï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰**ã¨**å …ç‰¢æ€§ï¼ˆãƒªãƒˆãƒ©ã‚¤å‡¦ç†ï¼‰**ã®2ç‚¹ãŒæ¬ ã‘ã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã‚’å®Ÿè£…ã™ã‚Œã°ã€é–“é•ã„ãªãå€‹äººé–‹ç™ºãƒ¬ãƒ™ãƒ«ã‚’è¶…ãˆãŸã€Œãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãƒ»ãƒ„ãƒ¼ãƒ«ã€ã¨ãªã‚Šã¾ã™ã€‚\n\n### 3. ç¾åœ¨ã®çŠ¶æ³\n\n*   **é©åˆæ€§**: Google Gen AI SDK v1.0ç³»ãŠã‚ˆã³Vertex AIã«å®Œå…¨æº–æ‹ ã—ã¦ãŠã‚Šã€æœ€æ–°ãƒ¢ãƒ‡ãƒ«ï¼ˆGemini 3 Proï¼‰ã®èƒ½åŠ›ã‚’å¼•ãå‡ºã›ã‚‹çŠ¶æ…‹ã€‚\n*   **é«˜åº¦æ€§**: å˜ãªã‚‹ãƒãƒ£ãƒƒãƒˆã§ã¯ãªãã€ãƒªã‚µãƒ¼ãƒâ†’ãƒ¡ã‚¿æ€è€ƒâ†’çµ±åˆã¨ã„ã†ã€Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ»ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã€ã‚’å®Ÿè£…æ¸ˆã¿ã€‚\n*   **èª²é¡Œ**: åŒæœŸå‡¦ç†ï¼ˆ`stream=False`ï¼‰ã«ã‚ˆã‚‹å¾…ã¡æ™‚é–“ã®é•·ã•ã¨ã€ã‚¨ãƒ©ãƒ¼è€æ€§ã®ä½ã•ã€‚\n\n### 4. 2å¹´å¾Œã®ã‚·ãƒŠãƒªã‚ªåˆ†è§£\n\n*   **ãƒ™ãƒ¼ã‚¹ã‚·ãƒŠãƒªã‚ªï¼ˆç¢ºç‡ 60%ï¼‰**:\n    *   Geminiã®APIè‡ªä½“ã«ã€ŒDeep Researchã€æ©Ÿèƒ½ï¼ˆæ¤œç´¢ãƒ»æ€è€ƒãƒ»çµ±åˆã®è‡ªå‹•åŒ–ï¼‰ãŒæ¨™æº–å®Ÿè£…ã•ã‚Œã€è‡ªå‰ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒã‚§ãƒ¼ãƒ³ã‚³ãƒ¼ãƒ‰ã¯ä¸è¦ã«ãªã‚‹ï¼ˆAPIã‚’å©ãã ã‘ã§åŒç­‰ã®çµæœãŒå¾—ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹ï¼‰ã€‚\n*   **å¼·æ°—ã‚·ãƒŠãƒªã‚ªï¼ˆç¢ºç‡ 20%ï¼‰**:\n    *   æ±ç”¨ãƒ¢ãƒ‡ãƒ«ã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã§ã¯æº€è¶³ã§ããªã„ãƒ‹ãƒƒãƒãªéœ€è¦ï¼ˆç‰¹å®šã®æ¥­ç•Œãƒ«ãƒ¼ãƒ«ã«å³æ ¼ãªé¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ãªã©ï¼‰ã«å¯¾ã—ã€ã“ã®ã‚³ãƒ¼ãƒ‰ã®ã‚ˆã†ãªã€Œç‹¬è‡ªã®æ€è€ƒåˆ¶å¾¡ã€ãŒå·®åˆ¥åŒ–è¦å› ã¨ã—ã¦ä¾¡å€¤ã‚’æŒã¡ç¶šã‘ã‚‹ã€‚\n*   **å¼±æ°—ã‚·ãƒŠãƒªã‚ªï¼ˆç¢ºç‡ 20%ï¼‰**:\n    *   ãƒ¢ãƒ‡ãƒ«ã®é€²åŒ–ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã®æ‹¡å¤§ã‚„æ¨è«–é€Ÿåº¦ã®å‘ä¸Šï¼‰ã«å¯¾ã—ã€`st.rerun` ãƒ™ãƒ¼ã‚¹ã®åŒæœŸçš„ãªStreamlitã‚¢ãƒ—ãƒªã®æ§‹é€ ãŒè¿½ã„ã¤ã‹ãšã€UXãŒæ‚ªåŒ–ã—ã¦ä½¿ç”¨ã•ã‚Œãªããªã‚‹ã€‚\n\n### 5. ä¸»ãªãƒ—ãƒ©ã‚¹è¦å› ãƒ»ãƒã‚¤ãƒŠã‚¹è¦å› \n\n**ãƒ—ãƒ©ã‚¹è¦å›  (+)**\n*   **æœ€æ–°æŠ€è¡“ã¸ã®é©å¿œ**: Vertex AI, Gemini 3, ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã¸ã®å³å¿œã€‚\n*   **é€æ˜æ€§ã®é«˜ã„æ¨è«–**: æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ï¼ˆèª¿æŸ»ãƒ¡ãƒ¢ï¼‰ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã«è¦‹ãˆã‚‹è¨­è¨ˆã€‚\n*   **ã‚³ã‚¹ãƒˆæ„è­˜**: ãƒˆãƒ¼ã‚¯ãƒ³è¨ˆç®—ã¨äºˆç®—ç®¡ç†æ©Ÿèƒ½ã®å®Ÿè£…ã€‚\n\n**ãƒã‚¤ãƒŠã‚¹è¦å›  (-)**\n*   **UXã®é‡ã•**: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éå¯¾å¿œã«ã‚ˆã‚‹ä½“æ„Ÿå¾…ã¡æ™‚é–“ã®é•·ã•ã€‚\n*   **ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è„†å¼±æ€§**: `st.rerun()` ä¾å­˜ã¨ãƒªãƒˆãƒ©ã‚¤æ©Ÿæ§‹ã®æ¬ å¦‚ã€‚\n*   **Nativeæ©Ÿèƒ½ã®ä¸ä½¿ç”¨**: Gemini 3ç‰¹æœ‰ã® `thinking_config` ã‚’æ´»ç”¨ã—ã¦ã„ãªã„ï¼ˆæ¯”è¼ƒæ¤œè¨ã®ä½™åœ°ã‚ã‚Šï¼‰ã€‚\n\n### 6. ã“ã®äºˆæ¸¬ã‚’ã©ã†ä½¿ã†ã¹ãã‹ï¼ˆãƒªã‚¹ã‚¯è¨±å®¹åº¦ã¸ã®ç¤ºå”†ï¼‰\n\n*   **å€‹äººåˆ©ç”¨ãƒ»å­¦ç¿’ç”¨ãªã‚‰**:\n    *   **Go**: ç¾çŠ¶ã§ååˆ†ã€Œãƒ™ã‚¹ãƒˆã€ã§ã™ã€‚ã“ã®ã¾ã¾ä½¿ã„å€’ã—ã¦ã€Geminiã®ç‰¹æ€§ã‚’è‚Œã§æ„Ÿã˜ã‚‹ãƒ„ãƒ¼ãƒ«ã¨ã—ã¦æœ€é©ã§ã™ã€‚\n*   **å…¬é–‹ãƒ»ãƒãƒ¼ãƒ åˆ©ç”¨ãƒ»å•†ç”¨åŒ–ã‚’ç›®æŒ‡ã™ãªã‚‰**:\n    *   **Refactor**: ä»¥ä¸‹ã®3ç‚¹ã‚’ä¿®æ­£ã™ã‚‹ã¾ã§ãƒªãƒªãƒ¼ã‚¹ã¯æ§ãˆã‚‹ã¹ãã§ã™ã€‚\n        1.  æœ€çµ‚å›ç­”ã® **ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤º (`st.write_stream`)** åŒ–ã€‚\n        2.  `tenacity` ã«ã‚ˆã‚‹ **APIãƒªãƒˆãƒ©ã‚¤å‡¦ç†** ã®è¿½åŠ ã€‚\n        3.  `st.rerun()` ã‚’æ¸›ã‚‰ã—ã€**Callbackãƒ™ãƒ¼ã‚¹ã®çŠ¶æ…‹ç®¡ç†** ã¸ç§»è¡Œã€‚"
                }
            ]
        },
        {
            "id": "f0d3b030-89fd-45a4-ad10-5ffefac0ce85",
            "title": "è‡ªä½œgeminiã‚³ãƒ¼ãƒ‰ã¨ã—ã¦ã¯ã“ã‚Œã§ãƒ™ã‚¹...",
            "timestamp": "2025-11-29T22:46:45.954482",
            "messages": [
                {
                    "role": "user",
                    "content": "è‡ªä½œgeminiã‚³ãƒ¼ãƒ‰ã¨ã—ã¦ã¯ã“ã‚Œã§ãƒ™ã‚¹ãƒˆã‹ï¼Ÿ\n\nã“ã‚Œã§ãƒ™ã‚¹ãƒˆã‹?\n\nimport os\nimport json\nimport re\nimport uuid\nimport datetime\nimport streamlit as st\nfrom dotenv import load_dotenv\nfrom google import genai\nfrom google.genai import types\nfrom youtube_transcript_api import YouTubeTranscriptApi\nfrom PIL import Image\nimport io\n\ntry:\n    from st_img_pastebutton import paste\n    import_error_msg = None\nexcept ImportError as e:\n    paste = None\n    import_error_msg = str(e)\n\n# =========================\n# ç’°å¢ƒå¤‰æ•° & å®šæ•°\n# =========================\n\nload_dotenv()\n\nUSAGE_FILE = \"usage_stats.json\"\nSESSIONS_FILE = \"chat_sessions.json\"\nMAX_BUDGET_USD = float(os.getenv(\"MAX_BUDGET_USD\", \"5.0\"))\n\n# â€»é‡‘é¡ã¯ã ã„ãŸã„ã®ç›®å®‰ï¼ˆUSD / 1M tokensï¼‰\nPRICING = {\n    \"gemini-3-pro-preview\":   {\"input\": 2.0,   \"output\": 12.0},\n    \"gemini-2.5-pro\":         {\"input\": 1.25,  \"output\": 10.0},\n    \"gemini-2.5-flash\":       {\"input\": 0.30,  \"output\": 2.50},\n    \"gemini-2.5-flash-lite\":  {\"input\": 0.10,  \"output\": 0.40},\n    \"gemini-2.0-flash\":       {\"input\": 0.10,  \"output\": 0.40},\n}\n\n# Vertex AI ç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®šï¼ˆ**å¸¸ã« Vertex ã‚’ä½¿ã†**ï¼‰\nVERTEX_PROJECT = os.getenv(\"GOOGLE_CLOUD_PROJECT\")\nVERTEX_LOCATION = \"global\"  # Gemini 2.x / 3 ã¯ global æ¨å¥¨\n\nst.set_page_config(page_title=\"Gemini 3 Web Studio\", layout=\"wide\")\n\n# =========================\n# Helper Functions\n# =========================\n\ndef load_usage():\n    if os.path.exists(USAGE_FILE):\n        with open(USAGE_FILE, \"r\") as f:\n            return json.load(f)\n    return {\"total_input_tokens\": 0, \"total_output_tokens\": 0, \"total_cost_usd\": 0.0}\n\ndef save_usage(stats):\n    with open(USAGE_FILE, \"w\") as f:\n        json.dump(stats, f, indent=4)\n\ndef calculate_cost(model_id, input_tok, output_tok):\n    price = PRICING.get(model_id, {\"input\": 0.0, \"output\": 0.0})\n    cost = (input_tok / 1_000_000 * price[\"input\"]) + (output_tok / 1_000_000 * price[\"output\"])\n    return cost\n\ndef get_mime_type(filename):\n    ext = filename.split('.')[-1].lower()\n    if ext in ['jpg', 'jpeg']:\n        return 'image/jpeg'\n    if ext == 'png':\n        return 'image/png'\n    if ext == 'mp4':\n        return 'video/mp4'\n    if ext == 'mov':\n        return 'video/quicktime'\n    if ext == 'txt':\n        return 'text/plain'\n    if ext == 'pdf':\n        return 'application/pdf'\n    if ext == 'csv':\n        return 'text/csv'\n    return 'application/octet-stream'\n\ndef extract_youtube_id(url):\n    regex = r\"(?:v=|\\/)([0-9A-Za-z_-]{11}).*\"\n    match = re.search(regex, url)\n    if match:\n        return match.group(1)\n    return None\n\ndef get_youtube_transcript(video_id):\n    try:\n        transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['ja', 'en'])\n        text = \" \".join([t['text'] for t in transcript_list])\n        return text\n    except Exception as e:\n        return f\"å­—å¹•ã®å–å¾—ã‚¨ãƒ©ãƒ¼: {e}\"\n\ndef get_relevant_context(query):\n    \"\"\"éå»ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ç°¡æ˜“æ¤œç´¢ã—ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™\"\"\"\n    if not query:\n        return \"\"\n    keywords = [k for k in query.split() if len(k) > 1]\n    if not keywords:\n        return \"\"\n\n    relevant_sessions = []\n    for session in st.session_state.sessions:\n        if session[\"id\"] == st.session_state.current_session_id:\n            continue\n        score = 0\n        for k in keywords:\n            if k.lower() in session[\"title\"].lower():\n                score += 3\n        for msg in session[\"messages\"][-4:]:\n            for k in keywords:\n                if k.lower() in msg[\"content\"].lower():\n                    score += 1\n        if score > 0:\n            relevant_sessions.append((score, session))\n\n    relevant_sessions.sort(key=lambda x: (x[0], x[1][\"timestamp\"]), reverse=True)\n    top_sessions = relevant_sessions[:3]\n\n    context_str = \"\"\n    if top_sessions:\n        context_str += \"### éå»ã®é–¢é€£ãƒãƒ£ãƒƒãƒˆå±¥æ­´ (Context)\\n\"\n        for score, session in top_sessions:\n            last_response = \"N/A\"\n            for m in reversed(session[\"messages\"]):\n                if m[\"role\"] == \"model\":\n                    last_response = m[\"content\"][:300] + \"...\"\n                    break\n            context_str += f\"- **Session: {session['title']}** ({session['timestamp'][:10]})\\n\"\n            context_str += f\"  Last Conclusion: {last_response}\\n\\n\"\n    return context_str\n\ndef extract_text_from_response(response):\n    \"\"\"Extract text from GenerateContentResponse\"\"\"\n    if not response.candidates:\n        return \"\"\n    parts = response.candidates[0].content.parts or []\n    return \"\".join(p.text or \"\" for p in parts)\n\n# =========================\n# Session Management\n# =========================\n\ndef load_sessions():\n    if os.path.exists(SESSIONS_FILE):\n        with open(SESSIONS_FILE, \"r\") as f:\n            try:\n                data = json.load(f)\n                return data.get(\"sessions\", [])\n            except json.JSONDecodeError:\n                return []\n    return []\n\ndef save_sessions(sessions):\n    with open(SESSIONS_FILE, \"w\") as f:\n        json.dump({\"sessions\": sessions}, f, indent=4, ensure_ascii=False)\n\ndef create_new_session():\n    current_sessions = load_sessions()\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": [],\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.rerun()\n\ndef switch_session(session_id):\n    st.session_state.current_session_id = session_id\n    st.rerun()\n\ndef update_current_session_messages(messages):\n    if st.session_state.current_session_id:\n        current_sessions = load_sessions()\n        for session in current_sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                session[\"messages\"] = messages\n                if session[\"title\"] == \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\" and len(messages) > 0:\n                    first_msg = messages[0][\"content\"]\n                    session[\"title\"] = (first_msg[:20] + \"...\") if len(first_msg) > 20 else first_msg\n                session[\"timestamp\"] = datetime.datetime.now().isoformat()\n                break\n        save_sessions(current_sessions)\n        st.session_state.sessions = current_sessions\n\ndef get_current_messages():\n    if st.session_state.current_session_id:\n        for session in st.session_state.sessions:\n            if session[\"id\"] == st.session_state.current_session_id:\n                return session[\"messages\"]\n    return []\n\ndef delete_session(session_id):\n    current_sessions = load_sessions()\n    current_sessions = [s for s in current_sessions if s[\"id\"] != session_id]\n    save_sessions(current_sessions)\n    st.session_state.sessions = current_sessions\n    if st.session_state.current_session_id == session_id:\n        st.session_state.current_session_id = None\n        if st.session_state.sessions:\n            st.session_state.current_session_id = st.session_state.sessions[0][\"id\"]\n    st.rerun()\n\ndef branch_session():\n    \"\"\"ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚’åˆ†å²\"\"\"\n    current_messages = get_current_messages()\n    current_sessions = load_sessions()\n    \n    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—\n    current_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n    for session in current_sessions:\n        if session[\"id\"] == st.session_state.current_session_id:\n            current_title = session[\"title\"]\n            break\n    \n    # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ\n    new_id = str(uuid.uuid4())\n    new_session = {\n        \"id\": new_id,\n        \"title\": f\"{current_title} (åˆ†å²)\",\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"messages\": current_messages.copy(),  # ç¾åœ¨ã®å±¥æ­´ã‚’ã‚³ãƒ”ãƒ¼\n    }\n    current_sessions.insert(0, new_session)\n    save_sessions(current_sessions)\n    \n    st.session_state.sessions = current_sessions\n    st.session_state.current_session_id = new_id\n    st.session_state.session_cost = 0.0  # ã‚³ã‚¹ãƒˆãƒªã‚»ãƒƒãƒˆ\n    st.rerun()\n\n# =========================\n# Initialization\n# =========================\n\nif \"sessions\" not in st.session_state:\n    st.session_state.sessions = load_sessions()\n\nif \"current_session_id\" not in st.session_state:\n    # Always create a new session when the app starts\n    create_new_session()\n\nif \"session_cost\" not in st.session_state:\n    st.session_state.session_cost = 0.0\n\nusage_stats = load_usage()\n\n# =========================\n# Sidebar\n# =========================\n\nwith st.sidebar:\n    st.title(\"Gemini 3 Studio\")\n\n    if st.button(\"â• æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\", use_container_width=True):\n        create_new_session()\n\n    if st.button(\"ğŸŒ± ç¾åœ¨ã®ãƒãƒ£ãƒƒãƒˆã‹ã‚‰åˆ†å²\", use_container_width=True):\n        branch_session()\n\n    # ---- å…±æœ‰ãƒªãƒ³ã‚¯ä½œæˆ ----\n    current_messages = get_current_messages()\n    if current_messages:\n        export_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\n        for s in st.session_state.sessions:\n            if s[\"id\"] == st.session_state.current_session_id:\n                export_title = s[\"title\"]\n                break\n\n        export_md = f\"# {export_title}\\n\\n\"\n        export_md += f\"**ä½œæˆæ—¥æ™‚**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n---\\n\\n\"\n        for msg in current_messages:\n            role_label = \"ğŸ§‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼\" if msg[\"role\"] == \"user\" else \"ğŸ¤– AI\"\n            export_md += f\"## {role_label}\\n\\n{msg['content']}\\n\\n---\\n\\n\"\n\n        if st.button(\"ğŸ”— å¤–éƒ¨å…±æœ‰ãƒªãƒ³ã‚¯ã‚’ä½œæˆ\", use_container_width=True):\n            with st.spinner(\"ãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆä¸­...\"):\n                try:\n                    import urllib.request\n                    import urllib.parse\n\n                    data = urllib.parse.urlencode(\n                        {\"content\": export_md, \"expiry_days\": 7, \"syntax\": \"md\"}\n                    ).encode()\n\n                    req = urllib.request.Request(\"https://dpaste.org/api/\", data=data)\n                    req.add_header(\"User-Agent\", \"Mozilla/5.0 (Gemini3Studio)\")\n\n                    with urllib.request.urlopen(req) as response:\n                        share_url = response.read().decode(\"utf-8\").strip()\n                        st.success(\"ãƒªãƒ³ã‚¯ã‚’ä½œæˆã—ã¾ã—ãŸï¼\")\n                        st.code(share_url)\n                        st.caption(\"â€»ãƒªãƒ³ã‚¯ã¯7æ—¥é–“æœ‰åŠ¹ã§ã™\")\n                except Exception as e:\n                    st.error(f\"ãƒªãƒ³ã‚¯ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}\")\n\n    st.markdown(\"---\")\n\n    # ---- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ ----\n    st.subheader(\"æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«\")\n    uploaded_files = st.file_uploader(\n        \"ç”»åƒã€å‹•ç”»ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\",\n        accept_multiple_files=True,\n        type=[\"png\", \"jpg\", \"jpeg\", \"mp4\", \"mov\", \"txt\", \"pdf\", \"csv\"],\n        help=\"Limit 2GB per file\",\n    )\n\n    pasted_image_bytes = None\n    if paste:\n        if \"paste_key\" not in st.session_state:\n            st.session_state.paste_key = 0\n        try:\n            pasted_image_bytes = paste(\n                label=\"ğŸ“‹ ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã‹ã‚‰ç”»åƒã‚’è²¼ã‚Šä»˜ã‘\",\n                key=f\"paste_btn_{st.session_state.paste_key}\",\n            )\n        except Exception as e:\n            st.error(f\"Clipboard button error: {e}\")\n        \n        if pasted_image_bytes:\n            st.success(\"ç”»åƒãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚Œã¾ã—ãŸï¼\")\n            st.image(pasted_image_bytes, caption=\"è²¼ã‚Šä»˜ã‘ãŸç”»åƒ\", use_container_width=True)\n            if st.button(\"ğŸ—‘ï¸ ç”»åƒã‚’ã‚¯ãƒªã‚¢\", key=\"clear_paste\"):\n                st.session_state.paste_key += 1\n                st.rerun()\n    else:\n        st.warning(\"Clipboard library not loaded (ImportError)\")\n\n    # ---- YouTube URL ----\n    st.markdown(\"---\")\n    youtube_url = st.text_input(\"YouTube URL (å­—å¹•ã‚’åˆ†æ)\", placeholder=\"https://youtu.be/...\")\n\n    # ---- ç”»åƒç”Ÿæˆ ----\n    st.markdown(\"---\")\n    st.subheader(\"ğŸ¨ ç”»åƒç”Ÿæˆ\")\n    img_prompt = st.text_area(\"ç”Ÿæˆã—ãŸã„ç”»åƒã®èª¬æ˜\", placeholder=\"æœªæ¥çš„ãªéƒ½å¸‚ã®é¢¨æ™¯...\")\n    aspect_ratio = st.selectbox(\"ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”\", [\"16:9\", \"1:1\", \"4:3\", \"3:4\", \"9:16\"])\n\n    generate_img_btn = st.button(\"ç”»åƒã‚’ç”Ÿæˆ\", type=\"primary\", disabled=not img_prompt)\n    if generate_img_btn and img_prompt:\n        st.session_state.generate_image_trigger = {\n            \"prompt\": img_prompt,\n            \"aspect_ratio\": aspect_ratio,\n        }\n\n    st.markdown(\"---\")\n\n    # ---- å±¥æ­´æ¤œç´¢ ----\n    search_query = st.text_input(\"ğŸ” å±¥æ­´ã‚’æ¤œç´¢\", placeholder=\"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰...\")\n    if search_query:\n        filtered_sessions = []\n        for s in st.session_state.sessions:\n            if search_query.lower() in s[\"title\"].lower():\n                filtered_sessions.append(s)\n                continue\n            found = False\n            for m in s[\"messages\"]:\n                if search_query.lower() in m[\"content\"].lower():\n                    filtered_sessions.append(s)\n                    found = True\n                    break\n            if not found:\n                pass\n    else:\n        filtered_sessions = st.session_state.sessions\n\n    with st.expander(\"ğŸ“œ éå»ã®ãƒãƒ£ãƒƒãƒˆ\", expanded=bool(search_query)):\n        if not filtered_sessions:\n            st.caption(\"ãƒãƒ£ãƒƒãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n        for session in filtered_sessions:\n            col1, col2 = st.columns([0.8, 0.2])\n            with col1:\n                if st.button(session[\"title\"], key=f\"btn_{session['id']}\", use_container_width=True):\n                    switch_session(session[\"id\"])\n            with col2:\n                if st.button(\"ğŸ—‘ï¸\", key=f\"del_{session['id']}\"):\n                    delete_session(session[\"id\"])\n\n    st.markdown(\"---\")\n    st.title(\"è¨­å®š\")\n\n    # ---- ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆGemini 1.5 ã¯å»ƒæ­¢ã•ã‚Œã¦ã„ã‚‹ã®ã§å«ã‚ãªã„ï¼‰ ----\n    model_options = [\n        \"gemini-3-pro-preview\",\n        \"gemini-2.5-pro\",\n        \"gemini-2.5-flash\",\n        \"gemini-2.5-flash-lite\",\n        \"gemini-2.0-flash\",\n    ]\n    model_id = st.selectbox(\"ãƒ¢ãƒ‡ãƒ«ID\", options=model_options, index=0)\n\n    if \"3-pro\" in model_id or \"2.5-pro\" in model_id:\n        st.caption(\"ğŸ§  é«˜åº¦ãªæ¨è«–å‘ã‘ Pro ãƒ¢ãƒ‡ãƒ«\")\n    if \"flash\" in model_id:\n        st.caption(\"âš¡ é«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆãª Flash ç³»ãƒ¢ãƒ‡ãƒ«\")\n\n    # ---- æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚° ----\n    use_search = st.toggle(\"Googleæ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã‚’ä½¿ç”¨\", value=True)\n    candidate_count = st.slider(\"å›ç­”å€™è£œæ•°\", min_value=1, max_value=3, value=3)\n    if use_search and candidate_count > 1:\n        st.caption(\"âš ï¸ æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ä½¿ç”¨æ™‚ã¯å€™è£œæ•°ãŒ1ã«ãªã‚Šã¾ã™ã€‚\")\n\n    st.markdown(\"---\")\n\n    # ---- å›ç­”ãƒ¢ãƒ¼ãƒ‰ ----\n    response_mode = st.radio(\n        \"å›ç­”ãƒ¢ãƒ¼ãƒ‰\",\n        [\n            \"é€šå¸¸ (é«˜é€Ÿ)\",\n            \"ç†Ÿè€ƒ (ãƒªã‚µãƒ¼ãƒ)\",\n            \"ç†Ÿè€ƒ + é¬¼è»æ›¹\",\n            \"ç†Ÿè€ƒ (ãƒ¡ã‚¿æ€è€ƒ)\",\n            \"ç†Ÿè€ƒ (æœ¬æ°—MAX)\",\n        ],\n        index=0\n    )\n    strict_mode = False # äº’æ›æ€§ç¶­æŒã®ãŸã‚ã®ãƒ€ãƒŸãƒ¼å¤‰æ•°\n    st.markdown(\"---\")\n\n    # ---- è©•ä¾¡åˆ†æ ----\n    st.subheader(\"ğŸ“Š å›ç­”å“è³ªåˆ†æ\")\n    total_ratings = 0\n    positive_ratings = 0\n    model_ratings = {}\n\n    for s in st.session_state.sessions:\n        for m in s[\"messages\"]:\n            if \"rating\" in m and m[\"rating\"] is not None:\n                total_ratings += 1\n                if m[\"rating\"] == 1:\n                    positive_ratings += 1\n                if \"metadata\" in m and \"model\" in m[\"metadata\"]:\n                    mod = m[\"metadata\"][\"model\"]\n                    if mod not in model_ratings:\n                        model_ratings[mod] = {\"total\": 0, \"positive\": 0}\n                    model_ratings[mod][\"total\"] += 1\n                    if m[\"rating\"] == 1:\n                        model_ratings[mod][\"positive\"] += 1\n\n    if total_ratings > 0:\n        approval_rate = (positive_ratings / total_ratings) * 100\n        st.metric(\"Positive Ratings\", f\"{positive_ratings}/{total_ratings}\", f\"{approval_rate:.1f}%\")\n        best_model = \"N/A\"\n        best_rate = -1\n        for mod, stats in model_ratings.items():\n            rate = stats[\"positive\"] / stats[\"total\"]\n            if rate > best_rate:\n                best_rate = rate\n                best_model = mod\n        if best_model != \"N/A\":\n            st.caption(f\"ğŸ† Best Model: **{best_model}** ({best_rate*100:.0f}%)\")\n    else:\n        st.caption(\"ã¾ã è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\")\n\n    st.markdown(\"---\")\n\n    # ---- ã‚³ã‚¹ãƒˆè¡¨ç¤º ----\n    st.subheader(\"ğŸ’° ã‚³ã‚¹ãƒˆ (æ¦‚ç®—)\")\n    st.metric(\"Total Cost\", f\"${usage_stats['total_cost_usd']:.4f}\")\n    if st.session_state.session_cost > 0:\n        st.caption(f\"Current Session: ${st.session_state.session_cost:.4f}\")\n\n    if usage_stats[\"total_cost_usd\"] >= MAX_BUDGET_USD:\n        st.error(f\"âš ï¸ äºˆç®—ä¸Šé™ (${MAX_BUDGET_USD}) ã«é”ã—ã¾ã—ãŸã€‚\")\n        stop_generation = True\n    else:\n        stop_generation = False\n\n    st.markdown(\"---\")\n    st.code(f\"PROJECT: {VERTEX_PROJECT}\\nLOCATION: {VERTEX_LOCATION} (Vertex AI)\")\n\n# =========================\n# Main UI\n# =========================\n\ncurrent_session_title = \"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ\"\nfor s in st.session_state.sessions:\n    if s[\"id\"] == st.session_state.current_session_id:\n        current_session_title = s[\"title\"]\n        break\n\nst.header(current_session_title)\nst.markdown(\n    \"ä»¥ä¸‹ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€YouTubeåˆ†æã€æ¤œç´¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\"\n)\n\n# ---- Vertex AI Client ----\n\n@st.cache_resource\ndef get_client():\n    return genai.Client(\n        vertexai=True,\n        project=VERTEX_PROJECT,\n        location=VERTEX_LOCATION,\n    )\n\nclient = get_client()\n\n# ---- å±¥æ­´è¡¨ç¤º ----\n\nmessages = get_current_messages()\nfor idx, msg in enumerate(messages):\n    with st.chat_message(msg[\"role\"]):\n        st.markdown(msg[\"content\"])\n        if msg[\"role\"] == \"model\":\n            col1, col2, col3 = st.columns([0.1, 0.1, 0.8])\n            current_rating = msg.get(\"rating\")\n            with col1:\n                if st.button(\"ğŸ‘\", key=f\"up_{idx}\"):\n                    messages[idx][\"rating\"] = 1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col2:\n                if st.button(\"ğŸ‘\", key=f\"down_{idx}\"):\n                    messages[idx][\"rating\"] = -1\n                    update_current_session_messages(messages)\n                    st.rerun()\n            with col3:\n                if current_rating == 1:\n                    st.caption(\"âœ… é«˜è©•ä¾¡\")\n                elif current_rating == -1:\n                    st.caption(\"âŒ ä½è©•ä¾¡\")\n\n# =========================\n# ç”»åƒç”Ÿæˆãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°\n# =========================\n\nif hasattr(st.session_state, \"generate_image_trigger\") and st.session_state.generate_image_trigger:\n    img_data = st.session_state.generate_image_trigger\n    del st.session_state.generate_image_trigger\n\n    with st.chat_message(\"user\"):\n        st.markdown(f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\")\n        st.caption(f\"ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”: {img_data['aspect_ratio']}\")\n\n    messages.append({\"role\": \"user\", \"content\": f\"ğŸ¨ ç”»åƒç”Ÿæˆ: {img_data['prompt']}\"})\n    update_current_session_messages(messages)\n\n    with st.chat_message(\"assistant\"):\n        with st.status(\"ç”»åƒã‚’ç”Ÿæˆä¸­...\", expanded=True) as status:\n            try:\n                config = types.GenerateContentConfig(\n                    response_modalities=[\"IMAGE\"],\n                    image_config=types.ImageConfig(\n                        aspect_ratio=img_data[\"aspect_ratio\"]\n                    ),\n                )\n                status.write(\"Gemini 3 Pro Imageã§ç”Ÿæˆä¸­...\")\n                response = client.models.generate_content(\n                    model=\"gemini-3-pro-image-preview\",\n                    contents=img_data[\"prompt\"],\n                    config=config,\n                )\n\n                generated_image = None\n\n                # ç”»åƒã‚’å–ã‚Šå‡ºã™\n                if getattr(response, \"candidates\", None):\n                    for candidate in response.candidates:\n                        if getattr(candidate, \"content\", None) and candidate.content.parts:\n                            for part in candidate.content.parts:\n                                if getattr(part, \"inline_data\", None):\n                                    try:\n                                        generated_image = part.as_image()\n                                    except AttributeError:\n                                        image_bytes_raw = part.inline_data.data\n                                        generated_image = Image.open(io.BytesIO(image_bytes_raw))\n                                    break\n                        if generated_image is not None:\n                            break\n\n                if generated_image is not None:\n                    st.image(generated_image, caption=img_data[\"prompt\"])\n                    buf = io.BytesIO()\n                    generated_image.save(buf, format=\"PNG\")\n                    image_bytes = buf.getvalue()\n                    st.download_button(\n                        label=\"ğŸ’¾ ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\",\n                        data=image_bytes,\n                        file_name=f\"generated_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png\",\n                        mime=\"image/png\",\n                    )\n                    messages.append(\n                        {\"role\": \"model\", \"content\": f\"âœ… ç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {img_data['prompt']}\"}\n                    )\n                    update_current_session_messages(messages)\n                    status.update(label=\"âœ… ç”»åƒç”Ÿæˆå®Œäº†\", state=\"complete\")\n                else:\n                    st.error(\"ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")\n                    status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n\n            except Exception as e:\n                status.update(label=\"âŒ ã‚¨ãƒ©ãƒ¼\", state=\"error\")\n                st.error(f\"ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}\")\n\n# =========================\n# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›\n# =========================\n\nprompt = st.chat_input(\"ä½•ã‹èã„ã¦ãã ã•ã„...\", disabled=stop_generation)\n\nif prompt:\n    if stop_generation:\n        st.error(\"äºˆç®—ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚\")\n    else:\n        # ---- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€è¡¨ç¤º ----\n        with st.chat_message(\"user\"):\n            st.markdown(prompt)\n            if uploaded_files:\n                for uf in uploaded_files:\n                    st.caption(f\"ğŸ“ æ·»ä»˜: {uf.name}\")\n            if youtube_url:\n                st.caption(f\"ğŸ“º YouTube: {youtube_url}\")\n            if pasted_image_bytes:\n                st.caption(\"ğŸ“‹ ç”»åƒãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚Œã¾ã—ãŸ\")\n\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        update_current_session_messages(messages)\n\n        # ---- ãƒ¢ãƒ‡ãƒ«å¿œç­” ----\n        with st.chat_message(\"assistant\"):\n            status_container = st.status(\"æ€è€ƒä¸­...\", expanded=True)\n            try:\n                # ä¼šè©±å±¥æ­´\n                model_history = []\n                for msg in messages[:-1]:\n                    model_history.append(\n                        types.Content(\n                            role=msg[\"role\"],\n                            parts=[types.Part.from_text(text=msg[\"content\"])],\n                        )\n                    )\n\n                # ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³\n                current_parts = [types.Part.from_text(text=prompt)]\n\n                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«\n                for uploaded_file in uploaded_files or []:\n                    try:\n                        mime_type = get_mime_type(uploaded_file.name)\n                        bytes_data = uploaded_file.getvalue()\n                        part = types.Part.from_bytes(data=bytes_data, mime_type=mime_type)\n                        current_parts.append(part)\n                        status_container.write(f\"ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™å®Œäº†: {uploaded_file.name}\")\n                    except Exception as e:\n                        status_container.error(\n                            f\"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {uploaded_file.name} - {e}\"\n                        )\n\n                # è²¼ã‚Šä»˜ã‘ç”»åƒ\n                if pasted_image_bytes:\n                    import base64\n\n                    status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã‚’å‡¦ç†ä¸­...\")\n                    try:\n                        if isinstance(pasted_image_bytes, str):\n                            if pasted_image_bytes.startswith(\"data:\"):\n                                base64_str = pasted_image_bytes.split(\",\", 1)[1]\n                                image_bytes_decoded = base64.b64decode(base64_str)\n                            else:\n                                image_bytes_decoded = base64.b64decode(pasted_image_bytes)\n                        else:\n                            image_bytes_decoded = pasted_image_bytes\n                        part = types.Part.from_bytes(\n                            data=image_bytes_decoded, mime_type=\"image/png\"\n                        )\n                        current_parts.append(part)\n                        status_container.write(\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®æº–å‚™å®Œäº†\")\n                    except Exception as e:\n                        status_container.error(f\"è²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸç”»åƒã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n\n                # YouTube å­—å¹•\n                if youtube_url:\n                    vid_id = extract_youtube_id(youtube_url)\n                    if vid_id:\n                        status_container.write(\"YouTubeã®å­—å¹•ã‚’å–å¾—ä¸­...\")\n                        transcript_text = get_youtube_transcript(vid_id)\n                        current_parts.append(\n                            types.Part.from_text(text=f\"YouTube Transcript:\\n{transcript_text}\")\n                        )\n                    else:\n                        status_container.write(\"ç„¡åŠ¹ãªYouTube URLã§ã™ã€‚\")\n\n                contents_for_model = model_history + [\n                    types.Content(role=\"user\", parts=current_parts)\n                ]\n\n                # ---- Tool / Config ----\n                tools = []\n                final_candidate_count = candidate_count\n                if use_search:\n                    tools.append(types.Tool(google_search=types.GoogleSearch()))\n                    final_candidate_count = 1\n\n                # â˜… System Instruction ã®æ”¹å–„: ãƒ¡ã‚¿ç™ºè¨€ç¦æ­¢ã¨ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªæŒ¯ã‚‹èˆã„ã‚’æŒ‡ç¤º\n                base_system_instruction = (\n                    \"ã‚ãªãŸã¯é«˜åº¦ãªçŸ¥æ€§ã‚’æŒã¤å°‚é–€çš„ãªãƒªã‚µãƒ¼ãƒãƒ»ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\\n\"\n                    \"ä»¥ä¸‹ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’å³å®ˆã—ã¦ãã ã•ã„ï¼š\\n\"\n                    \"1. **ãƒ¡ã‚¿ç™ºè¨€ã®ç¦æ­¢**: ã€Œç§ã¯AIã§ã™ã€ã€Œä¸–ç•Œæœ€é«˜å³°ã®ï½ã¨ã—ã¦ã€ãªã©ã®è‡ªå·±è¨€åŠã‚„å‰ç½®ãã¯ä¸€åˆ‡è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚\\n\"\n                    \"2. **æ„å›³ã®æ±²ã¿å–ã‚Š**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã®èƒŒå¾Œã«ã‚ã‚‹æ„å›³ï¼ˆæ–‡è„ˆã€æš—é»™ã®å‰æï¼‰ã‚’æ¨æ¸¬ã—ã€è¨€è‘‰é€šã‚Šã§ã¯ãªãã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ¬å½“ã«çŸ¥ã‚ŠãŸã„ã“ã¨ã€ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n\"\n                    \"3. **æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”**: çµè«–ã‚’å…ˆã«è¿°ã¹ã€ãã®å¾Œã«è©³ç´°ãªæ ¹æ‹ ã€ã‚·ãƒŠãƒªã‚ªåˆ†æã€ãƒªã‚¹ã‚¯è¦å› ã‚’è«–ç†çš„ã«å±•é–‹ã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"4. **å®¢è¦³æ€§**: äºˆæ¸¬ã‚’è¡Œã†å ´åˆã¯ã€æ–­å®šã‚’é¿ã‘ã€è¤‡æ•°ã®ã‚·ãƒŠãƒªã‚ªï¼ˆæ¥½è¦³ã€æ‚²è¦³ã€ä¸­ç«‹ï¼‰ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚\\n\"\n                    \"5. **å¼•ç”¨**: æ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸå ´åˆã¯ã€å¿…ãšæƒ…å ±æºã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚\"\n                )\n\n                final_answer = \"\"\n                grounding_metadata = None\n                \n                # =========================\n                # ãƒ¢ãƒ¼ãƒ‰è¨­å®šã®è§£æ\n                # =========================\n                enable_research = True  # å…¨ãƒ¢ãƒ¼ãƒ‰ã§ãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œ\n                enable_meta = \"ãƒ¡ã‚¿\" in response_mode or \"MAX\" in response_mode\n                enable_strict = \"é¬¼è»æ›¹\" in response_mode or \"MAX\" in response_mode\n\n                # =========================\n                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (é«˜é€Ÿ / é¬¼è»æ›¹)\n                # =========================\n                if not enable_research:\n                    config = types.GenerateContentConfig(\n                        temperature=0.7,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=base_system_instruction,\n                    )\n                    \n                    status_container.write(\"å›ç­”ç”Ÿæˆä¸­...\")\n                    response = client.models.generate_content(\n                        model=model_id,\n                        contents=contents_for_model,\n                        config=config,\n                    )\n                    \n                    final_answer = extract_text_from_response(response)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®—\n                    if response.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            response.usage_metadata.prompt_token_count,\n                            response.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += response.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += response.usage_metadata.candidates_token_count\n\n                    # é¬¼è»æ›¹ãƒ¬ãƒ“ãƒ¥ãƒ¼ (é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ç‰ˆ)\n                    if enable_strict:\n                        status_container.write(\"ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        reviewer_instruction = base_system_instruction + \"\"\"\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n                        review_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\nåˆç‰ˆå›ç­”:\\n{final_answer}\\n\\nãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\")])]\n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=types.GenerateContentConfig(temperature=0.1, candidate_count=1, system_instruction=reviewer_instruction)\n                        )\n                        final_answer = extract_text_from_response(review_resp)\n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        \n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(model_id, review_resp.usage_metadata.prompt_token_count, review_resp.usage_metadata.candidates_token_count)\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n\n                # =========================\n                # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰\n                # =========================\n                else:\n                    # =========================\n                    # ç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰: å¤šæ®µéšã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ \n                    # =========================\n                    \n                    # --- Phase 1: ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 1: ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    research_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒªã‚µãƒ¼ãƒå°‚ä»»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚æœ€çµ‚å›ç­”ã¯æ›¸ã‹ãšã€äº‹å®Ÿåé›†ã«é›†ä¸­ã™ã‚‹ã“ã¨ã€‚\n\n**èª¿æŸ»è¦³ç‚¹**:\n- è³ªå•ã«é–¢é€£ã™ã‚‹æœ€æ–°ã®äº‹å®Ÿãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ»çµ±è¨ˆ\n- å…¬å¼æƒ…å ±ã‚„ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã‹ã‚‰ã®å¼•ç”¨\n- é–¢é€£ã™ã‚‹èƒŒæ™¯æƒ…å ±ã‚„æ–‡è„ˆ\n- ç«¶åˆãƒ»ä»£æ›¿æ¡ˆãƒ»æ¯”è¼ƒå¯¾è±¡ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n- ãƒªã‚¹ã‚¯ãƒ»åˆ¶ç´„ãƒ»æ³¨æ„ç‚¹ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n- å‚è€ƒã«ã—ãŸä¸»è¦ãªæƒ…å ±æºã®URL\n\n**é‡è¦**: \n- çµè«–ã‚„æ¨å¥¨ã¯æ›¸ã‹ãšã€å¾Œå·¥ç¨‹ãŒåˆ¤æ–­ã§ãã‚‹èª¿æŸ»ãƒ¡ãƒ¢ã«é›†ä¸­ã™ã‚‹ã“ã¨\n- æœ€æ–°ã®æƒ…å ±ã‚’å„ªå…ˆçš„ã«æ¤œç´¢ã™ã‚‹ã“ã¨\n- æ¤œç´¢çµæœã‚’å¿…ãšæ´»ç”¨ã—ã€æƒ…å ±æºã‚’æ˜è¨˜ã™ã‚‹ã“ã¨\n\"\"\"\n\n                    # éå»ã®é–¢é€£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—\n                    past_context = get_relevant_context(prompt)\n                    \n                    # ãƒªã‚µãƒ¼ãƒç”¨ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ§‹ç¯‰\n                    research_parts = [types.Part(text=f\"ã“ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®èª¿æŸ»ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š\\n{prompt}\")]\n                    \n                    if past_context:\n                        research_parts.insert(0, types.Part(text=\"ä»¥ä¸‹ã¯éå»ã®é–¢é€£ãƒãƒ£ãƒƒãƒˆã‹ã‚‰æŠ½å‡ºã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã™ï¼š\\n\\n\" + past_context))\n                    \n                    research_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=research_parts)\n                    ]\n                    \n                    research_config = types.GenerateContentConfig(\n                        temperature=0.2,\n                        candidate_count=1,\n                        tools=tools,\n                        system_instruction=research_instruction,\n                    )\n                    \n                    research_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=research_contents,\n                        config=research_config,\n                    )\n                    \n                    research_text = extract_text_from_response(research_resp)\n                    \n                    # ãƒªã‚µãƒ¼ãƒãƒ•ã‚§ãƒ¼ã‚ºã®ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ±ã‚’ä¿å­˜\n                    if research_resp.candidates and research_resp.candidates[0].grounding_metadata:\n                        grounding_metadata = research_resp.candidates[0].grounding_metadata\n                    \n                    status_container.write(\"âœ“ ãƒªã‚µãƒ¼ãƒå®Œäº†\")\n                    with status_container.expander(\"åé›†ã—ãŸèª¿æŸ»ãƒ¡ãƒ¢\", expanded=False):\n                        st.markdown(research_text)\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1)\n                    if research_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            research_resp.usage_metadata.prompt_token_count,\n                            research_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += research_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += research_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 1.5: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    questions_text = \"\"\n                    if enable_meta:\n                        status_container.write(\"Phase 1.5: ãƒ¡ã‚¿è³ªå•ç”Ÿæˆä¸­...\")\n                        \n                        question_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: ãƒ¡ã‚¿è³ªå•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ç›®çš„**: \nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•ã¨èª¿æŸ»ãƒ¡ãƒ¢ã‚’è¸ã¾ãˆã¦ã€ã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±ãç†è§£ã™ã‚‹ãŸã‚ã®ã€Œé‹­ã„ã‚µãƒ–è³ªå•ã€ã‚’ä½œæˆã™ã‚‹ã“ã¨ã€‚\n\n**ãƒ«ãƒ¼ãƒ«**:\n- æœ€å¤§5å€‹ã¾ã§\n- å„è³ªå•ã¯1-2è¡Œã§å…·ä½“çš„ã‹ã¤é‹­ã\n- ä»¥ä¸‹ã®è¦³ç‚¹ã‚’æ„è­˜:\n  1. å‰æãŒå´©ã‚Œã‚‹å¯èƒ½æ€§ã¯ã©ã“ã‹ï¼Ÿ\n  2. å¼·æ°—/å¼±æ°—ã‚·ãƒŠãƒªã‚ªã®åˆ†å²ç‚¹ã¯ä½•ã‹ï¼Ÿ\n  3. ç«¶åˆãƒ»æŠ€è¡“ãƒ»è¦åˆ¶ã®ä¸ç¢ºå®Ÿæ€§ã¯ï¼Ÿ\n  4. ã€Œäºˆæ¸¬ãŒå¤–ã‚Œã‚‹ã¨ã—ãŸã‚‰ã©ã‚“ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ï¼Ÿã€\n\n**å‡ºåŠ›**: ç®‡æ¡æ›¸ãï¼ˆQ1, Q2...ï¼‰ã®ã¿\n\"\"\"\n\n                        question_contents = [types.Content(role=\"user\", parts=[types.Part(text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•:\\n{prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\nã“ã®ãƒ†ãƒ¼ãƒã‚’ã•ã‚‰ã«æ·±æ˜ã‚Šã™ã‚‹ãŸã‚ã®é‡è¦ãªã‚µãƒ–è³ªå•ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\")])]\n                        \n                        question_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=question_contents,\n                            config=types.GenerateContentConfig(\n                                temperature=0.4,\n                                candidate_count=1,\n                                system_instruction=question_instruction,\n                            )\n                        )\n                        \n                        questions_text = extract_text_from_response(question_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¡ã‚¿è³ªå•ç”Ÿæˆå®Œäº†\")\n                        with status_container.expander(\"ç”Ÿæˆã•ã‚ŒãŸãƒ¡ã‚¿è³ªå•\", expanded=False):\n                            st.markdown(questions_text)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 1.5)\n                        if question_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                question_resp.usage_metadata.prompt_token_count,\n                                question_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += question_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += question_resp.usage_metadata.candidates_token_count\n\n                    # --- Phase 2: çµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ---\n                    status_container.write(\"Phase 2: çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                    \n                    deep_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: æœ€çµ‚å›ç­”ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n**ã‚¿ã‚¹ã‚¯**: èª¿æŸ»ãƒ¡ãƒ¢ã¨ãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ã‚’æ ¹æ‹ ã¨ã—ã¦ã€ä»¥ä¸‹ã®æ§‹æˆã§å›ç­”ï¼š\n1. **æ·±æ˜ã‚Šè€ƒå¯Ÿ**ï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n2. **çµè«–**ï¼ˆ2-3è¡Œï¼‰\n3. **ç¾åœ¨ã®çŠ¶æ³**ï¼ˆæ•°å­—ãƒ»äº‹å®Ÿãƒ™ãƒ¼ã‚¹ï¼‰\n4. **2å¹´å¾Œã®ã‚·ãƒŠãƒªã‚ªåˆ†è§£**ï¼ˆãƒ™ãƒ¼ã‚¹ï¼å¼·æ°—ï¼å¼±æ°—ï¼‰\n5. **ä¸»ãªãƒ—ãƒ©ã‚¹è¦å› ãƒ»ãƒã‚¤ãƒŠã‚¹è¦å› **\n6. **ã“ã®äºˆæ¸¬ã‚’ã©ã†ä½¿ã†ã¹ãã‹**ï¼ˆãƒªã‚¹ã‚¯è¨±å®¹åº¦ã¸ã®ç¤ºå”†ï¼‰\n\n**é‡è¦**: æ–°ã—ã„äº‹å®Ÿã‚’å‹æ‰‹ã«ä½œã‚‰ãšã€èª¿æŸ»ãƒ¡ãƒ¢ã®ç¯„å›²å†…ã§æ¨è«–ã™ã‚‹ã“ã¨\n\"\"\"\n                    synthesis_prompt_text = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}\\n\\n==== èª¿æŸ»ãƒ¡ãƒ¢ ====\\n{research_text}\\n==== èª¿æŸ»ãƒ¡ãƒ¢ã“ã“ã¾ã§ ====\\n\\n\"\n                    \n                    if enable_meta and questions_text:\n                        synthesis_prompt_text += f\"==== ãƒ¡ã‚¿è³ªå•ä¸€è¦§ ====\\n{questions_text}\\n==== ãƒ¡ã‚¿è³ªå•ã“ã“ã¾ã§ ====\\n\\næŒ‡ç¤º:\\n1. ã¾ãšã€ãƒ¡ã‚¿è³ªå• Q1ã€œQn ã«ä¸€ã¤ãšã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n2. ãã®ã†ãˆã§ã€ãã‚Œã‚‰ã®å›ç­”ã‚’è¸ã¾ãˆãŸã€å…¨ä½“ã¨ã—ã¦ã®çµè«–ãƒ»ã‚·ãƒŠãƒªã‚ªåˆ†è§£ãƒ»ç¤ºå”†ã€ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\"\n                    else:\n                        synthesis_prompt_text += \"ä¸Šè¨˜ãƒ¡ãƒ¢ã‚’æ ¹æ‹ ã«ã€æœ€çµ‚å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\"\n\n                    synthesis_contents = contents_for_model + [\n                        types.Content(role=\"user\", parts=[\n                            types.Part(text=synthesis_prompt_text)\n                        ])\n                    ]\n                    \n                    synthesis_config = types.GenerateContentConfig(\n                        temperature=0.3,\n                        candidate_count=1,\n                        tools=[],  # çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºã§ã¯æ¤œç´¢OFF\n                        system_instruction=deep_instruction,\n                    )\n                    \n                    synthesis_resp = client.models.generate_content(\n                        model=model_id,\n                        contents=synthesis_contents,\n                        config=synthesis_config,\n                    )\n                    \n                    draft_answer = extract_text_from_response(synthesis_resp)\n                    \n                    status_container.write(\"âœ“ çµ±åˆå®Œäº†\")\n                    \n                    # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 2)\n                    if synthesis_resp.usage_metadata:\n                        cost = calculate_cost(\n                            model_id,\n                            synthesis_resp.usage_metadata.prompt_token_count,\n                            synthesis_resp.usage_metadata.candidates_token_count,\n                        )\n                        st.session_state.session_cost += cost\n                        usage_stats[\"total_cost_usd\"] += cost\n                        usage_stats[\"total_input_tokens\"] += synthesis_resp.usage_metadata.prompt_token_count\n                        usage_stats[\"total_output_tokens\"] += synthesis_resp.usage_metadata.candidates_token_count\n                    \n                    # --- Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (é¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã®ã¿) ---\n                    if enable_strict:\n                        status_container.write(\"Phase 3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œä¸­...\")\n                        \n                        reviewer_instruction = base_system_instruction + \"\"\"\n\n**ã‚ãªãŸã®å½¹å‰²**: é¬¼è»æ›¹ãƒ¬ãƒ™ãƒ«ã®å³æ ¼ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢\n\n**ã‚¿ã‚¹ã‚¯**: åˆç‰ˆå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’è¿”ã™ï¼š\n- äº‹å®Ÿã¨æ¨æ¸¬ã‚’æ˜ç¢ºã«åˆ†ã‘ã‚‹\n- éåº¦ã«è‡ªä¿¡ã®ã‚ã‚‹æ–­å®šã‚’å¼±ã‚ã‚‹\n- æ•°å­—ã‚„å›ºæœ‰åè©ãŒèª¿æŸ»ãƒ¡ãƒ¢ã¨çŸ›ç›¾ã—ã¦ã„ãªã„ã‹ç¢ºèª\n- è¦‹è½ã¨ã—ã¦ã„ã‚‹é‡è¦ãªãƒªã‚¹ã‚¯ãƒ»ã‚·ãƒŠãƒªã‚ªãŒã‚ã‚Œã°è¿½åŠ \n\n**å‡ºåŠ›**: ä¿®æ­£ç‰ˆã®å›ç­”å…¨æ–‡ã®ã¿\n\"\"\"\n\n                        review_contents = [\n                            types.Content(role=\"user\", parts=[\n                                types.Part.from_text(\n                                    text=f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {prompt}\\n\\n\"\n                                    f\"åˆç‰ˆå›ç­”:\\n{draft_answer}\\n\\n\"\n                                    \"ä¸Šè¨˜ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å¿…è¦ãªã‚‰ä¿®æ­£ç‰ˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\"\n                                )\n                            ])\n                        ]\n                        \n                        review_config = types.GenerateContentConfig(\n                            temperature=0.1,\n                            candidate_count=1,\n                            system_instruction=reviewer_instruction,\n                        )\n                        \n                        review_resp = client.models.generate_content(\n                            model=model_id,\n                            contents=review_contents,\n                            config=review_config,\n                        )\n                        \n                        final_answer = extract_text_from_response(review_resp)\n                        \n                        status_container.write(\"âœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†\")\n                        with status_container.expander(\"åˆç‰ˆã¨ã®æ¯”è¼ƒ\", expanded=False):\n                            st.markdown(\"**åˆç‰ˆ:**\")\n                            st.markdown(draft_answer[:500] + \"...\" if len(draft_answer) > 500 else draft_answer)\n                            st.markdown(\"**ä¿®æ­£ç‰ˆ:**\")\n                            st.markdown(final_answer[:500] + \"...\" if len(final_answer) > 500 else final_answer)\n                        \n                        # ã‚³ã‚¹ãƒˆè¨ˆç®— (Phase 3)\n                        if review_resp.usage_metadata:\n                            cost = calculate_cost(\n                                model_id,\n                                review_resp.usage_metadata.prompt_token_count,\n                                review_resp.usage_metadata.candidates_token_count,\n                            )\n                            st.session_state.session_cost += cost\n                            usage_stats[\"total_cost_usd\"] += cost\n                            usage_stats[\"total_input_tokens\"] += review_resp.usage_metadata.prompt_token_count\n                            usage_stats[\"total_output_tokens\"] += review_resp.usage_metadata.candidates_token_count\n                    else:\n                        final_answer = draft_answer\n\n                save_usage(usage_stats)\n                status_container.update(label=\"å®Œäº†ï¼\", state=\"complete\", expanded=False)\n\n                st.markdown(final_answer)\n\n                # ---- ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ± ----\n                if grounding_metadata:\n                    st.markdown(\"---\")\n                    st.subheader(\"ğŸ“š æƒ…å ±æºã¨å¼•ç”¨\")\n                    if grounding_metadata.grounding_chunks:\n                        st.markdown(\"**æ¤œç´¢çµæœã‹ã‚‰åˆ©ç”¨ã—ãŸæƒ…å ±æº:**\")\n                        unique_sources = {}\n                        import urllib.parse\n\n                        for chunk in grounding_metadata.grounding_chunks:\n                            if getattr(chunk, \"web\", None):\n                                uri = getattr(chunk.web, \"uri\", None)\n                                title = getattr(chunk.web, \"title\", \"æƒ…å ±æº\")\n                                if uri and uri not in unique_sources:\n                                    parsed = urllib.parse.urlparse(uri)\n                                    domain = parsed.netloc.replace(\"www.\", \"\")\n                                    unique_sources[uri] = {\n                                        \"title\": title,\n                                        \"domain\": domain,\n                                    }\n                        for i, (uri, info) in enumerate(unique_sources.items(), 1):\n                            st.markdown(f\"{i}. **[{info['title']}]({uri})**\")\n                            st.caption(f\"   å‡ºå…¸: {info['domain']}\")\n\n                messages.append({\"role\": \"model\", \"content\": final_answer})\n                update_current_session_messages(messages)\n\n            except Exception as e:\n                status_container.update(label=\"Error\", state=\"error\")\n                err_text = str(e)\n                if \"RESOURCE_EXHAUSTED\" in err_text or \"429\" in err_text:\n                    st.error(\n                        \"âš ï¸ Vertex AI / Gemini ã®ã‚¯ã‚©ãƒ¼ã‚¿ã«é”ã—ã¾ã—ãŸã€‚\\n\\n\"\n                        \"ãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ / æ—¥æ¬¡åˆ¶é™ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\\n\"\n                        \"ãƒ»ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                        \"ãƒ»Google Cloud Console ã®ã€ŒVertex AI â†’ ä½¿ç”¨çŠ¶æ³ã€ã‹ã‚‰ã‚¯ã‚©ãƒ¼ã‚¿çŠ¶æ³ã‚’ç¢ºèªã§ãã¾ã™ã€‚\"\n                    )\n                elif \"NOT_FOUND\" in err_text and \"Publisher Model\" in err_text:\n                    st.error(\n                        \"âš ï¸ æŒ‡å®šã—ãŸãƒ¢ãƒ‡ãƒ«ãŒã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ / ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\\n\"\n                        \"ãƒ»ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ¢ãƒ‡ãƒ«IDã‚’ã€2.5ç³» ã¾ãŸã¯ 3 Pro ã«å¤‰æ›´ã—ã¦ãŠè©¦ã—ãã ã•ã„ã€‚\\n\"\n                    )\n                else:\n                    st.error(f\"An error occurred: {e}\")"
                },
                {
                    "role": "model",
                    "content": "### 1. æ·±æ˜ã‚Šè€ƒå¯Ÿï¼ˆãƒ¡ã‚¿è³ªå•ã¸ã®å›ç­”ï¼‰\n\nã“ã®ã‚³ãƒ¼ãƒ‰ãŒã€Œãƒ™ã‚¹ãƒˆã€ã§ã‚ã‚‹ã‹ã‚’åˆ¤æ–­ã™ã‚‹ã«ã¯ã€**ã€Œãƒ­ã‚¸ãƒƒã‚¯ã®é«˜åº¦ã•ã€ã¨ã€Œå®Ÿè£…ã®å …ç‰¢æ€§ã€ã‚’åˆ†ã‘ã¦è©•ä¾¡**ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n\n*   **Q1. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®Ÿè£…ã¯é©åˆ‡ã‹ï¼Ÿ**\n    *   **å›ç­”**: æ¥µã‚ã¦é«˜åº¦ã§ã™ã€‚ã€Œç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰ã€ã«ãŠã‘ã‚‹ã€Œãƒªã‚µãƒ¼ãƒâ†’ãƒ¡ã‚¿è³ªå•â†’çµ±åˆâ†’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€ã¨ã„ã†å¤šæ®µéšæ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã¯ã€ç¾åœ¨ã®LLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹ç™ºã«ãŠã‘ã‚‹**æœ€å…ˆç«¯ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ï¼ˆAgentic Workflowï¼‰**ã‚’çš„ç¢ºã«æ‰ãˆã¦ã„ã¾ã™ã€‚å˜ç™ºã®APIå‘¼ã³å‡ºã—ã§ã¯ãªãã€æ€è€ƒã®é€£é–ï¼ˆChain of Thoughtï¼‰ã‚’ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«ã§å¼·åˆ¶ã—ã¦ã„ã‚‹ç‚¹ã¯ã€å›ç­”å“è³ªã‚’åŠ‡çš„ã«é«˜ã‚ã‚‹è¨­è¨ˆã§ã™ã€‚\n*   **Q2. ãƒ‡ãƒ¼ã‚¿ç®¡ç†æ‰‹æ³•ã«è‡´å‘½çš„ãªæ¬ é™¥ã¯ãªã„ã‹ï¼Ÿ**\n    *   **å›ç­”**: ã‚ã‚Šã¾ã™ã€‚`json` ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ç›´æ¥èª­ã¿æ›¸ãï¼ˆ`SESSIONS_FILE`ï¼‰ã¯ã€Streamlitã®ã‚ˆã†ãªãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ç’°å¢ƒã‚„ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ‡ãƒ—ãƒ­ã‚¤ç’°å¢ƒã§ã¯**ãƒ‡ãƒ¼ã‚¿ç«¶åˆï¼ˆRace Conditionï¼‰ã‚„æ¶ˆå¤±**ã‚’å¼•ãèµ·ã“ã—ã¾ã™ã€‚å€‹äººãŒãƒ­ãƒ¼ã‚«ãƒ«ã§ã‚·ãƒ³ã‚°ãƒ«ã‚¿ã‚¹ã‚¯ã¨ã—ã¦ä½¿ã†åˆ†ã«ã¯å‹•ä½œã—ã¾ã™ãŒã€Webã‚¢ãƒ—ãƒªã¨ã—ã¦ã®è¨­è¨ˆã¨ã—ã¦ã¯ã€Œãƒ™ã‚¹ãƒˆã€ã¨ã¯è¨€ãˆã¾ã›ã‚“ã€‚\n*   **Q3. ãƒ¢ãƒ‡ãƒ«IDã®å®šç¾©ã¯ç¾å®Ÿã«å³ã—ã¦ã„ã‚‹ã‹ï¼Ÿ**\n    *   **å›ç­”**: ç¾å®Ÿã¨ä¹–é›¢ã—ã¦ã„ã¾ã™ã€‚`gemini-3-pro` ã‚„ `gemini-2.5` ã¯ç¾æ™‚ç‚¹ã§ä¸€èˆ¬å…¬é–‹ã•ã‚Œã¦ã„ãªã„ï¼ˆã¾ãŸã¯å­˜åœ¨ã—ãªã„ï¼‰IDã§ã™ã€‚ã“ã®ã¾ã¾å®Ÿè¡Œã™ã‚‹ã¨ `404 Not Found` ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ãŸã‚ã€å®Ÿç”¨ã™ã‚‹ã«ã¯ç¾è¡Œã® `gemini-2.0-flash` ã‚„ `gemini-1.5-pro` ã«ä¿®æ­£ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n\n---\n\n### 2. çµè«–\n\n**ã€Œãƒ­ã‚¸ãƒƒã‚¯è¨­è¨ˆã¯æœ€é«˜å³°ã ãŒã€ã‚¤ãƒ³ãƒ•ãƒ©å®Ÿè£…ã¯ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—æ­¢ã¾ã‚Šã€**ã§ã™ã€‚\n\nLLMã®èƒ½åŠ›ã‚’å¼•ãå‡ºã™ãŸã‚ã®**ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­è¨ˆï¼ˆæ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ï¼‰ã«é–¢ã—ã¦ã¯ã€è‡ªä½œã‚³ãƒ¼ãƒ‰ã¨ã—ã¦ãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã®å®Œæˆåº¦**ã§ã™ã€‚ã—ã‹ã—ã€ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜æ–¹æ³•ã‚„ãƒ¢ãƒ‡ãƒ«å®šç¾©ã«ãŠã„ã¦ã¯ã€å®Ÿé‹ç”¨ã«è€ãˆã‚‰ã‚Œãªã„è„†å¼±æ€§ã‚’å«ã‚“ã§ã„ã¾ã™ã€‚ã€Œå€‹äººãŒãƒ­ãƒ¼ã‚«ãƒ«ã§å®Ÿé¨“çš„ã«ä½¿ã†æœ€å¼·ã®ãƒ„ãƒ¼ãƒ«ã€ã¨ã—ã¦ã¯ã»ã¼ãƒ™ã‚¹ãƒˆã§ã™ãŒã€Webã‚µãƒ¼ãƒ“ã‚¹ã¨ã—ã¦å…¬é–‹ã™ã‚‹ã«ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å°å…¥ãŒä¸å¯æ¬ ã§ã™ã€‚\n\n---\n\n### 3. ç¾åœ¨ã®çŠ¶æ³ï¼ˆäº‹å®Ÿãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡ï¼‰\n\n*   **SDKé¸å®š**: âœ… **Best**. æœ€æ–°ã® `google.genai` (v1.0+) ã‚’æ¡ç”¨ã—ã¦ãŠã‚Šã€Vertex AI ã®æœ€æ–°æ©Ÿèƒ½ã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã§ã™ã€‚\n*   **æ¨è«–ãƒ•ãƒ­ãƒ¼**: âœ… **Best**. ã€Œé¬¼è»æ›¹ãƒ¢ãƒ¼ãƒ‰ã€ã‚„ã€Œãƒ¡ã‚¿æ€è€ƒã€ãªã©ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’ã‚³ãƒ¼ãƒ‰ã«è½ã¨ã—è¾¼ã‚€å®Ÿè£…ã¯éå¸¸ã«æ´—ç·´ã•ã‚Œã¦ã„ã¾ã™ã€‚\n*   **ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«**: âœ… **Excellent**. ç”»åƒã€YouTubeã€ãƒ•ã‚¡ã‚¤ãƒ«æ·»ä»˜ã‚’ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«çµ±åˆã§ãã¦ã„ã¾ã™ã€‚\n*   **ãƒ‡ãƒ¼ã‚¿æ°¸ç¶šåŒ–**: âŒ **Risk**. JSONãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†ã¯ã€åŒæ™‚ã‚¢ã‚¯ã‚»ã‚¹æ™‚ã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒç ´æã™ã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚\n*   **ãƒ¢ãƒ‡ãƒ«è¨­å®š**: âš ï¸ **Caution**. æ¶ç©ºã®ãƒ¢ãƒ‡ãƒ«IDãŒå«ã¾ã‚Œã¦ãŠã‚Šã€ä¿®æ­£ãªã—ã§ã¯å‹•ä½œã—ã¾ã›ã‚“ã€‚\n\n---\n\n### 4. 2å¹´å¾Œã®ã‚·ãƒŠãƒªã‚ªåˆ†è§£\n\nã“ã®ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’èµ·ç‚¹ã¨ã—ãŸå ´åˆã®é€²åŒ–ã‚·ãƒŠãƒªã‚ªã§ã™ã€‚\n\n*   **ãƒ™ãƒ¼ã‚¹ã‚·ãƒŠãƒªã‚ªï¼ˆé †å½“ãªé€²åŒ–ï¼‰**:\n    *   ãƒ¢ãƒ‡ãƒ«IDã‚’ç¾è¡Œç‰ˆï¼ˆGemini 2.0/1.5ï¼‰ã«ä¿®æ­£ã—ã€å€‹äººç”¨ãƒ„ãƒ¼ãƒ«ã¨ã—ã¦æ´»ç”¨ã€‚\n    *   Googleæ¤œç´¢ã‚„YouTubeåˆ†æã®ç²¾åº¦ãŒé«˜ãã€å€‹äººã®å­¦ç¿’ãƒ»èª¿æŸ»åŠ¹ç‡ãŒåŠ‡çš„ã«å‘ä¸Šã™ã‚‹ã€‚\n*   **å¼·æ°—ã‚·ãƒŠãƒªã‚ªï¼ˆãƒ—ãƒ­ãƒ€ã‚¯ãƒˆåŒ–ï¼‰**:\n    *   ãƒ‡ãƒ¼ã‚¿ä¿å­˜å…ˆã‚’ Firestore ã‚„ SQLite ã«å¤‰æ›´ã—ã€èªè¨¼æ©Ÿèƒ½ã‚’è¿½åŠ ã€‚\n    *   ã€Œç†Ÿè€ƒãƒ¢ãƒ¼ãƒ‰ã€ã®ãƒ­ã‚¸ãƒƒã‚¯ãŒè©•ä¾¡ã•ã‚Œã€ç‰¹å®šã®ãƒ‰ãƒ¡ã‚¤ãƒ³ï¼ˆå¸‚å ´èª¿æŸ»ã€è«–æ–‡åŸ·ç­†ãªã©ï¼‰ã«ç‰¹åŒ–ã—ãŸSaaSã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ãƒ¬ãƒ™ãƒ«ã«ãªã‚‹ã€‚\n*   **å¼±æ°—ã‚·ãƒŠãƒªã‚ªï¼ˆæŠ€è¡“çš„è² å‚µï¼‰**:\n    *   JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒè‚¥å¤§åŒ–ã—ã€èª­ã¿è¾¼ã¿é€Ÿåº¦ãŒä½ä¸‹ã€‚\n    *   Streamlitã®ä»•æ§˜å¤‰æ›´ã‚„éåŒæœŸå‡¦ç†ã®æ¬ å¦‚ã«ã‚ˆã‚Šã€ç”Ÿæˆä¸­ã«UIãŒãƒ•ãƒªãƒ¼ã‚ºã™ã‚‹é »åº¦ãŒå¢—ãˆã€ä½¿ç”¨æ„ŸãŒæ‚ªåŒ–ã™ã‚‹ã€‚\n\n---\n\n### 5. ä¸»ãªãƒ—ãƒ©ã‚¹è¦å› ãƒ»ãƒã‚¤ãƒŠã‚¹è¦å› \n\n**ãƒ—ãƒ©ã‚¹è¦å› ï¼ˆå¼·ã¿ï¼‰**\n*   **Agentic Workflow**: å˜ãªã‚‹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’è¶…ãˆãŸã€Œèª¿æŸ»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹è¨­è¨ˆã€‚\n*   **ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†**: éå»ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰é–¢é€£æƒ…å ±ã‚’æ¤œç´¢ã™ã‚‹ `get_relevant_context` é–¢æ•°ã¯ã€ç°¡æ˜“RAGï¼ˆæ¤œç´¢æ‹¡å¼µç”Ÿæˆï¼‰ã¨ã—ã¦æ©Ÿèƒ½ã—ã¦ãŠã‚Šå„ªç§€ã€‚\n*   **ã‚³ã‚¹ãƒˆæ„è­˜**: ãƒˆãƒ¼ã‚¯ãƒ³å˜ä¾¡ã®è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ãŒçµ„ã¿è¾¼ã¾ã‚Œã¦ãŠã‚Šã€APIç ´ç”£ã‚’é˜²ãå·¥å¤«ãŒã‚ã‚‹ã€‚\n\n**ãƒã‚¤ãƒŠã‚¹è¦å› ï¼ˆæ”¹å–„ç‚¹ï¼‰**\n*   **åŒæ™‚å®Ÿè¡Œæ€§ï¼ˆConcurrencyï¼‰**: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã®ä¿å­˜ã¯ã€è¤‡æ•°ã‚¿ãƒ–ã‚„è¤‡æ•°äººã§ã®åˆ©ç”¨ã«è€ãˆã‚‰ã‚Œãªã„ã€‚\n*   **æ§‹é€ åŒ–å‡ºåŠ›ã®æ¬ å¦‚**: æ­£è¦è¡¨ç¾ã§ã®ãƒ‘ãƒ¼ã‚¹ã¯ä¸å®‰å®šã€‚Geminiã® `response_schema` (JSON Schema) ã‚’ä½¿ã£ã¦ã€ãƒ¡ã‚¿è³ªå•ã‚„ãƒªã‚µãƒ¼ãƒçµæœã‚’ç¢ºå®ŸãªJSONã¨ã—ã¦å—ã‘å–ã‚‹ã¹ãã€‚\n*   **éåŒæœŸå‡¦ç†**: `generate_content` ã¯åŒæœŸå‡¦ç†ã§ã‚ã‚‹ãŸã‚ã€é•·æ–‡ç”Ÿæˆä¸­ã¯UIãŒå®Œå…¨ã«ãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã‚‹ã€‚\n\n---\n\n### 6. ã“ã®äºˆæ¸¬ã‚’ã©ã†ä½¿ã†ã¹ãã‹ï¼ˆãƒªã‚¹ã‚¯è¨±å®¹åº¦ã¸ã®ç¤ºå”†ï¼‰\n\nã“ã®ã‚³ãƒ¼ãƒ‰ã‚’ã€Œãƒ™ã‚¹ãƒˆã€ã«ã™ã‚‹ãŸã‚ã®å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã§ã™ã€‚\n\n1.  **å³æ™‚ä¿®æ­£ï¼ˆMustï¼‰**:\n    *   `PRICING` è¾æ›¸ã¨ `model_options` ã‚’ã€å®Ÿéš›ã«åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«IDï¼ˆä¾‹: `gemini-2.0-flash-001`, `gemini-1.5-pro-002`ï¼‰ã«æ›¸ãæ›ãˆã¦ãã ã•ã„ã€‚\n2.  **å®‰å®šåŒ–ï¼ˆShouldï¼‰**:\n    *   `SESSIONS_FILE` ã¸ã®ä¾å­˜ã‚’ã‚„ã‚ã€**SQLite** (`sqlite3` æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª) ã¾ãŸã¯ **Google Firestore** ã«ç§»è¡Œã—ã¦ãã ã•ã„ã€‚ã“ã‚Œã«ã‚ˆã‚Šãƒ‡ãƒ¼ã‚¿ç ´æãƒªã‚¹ã‚¯ãŒãªããªã‚Šã¾ã™ã€‚\n3.  **é«˜åº¦åŒ–ï¼ˆBetterï¼‰**:\n    *   å‡ºåŠ›ã®ãƒ‘ãƒ¼ã‚¹ï¼ˆãƒ¡ã‚¿è³ªå•ã®æŠ½å‡ºãªã©ï¼‰ã« `response_schema` ã‚’ä½¿ç”¨ã—ã€æ­£è¦è¡¨ç¾ã¸ã®ä¾å­˜ã‚’æ’é™¤ã—ã¦ãã ã•ã„ã€‚\n    *   ç”»åƒç”Ÿæˆéƒ¨åˆ†ã¯ã€Vertex AI ã® `imagen-3.0` ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã‚ˆã†ã«ä¿®æ­£ãŒå¿…è¦ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆGeminiãƒ¢ãƒ‡ãƒ«è‡ªä½“ã®ç”»åƒå‡ºåŠ›æ©Ÿèƒ½ã¯å®Ÿé¨“çš„ãªãŸã‚ï¼‰ã€‚\n\n**ç·è©•**:\nã‚³ãƒ¼ãƒ‰ã®ã€Œè„³ã¿ãï¼ˆãƒ­ã‚¸ãƒƒã‚¯ï¼‰ã€ã¯éå¸¸ã«å„ªç§€ã§ã™ã€‚ã€Œä½“ï¼ˆã‚¤ãƒ³ãƒ•ãƒ©ï¼‰ã€ã‚’å°‘ã—å¼·åŒ–ã™ã‚Œã°ã€å¸‚è²©ã®AIãƒ„ãƒ¼ãƒ«ã‚’å‡Œé§•ã™ã‚‹å¼·åŠ›ãªæ­¦å™¨ã«ãªã‚Šã¾ã™ã€‚"
                }
            ]
        }
    ]
}